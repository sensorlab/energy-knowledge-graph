{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/nilmtk/nilmtk@master\n",
      "  Cloning https://github.com/nilmtk/nilmtk (to revision master) to /tmp/pip-req-build-p5mo8pze\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/nilmtk/nilmtk /tmp/pip-req-build-p5mo8pze\n",
      "  Resolved https://github.com/nilmtk/nilmtk to commit b2c514479cef478cab872cb635056da08d5352a1\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: nilmtk\n",
      "  Building wheel for nilmtk (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nilmtk: filename=nilmtk-0.4.0.dev1+git.b2c5144-py3-none-any.whl size=279177 sha256=29a3eb7362c66a95d828cc4452a2e9d74555c237fc93be0d8f424260cffd71bd\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-x_r_p2jv/wheels/05/a4/8e/b767c3d1714f61fd30ec991c25780be8cc04c474da8205aeee\n",
      "Successfully built nilmtk\n",
      "Installing collected packages: nilmtk\n",
      "Successfully installed nilmtk-0.4.0.dev1+git.b2c5144\n",
      "Collecting git+https://github.com/nilmtk/nilm_metadata@master\n",
      "  Cloning https://github.com/nilmtk/nilm_metadata (to revision master) to /tmp/pip-req-build-2ezg_axv\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/nilmtk/nilm_metadata /tmp/pip-req-build-2ezg_axv\n",
      "  Resolved https://github.com/nilmtk/nilm_metadata to commit 7ed4bab9062d04cb35c6b6000b451715dc5ab4af\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: nilm-metadata\n",
      "  Building wheel for nilm-metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nilm-metadata: filename=nilm_metadata-0.2.5-py3-none-any.whl size=24340 sha256=cfff23acb2d86e7c1debdeb553a96d77caf0729b1101ad51852c9206e97356bb\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-clng963_/wheels/7e/2f/7f/e41975c202542dbc11228875ff8473ed4cb95e04a274222bb7\n",
      "Successfully built nilm-metadata\n",
      "Installing collected packages: nilm-metadata\n",
      "Successfully installed nilm-metadata-0.2.5\n"
     ]
    }
   ],
   "source": [
    "#!rm -r /home/jovyan/.local/share/jupyter/kernels/nilmtk\n",
    "!mamba install tensorflow-gpu==2.10 -y -q\n",
    "#!mamba install tensorflow-gpu==2.11.0 -y -q\n",
    "!pip uninstall -y -q nilmtk nilm_metadata\n",
    "#!pip install -q pandas networkx tables scikit-learn hmmlearn pyyaml matplotlib==3.1.3 xgboost pyts\n",
    "# Trick to install NILM regardless of its dependencies\n",
    "#!pip install --no-cache -U git+https://github.com/nilmtk/nilm_metadata.git\n",
    "#!pip install --no-cache -U git+https://github.com/nilmtk/nilmtk.git@0.4.3\n",
    "!python3 -m pip install --no-deps git+https://github.com/nilmtk/nilmtk@master\n",
    "!python3 -m pip install --no-deps git+https://github.com/nilmtk/nilm_metadata@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-20 06:30:15.414795: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA A100 80GB PCIe MIG 3g.40gb, compute capability 8.0\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from nilmtk import DataSet\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from joblib import Memory\n",
    "import pickle\n",
    "from pprint import pprint\n",
    "\n",
    "#from nilmtk import DataSet\n",
    "import multiprocessing as mp\n",
    "\n",
    "from typing import Dict\n",
    "\n",
    "!pip install -q scikit-learn-intelex\n",
    "#from sklearnex import patch_sklearn\n",
    "#patch_sklearn()\n",
    "\n",
    "from sklearn import pipeline, metrics, linear_model, model_selection, multioutput, tree, ensemble, neural_network\n",
    "!pip install xgboost -q\n",
    "import xgboost as xgb\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import cross_val_predict, train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "import numpy as np\n",
    "#import graphviz\n",
    "import keras\n",
    "from sklearn.utils import class_weight\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#from ann_visualizer.visualize import ann_viz\n",
    "from matplotlib import pyplot as plt \n",
    "from sklearn.metrics import multilabel_confusion_matrix, classification_report, confusion_matrix\n",
    "# GPU goes brrrrrrrrrrrrrrrrrrrr\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "!pip3 install tqdm -q\n",
    "from tqdm import tqdm\n",
    "import NUK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "epochs =25\n",
    "window_size = 2700\n",
    "batch_size = 256\n",
    "NmDevices = 82\n",
    "# table_of_options = [1,2,3,4]\n",
    "k = 0.25\n",
    "# Define a learning rate scheduler function\n",
    "def scheduler(epoch, lr):\n",
    "    return lr\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "test_size = 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_pickle(\"../../Energy_graph/data/processed_all_X_Y_watts.pkl\")\n",
    "data_syn = pd.read_pickle(\"../../Energy_graph/data/training_data/synthetic/synthetic_test_50k_2700.pkl\")\n",
    "labels = pd.read_pickle(\"../../Energy_graph/labeles.pkl\")\n",
    "\n",
    "\n",
    "# Separate the tuples into X and y\n",
    "X_syn = np.array([i[0] for i in data_syn])\n",
    "y_syn = np.array([i[1] for i in data_syn])\n",
    "\n",
    "X = np.array([i[0] for i in data])\n",
    "y = np.array([i[1] for i in data])\n",
    "\n",
    "# y = y.astype(int)\n",
    "\n",
    "X = np.concatenate((X, X_syn), axis=0)\n",
    "y = np.concatenate((y, y_syn), axis=0)\n",
    "\n",
    "# X_test = np.array([i[0] for i in data_test])\n",
    "# y_test = np.array([i[1] for i in data_test])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PC0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train indices: [    0     1     2 ... 97051 97053 97054] Test indices: [    8    39    53 ... 97049 97052 97055]\n",
      "Epoch 1/25\n",
      "304/304 [==============================] - 9s 26ms/step - loss: nan - F1Score: 0.0209 - WeightedF1: 0.0510 - lr: 3.0000e-04\n",
      "Epoch 2/25\n",
      "304/304 [==============================] - 8s 26ms/step - loss: nan - F1Score: 0.0605 - WeightedF1: 0.1250 - lr: 3.0000e-04\n",
      "Epoch 3/25\n",
      "304/304 [==============================] - 8s 26ms/step - loss: nan - F1Score: 0.0931 - WeightedF1: 0.1758 - lr: 3.0000e-04\n",
      "Epoch 4/25\n",
      "304/304 [==============================] - 8s 26ms/step - loss: nan - F1Score: 0.1166 - WeightedF1: 0.2043 - lr: 3.0000e-04\n",
      "Epoch 5/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.1424 - WeightedF1: 0.2347 - lr: 3.0000e-04\n",
      "Epoch 6/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.1747 - WeightedF1: 0.2717 - lr: 3.0000e-04\n",
      "Epoch 7/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.2070 - WeightedF1: 0.3040 - lr: 3.0000e-04\n",
      "Epoch 8/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.2556 - WeightedF1: 0.3510 - lr: 3.0000e-04\n",
      "Epoch 9/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.3358 - WeightedF1: 0.4256 - lr: 3.0000e-04\n",
      "Epoch 10/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.4482 - WeightedF1: 0.5198 - lr: 3.0000e-04\n",
      "Epoch 11/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.5735 - WeightedF1: 0.6222 - lr: 3.0000e-04\n",
      "Epoch 12/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.6690 - WeightedF1: 0.6998 - lr: 3.0000e-04\n",
      "Epoch 13/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.7451 - WeightedF1: 0.7634 - lr: 3.0000e-04\n",
      "Epoch 14/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.7896 - WeightedF1: 0.8006 - lr: 3.0000e-04\n",
      "Epoch 15/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.8191 - WeightedF1: 0.8261 - lr: 3.0000e-04\n",
      "Epoch 16/25\n",
      "304/304 [==============================] - 8s 26ms/step - loss: nan - F1Score: 0.8340 - WeightedF1: 0.8387 - lr: 3.0000e-04\n",
      "Epoch 17/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.8340 - WeightedF1: 0.8375 - lr: 3.0000e-04\n",
      "Epoch 18/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.8417 - WeightedF1: 0.8444 - lr: 3.0000e-04\n",
      "Epoch 19/25\n",
      "304/304 [==============================] - 8s 28ms/step - loss: nan - F1Score: 0.8543 - WeightedF1: 0.8565 - lr: 3.0000e-04\n",
      "Epoch 20/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.8599 - WeightedF1: 0.8618 - lr: 3.0000e-04\n",
      "Epoch 21/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.8550 - WeightedF1: 0.8567 - lr: 3.0000e-04\n",
      "Epoch 22/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.8585 - WeightedF1: 0.8600 - lr: 3.0000e-04\n",
      "Epoch 23/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.8550 - WeightedF1: 0.8562 - lr: 3.0000e-04\n",
      "Epoch 24/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.8633 - WeightedF1: 0.8645 - lr: 3.0000e-04\n",
      "Epoch 25/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.8542 - WeightedF1: 0.8552 - lr: 3.0000e-04\n",
      "607/607 [==============================] - 2s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [03:30, 210.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train indices: [    0     1     2 ... 97053 97054 97055] Test indices: [    4     6     7 ... 97042 97047 97050]\n",
      "Epoch 1/25\n",
      "304/304 [==============================] - 10s 27ms/step - loss: nan - F1Score: 0.0201 - WeightedF1: 0.0482 - lr: 3.0000e-04\n",
      "Epoch 2/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.0597 - WeightedF1: 0.1219 - lr: 3.0000e-04\n",
      "Epoch 3/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.0861 - WeightedF1: 0.1642 - lr: 3.0000e-04\n",
      "Epoch 4/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.1096 - WeightedF1: 0.1954 - lr: 3.0000e-04\n",
      "Epoch 5/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.1338 - WeightedF1: 0.2246 - lr: 3.0000e-04\n",
      "Epoch 6/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.1599 - WeightedF1: 0.2536 - lr: 3.0000e-04\n",
      "Epoch 7/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.1928 - WeightedF1: 0.2879 - lr: 3.0000e-04\n",
      "Epoch 8/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.2356 - WeightedF1: 0.3299 - lr: 3.0000e-04\n",
      "Epoch 9/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.3026 - WeightedF1: 0.3940 - lr: 3.0000e-04\n",
      "Epoch 10/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.4030 - WeightedF1: 0.4815 - lr: 3.0000e-04\n",
      "Epoch 11/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.5230 - WeightedF1: 0.5810 - lr: 3.0000e-04\n",
      "Epoch 12/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.6379 - WeightedF1: 0.6756 - lr: 3.0000e-04\n",
      "Epoch 13/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.7098 - WeightedF1: 0.7337 - lr: 3.0000e-04\n",
      "Epoch 14/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.7755 - WeightedF1: 0.7894 - lr: 3.0000e-04\n",
      "Epoch 15/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.8110 - WeightedF1: 0.8199 - lr: 3.0000e-04\n",
      "Epoch 16/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.8237 - WeightedF1: 0.8295 - lr: 3.0000e-04\n",
      "Epoch 17/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.8400 - WeightedF1: 0.8444 - lr: 3.0000e-04\n",
      "Epoch 18/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.8561 - WeightedF1: 0.8593 - lr: 3.0000e-04\n",
      "Epoch 19/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.8514 - WeightedF1: 0.8539 - lr: 3.0000e-04\n",
      "Epoch 20/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.8569 - WeightedF1: 0.8591 - lr: 3.0000e-04\n",
      "Epoch 21/25\n",
      "304/304 [==============================] - 8s 28ms/step - loss: nan - F1Score: 0.8632 - WeightedF1: 0.8650 - lr: 3.0000e-04\n",
      "Epoch 22/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.8518 - WeightedF1: 0.8541 - lr: 3.0000e-04\n",
      "Epoch 23/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.8658 - WeightedF1: 0.8670 - lr: 3.0000e-04\n",
      "Epoch 24/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.8643 - WeightedF1: 0.8652 - lr: 3.0000e-04\n",
      "Epoch 25/25\n",
      "304/304 [==============================] - 8s 28ms/step - loss: nan - F1Score: 0.8645 - WeightedF1: 0.8656 - lr: 3.0000e-04\n",
      "607/607 [==============================] - 2s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [07:02, 211.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train indices: [    1     2     4 ... 97053 97054 97055] Test indices: [    0     3     9 ... 97039 97044 97048]\n",
      "Epoch 1/25\n",
      "304/304 [==============================] - 9s 27ms/step - loss: nan - F1Score: 0.0200 - WeightedF1: 0.0473 - lr: 3.0000e-04\n",
      "Epoch 2/25\n",
      "304/304 [==============================] - 8s 26ms/step - loss: nan - F1Score: 0.0593 - WeightedF1: 0.1188 - lr: 3.0000e-04\n",
      "Epoch 3/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.0874 - WeightedF1: 0.1640 - lr: 3.0000e-04\n",
      "Epoch 4/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.1103 - WeightedF1: 0.1944 - lr: 3.0000e-04\n",
      "Epoch 5/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.1366 - WeightedF1: 0.2244 - lr: 3.0000e-04\n",
      "Epoch 6/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.1643 - WeightedF1: 0.2550 - lr: 3.0000e-04\n",
      "Epoch 7/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.1989 - WeightedF1: 0.2914 - lr: 3.0000e-04\n",
      "Epoch 8/25\n",
      "304/304 [==============================] - 8s 26ms/step - loss: nan - F1Score: 0.2365 - WeightedF1: 0.3273 - lr: 3.0000e-04\n",
      "Epoch 9/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.2909 - WeightedF1: 0.3777 - lr: 3.0000e-04\n",
      "Epoch 10/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.3715 - WeightedF1: 0.4471 - lr: 3.0000e-04\n",
      "Epoch 11/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.4888 - WeightedF1: 0.5477 - lr: 3.0000e-04\n",
      "Epoch 12/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.6003 - WeightedF1: 0.6398 - lr: 3.0000e-04\n",
      "Epoch 13/25\n",
      "304/304 [==============================] - 8s 26ms/step - loss: nan - F1Score: 0.6868 - WeightedF1: 0.7117 - lr: 3.0000e-04\n",
      "Epoch 14/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.7505 - WeightedF1: 0.7657 - lr: 3.0000e-04\n",
      "Epoch 15/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.7861 - WeightedF1: 0.7955 - lr: 3.0000e-04\n",
      "Epoch 16/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.8048 - WeightedF1: 0.8112 - lr: 3.0000e-04\n",
      "Epoch 17/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.8186 - WeightedF1: 0.8228 - lr: 3.0000e-04\n",
      "Epoch 18/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.8267 - WeightedF1: 0.8299 - lr: 3.0000e-04\n",
      "Epoch 19/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.8416 - WeightedF1: 0.8441 - lr: 3.0000e-04\n",
      "Epoch 20/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.8341 - WeightedF1: 0.8363 - lr: 3.0000e-04\n",
      "Epoch 21/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.7522 - WeightedF1: 0.7620 - lr: 3.0000e-04\n",
      "Epoch 22/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.8209 - WeightedF1: 0.8241 - lr: 3.0000e-04\n",
      "Epoch 23/25\n",
      "304/304 [==============================] - 8s 27ms/step - loss: nan - F1Score: 0.8472 - WeightedF1: 0.8489 - lr: 3.0000e-04\n",
      "Epoch 24/25\n",
      "304/304 [==============================] - 8s 26ms/step - loss: nan - F1Score: 0.8516 - WeightedF1: 0.8526 - lr: 3.0000e-04\n",
      "Epoch 25/25\n",
      "304/304 [==============================] - 8s 26ms/step - loss: nan - F1Score: 0.8457 - WeightedF1: 0.8466 - lr: 3.0000e-04\n",
      "607/607 [==============================] - 2s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [10:32, 210.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train indices: [    0     2     3 ... 97052 97053 97055] Test indices: [    1    10    13 ... 97032 97045 97054]\n",
      "Epoch 1/25\n",
      "304/304 [==============================] - 11s 26ms/step - loss: nan - F1Score: 0.0176 - WeightedF1: 0.0431 - lr: 3.0000e-04\n",
      "Epoch 2/25\n",
      "304/304 [==============================] - 8s 26ms/step - loss: nan - F1Score: 0.0529 - WeightedF1: 0.1104 - lr: 3.0000e-04\n",
      "Epoch 3/25\n",
      "304/304 [==============================] - 8s 26ms/step - loss: nan - F1Score: 0.0829 - WeightedF1: 0.1607 - lr: 3.0000e-04\n",
      "Epoch 4/25\n",
      " 17/304 [>.............................] - ETA: 7s - loss: nan - F1Score: 0.0854 - WeightedF1: 0.1591  "
     ]
    }
   ],
   "source": [
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "evaluation_results = []\n",
    "predictions = []\n",
    "for train_index, test_index in tqdm(kf.split(X)):\n",
    "    print(\"Train indices:\", train_index, \"Test indices:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    model = NUK.PC0(NmDevices, window_size, 'GRU', 128, k)\n",
    "    model.build((len(y_train) + len(y_test), window_size, 1))\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003), loss='binary_crossentropy', metrics=[NUK.F1Score, NUK.WeightedF1Score(NUK.class_weights_tool(y_test))])\n",
    "    lr_scheduler = LearningRateScheduler(scheduler)\n",
    "    callback = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.1,patience=2, min_lr=0.0000002)\n",
    "    # for class weights\n",
    "    # model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, class_weight=class_weights_UKD, callbacks=[lr_scheduler])\n",
    "    # class_weights = NUK.class_weights_tool(y_train)\n",
    "    model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=[lr_scheduler])\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_tf = (y_pred > 0.5)\n",
    "\n",
    "    predictions.append((y_pred_tf, y_test))\n",
    "\n",
    "    # n_labels = y_test.shape[1]\n",
    "    # co_occurrence_matrix = np.zeros((n_labels, n_labels))\n",
    "\n",
    "    # for true, pred in zip(y_test, y_pred_tf):\n",
    "    #     fn_labels = np.where((true == 1) & (pred == 0))[0]  # False negatives\n",
    "    #     fp_labels = np.where((true == 0) & (pred == 1))[0]  # False positives\n",
    "\n",
    "    #     for fn in fn_labels:\n",
    "    #         for fp in fp_labels:\n",
    "    #             co_occurrence_matrix[fn, fp] += 1\n",
    "\n",
    "\n",
    "\n",
    "    report = metrics.classification_report(y_test, y_pred_tf, target_names=labels, zero_division=0, output_dict=True)\n",
    "\n",
    "    # report_DF = NUK.ClassificationReportToDF(report, labels)  \n",
    "    # report_DF.rename(columns={report_DF.columns[0]: \"device\"}, inplace=True)\n",
    "    evaluation_results.append(report)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# save with pickle\n",
    "with open('predictions_50k_mixed.pkl', 'wb') as f:\n",
    "    pickle.dump(predictions, f)\n",
    "\n",
    "# plt.figure(figsize=(20, 20))\n",
    "# sns.heatmap(co_occurrence_matrix, annot=True, fmt='g', cmap='Blues')\n",
    "# plt.xlabel('False Positive Labels')\n",
    "# plt.ylabel('False Negative Labels')\n",
    "# plt.title('Co-occurrence of False Positives and False Negatives')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train indices: [     1      2      3 ... 147053 147054 147055] Test indices: [     0      4     12 ... 147049 147050 147052]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "jobs = 110\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "evaluation_results = []\n",
    "\n",
    "for train_index, test_index in tqdm(kf.split(X)):\n",
    "    print(\"Train indices:\", train_index, \"Test indices:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Initialize the Random Forest classifier wrapped in a MultiOutputClassifier\n",
    "    classifier = RandomForestClassifier(n_estimators=100, random_state=RANDOM_SEED, n_jobs=jobs)\n",
    "    # classifier = MultiOutputClassifier(forest, n_jobs=-1)\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the labels\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    # Evaluate the model using classification report\n",
    "    report = classification_report(y_test, y_pred, target_names=labels, zero_division=0, output_dict=True)\n",
    "\n",
    "    evaluation_results.append(report)\n",
    "\n",
    "\n",
    "for i in range(len(evaluation_results)):\n",
    "    if i == 0:\n",
    "        df = pd.DataFrame(evaluation_results[i]).T\n",
    "    else:\n",
    "        df = df + pd.DataFrame(evaluation_results[i]).T\n",
    "\n",
    "\n",
    "df = df / 5\n",
    "# df.to_csv(f\"../../Energy_graph/data/results/w_size{window_size}_epochs{epochs}_batch_size{batch_size}_k{k}_classes{NmDevices}_staticLR_LSTM_watts_mixed100k.csv\")\n",
    "df.to_csv(f\"../../Energy_graph/data/results/w_size{window_size}_classes{NmDevices}_watts_RF_mixed50k.csv\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_results = []\n",
    "model = NUK.PC0(NmDevices, window_size, 'GRU',128, k)\n",
    "model.build((len(y), window_size, 1))\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003), loss='binary_crossentropy', metrics=[NUK.F1Score, NUK.WeightedF1Score(NUK.class_weights_tool(y_test))])\n",
    "lr_scheduler = LearningRateScheduler(scheduler)\n",
    "\n",
    "model.fit(X, y, batch_size=batch_size, epochs=epochs, callbacks=[lr_scheduler])\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_tf = (y_pred > 0.5)\n",
    "report = metrics.classification_report(y_test, y_pred_tf, target_names=labels, zero_division=0, output_dict=True)\n",
    "\n",
    "# report_DF = NUK.ClassificationReportToDF(report, labels)  \n",
    "# report_DF.rename(columns={report_DF.columns[0]: \"device\"}, inplace=True)\n",
    "df = pd.DataFrame(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(evaluation_results)):\n",
    "    if i == 0:\n",
    "        df = pd.DataFrame(evaluation_results[i]).T\n",
    "    else:\n",
    "        df = df + pd.DataFrame(evaluation_results[i]).T\n",
    "\n",
    "\n",
    "df = df / 5\n",
    "df.to_csv(f\"../../Energy_graph/data/results/w_size{window_size}_epochs{epochs}_batch_size{batch_size}_k{k}_classes{NmDevices}_staticLR_GRU_watts_100k_unmetered.csv\")\n",
    "# df.to_csv(f\"../../Energy_graph/data/results/w_size{window_size}_classes{NmDevices}_watts_RF_mixed50k.csv\")\n",
    "    \n",
    "# evaluation_results+ evaluation_results[1].to_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
