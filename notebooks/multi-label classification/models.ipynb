{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... By downloading and using the CUDA Toolkit conda packages, you accept the terms and conditions of the CUDA End User License Agreement (EULA): https://docs.nvidia.com/cuda/eula/index.html\n",
      "\n",
      "By downloading and using the cuDNN conda packages, you accept the terms and conditions of the NVIDIA cuDNN EULA -\n",
      "  https://docs.nvidia.com/deeplearning/cudnn/sla/index.html\n",
      "\n",
      "done\n",
      "\u001b[33mWARNING: Skipping nilmtk as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping nilm_metadata as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting git+https://github.com/nilmtk/nilmtk@master\n",
      "  Cloning https://github.com/nilmtk/nilmtk (to revision master) to /tmp/pip-req-build-_wtii5xn\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/nilmtk/nilmtk /tmp/pip-req-build-_wtii5xn\n",
      "  Resolved https://github.com/nilmtk/nilmtk to commit b2c514479cef478cab872cb635056da08d5352a1\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: nilmtk\n",
      "  Building wheel for nilmtk (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nilmtk: filename=nilmtk-0.4.0.dev1+git.b2c5144-py3-none-any.whl size=279177 sha256=3ae8edb46e82ebfca9f6a26806c01f7b5991ddcb8922215e3ea072e4dfaac0d8\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-_rg4pzyd/wheels/05/a4/8e/b767c3d1714f61fd30ec991c25780be8cc04c474da8205aeee\n",
      "Successfully built nilmtk\n",
      "Installing collected packages: nilmtk\n",
      "Successfully installed nilmtk-0.4.0.dev1+git.b2c5144\n",
      "Collecting git+https://github.com/nilmtk/nilm_metadata@master\n",
      "  Cloning https://github.com/nilmtk/nilm_metadata (to revision master) to /tmp/pip-req-build-rbc2ztj6\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/nilmtk/nilm_metadata /tmp/pip-req-build-rbc2ztj6\n",
      "  Resolved https://github.com/nilmtk/nilm_metadata to commit 7ed4bab9062d04cb35c6b6000b451715dc5ab4af\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: nilm-metadata\n",
      "  Building wheel for nilm-metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nilm-metadata: filename=nilm_metadata-0.2.5-py3-none-any.whl size=24340 sha256=6860ee7c2818a3351eae684a8cb73f25a8c9d37cfbdf75341abdb0e20f368876\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-xn01_q4a/wheels/7e/2f/7f/e41975c202542dbc11228875ff8473ed4cb95e04a274222bb7\n",
      "Successfully built nilm-metadata\n",
      "Installing collected packages: nilm-metadata\n",
      "Successfully installed nilm-metadata-0.2.5\n"
     ]
    }
   ],
   "source": [
    "#!rm -r /home/jovyan/.local/share/jupyter/kernels/nilmtk\n",
    "!mamba install tensorflow-gpu==2.10 -y -q\n",
    "# !mamba install tensorflow-gpu==2.11.0 -y -q\n",
    "!pip uninstall -y -q nilmtk nilm_metadata\n",
    "#!pip install -q pandas networkx tables scikit-learn hmmlearn pyyaml matplotlib==3.1.3 xgboost pyts\n",
    "# Trick to install NILM regardless of its dependencies\n",
    "#!pip install --no-cache -U git+https://github.com/nilmtk/nilm_metadata.git\n",
    "#!pip install --no-cache -U git+https://github.com/nilmtk/nilmtk.git@0.4.3\n",
    "!python3 -m pip install --no-deps git+https://github.com/nilmtk/nilmtk@master\n",
    "!python3 -m pip install --no-deps git+https://github.com/nilmtk/nilm_metadata@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-03 08:23:20.213259: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA A100 80GB PCIe MIG 3g.40gb, compute capability 8.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# from nilmtk import DataSet\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from joblib import Memory\n",
    "import pickle\n",
    "from pprint import pprint\n",
    "\n",
    "#from nilmtk import DataSet\n",
    "import multiprocessing as mp\n",
    "\n",
    "from typing import Dict\n",
    "\n",
    "!pip install -q scikit-learn-intelex\n",
    "#from sklearnex import patch_sklearn\n",
    "#patch_sklearn()\n",
    "\n",
    "from sklearn import pipeline, metrics, linear_model, model_selection, multioutput, tree, ensemble, neural_network\n",
    "!pip install xgboost -q\n",
    "import xgboost as xgb\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import cross_val_predict, train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "import numpy as np\n",
    "#import graphviz\n",
    "import keras\n",
    "from sklearn.utils import class_weight\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#from ann_visualizer.visualize import ann_viz\n",
    "from matplotlib import pyplot as plt \n",
    "from sklearn.metrics import multilabel_confusion_matrix, classification_report, confusion_matrix\n",
    "# GPU goes brrrrrrrrrrrrrrrrrrrr\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_bfloat16') # bfloat16\n",
    "\n",
    "!pip3 install tqdm -q\n",
    "from tqdm.notebook import tqdm\n",
    "import NUK\n",
    "\n",
    "# import garbage collector\n",
    "import gc\n",
    "import time\n",
    "\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if physical_devices:\n",
    "    print(physical_devices)\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "else:\n",
    "    print(\"No GPU found, model will train on CPU.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "epochs =1200\n",
    "window_size = 2688\n",
    "batch_size = 128\n",
    "NmDevices = 64\n",
    "# table_of_options = [1,2,3,4]\n",
    "k = 0.125\n",
    "# Define a learning rate scheduler function\n",
    "# def scheduler(epoch, lr):\n",
    "#     return lr\n",
    "#     if epoch == 0 or epoch == 1:\n",
    "#         return lr\n",
    "#     if epoch == 35:\n",
    "#         return lr *0.5\n",
    "#     else:\n",
    "#         return lr\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "test_size = 0.2\n",
    "lambda_l2=0\n",
    "function = \"GRU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "# data= pd.read_pickle(\"../../Energy_graph/data/training_data/synthetic/X_Y_wsize2688_numW_50000_upper32_gap3600_numD64_ideal.pkl\")\n",
    "data= pd.read_pickle(\"../Energy_graph_data/X_Y_wsize2688_numW_100000_upper32_gap3600_numD64_ideal.pkl\")\n",
    "\n",
    "labels = pd.read_pickle(\"../../Energy_graph/data/labels_new.pkl\")\n",
    "\n",
    "\n",
    "NmDevices = len(labels)\n",
    "\n",
    "X = np.array([i[0] for i in data])\n",
    "y = np.array([i[1] for i in data])\n",
    "\n",
    "\n",
    "\n",
    "# T/F to 1/0\n",
    "y = y.astype(int)\n",
    "\n",
    "\n",
    "\n",
    "# min-max normalization Xmin=0 \n",
    "def normalize(X):\n",
    "    max_value = 0\n",
    "\n",
    "    for x in X:\n",
    "        v = np.max(x)\n",
    "        if v > max_value:\n",
    "            max_value = v\n",
    "\n",
    "    if max_value == 0:\n",
    "        return X\n",
    "    return X / max_value\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InceptionTime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InceptionTime class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK INCEPTION TIME IMPLEMENTATION \n",
    "\n",
    "\n",
    "class_weighs_pre = NUK.class_weights_tool(y)\n",
    "\n",
    "class Classifier_INCEPTION:\n",
    "\n",
    "    def __init__(self, output_directory, input_shape, nb_classes, iteration, verbose=False, build=True, batch_size=64,\n",
    "                 nb_filters=32, use_residual=True, use_bottleneck=True, depth=6, kernel_size=41, nb_epochs=1500, lr=0.001):\n",
    "\n",
    "        self.output_directory = output_directory\n",
    "\n",
    "        self.nb_filters = nb_filters\n",
    "        self.use_residual = use_residual\n",
    "        self.use_bottleneck = use_bottleneck\n",
    "        self.depth = depth\n",
    "        self.kernel_size = kernel_size - 1\n",
    "        self.callbacks = None\n",
    "        self.batch_size = batch_size\n",
    "        self.bottleneck_size = 32\n",
    "        self.nb_epochs = nb_epochs\n",
    "        self.lr = lr\n",
    "        self.iteration = iteration\n",
    "\n",
    "        if build == True:\n",
    "            self.model = self.build_model(input_shape, nb_classes)\n",
    "            self.verbose = verbose\n",
    "            self.model.save_weights(self.output_directory + 'model_init.hdf5')\n",
    "\n",
    "    def _inception_module(self, input_tensor, stride=1, activation='linear'):\n",
    "\n",
    "        if self.use_bottleneck and int(input_tensor.shape[-1]) > 1:\n",
    "            input_inception = keras.layers.Conv1D(filters=self.bottleneck_size, kernel_size=1,\n",
    "                                                  padding='same', activation=activation, use_bias=False)(input_tensor)\n",
    "        else:\n",
    "            input_inception = input_tensor\n",
    "\n",
    "        \n",
    "        kernel_size_s = [self.kernel_size // (2 ** i) for i in range(3)]\n",
    "\n",
    "        conv_list = []\n",
    "\n",
    "        for i in range(len(kernel_size_s)):\n",
    "            conv_list.append(keras.layers.Conv1D(filters=self.nb_filters, kernel_size=kernel_size_s[i],\n",
    "                                                 strides=stride, padding='same', activation=activation, use_bias=False)(\n",
    "                input_inception))\n",
    "\n",
    "        max_pool_1 = keras.layers.MaxPool1D(pool_size=3, strides=stride, padding='same')(input_tensor)\n",
    "\n",
    "        conv_6 = keras.layers.Conv1D(filters=self.nb_filters, kernel_size=1,\n",
    "                                     padding='same', activation=activation, use_bias=False)(max_pool_1)\n",
    "\n",
    "        conv_list.append(conv_6)\n",
    "\n",
    "        x = keras.layers.Concatenate(axis=2)(conv_list)\n",
    "        x = keras.layers.BatchNormalization()(x)\n",
    "        x = keras.layers.Activation(activation='relu')(x)\n",
    "        return x\n",
    "\n",
    "    def _shortcut_layer(self, input_tensor, out_tensor):\n",
    "        shortcut_y = keras.layers.Conv1D(filters=int(out_tensor.shape[-1]), kernel_size=1,\n",
    "                                         padding='same', use_bias=False)(input_tensor)\n",
    "        shortcut_y = keras.layers.BatchNormalization()(shortcut_y)\n",
    "\n",
    "        x = keras.layers.Add()([shortcut_y, out_tensor])\n",
    "        x = keras.layers.Activation('relu')(x)\n",
    "        return x\n",
    "\n",
    "    def build_model(self, input_shape, nb_classes):\n",
    "        input_layer = keras.layers.Input(input_shape)\n",
    "\n",
    "        x = input_layer\n",
    "        input_res = input_layer\n",
    "\n",
    "        for d in range(self.depth):\n",
    "\n",
    "            x = self._inception_module(x)\n",
    "\n",
    "            if self.use_residual and d % 3 == 2:\n",
    "                x = self._shortcut_layer(input_res, x)\n",
    "                input_res = x\n",
    "\n",
    "        gap_layer = keras.layers.GlobalAveragePooling1D()(x)\n",
    "\n",
    "        output_layer = keras.layers.Dense(nb_classes, activation='sigmoid')(gap_layer)\n",
    "\n",
    "        model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "        # cross entropy loss ?\n",
    "        model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=self.lr),\n",
    "                      metrics=['accuracy', NUK.F1Score, NUK.WeightedF1Score(class_weighs_pre)])\n",
    "\n",
    "        # callbacks\n",
    "        reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.25, patience=7, min_lr=0.0001)\n",
    "        early_stopping = keras.callbacks.EarlyStopping(patience=9, restore_best_weights=True, monitor='loss')\n",
    "\n",
    "        file_path = self.output_directory + f'best_model_{self.iteration}.hdf5'\n",
    "\n",
    "        model_checkpoint = keras.callbacks.ModelCheckpoint(filepath=file_path, monitor='loss',\n",
    "                                                           save_best_only=True)\n",
    "        self.callbacks = [reduce_lr, model_checkpoint, early_stopping]\n",
    "\n",
    "        return model\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "       \n",
    "\n",
    "        if self.batch_size is None:\n",
    "            mini_batch_size = int(min(x_train.shape[0] / 10, 16))\n",
    "        else:\n",
    "            mini_batch_size = self.batch_size\n",
    "\n",
    "        self.model.fit(x_train, y_train, batch_size=mini_batch_size, epochs=self.nb_epochs,\n",
    "                                  verbose=self.verbose, callbacks=self.callbacks, validation_split=0.1)\n",
    "\n",
    "\n",
    "        self.model.save(self.output_directory + f'last_model_{self.iteration}.hdf5')\n",
    "\n",
    "        keras.backend.clear_session()\n",
    "\n",
    "        return None\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        model_path = self.output_directory + f'last_model_{self.iteration}.hdf5'\n",
    "        model = keras.models.load_model(model_path, custom_objects={'F1Score': NUK.F1Score, \"WeightedF1\": NUK.WeightedF1Score(class_weighs_pre)})\n",
    "        y_pred = model.predict(x_test, batch_size=self.batch_size)\n",
    "\n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "evaluation_results = []\n",
    "predictions = []\n",
    "class_weights_all = NUK.class_weights_tool(y)\n",
    "itr = 0\n",
    "for train_index, test_index in tqdm(kf.split(X)):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    X_train = normalize(X_train)\n",
    "    X_test = normalize(X_test)\n",
    "    print(batch_size, epochs)\n",
    "    model = Classifier_INCEPTION(output_directory=\"./models/\", input_shape=(window_size, 1), nb_classes=78, verbose=True, build=True, batch_size=batch_size, nb_epochs=epochs, lr=0.001, depth=6)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_tf = (y_pred > 0.5)\n",
    "\n",
    "    predictions.append((y_pred_tf, y_test, y_pred))\n",
    "    t = (y_pred_tf, y_test, y_pred)\n",
    "    with open(f\"./predictions/test_inception_pickle_{itr}.pkl\", 'wb') as f:\n",
    "        pickle.dump(t, f)\n",
    "\n",
    "    itr += 1\n",
    "    report = metrics.classification_report(y_test, y_pred_tf, target_names=labels, zero_division=0, output_dict=True)\n",
    "    print(report[\"weighted avg\"])\n",
    "    evaluation_results.append(report)\n",
    "    gc.collect()\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "for i in range(len(evaluation_results)):\n",
    "    if i == 0:\n",
    "        df = pd.DataFrame(evaluation_results[i]).T\n",
    "    else:\n",
    "        df = df + pd.DataFrame(evaluation_results[i]).T\n",
    "\n",
    "\n",
    "df = df / 5\n",
    "import os\n",
    "# check if directory exsits\n",
    "if not os.path.exists(f\"../../Energy_graph/data/results/{window_size}\"):\n",
    "    os.makedirs(f\"../../Energy_graph/data/results/{window_size}\")\n",
    "if lambda_l2 == 0:\n",
    "    df.to_csv(f\"../../Energy_graph/data/results/{window_size}/Inception_epochs{epochs}_batch_size{batch_size}_k{k}_classes{NmDevices}_{function}_watts_syn.csv\")\n",
    "else:\n",
    "    df.to_csv(f\"../../Energy_graph/data/results/w_size{window_size}_epochs{epochs}_batch_size{batch_size}_k{k}_classes{NmDevices}_{function}_watts_syn_reg{lambda_l2}.csv\")\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_splits = 3\n",
    "treshold = 0.3\n",
    "kf = KFold(n_splits=num_splits, shuffle=True, random_state=RANDOM_SEED)\n",
    "evaluation_results = []\n",
    "predictions = []\n",
    "class_weights_all = NUK.class_weights_tool(y)\n",
    "for fold,(train_index, test_index) in tqdm(enumerate(kf.split(X))):\n",
    "    # print(\"Train indices:\", train_index, \"Test indices:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # normalization\n",
    "    X_train = normalize(X_train)\n",
    "    X_test = normalize(X_test)\n",
    "    model_predictions = []\n",
    "\n",
    "    print(batch_size, epochs)\n",
    "    # train ensemble of 5 models\n",
    "    for i in range(5):\n",
    "\n",
    "        model = Classifier_INCEPTION(output_directory=f\"./models/{fold}/\", input_shape=(window_size, 1), nb_classes=78, verbose=True, build=True, batch_size=batch_size, nb_epochs=epochs, lr=0.001, depth=8, iteration=i)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate the model\n",
    "        y_pred = model.predict(X_test)\n",
    "        model_predictions.append(y_pred)\n",
    "\n",
    "    # average the predictions of the 5 models\n",
    "    y_pred = np.mean(model_predictions, axis=0)\n",
    "    y_pred_tf = (y_pred > treshold)\n",
    "\n",
    "    predictions.append((y_pred_tf, y_test, y_pred))\n",
    "    t = (y_pred_tf, y_test, y_pred)\n",
    "    with open(f\"./predictions/test_inception_pickle_{fold}.pkl\", 'wb') as f:\n",
    "        pickle.dump(t, f)\n",
    "\n",
    "    report = metrics.classification_report(y_test, y_pred_tf, target_names=labels, zero_division=0, output_dict=True)\n",
    "    print(report[\"weighted avg\"])\n",
    "    \n",
    "    evaluation_results.append(report)\n",
    "    gc.collect()\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "for i in range(len(evaluation_results)):\n",
    "    if i == 0:\n",
    "        df = pd.DataFrame(evaluation_results[i]).T\n",
    "    else:\n",
    "        df = df + pd.DataFrame(evaluation_results[i]).T\n",
    "\n",
    "\n",
    "df = df / num_splits\n",
    "import os\n",
    "# check if directory exsits\n",
    "if not os.path.exists(f\"../../Energy_graph/data/results/{window_size}\"):\n",
    "    os.makedirs(f\"../../Energy_graph/data/results/{window_size}\")\n",
    "if lambda_l2 == 0:\n",
    "    df.to_csv(f\"../../Energy_graph/data/results/{window_size}/NNE_epochs{epochs}_batch_size{batch_size}_k{k}_classes{NmDevices}_{function}_watts_syn_3fold.csv\")\n",
    "else:\n",
    "    df.to_csv(f\"../../Energy_graph/data/results/w_size{window_size}_epochs{epochs}_batch_size{batch_size}_k{k}_classes{NmDevices}_{function}_watts_syn_reg{lambda_l2}.csv\")\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 80/20 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 1200\n",
      "Epoch 1/1200\n",
      "563/563 [==============================] - 204s 355ms/step - loss: 0.3595 - accuracy: 0.0551 - F1Score: 0.0380 - WeightedF1: 0.0387 - val_loss: 0.3762 - val_accuracy: 0.0126 - val_F1Score: 0.0226 - val_WeightedF1: 0.0229 - lr: 0.0010\n",
      "Epoch 2/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.3283 - accuracy: 0.1077 - F1Score: 0.1283 - WeightedF1: 0.1301 - val_loss: 0.3450 - val_accuracy: 0.0834 - val_F1Score: 0.1427 - val_WeightedF1: 0.1447 - lr: 0.0010\n",
      "Epoch 3/1200\n",
      "563/563 [==============================] - 198s 352ms/step - loss: 0.3100 - accuracy: 0.1207 - F1Score: 0.2067 - WeightedF1: 0.2094 - val_loss: 0.3788 - val_accuracy: 0.0943 - val_F1Score: 0.1892 - val_WeightedF1: 0.1917 - lr: 0.0010\n",
      "Epoch 4/1200\n",
      "563/563 [==============================] - 198s 352ms/step - loss: 0.2956 - accuracy: 0.1246 - F1Score: 0.2629 - WeightedF1: 0.2662 - val_loss: 0.3022 - val_accuracy: 0.1019 - val_F1Score: 0.2669 - val_WeightedF1: 0.2702 - lr: 0.0010\n",
      "Epoch 5/1200\n",
      "563/563 [==============================] - 198s 352ms/step - loss: 0.2846 - accuracy: 0.1266 - F1Score: 0.3043 - WeightedF1: 0.3080 - val_loss: 0.2861 - val_accuracy: 0.1123 - val_F1Score: 0.3164 - val_WeightedF1: 0.3202 - lr: 0.0010\n",
      "Epoch 6/1200\n",
      "563/563 [==============================] - 200s 355ms/step - loss: 0.2760 - accuracy: 0.1288 - F1Score: 0.3375 - WeightedF1: 0.3416 - val_loss: 0.2921 - val_accuracy: 0.1184 - val_F1Score: 0.3193 - val_WeightedF1: 0.3233 - lr: 0.0010\n",
      "Epoch 7/1200\n",
      "563/563 [==============================] - 201s 356ms/step - loss: 0.2695 - accuracy: 0.1316 - F1Score: 0.3603 - WeightedF1: 0.3647 - val_loss: 0.2815 - val_accuracy: 0.1120 - val_F1Score: 0.3275 - val_WeightedF1: 0.3314 - lr: 0.0010\n",
      "Epoch 8/1200\n",
      "563/563 [==============================] - 201s 356ms/step - loss: 0.2635 - accuracy: 0.1332 - F1Score: 0.3817 - WeightedF1: 0.3863 - val_loss: 0.2892 - val_accuracy: 0.1069 - val_F1Score: 0.3469 - val_WeightedF1: 0.3513 - lr: 0.0010\n",
      "Epoch 9/1200\n",
      "563/563 [==============================] - 200s 355ms/step - loss: 0.2584 - accuracy: 0.1349 - F1Score: 0.4005 - WeightedF1: 0.4051 - val_loss: 0.2895 - val_accuracy: 0.1151 - val_F1Score: 0.3674 - val_WeightedF1: 0.3714 - lr: 0.0010\n",
      "Epoch 10/1200\n",
      "563/563 [==============================] - 200s 354ms/step - loss: 0.2542 - accuracy: 0.1366 - F1Score: 0.4157 - WeightedF1: 0.4205 - val_loss: 0.2666 - val_accuracy: 0.1135 - val_F1Score: 0.3995 - val_WeightedF1: 0.4037 - lr: 0.0010\n",
      "Epoch 11/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.2506 - accuracy: 0.1392 - F1Score: 0.4281 - WeightedF1: 0.4330 - val_loss: 0.2770 - val_accuracy: 0.0955 - val_F1Score: 0.3950 - val_WeightedF1: 0.3993 - lr: 0.0010\n",
      "Epoch 12/1200\n",
      "563/563 [==============================] - 200s 355ms/step - loss: 0.2470 - accuracy: 0.1402 - F1Score: 0.4388 - WeightedF1: 0.4437 - val_loss: 0.2597 - val_accuracy: 0.1328 - val_F1Score: 0.4051 - val_WeightedF1: 0.4094 - lr: 0.0010\n",
      "Epoch 13/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.2439 - accuracy: 0.1413 - F1Score: 0.4472 - WeightedF1: 0.4522 - val_loss: 0.2987 - val_accuracy: 0.1211 - val_F1Score: 0.3905 - val_WeightedF1: 0.3945 - lr: 0.0010\n",
      "Epoch 14/1200\n",
      "563/563 [==============================] - 200s 354ms/step - loss: 0.2415 - accuracy: 0.1441 - F1Score: 0.4538 - WeightedF1: 0.4589 - val_loss: 0.2628 - val_accuracy: 0.1294 - val_F1Score: 0.4292 - val_WeightedF1: 0.4339 - lr: 0.0010\n",
      "Epoch 15/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.2391 - accuracy: 0.1458 - F1Score: 0.4599 - WeightedF1: 0.4651 - val_loss: 0.2922 - val_accuracy: 0.1050 - val_F1Score: 0.3958 - val_WeightedF1: 0.4001 - lr: 0.0010\n",
      "Epoch 16/1200\n",
      "563/563 [==============================] - 200s 355ms/step - loss: 0.2368 - accuracy: 0.1473 - F1Score: 0.4658 - WeightedF1: 0.4710 - val_loss: 0.2515 - val_accuracy: 0.1420 - val_F1Score: 0.4374 - val_WeightedF1: 0.4421 - lr: 0.0010\n",
      "Epoch 17/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.2345 - accuracy: 0.1483 - F1Score: 0.4721 - WeightedF1: 0.4774 - val_loss: 0.2955 - val_accuracy: 0.1246 - val_F1Score: 0.4188 - val_WeightedF1: 0.4232 - lr: 0.0010\n",
      "Epoch 18/1200\n",
      "563/563 [==============================] - 200s 355ms/step - loss: 0.2329 - accuracy: 0.1499 - F1Score: 0.4767 - WeightedF1: 0.4820 - val_loss: 0.2612 - val_accuracy: 0.1435 - val_F1Score: 0.4332 - val_WeightedF1: 0.4378 - lr: 0.0010\n",
      "Epoch 19/1200\n",
      "563/563 [==============================] - 200s 355ms/step - loss: 0.2310 - accuracy: 0.1527 - F1Score: 0.4823 - WeightedF1: 0.4876 - val_loss: 0.2806 - val_accuracy: 0.1332 - val_F1Score: 0.4365 - val_WeightedF1: 0.4409 - lr: 0.0010\n",
      "Epoch 20/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.2291 - accuracy: 0.1537 - F1Score: 0.4866 - WeightedF1: 0.4919 - val_loss: 0.2852 - val_accuracy: 0.1330 - val_F1Score: 0.4418 - val_WeightedF1: 0.4463 - lr: 0.0010\n",
      "Epoch 21/1200\n",
      "563/563 [==============================] - 200s 354ms/step - loss: 0.2275 - accuracy: 0.1554 - F1Score: 0.4921 - WeightedF1: 0.4975 - val_loss: 0.3044 - val_accuracy: 0.1182 - val_F1Score: 0.4332 - val_WeightedF1: 0.4375 - lr: 0.0010\n",
      "Epoch 22/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.2261 - accuracy: 0.1566 - F1Score: 0.4966 - WeightedF1: 0.5019 - val_loss: 0.2551 - val_accuracy: 0.1434 - val_F1Score: 0.4674 - val_WeightedF1: 0.4723 - lr: 0.0010\n",
      "Epoch 23/1200\n",
      "563/563 [==============================] - 200s 354ms/step - loss: 0.2244 - accuracy: 0.1594 - F1Score: 0.5014 - WeightedF1: 0.5068 - val_loss: 0.2684 - val_accuracy: 0.1476 - val_F1Score: 0.4570 - val_WeightedF1: 0.4620 - lr: 0.0010\n",
      "Epoch 24/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.2230 - accuracy: 0.1587 - F1Score: 0.5057 - WeightedF1: 0.5110 - val_loss: 0.2621 - val_accuracy: 0.1484 - val_F1Score: 0.4766 - val_WeightedF1: 0.4810 - lr: 0.0010\n",
      "Epoch 25/1200\n",
      "563/563 [==============================] - 200s 355ms/step - loss: 0.2216 - accuracy: 0.1619 - F1Score: 0.5101 - WeightedF1: 0.5154 - val_loss: 0.2897 - val_accuracy: 0.1274 - val_F1Score: 0.4588 - val_WeightedF1: 0.4634 - lr: 0.0010\n",
      "Epoch 26/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.2202 - accuracy: 0.1631 - F1Score: 0.5134 - WeightedF1: 0.5187 - val_loss: 0.2805 - val_accuracy: 0.1214 - val_F1Score: 0.4615 - val_WeightedF1: 0.4659 - lr: 0.0010\n",
      "Epoch 27/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.2192 - accuracy: 0.1648 - F1Score: 0.5167 - WeightedF1: 0.5220 - val_loss: 0.2443 - val_accuracy: 0.1262 - val_F1Score: 0.4808 - val_WeightedF1: 0.4857 - lr: 0.0010\n",
      "Epoch 28/1200\n",
      "563/563 [==============================] - 199s 353ms/step - loss: 0.2178 - accuracy: 0.1653 - F1Score: 0.5208 - WeightedF1: 0.5260 - val_loss: 0.3101 - val_accuracy: 0.1410 - val_F1Score: 0.4476 - val_WeightedF1: 0.4518 - lr: 0.0010\n",
      "Epoch 29/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.2168 - accuracy: 0.1675 - F1Score: 0.5235 - WeightedF1: 0.5287 - val_loss: 0.3079 - val_accuracy: 0.1103 - val_F1Score: 0.4507 - val_WeightedF1: 0.4553 - lr: 0.0010\n",
      "Epoch 30/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.2155 - accuracy: 0.1677 - F1Score: 0.5274 - WeightedF1: 0.5326 - val_loss: 0.3005 - val_accuracy: 0.1281 - val_F1Score: 0.4435 - val_WeightedF1: 0.4475 - lr: 0.0010\n",
      "Epoch 31/1200\n",
      "563/563 [==============================] - 199s 353ms/step - loss: 0.2142 - accuracy: 0.1701 - F1Score: 0.5308 - WeightedF1: 0.5359 - val_loss: 0.2524 - val_accuracy: 0.1555 - val_F1Score: 0.4813 - val_WeightedF1: 0.4858 - lr: 0.0010\n",
      "Epoch 32/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.2130 - accuracy: 0.1727 - F1Score: 0.5345 - WeightedF1: 0.5395 - val_loss: 0.2394 - val_accuracy: 0.1417 - val_F1Score: 0.4899 - val_WeightedF1: 0.4950 - lr: 0.0010\n",
      "Epoch 33/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.2118 - accuracy: 0.1734 - F1Score: 0.5378 - WeightedF1: 0.5428 - val_loss: 0.2396 - val_accuracy: 0.1695 - val_F1Score: 0.5035 - val_WeightedF1: 0.5081 - lr: 0.0010\n",
      "Epoch 34/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.2112 - accuracy: 0.1745 - F1Score: 0.5399 - WeightedF1: 0.5449 - val_loss: 0.2854 - val_accuracy: 0.1733 - val_F1Score: 0.4743 - val_WeightedF1: 0.4786 - lr: 0.0010\n",
      "Epoch 35/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.2099 - accuracy: 0.1739 - F1Score: 0.5432 - WeightedF1: 0.5482 - val_loss: 0.2544 - val_accuracy: 0.1813 - val_F1Score: 0.4805 - val_WeightedF1: 0.4850 - lr: 0.0010\n",
      "Epoch 36/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.2086 - accuracy: 0.1774 - F1Score: 0.5469 - WeightedF1: 0.5517 - val_loss: 0.3143 - val_accuracy: 0.1663 - val_F1Score: 0.4890 - val_WeightedF1: 0.4938 - lr: 0.0010\n",
      "Epoch 37/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.2079 - accuracy: 0.1779 - F1Score: 0.5488 - WeightedF1: 0.5536 - val_loss: 0.2723 - val_accuracy: 0.1626 - val_F1Score: 0.4755 - val_WeightedF1: 0.4799 - lr: 0.0010\n",
      "Epoch 38/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.2067 - accuracy: 0.1804 - F1Score: 0.5526 - WeightedF1: 0.5573 - val_loss: 0.2457 - val_accuracy: 0.1730 - val_F1Score: 0.5046 - val_WeightedF1: 0.5089 - lr: 0.0010\n",
      "Epoch 39/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.2059 - accuracy: 0.1803 - F1Score: 0.5552 - WeightedF1: 0.5599 - val_loss: 0.2417 - val_accuracy: 0.2050 - val_F1Score: 0.5184 - val_WeightedF1: 0.5227 - lr: 0.0010\n",
      "Epoch 40/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.2050 - accuracy: 0.1813 - F1Score: 0.5576 - WeightedF1: 0.5623 - val_loss: 0.3897 - val_accuracy: 0.1326 - val_F1Score: 0.4388 - val_WeightedF1: 0.4429 - lr: 0.0010\n",
      "Epoch 41/1200\n",
      "563/563 [==============================] - 199s 353ms/step - loss: 0.2040 - accuracy: 0.1835 - F1Score: 0.5598 - WeightedF1: 0.5644 - val_loss: 0.3061 - val_accuracy: 0.1396 - val_F1Score: 0.4555 - val_WeightedF1: 0.4598 - lr: 0.0010\n",
      "Epoch 42/1200\n",
      "563/563 [==============================] - 199s 353ms/step - loss: 0.2032 - accuracy: 0.1865 - F1Score: 0.5622 - WeightedF1: 0.5668 - val_loss: 0.2631 - val_accuracy: 0.1469 - val_F1Score: 0.4907 - val_WeightedF1: 0.4950 - lr: 0.0010\n",
      "Epoch 43/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.2023 - accuracy: 0.1868 - F1Score: 0.5649 - WeightedF1: 0.5694 - val_loss: 0.2598 - val_accuracy: 0.1852 - val_F1Score: 0.5135 - val_WeightedF1: 0.5175 - lr: 0.0010\n",
      "Epoch 44/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.2016 - accuracy: 0.1863 - F1Score: 0.5672 - WeightedF1: 0.5717 - val_loss: 0.2538 - val_accuracy: 0.1776 - val_F1Score: 0.5018 - val_WeightedF1: 0.5054 - lr: 0.0010\n",
      "Epoch 45/1200\n",
      "563/563 [==============================] - 199s 353ms/step - loss: 0.2005 - accuracy: 0.1876 - F1Score: 0.5697 - WeightedF1: 0.5742 - val_loss: 0.2714 - val_accuracy: 0.1566 - val_F1Score: 0.4788 - val_WeightedF1: 0.4829 - lr: 0.0010\n",
      "Epoch 46/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.1996 - accuracy: 0.1894 - F1Score: 0.5726 - WeightedF1: 0.5770 - val_loss: 0.2714 - val_accuracy: 0.1636 - val_F1Score: 0.4759 - val_WeightedF1: 0.4803 - lr: 0.0010\n",
      "Epoch 47/1200\n",
      "563/563 [==============================] - 200s 355ms/step - loss: 0.1989 - accuracy: 0.1912 - F1Score: 0.5737 - WeightedF1: 0.5781 - val_loss: 0.2609 - val_accuracy: 0.1416 - val_F1Score: 0.4880 - val_WeightedF1: 0.4914 - lr: 0.0010\n",
      "Epoch 48/1200\n",
      "563/563 [==============================] - 200s 355ms/step - loss: 0.1981 - accuracy: 0.1930 - F1Score: 0.5765 - WeightedF1: 0.5809 - val_loss: 0.3445 - val_accuracy: 0.1415 - val_F1Score: 0.4879 - val_WeightedF1: 0.4913 - lr: 0.0010\n",
      "Epoch 49/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.1971 - accuracy: 0.1956 - F1Score: 0.5787 - WeightedF1: 0.5831 - val_loss: 0.2722 - val_accuracy: 0.1550 - val_F1Score: 0.4994 - val_WeightedF1: 0.5037 - lr: 0.0010\n",
      "Epoch 50/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.1962 - accuracy: 0.1974 - F1Score: 0.5813 - WeightedF1: 0.5857 - val_loss: 0.2330 - val_accuracy: 0.2011 - val_F1Score: 0.5332 - val_WeightedF1: 0.5374 - lr: 0.0010\n",
      "Epoch 51/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.1958 - accuracy: 0.1962 - F1Score: 0.5823 - WeightedF1: 0.5867 - val_loss: 0.2674 - val_accuracy: 0.1701 - val_F1Score: 0.4982 - val_WeightedF1: 0.5024 - lr: 0.0010\n",
      "Epoch 52/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.1949 - accuracy: 0.1962 - F1Score: 0.5844 - WeightedF1: 0.5888 - val_loss: 0.2318 - val_accuracy: 0.1845 - val_F1Score: 0.5330 - val_WeightedF1: 0.5366 - lr: 0.0010\n",
      "Epoch 53/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.1944 - accuracy: 0.1952 - F1Score: 0.5860 - WeightedF1: 0.5903 - val_loss: 0.3186 - val_accuracy: 0.1468 - val_F1Score: 0.4896 - val_WeightedF1: 0.4928 - lr: 0.0010\n",
      "Epoch 54/1200\n",
      "563/563 [==============================] - 199s 353ms/step - loss: 0.1932 - accuracy: 0.2017 - F1Score: 0.5886 - WeightedF1: 0.5930 - val_loss: 0.2473 - val_accuracy: 0.1595 - val_F1Score: 0.5061 - val_WeightedF1: 0.5099 - lr: 0.0010\n",
      "Epoch 55/1200\n",
      "563/563 [==============================] - 199s 353ms/step - loss: 0.1926 - accuracy: 0.2012 - F1Score: 0.5904 - WeightedF1: 0.5947 - val_loss: 0.2438 - val_accuracy: 0.1715 - val_F1Score: 0.5225 - val_WeightedF1: 0.5258 - lr: 0.0010\n",
      "Epoch 56/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.1921 - accuracy: 0.2031 - F1Score: 0.5918 - WeightedF1: 0.5961 - val_loss: 0.2796 - val_accuracy: 0.1797 - val_F1Score: 0.4905 - val_WeightedF1: 0.4944 - lr: 0.0010\n",
      "Epoch 57/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.1912 - accuracy: 0.2061 - F1Score: 0.5940 - WeightedF1: 0.5983 - val_loss: 0.2570 - val_accuracy: 0.1979 - val_F1Score: 0.5103 - val_WeightedF1: 0.5140 - lr: 0.0010\n",
      "Epoch 58/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.1901 - accuracy: 0.2033 - F1Score: 0.5961 - WeightedF1: 0.6003 - val_loss: 0.3168 - val_accuracy: 0.1775 - val_F1Score: 0.4802 - val_WeightedF1: 0.4840 - lr: 0.0010\n",
      "Epoch 59/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.1898 - accuracy: 0.2060 - F1Score: 0.5974 - WeightedF1: 0.6017 - val_loss: 0.2946 - val_accuracy: 0.1918 - val_F1Score: 0.5121 - val_WeightedF1: 0.5157 - lr: 0.0010\n",
      "Epoch 60/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.1890 - accuracy: 0.2068 - F1Score: 0.5992 - WeightedF1: 0.6035 - val_loss: 0.2708 - val_accuracy: 0.1805 - val_F1Score: 0.5077 - val_WeightedF1: 0.5110 - lr: 0.0010\n",
      "Epoch 61/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.1887 - accuracy: 0.2085 - F1Score: 0.6002 - WeightedF1: 0.6045 - val_loss: 0.3194 - val_accuracy: 0.1739 - val_F1Score: 0.4996 - val_WeightedF1: 0.5033 - lr: 0.0010\n",
      "Epoch 62/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.1875 - accuracy: 0.2079 - F1Score: 0.6028 - WeightedF1: 0.6070 - val_loss: 0.3288 - val_accuracy: 0.1676 - val_F1Score: 0.4850 - val_WeightedF1: 0.4887 - lr: 0.0010\n",
      "Epoch 63/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.1869 - accuracy: 0.2106 - F1Score: 0.6036 - WeightedF1: 0.6079 - val_loss: 0.3187 - val_accuracy: 0.1661 - val_F1Score: 0.5136 - val_WeightedF1: 0.5172 - lr: 0.0010\n",
      "Epoch 64/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.1862 - accuracy: 0.2108 - F1Score: 0.6054 - WeightedF1: 0.6096 - val_loss: 0.3861 - val_accuracy: 0.1441 - val_F1Score: 0.4598 - val_WeightedF1: 0.4630 - lr: 0.0010\n",
      "Epoch 65/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.1857 - accuracy: 0.2119 - F1Score: 0.6074 - WeightedF1: 0.6117 - val_loss: 0.2697 - val_accuracy: 0.1873 - val_F1Score: 0.5125 - val_WeightedF1: 0.5157 - lr: 0.0010\n",
      "Epoch 66/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.1852 - accuracy: 0.2142 - F1Score: 0.6082 - WeightedF1: 0.6124 - val_loss: 0.2811 - val_accuracy: 0.2016 - val_F1Score: 0.5063 - val_WeightedF1: 0.5105 - lr: 0.0010\n",
      "Epoch 67/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.1845 - accuracy: 0.2148 - F1Score: 0.6097 - WeightedF1: 0.6140 - val_loss: 0.2614 - val_accuracy: 0.1881 - val_F1Score: 0.5246 - val_WeightedF1: 0.5281 - lr: 0.0010\n",
      "Epoch 68/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.1834 - accuracy: 0.2177 - F1Score: 0.6125 - WeightedF1: 0.6167 - val_loss: 0.3353 - val_accuracy: 0.1781 - val_F1Score: 0.5104 - val_WeightedF1: 0.5139 - lr: 0.0010\n",
      "Epoch 69/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.1829 - accuracy: 0.2179 - F1Score: 0.6135 - WeightedF1: 0.6177 - val_loss: 0.2503 - val_accuracy: 0.2128 - val_F1Score: 0.5291 - val_WeightedF1: 0.5325 - lr: 0.0010\n",
      "Epoch 70/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.1823 - accuracy: 0.2186 - F1Score: 0.6152 - WeightedF1: 0.6194 - val_loss: 0.2811 - val_accuracy: 0.1723 - val_F1Score: 0.4973 - val_WeightedF1: 0.5010 - lr: 0.0010\n",
      "Epoch 71/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.1818 - accuracy: 0.2195 - F1Score: 0.6164 - WeightedF1: 0.6205 - val_loss: 0.2756 - val_accuracy: 0.1870 - val_F1Score: 0.5170 - val_WeightedF1: 0.5206 - lr: 0.0010\n",
      "Epoch 72/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.1811 - accuracy: 0.2216 - F1Score: 0.6181 - WeightedF1: 0.6223 - val_loss: 0.3969 - val_accuracy: 0.1689 - val_F1Score: 0.4666 - val_WeightedF1: 0.4702 - lr: 0.0010\n",
      "Epoch 73/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.1803 - accuracy: 0.2212 - F1Score: 0.6197 - WeightedF1: 0.6239 - val_loss: 0.3878 - val_accuracy: 0.1929 - val_F1Score: 0.5116 - val_WeightedF1: 0.5151 - lr: 0.0010\n",
      "Epoch 74/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.1796 - accuracy: 0.2236 - F1Score: 0.6211 - WeightedF1: 0.6253 - val_loss: 0.3038 - val_accuracy: 0.1945 - val_F1Score: 0.5105 - val_WeightedF1: 0.5141 - lr: 0.0010\n",
      "Epoch 75/1200\n",
      " 87/563 [===>..........................] - ETA: 2:44 - loss: 0.1761 - accuracy: 0.2227 - F1Score: 0.6289 - WeightedF1: 0.6331"
     ]
    }
   ],
   "source": [
    "# CHECK CODE HERE ############################################################################################################################################################################################################################\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)\n",
    "X_train = normalize(X_train)\n",
    "X_test = normalize(X_test)\n",
    "\n",
    "evaluation_results = []\n",
    "predictions = []\n",
    "class_weights_all = NUK.class_weights_tool(y)\n",
    "model_predictions = []\n",
    "\n",
    "print(batch_size, epochs)\n",
    "# train ensemble of 5 models\n",
    "for i in range(5):\n",
    "\n",
    "    model = Classifier_INCEPTION(output_directory=f\"./models/performance/\", input_shape=(window_size, 1), nb_classes=NmDevices, verbose=True, build=True, batch_size=batch_size, nb_epochs=epochs, lr=0.001, depth=10, iteration=i, kernel_size=128)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    model_predictions.append(y_pred)\n",
    "\n",
    "# ensemble predictions\n",
    "y_pred = np.mean(model_predictions, axis=0)\n",
    "\n",
    "# thresholding\n",
    "y_pred_tf = (y_pred > 0.3)\n",
    "\n",
    "# save predictions for later analaysis\n",
    "predictions.append((y_pred_tf, y_test, y_pred))\n",
    "t = (y_pred_tf, y_test, y_pred)\n",
    "with open(f\"./predictions/test_inception_pickle_bfloat16_testing.pkl\", 'wb') as f:\n",
    "    pickle.dump(t, f)\n",
    "\n",
    "report = metrics.classification_report(y_test, y_pred_tf, target_names=labels, zero_division=0, output_dict=True)\n",
    "print(report[\"weighted avg\"])\n",
    "\n",
    "evaluation_results.append(report)\n",
    "gc.collect()\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "\n",
    "df = pd.DataFrame(report).T\n",
    "\n",
    "import os\n",
    "# check if directory exsits\n",
    "if not os.path.exists(f\"../../Energy_graph/data/results/{window_size}\"):\n",
    "    os.makedirs(f\"../../Energy_graph/data/results/{window_size}\")\n",
    "# save results to csv\n",
    "df.to_csv(f\"../../Energy_graph/data/results/{window_size}/NNE_epochs{epochs}_batch_size{batch_size}_k{k}_classes{NmDevices}_{function}_watts_bfloat16.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## PC0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "evaluation_results = []\n",
    "predictions = []\n",
    "class_weights_all = NUK.class_weights_tool(y)\n",
    "treshold = 0.5\n",
    "debug = 0\n",
    "for train_index, test_index in tqdm(kf.split(X)):\n",
    "    print(\"Train indices:\", train_index, \"Test indices:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    X_train[:, 0] = normalize(X_train[:, 0])\n",
    "    X_test[:,0] = normalize(X_test[:, 0])\n",
    "\n",
    "    # break\n",
    "    # class_weights_all = NUK.class_weights_tool(y_train)\n",
    "    # for k in class_weights_all:\n",
    "    #     class_weights_all[k] += 1\n",
    "    \n",
    "    # print(class_weights_all)\n",
    "    # break\n",
    "    model = NUK.PC0_reg(NmDevices, window_size, function, 128, k, lambda_l2=lambda_l2)\n",
    "    # model = NUK.VGG11_1D(NmDevices, window_size)\n",
    "    model.build((len(y_train) + len(y_test), window_size, 1))\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003), loss='binary_crossentropy', metrics=[NUK.F1Score, NUK.WeightedF1Score(NUK.class_weights_tool(y_test))])\n",
    "    # lr_scheduler = LearningRateScheduler(scheduler)\n",
    "    reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.25, patience=3, min_lr=0.000001)\n",
    "    # callback = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.1,patience=2, min_lr=0.0000002)\n",
    "    # for class weights\n",
    "    # model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, class_weight=class_weights_UKD, callbacks=[lr_scheduler])\n",
    "    # class_weights = NUK.class_weights_tool(y_train)\n",
    "    model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=[reduce_lr])\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_tf = (y_pred > treshold)\n",
    "\n",
    "    predictions.append((y_pred, y_pred_tf, y_test))\n",
    "\n",
    "    # n_labels = y_test.shape[1]\n",
    "    # co_occurrence_matrix = np.zeros((n_labels, n_labels))\n",
    "\n",
    "    # for true, pred in zip(y_test, y_pred_tf):\n",
    "    #     fn_labels = np.where((true == 1) & (pred == 0))[0]  # False negatives\n",
    "    #     fp_labels = np.where((true == 0) & (pred == 1))[0]  # False positives\n",
    "\n",
    "    #     for fn in fn_labels:\n",
    "    #         for fp in fp_labels:\n",
    "    #             co_occurrence_matrix[fn, fp] += 1\n",
    "\n",
    "\n",
    "\n",
    "    report = metrics.classification_report(y_test, y_pred_tf, target_names=labels, zero_division=0, output_dict=True)\n",
    "    print(report[\"weighted avg\"], \"|||\", report[\"samples avg\"])\n",
    "\n",
    "    # report_DF = NUK.ClassificationReportToDF(report, labels)  \n",
    "    # report_DF.rename(columns={report_DF.columns[0]: \"device\"}, inplace=True)\n",
    "    evaluation_results.append(report)\n",
    "    gc.collect()\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSMixer\n",
    "https://github.com/google-research/google-research/tree/master/tsmixer/tsmixer_basic/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    }
   ],
   "source": [
    "# coding=utf-8\n",
    "# Copyright 2023 The Google Research Authors.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "\"\"\"Implementation of TSMixer.\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "def res_block(inputs, norm_type, activation, dropout, ff_dim):\n",
    "  \"\"\"Residual block of TSMixer.\"\"\"\n",
    "\n",
    "  norm = (\n",
    "      layers.LayerNormalization\n",
    "      if norm_type == 'L'\n",
    "      else layers.BatchNormalization\n",
    "  )\n",
    "\n",
    "  # Temporal Linear\n",
    "  x = norm(axis=[-2, -1])(inputs)\n",
    "  x = tf.transpose(x, perm=[0, 2, 1])  # [Batch, Channel, Input Length]\n",
    "  x = layers.Dense(x.shape[-1], activation=activation)(x)\n",
    "  x = tf.transpose(x, perm=[0, 2, 1])  # [Batch, Input Length, Channel]\n",
    "  x = layers.Dropout(dropout)(x)\n",
    "  res = x + inputs\n",
    "\n",
    "  # Feature Linear\n",
    "  x = norm(axis=[-2, -1])(res)\n",
    "  x = layers.Dense(ff_dim, activation=activation)(\n",
    "      x\n",
    "  )  # [Batch, Input Length, FF_Dim]\n",
    "  x = layers.Dropout(dropout)(x)\n",
    "  x = layers.Dense(inputs.shape[-1])(x)  # [Batch, Input Length, Channel]\n",
    "  x = layers.Dropout(dropout)(x)\n",
    "  return x + res\n",
    "\n",
    "\n",
    "def build_model(\n",
    "    input_shape,\n",
    "    pred_len,\n",
    "    norm_type,\n",
    "    activation,\n",
    "    n_block,\n",
    "    dropout,\n",
    "    ff_dim,\n",
    "    target_slice,\n",
    "):\n",
    "  \"\"\"Build TSMixer model.\"\"\"\n",
    "\n",
    "  inputs = tf.keras.Input(shape=input_shape)\n",
    "  x = inputs  # [Batch, Input Length, Channel]\n",
    "  for _ in range(n_block):\n",
    "    x = res_block(x, norm_type, activation, dropout, ff_dim)\n",
    "\n",
    "  if target_slice:\n",
    "    x = x[:, :, target_slice]\n",
    "\n",
    "  x = tf.transpose(x, perm=[0, 2, 1])  # [Batch, Channel, Input Length]\n",
    "  x = layers.Dense(pred_len, activation=tf.nn.sigmoid)(x)  # [Batch, Channel, Output Length]\n",
    "  outputs = tf.transpose(x, perm=[0, 2, 1])  # [Batch, Output Length, Channel])\n",
    "\n",
    "  return tf.keras.Model(inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train indices: [     1      2      3 ... 147053 147054 147055] Test indices: [     0      4     12 ... 147049 147050 147052]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "jobs = 110\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "evaluation_results = []\n",
    "\n",
    "for train_index, test_index in tqdm(kf.split(X)):\n",
    "    print(\"Train indices:\", train_index, \"Test indices:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Initialize the Random Forest classifier wrapped in a MultiOutputClassifier\n",
    "    classifier = RandomForestClassifier(n_estimators=100, random_state=RANDOM_SEED, n_jobs=jobs)\n",
    "    # classifier = MultiOutputClassifier(forest, n_jobs=-1)\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the labels\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    # Evaluate the model using classification report\n",
    "    report = classification_report(y_test, y_pred, target_names=labels, zero_division=0, output_dict=True)\n",
    "\n",
    "    evaluation_results.append(report)\n",
    "\n",
    "\n",
    "for i in range(len(evaluation_results)):\n",
    "    if i == 0:\n",
    "        df = pd.DataFrame(evaluation_results[i]).T\n",
    "    else:\n",
    "        df = df + pd.DataFrame(evaluation_results[i]).T\n",
    "\n",
    "\n",
    "df = df / 5\n",
    "# df.to_csv(f\"../../Energy_graph/data/results/w_size{window_size}_epochs{epochs}_batch_size{batch_size}_k{k}_classes{NmDevices}_staticLR_LSTM_watts_mixed100k.csv\")\n",
    "df.to_csv(f\"../../Energy_graph/data/results/w_size{window_size}_classes{NmDevices}_watts_RF_mixed50k.csv\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_results = []\n",
    "model = NUK.PC0(NmDevices, window_size, 'GRU',128, k)\n",
    "model.build((len(y), window_size, 1))\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003), loss='binary_crossentropy', metrics=[NUK.F1Score, NUK.WeightedF1Score(NUK.class_weights_tool(y_test))])\n",
    "lr_scheduler = LearningRateScheduler(scheduler)\n",
    "\n",
    "model.fit(X, y, batch_size=batch_size, epochs=epochs, callbacks=[lr_scheduler])\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_tf = (y_pred > 0.5)\n",
    "report = metrics.classification_report(y_test, y_pred_tf, target_names=labels, zero_division=0, output_dict=True)\n",
    "\n",
    "# report_DF = NUK.ClassificationReportToDF(report, labels)  \n",
    "# report_DF.rename(columns={report_DF.columns[0]: \"device\"}, inplace=True)\n",
    "df = pd.DataFrame(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\n",
      "  Using cached catboost-1.2.2-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
      "Collecting graphviz\n",
      "  Using cached graphviz-0.20.1-py3-none-any.whl (47 kB)\n",
      "Requirement already satisfied: pandas>=0.24 in /opt/conda/lib/python3.10/site-packages (from catboost) (1.5.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from catboost) (1.9.3)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /opt/conda/lib/python3.10/site-packages (from catboost) (1.23.5)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from catboost) (3.6.2)\n",
      "Collecting plotly\n",
      "  Using cached plotly-5.18.0-py3-none-any.whl (15.6 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2022.6)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (9.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (1.0.6)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (4.38.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (3.0.9)\n",
      "Collecting tenacity>=6.2.0\n",
      "  Using cached tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: tenacity, graphviz, plotly, catboost\n",
      "Successfully installed catboost-1.2.2 graphviz-0.20.1 plotly-5.18.0 tenacity-8.2.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install catboost\n",
    "import catboost as cb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_pickle(\"../../Energy_graph/data/training_data/synthetic/X_Y_wsize2688_numW_50000_upper32_gap3600_numD64_ideal_sanitycheck.pkl\")\n",
    "# data = pd.read_pickle(\"../../Energy_graph/data/training_data/synthetic/X_Y_wsize2688_numW_50000_upper32_gap3600_numD64_ideal.pkl\") \n",
    "# data_syn_ideal = pd.read_pickle(\"../../Energy_graph/data/training_data/synthetic/X_Y_wsize2688_numW_50000_upper32_gap3600_numD64_ideal.pkl\") \n",
    "# data_syn_unmetered = pd.read_pickle(\"../../Energy_graph/data/training_data/synthetic/X_Y_wsize2688_numW_50000_upper32_gap3600_numD64_unmetered.pkl\")\n",
    "\n",
    "labels = pd.read_pickle(\"../../Energy_graph/data/labels_new.pkl\")\n",
    "\n",
    "\n",
    "# Separate the tuples into X and y\n",
    "# X_syn_ideal = np.array([i[0] for i in data_syn_ideal])\n",
    "# y_syn_ideal = np.array([i[1] for i in data_syn_ideal])\n",
    "\n",
    "# X_syn_unmetered = np.array([i[0] for i in data_syn_unmetered])\n",
    "# y_syn_unmetered = np.array([i[1] for i in data_syn_unmetered])\n",
    "\n",
    "X = np.array([i[0] for i in data])\n",
    "y = np.array([i[1] for i in data])\n",
    "\n",
    "\n",
    "# X = np.concatenate((X, X_syn_ideal,X_syn_unmetered), axis=0)\n",
    "# y = np.concatenate((y, y_syn_ideal, y_syn_unmetered), axis=0)\n",
    "\n",
    "\n",
    "y = y.astype(int)\n",
    "\n",
    "\n",
    "# X_test = np.array([i[0] for i in data_test])\n",
    "# y_test = np.array([i[1] for i in data_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce804085ef3b45f9887cda9f2b7266ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train indices: [    0     1     2 ... 49994 49995 49999] Test indices: [   11    12    15 ... 49996 49997 49998]\n",
      "Learning rate set to 0.006507\n",
      "0:\tlearn: 0.6844442\ttotal: 1.25s\tremaining: 1h 44m 30s\n",
      "250:\tlearn: 0.2194012\ttotal: 4m 57s\tremaining: 1h 33m 55s\n",
      "500:\tlearn: 0.1995254\ttotal: 9m 50s\tremaining: 1h 28m 25s\n",
      "750:\tlearn: 0.1902022\ttotal: 14m 34s\tremaining: 1h 22m 30s\n",
      "1000:\tlearn: 0.1832065\ttotal: 19m 11s\tremaining: 1h 16m 39s\n",
      "1250:\tlearn: 0.1772213\ttotal: 23m 48s\tremaining: 1h 11m 20s\n",
      "1500:\tlearn: 0.1717494\ttotal: 28m 23s\tremaining: 1h 6m 10s\n",
      "1750:\tlearn: 0.1668553\ttotal: 32m 58s\tremaining: 1h 1m 11s\n",
      "2000:\tlearn: 0.1622493\ttotal: 37m 32s\tremaining: 56m 16s\n",
      "2250:\tlearn: 0.1577867\ttotal: 42m 9s\tremaining: 51m 28s\n",
      "2500:\tlearn: 0.1535659\ttotal: 46m 45s\tremaining: 46m 43s\n",
      "2750:\tlearn: 0.1496007\ttotal: 51m 20s\tremaining: 41m 58s\n",
      "3000:\tlearn: 0.1459705\ttotal: 55m 54s\tremaining: 37m 14s\n",
      "3250:\tlearn: 0.1423770\ttotal: 1h 28s\tremaining: 32m 32s\n",
      "3500:\tlearn: 0.1390359\ttotal: 1h 5m 3s\tremaining: 27m 51s\n",
      "3750:\tlearn: 0.1357758\ttotal: 1h 9m 35s\tremaining: 23m 10s\n",
      "4000:\tlearn: 0.1326742\ttotal: 1h 14m 8s\tremaining: 18m 30s\n",
      "4250:\tlearn: 0.1296711\ttotal: 1h 18m 42s\tremaining: 13m 52s\n",
      "4500:\tlearn: 0.1268947\ttotal: 1h 23m 14s\tremaining: 9m 13s\n",
      "4750:\tlearn: 0.1240538\ttotal: 1h 27m 48s\tremaining: 4m 36s\n",
      "4999:\tlearn: 0.1214127\ttotal: 1h 32m 21s\tremaining: 0us\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "{'precision': 0.4408025798685414, 'recall': 0.056723117731075294, 'f1-score': 0.08100608300562134, 'support': 44109}\n",
      "Train indices: [    0     1     3 ... 49997 49998 49999] Test indices: [    2     7     8 ... 49985 49994 49995]\n",
      "Learning rate set to 0.006507\n",
      "0:\tlearn: 0.6842080\ttotal: 1.27s\tremaining: 1h 45m 48s\n",
      "250:\tlearn: 0.2181177\ttotal: 5m 1s\tremaining: 1h 34m 56s\n",
      "500:\tlearn: 0.1983823\ttotal: 9m 52s\tremaining: 1h 28m 38s\n",
      "750:\tlearn: 0.1890429\ttotal: 14m 36s\tremaining: 1h 22m 36s\n",
      "1000:\tlearn: 0.1821489\ttotal: 19m 14s\tremaining: 1h 16m 52s\n",
      "1250:\tlearn: 0.1761663\ttotal: 23m 49s\tremaining: 1h 11m 23s\n",
      "1500:\tlearn: 0.1707780\ttotal: 28m 23s\tremaining: 1h 6m 11s\n",
      "1750:\tlearn: 0.1658008\ttotal: 32m 56s\tremaining: 1h 1m 7s\n",
      "2000:\tlearn: 0.1611087\ttotal: 37m 33s\tremaining: 56m 17s\n",
      "2250:\tlearn: 0.1567048\ttotal: 42m 9s\tremaining: 51m 29s\n",
      "2500:\tlearn: 0.1525708\ttotal: 46m 46s\tremaining: 46m 44s\n",
      "2750:\tlearn: 0.1486696\ttotal: 51m 24s\tremaining: 42m 1s\n",
      "3000:\tlearn: 0.1450142\ttotal: 56m 1s\tremaining: 37m 18s\n",
      "3250:\tlearn: 0.1414636\ttotal: 1h 37s\tremaining: 32m 36s\n",
      "3500:\tlearn: 0.1380836\ttotal: 1h 5m 13s\tremaining: 27m 55s\n",
      "3750:\tlearn: 0.1348500\ttotal: 1h 9m 47s\tremaining: 23m 14s\n",
      "4000:\tlearn: 0.1318546\ttotal: 1h 14m 20s\tremaining: 18m 33s\n",
      "4250:\tlearn: 0.1288564\ttotal: 1h 18m 53s\tremaining: 13m 53s\n",
      "4500:\tlearn: 0.1259589\ttotal: 1h 23m 29s\tremaining: 9m 15s\n",
      "4750:\tlearn: 0.1233008\ttotal: 1h 28m 2s\tremaining: 4m 36s\n",
      "4999:\tlearn: 0.1207115\ttotal: 1h 32m 35s\tremaining: 0us\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "{'precision': 0.38729241652191376, 'recall': 0.029420859654547864, 'f1-score': 0.04903419530885325, 'support': 45274}\n",
      "Train indices: [    0     2     4 ... 49996 49997 49998] Test indices: [    1     3     5 ... 49974 49993 49999]\n",
      "Learning rate set to 0.006507\n",
      "0:\tlearn: 0.6844013\ttotal: 1.27s\tremaining: 1h 46m 1s\n",
      "250:\tlearn: 0.2179851\ttotal: 5m 1s\tremaining: 1h 35m 2s\n",
      "500:\tlearn: 0.1987558\ttotal: 9m 49s\tremaining: 1h 28m 11s\n",
      "750:\tlearn: 0.1893806\ttotal: 14m 34s\tremaining: 1h 22m 26s\n",
      "1000:\tlearn: 0.1823203\ttotal: 19m 16s\tremaining: 1h 16m 58s\n",
      "1250:\tlearn: 0.1762454\ttotal: 23m 54s\tremaining: 1h 11m 37s\n",
      "1500:\tlearn: 0.1708995\ttotal: 28m 28s\tremaining: 1h 6m 23s\n",
      "1750:\tlearn: 0.1659844\ttotal: 33m 6s\tremaining: 1h 1m 26s\n",
      "2000:\tlearn: 0.1614619\ttotal: 37m 42s\tremaining: 56m 30s\n",
      "2250:\tlearn: 0.1569847\ttotal: 42m 19s\tremaining: 51m 41s\n",
      "2500:\tlearn: 0.1529185\ttotal: 46m 56s\tremaining: 46m 53s\n",
      "2750:\tlearn: 0.1491333\ttotal: 51m 32s\tremaining: 42m 8s\n",
      "3000:\tlearn: 0.1453915\ttotal: 56m 9s\tremaining: 37m 24s\n",
      "3250:\tlearn: 0.1418039\ttotal: 1h 45s\tremaining: 32m 41s\n",
      "3500:\tlearn: 0.1384498\ttotal: 1h 5m 19s\tremaining: 27m 58s\n",
      "3750:\tlearn: 0.1351578\ttotal: 1h 9m 51s\tremaining: 23m 15s\n",
      "4000:\tlearn: 0.1320607\ttotal: 1h 14m 23s\tremaining: 18m 34s\n",
      "4250:\tlearn: 0.1290372\ttotal: 1h 18m 54s\tremaining: 13m 54s\n",
      "4500:\tlearn: 0.1261169\ttotal: 1h 23m 28s\tremaining: 9m 15s\n",
      "4750:\tlearn: 0.1233606\ttotal: 1h 28m\tremaining: 4m 36s\n",
      "4999:\tlearn: 0.1207234\ttotal: 1h 32m 31s\tremaining: 0us\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "{'precision': 0.4210338300632099, 'recall': 0.058637329555516204, 'f1-score': 0.08431347760505552, 'support': 45176}\n",
      "Train indices: [    0     1     2 ... 49997 49998 49999] Test indices: [    4     6     9 ... 49987 49988 49989]\n",
      "Learning rate set to 0.006507\n",
      "0:\tlearn: 0.6843969\ttotal: 1.25s\tremaining: 1h 44m 33s\n",
      "250:\tlearn: 0.2189830\ttotal: 4m 56s\tremaining: 1h 33m 36s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\foglo\\Documents\\IJS\\energy-knowledge-graph\\scripts\\notebooks\\multi-label classification\\models.ipynb Cell 36\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/foglo/Documents/IJS/energy-knowledge-graph/scripts/notebooks/multi-label%20classification/models.ipynb#X46sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m model \u001b[39m=\u001b[39m cb\u001b[39m.\u001b[39mCatBoostClassifier(\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/foglo/Documents/IJS/energy-knowledge-graph/scripts/notebooks/multi-label%20classification/models.ipynb#X46sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     loss_function\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mMultiLogloss\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/foglo/Documents/IJS/energy-knowledge-graph/scripts/notebooks/multi-label%20classification/models.ipynb#X46sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39m250\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/foglo/Documents/IJS/energy-knowledge-graph/scripts/notebooks/multi-label%20classification/models.ipynb#X46sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/foglo/Documents/IJS/energy-knowledge-graph/scripts/notebooks/multi-label%20classification/models.ipynb#X46sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     )  \u001b[39m# Add other hyperparameters if needed\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/foglo/Documents/IJS/energy-knowledge-graph/scripts/notebooks/multi-label%20classification/models.ipynb#X46sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/c%3A/Users/foglo/Documents/IJS/energy-knowledge-graph/scripts/notebooks/multi-label%20classification/models.ipynb#X46sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/foglo/Documents/IJS/energy-knowledge-graph/scripts/notebooks/multi-label%20classification/models.ipynb#X46sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m# Get predictions\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/foglo/Documents/IJS/energy-knowledge-graph/scripts/notebooks/multi-label%20classification/models.ipynb#X46sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/catboost/core.py:5100\u001b[0m, in \u001b[0;36mCatBoostClassifier.fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5097\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m params:\n\u001b[1;32m   5098\u001b[0m     CatBoostClassifier\u001b[39m.\u001b[39m_check_is_compatible_loss(params[\u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m-> 5100\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, cat_features, text_features, embedding_features, \u001b[39mNone\u001b[39;49;00m, sample_weight, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, baseline, use_best_model,\n\u001b[1;32m   5101\u001b[0m           eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period,\n\u001b[1;32m   5102\u001b[0m           silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n\u001b[1;32m   5103\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/catboost/core.py:2319\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2315\u001b[0m allow_clear_pool \u001b[39m=\u001b[39m train_params[\u001b[39m\"\u001b[39m\u001b[39mallow_clear_pool\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   2317\u001b[0m \u001b[39mwith\u001b[39;00m log_fixup(log_cout, log_cerr), \\\n\u001b[1;32m   2318\u001b[0m     plot_wrapper(plot, plot_file, \u001b[39m'\u001b[39m\u001b[39mTraining plots\u001b[39m\u001b[39m'\u001b[39m, [_get_train_dir(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_params())]):\n\u001b[0;32m-> 2319\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train(\n\u001b[1;32m   2320\u001b[0m         train_pool,\n\u001b[1;32m   2321\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39meval_sets\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m   2322\u001b[0m         params,\n\u001b[1;32m   2323\u001b[0m         allow_clear_pool,\n\u001b[1;32m   2324\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39minit_model\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m   2325\u001b[0m     )\n\u001b[1;32m   2327\u001b[0m \u001b[39m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[1;32m   2328\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_object\u001b[39m.\u001b[39m_get_loss_function_name()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/catboost/core.py:1723\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1722\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_train\u001b[39m(\u001b[39mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[0;32m-> 1723\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_object\u001b[39m.\u001b[39;49m_train(train_pool, test_pool, params, allow_clear_pool, init_model\u001b[39m.\u001b[39;49m_object \u001b[39mif\u001b[39;49;00m init_model \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m   1724\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_trained_model_attributes()\n",
      "File \u001b[0;32m_catboost.pyx:4645\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:4694\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Closing remaining open files:/tmp/nilmtk-43g7cwfb.h5...done\n"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED=32\n",
    "num_splits = 5\n",
    "kf = KFold(n_splits=num_splits, shuffle=True, random_state=RANDOM_SEED)\n",
    "evaluation_results = []\n",
    "predictions = []\n",
    "class_weights_all = NUK.class_weights_tool(y)\n",
    "debug = 0\n",
    "for train_index, test_index in tqdm(kf.split(X)):\n",
    "    print(\"Train indices:\", train_index, \"Test indices:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    X_train = normalize(X_train)\n",
    "    X_test = normalize(X_test)\n",
    "\n",
    "    # break\n",
    "\n",
    "    # Initialize CatBoost multilabel classifier\n",
    "    model = cb.CatBoostClassifier(\n",
    "        loss_function='MultiLogloss',\n",
    "        verbose=250,\n",
    "        random_seed=RANDOM_SEED,\n",
    "        task_type=\"GPU\",\n",
    "        devices='0:1',\n",
    "        depth=8,   \n",
    "        # class_weights=class_weights_all,\n",
    "        iterations=5000,\n",
    "        \n",
    "\n",
    "        )  # Add other hyperparameters if needed\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Get predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Convert predictions to boolean format similar to y_test for evaluation\n",
    "    y_pred_tf = (y_pred == 1)\n",
    "    print(y_pred)\n",
    "\n",
    "    predictions.append((y_pred_tf, y_test))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    report = metrics.classification_report(y_test, y_pred_tf, target_names=labels, zero_division=0, output_dict=True)\n",
    "    print(report[\"weighted avg\"])\n",
    "    # break\n",
    "    # report_DF = NUK.ClassificationReportToDF(report, labels)  \n",
    "    # report_DF.rename(columns={report_DF.columns[0]: \"device\"}, inplace=True)\n",
    "    evaluation_results.append(report)\n",
    "    del model\n",
    "\n",
    "\n",
    "for i in range(len(evaluation_results)):\n",
    "    if i == 0:\n",
    "        df = pd.DataFrame(evaluation_results[i]).T\n",
    "    else:\n",
    "        df = df + pd.DataFrame(evaluation_results[i]).T\n",
    "\n",
    "df = df / num_splits\n",
    "df\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optuna hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Using cached optuna-3.4.0-py3-none-any.whl (409 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (21.3)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (1.4.44)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from optuna) (1.23.5)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (1.8.1)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from optuna) (6.0)\n",
      "Collecting colorlog\n",
      "  Using cached colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from optuna) (4.66.1)\n",
      "Requirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (1.2.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->optuna) (3.0.9)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna) (2.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/conda/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.1)\n",
      "Installing collected packages: colorlog, optuna\n",
      "Successfully installed colorlog-6.7.0 optuna-3.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-27 13:15:24,552] A new study created in memory with name: no-name-be90d17e-8ac2-4785-a77a-7eada4e00fed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7cfb96097874364b4821a89aa9c1ce8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-11-27 13:50:50,035] Trial 0 finished with value: 0.023022892328962187 and parameters: {'iterations': 760, 'depth': 7, 'learning_rate': 0.04064904160617694}. Best is trial 0 with value: 0.023022892328962187.\n",
      "New best value: 0.0230\n",
      "[I 2023-11-27 14:01:38,161] Trial 1 finished with value: 0.03701412972494217 and parameters: {'iterations': 630, 'depth': 5, 'learning_rate': 0.19386570776436488}. Best is trial 1 with value: 0.03701412972494217.\n",
      "New best value: 0.0370\n",
      "[I 2023-11-27 14:11:51,989] Trial 2 finished with value: 0.03336795180037944 and parameters: {'iterations': 595, 'depth': 5, 'learning_rate': 0.18128112677663014}. Best is trial 1 with value: 0.03701412972494217.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import logging\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn import metrics\n",
    "from optuna.visualization import plot_optimization_history\n",
    "\n",
    "RANDOM_SEED = 32\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X[:25000], y[:25000], test_size=0.2, random_state=RANDOM_SEED)\n",
    "# Configure logging to file\n",
    "logging.basicConfig(filename='../../Energy_graph/data/optuna_log.log', level=logging.INFO, \n",
    "                    format='%(asctime)s %(levelname)s %(message)s')\n",
    "# Enable logging at the INFO level\n",
    "optuna.logging.get_logger(\"optuna\").setLevel(logging.INFO)\n",
    "\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'iterations': trial.suggest_int('iterations', 100, 1000),\n",
    "        'depth': trial.suggest_int('depth', 4, 8),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        # Add other parameters here\n",
    "        'random_seed': RANDOM_SEED,\n",
    "        'loss_function': 'MultiLogloss',\n",
    "        'verbose': False,\n",
    "        'task_type': \"GPU\",\n",
    "        'devices': '0:1'\n",
    "    }\n",
    "\n",
    "    model = CatBoostClassifier(**param)\n",
    "    X_train_norm = normalize(X_train)\n",
    "    score = cross_val_score(model, X_train_norm, y_train, cv=5, scoring='f1_weighted').mean()\n",
    "    return score\n",
    "\n",
    "# Define a simple callback function to print the best value so far\n",
    "def callback(study, trial):\n",
    "    if study.best_trial == trial:\n",
    "        print(f\"New best value: {trial.value:.4f}\")\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100, callbacks=[callback], show_progress_bar=True)  # Adjust the number of trials\n",
    "\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.params)\n",
    "\n",
    "try: \n",
    "    # Save the study if you want to\n",
    "    with open(\"study.pkl\", \"wb\") as f:\n",
    "        pickle.dump(study, f)\n",
    "\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Train the final model with the best parameters\n",
    "best_params = study.best_trial.params\n",
    "best_model = CatBoostClassifier(**best_params)\n",
    "best_model.fit(normalize(X_train), y_train)\n",
    "\n",
    "# Evaluate the model on the holdout validation set\n",
    "X_val_norm = normalize(X_val)\n",
    "val_predictions = best_model.predict(X_val_norm)\n",
    "val_score = metrics.f1_score(y_val, val_predictions, average='weighted')\n",
    "print(\"Validation F1 Score:\", val_score)\n",
    "\n",
    "# Plot the optimization history\n",
    "plot_optimization_history(study)\n",
    "# Remember to close the logging file handler if necessary\n",
    "logging.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "# data = pd.read_pickle(\"./Energy_graph/data/training_data/synthetic/X_Y_wsize2688_numW_50000_upper32_gap3600_numD64_ideal_sanitycheck.pkl\")\n",
    "data = pd.read_pickle(\"./Energy_graph/data/training_data/synthetic/X_Y_wsize2688_numW_50000_upper32_gap3600_numD64_ideal.pkl\")\n",
    "labels  = pd.read_pickle(\"./Energy_graph/data/labels_new.pkl\")\n",
    "X = np.array([i[0] for i in data])\n",
    "y = np.array([i[1] for i in data])\n",
    "y = y.astype(int)\n",
    "# X = X[:1000]\n",
    "# y = y[:1000]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "params = dict()\n",
    "params[\"device\"] = \"cuda\"\n",
    "params[\"tree_method\"] = \"gpu_hist\"\n",
    "params[\"verbosity\"] = 3\n",
    "\n",
    "\n",
    "model = XGBClassifier(**params)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "report = classification_report(y_test, y_pred, output_dict=True, target_names=labels)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(report).T\n",
    "df.to_csv(\"./Energy_graph/data/results/2688/XGB_50000_2688.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for i in range(len(evaluation_results)):\n",
    "    if i == 0:\n",
    "        df = pd.DataFrame(evaluation_results[i]).T\n",
    "    else:\n",
    "        df = df + pd.DataFrame(evaluation_results[i]).T\n",
    "\n",
    "\n",
    "df = df / 5\n",
    "# check if directory exsits\n",
    "if not os.path.exists(f\"../../Energy_graph/data/results/{window_size}\"):\n",
    "    os.makedirs(f\"../../Energy_graph/data/results/{window_size}\")\n",
    "if lambda_l2 == 0:\n",
    "    df.to_csv(f\"../../Energy_graph/data/results/{window_size}/PC0_epochs{epochs}_batch_size{batch_size}_k{k}_classes{NmDevices}_{function}_watts_syn_mix.csv\")\n",
    "else:\n",
    "    df.to_csv(f\"../../Energy_graph/data/results/w_size{window_size}_epochs{epochs}_batch_size{batch_size}_k{k}_classes{NmDevices}_{function}_watts_syn_reg{lambda_l2}.csv\")\n",
    "# df.to_csv(f\"../../Energy_graph/data/results/w_size{window_size}_classes{NmDevices}_watts_RF_mixed50k.csv\")\n",
    "    \n",
    "# evaluation_results+ evaluation_results[1].to_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 2688, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 2688, 1)      0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 2688, 32)     1280        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 2688, 32)     640         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 2688, 32)     320         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 2688, 32)     32          ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 2688, 128)    0           ['conv1d[0][0]',                 \n",
      "                                                                  'conv1d_1[0][0]',               \n",
      "                                                                  'conv1d_2[0][0]',               \n",
      "                                                                  'conv1d_3[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 2688, 128)   512         ['concatenate[0][0]']            \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 2688, 128)    0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 2688, 32)     4096        ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 2688, 128)   0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 2688, 32)     40960       ['conv1d_4[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 2688, 32)     20480       ['conv1d_4[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 2688, 32)     10240       ['conv1d_4[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)              (None, 2688, 32)     4096        ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 2688, 128)    0           ['conv1d_5[0][0]',               \n",
      "                                                                  'conv1d_6[0][0]',               \n",
      "                                                                  'conv1d_7[0][0]',               \n",
      "                                                                  'conv1d_8[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 2688, 128)   512         ['concatenate_1[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 2688, 128)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_9 (Conv1D)              (None, 2688, 32)     4096        ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 2688, 128)   0           ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_10 (Conv1D)             (None, 2688, 32)     40960       ['conv1d_9[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_11 (Conv1D)             (None, 2688, 32)     20480       ['conv1d_9[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_12 (Conv1D)             (None, 2688, 32)     10240       ['conv1d_9[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_13 (Conv1D)             (None, 2688, 32)     4096        ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 2688, 128)    0           ['conv1d_10[0][0]',              \n",
      "                                                                  'conv1d_11[0][0]',              \n",
      "                                                                  'conv1d_12[0][0]',              \n",
      "                                                                  'conv1d_13[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_14 (Conv1D)             (None, 2688, 128)    128         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 2688, 128)   512         ['concatenate_2[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 2688, 128)   512         ['conv1d_14[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 2688, 128)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 2688, 128)    0           ['batch_normalization_3[0][0]',  \n",
      "                                                                  'activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 2688, 128)    0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv1d_15 (Conv1D)             (None, 2688, 32)     4096        ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 2688, 128)   0           ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_16 (Conv1D)             (None, 2688, 32)     40960       ['conv1d_15[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_17 (Conv1D)             (None, 2688, 32)     20480       ['conv1d_15[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_18 (Conv1D)             (None, 2688, 32)     10240       ['conv1d_15[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_19 (Conv1D)             (None, 2688, 32)     4096        ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 2688, 128)    0           ['conv1d_16[0][0]',              \n",
      "                                                                  'conv1d_17[0][0]',              \n",
      "                                                                  'conv1d_18[0][0]',              \n",
      "                                                                  'conv1d_19[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 2688, 128)   512         ['concatenate_3[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 2688, 128)    0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_20 (Conv1D)             (None, 2688, 32)     4096        ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 2688, 128)   0           ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_21 (Conv1D)             (None, 2688, 32)     40960       ['conv1d_20[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_22 (Conv1D)             (None, 2688, 32)     20480       ['conv1d_20[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_23 (Conv1D)             (None, 2688, 32)     10240       ['conv1d_20[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_24 (Conv1D)             (None, 2688, 32)     4096        ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 2688, 128)    0           ['conv1d_21[0][0]',              \n",
      "                                                                  'conv1d_22[0][0]',              \n",
      "                                                                  'conv1d_23[0][0]',              \n",
      "                                                                  'conv1d_24[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 2688, 128)   512         ['concatenate_4[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 2688, 128)    0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_25 (Conv1D)             (None, 2688, 32)     4096        ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 2688, 128)   0           ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_26 (Conv1D)             (None, 2688, 32)     40960       ['conv1d_25[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_27 (Conv1D)             (None, 2688, 32)     20480       ['conv1d_25[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_28 (Conv1D)             (None, 2688, 32)     10240       ['conv1d_25[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_29 (Conv1D)             (None, 2688, 32)     4096        ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 2688, 128)    0           ['conv1d_26[0][0]',              \n",
      "                                                                  'conv1d_27[0][0]',              \n",
      "                                                                  'conv1d_28[0][0]',              \n",
      "                                                                  'conv1d_29[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_30 (Conv1D)             (None, 2688, 128)    16384       ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 2688, 128)   512         ['concatenate_5[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 2688, 128)   512         ['conv1d_30[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 2688, 128)    0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 2688, 128)    0           ['batch_normalization_7[0][0]',  \n",
      "                                                                  'activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 2688, 128)    0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_31 (Conv1D)             (None, 2688, 32)     4096        ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 2688, 128)   0           ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_32 (Conv1D)             (None, 2688, 32)     40960       ['conv1d_31[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_33 (Conv1D)             (None, 2688, 32)     20480       ['conv1d_31[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_34 (Conv1D)             (None, 2688, 32)     10240       ['conv1d_31[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_35 (Conv1D)             (None, 2688, 32)     4096        ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 2688, 128)    0           ['conv1d_32[0][0]',              \n",
      "                                                                  'conv1d_33[0][0]',              \n",
      "                                                                  'conv1d_34[0][0]',              \n",
      "                                                                  'conv1d_35[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 2688, 128)   512         ['concatenate_6[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 2688, 128)    0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_36 (Conv1D)             (None, 2688, 32)     4096        ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling1d_7 (MaxPooling1D)  (None, 2688, 128)   0           ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_37 (Conv1D)             (None, 2688, 32)     40960       ['conv1d_36[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_38 (Conv1D)             (None, 2688, 32)     20480       ['conv1d_36[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_39 (Conv1D)             (None, 2688, 32)     10240       ['conv1d_36[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_40 (Conv1D)             (None, 2688, 32)     4096        ['max_pooling1d_7[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 2688, 128)    0           ['conv1d_37[0][0]',              \n",
      "                                                                  'conv1d_38[0][0]',              \n",
      "                                                                  'conv1d_39[0][0]',              \n",
      "                                                                  'conv1d_40[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 2688, 128)   512         ['concatenate_7[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 2688, 128)    0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_41 (Conv1D)             (None, 2688, 32)     4096        ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling1d_8 (MaxPooling1D)  (None, 2688, 128)   0           ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_42 (Conv1D)             (None, 2688, 32)     40960       ['conv1d_41[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_43 (Conv1D)             (None, 2688, 32)     20480       ['conv1d_41[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_44 (Conv1D)             (None, 2688, 32)     10240       ['conv1d_41[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_45 (Conv1D)             (None, 2688, 32)     4096        ['max_pooling1d_8[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 2688, 128)    0           ['conv1d_42[0][0]',              \n",
      "                                                                  'conv1d_43[0][0]',              \n",
      "                                                                  'conv1d_44[0][0]',              \n",
      "                                                                  'conv1d_45[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_46 (Conv1D)             (None, 2688, 128)    16384       ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 2688, 128)   512         ['concatenate_8[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 2688, 128)   512         ['conv1d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 2688, 128)    0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 2688, 128)    0           ['batch_normalization_11[0][0]', \n",
      "                                                                  'activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 2688, 128)    0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_47 (Conv1D)             (None, 2688, 32)     4096        ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling1d_9 (MaxPooling1D)  (None, 2688, 128)   0           ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_48 (Conv1D)             (None, 2688, 32)     40960       ['conv1d_47[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_49 (Conv1D)             (None, 2688, 32)     20480       ['conv1d_47[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_50 (Conv1D)             (None, 2688, 32)     10240       ['conv1d_47[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_51 (Conv1D)             (None, 2688, 32)     4096        ['max_pooling1d_9[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate)    (None, 2688, 128)    0           ['conv1d_48[0][0]',              \n",
      "                                                                  'conv1d_49[0][0]',              \n",
      "                                                                  'conv1d_50[0][0]',              \n",
      "                                                                  'conv1d_51[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 2688, 128)   512         ['concatenate_9[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 2688, 128)    0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 128)         0           ['activation_12[0][0]']          \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 64)           8256        ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 768,928\n",
      "Trainable params: 765,600\n",
      "Non-trainable params: 3,328\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"./models/test/last_model_4.hdf5\", custom_objects={'F1Score': NUK.F1Score, \"WeightedF1\": NUK.WeightedF1Score(class_weighs_pre)})\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../../Energy_graph/data/processed_watts/REFIT_clean.pkl\")\n",
    "df[\"REFIT_1\"]\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open(\"../../Energy_graph/data/processed_watts/refit/REFIT1_clean.pkl\", 'wb') as f:\n",
    "    pickle.dump({\"REFIT_1\" : df[\"REFIT_1\"]}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from collections import Counter\n",
    "import concurrent.futures\n",
    "import argparse\n",
    "# from helper import preprocess_string\n",
    "\n",
    "import re\n",
    "\n",
    "def preprocess_string(string : str) -> str:\n",
    "    string = string.lower().strip()\n",
    "    string = re.sub(' +', ' ', string)\n",
    "    string = string.replace(\"_\", \" \")\n",
    "    string = string.replace(\"-\", \" \")\n",
    "    string = string.replace(\"&\", \" \")\n",
    "    string = string.split(\"(\")[0]\n",
    "    string = string.split(\"#\")[0]\n",
    "\n",
    "    string = string.strip()\n",
    "\n",
    "    # handle known synoynms\n",
    "    synonyms = {\n",
    "        \"refrigerator\": \"fridge\",\n",
    "        \"vaccumcleaner\": \"vacuum cleaner\",\n",
    "        \"breadmaker\": \"bread maker\",\n",
    "      \n",
    "        \n",
    "    }\n",
    "    if \"freezer\" in string:\n",
    "        string = \"fridge\"\n",
    "\n",
    "    if string in synonyms:\n",
    "        string = synonyms[string]\n",
    "\n",
    "    if 'hi fi' in string:\n",
    "        string = \"audio system\"\n",
    "\n",
    "    if \"router\" in string:\n",
    "        string = \"router\"\n",
    "\n",
    "    if \"treadmill\" in string:\n",
    "        string = \"running machine\"\n",
    "        \n",
    "\n",
    "    if \"laptop\" in string:\n",
    "        string = \"laptop\"\n",
    "    \n",
    "    if \"server\" in string:\n",
    "        string = \"server\"\n",
    "\n",
    "    if \"monitor\" in string and not \"baby\" in string:\n",
    "        string = \"monitor\"\n",
    "    # special cases\n",
    "    if \"computer\" in string and \"charger\" not in string:\n",
    "        string = \"pc\"\n",
    "\n",
    "    if \"tv\" in string:\n",
    "        string = \"television\"\n",
    "\n",
    "    if \"television\" in string:\n",
    "        string = \"television\"\n",
    "\n",
    "    if \"macbook\" in string:\n",
    "        string = \"laptop\"\n",
    "        \n",
    "    if \"car charger\" == string:\n",
    "        string = \"ev\"\n",
    "    \n",
    "    if \"toast\" in string:\n",
    "        string = \"toaster\"\n",
    "    \n",
    "    if \"modem\" in string:\n",
    "        string = \"router\"\n",
    "\n",
    "    # we treat all audio devices as speakers so subwoofer is also a speaker\n",
    "    if \"subwoofer\" in string:\n",
    "        string = \"speaker\"\n",
    "\n",
    "    if \"speaker\" in string:\n",
    "        string = \"speaker\"\n",
    "\n",
    "    if \"iron\" in string and \"soldering\" not in string:\n",
    "        string = \"iron\"\n",
    "\n",
    "    \n",
    "    if \"coffeemachine\" in string:\n",
    "        string = \"coffee machine\"\n",
    "    if \"coffee maker\" in string:\n",
    "        string = \"coffee machine\"\n",
    "\n",
    "    if \"dishwasher\" in string:\n",
    "        string = \"dish washer\"\n",
    "    if \"air conditioner\" in string:\n",
    "        string = \"ac\"\n",
    "\n",
    "    if \"air conditioning\" in string:\n",
    "        string = \"ac\"\n",
    "    \n",
    "    string = re.sub(' +', ' ', string)\n",
    "    string = re.sub(r'\\d+', '', string)\n",
    "    return string.strip()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def process_dictionary(data: dict, values=0) -> pd.DataFrame:\n",
    "\n",
    "    ignored_devices = [\n",
    "        \"light\",\n",
    "        \"outlet\",\n",
    "        \"sockets\",\n",
    "        \"lamp\",\n",
    "        \"plug\",\n",
    "        'CE appliance'\n",
    "        'kettle/toaster',\n",
    "        'dehumidifier/heater',\n",
    "        'HairDryer-Straightener',\n",
    "        'Office Desk',\n",
    "        'heat basement',\n",
    "        'set top box',\n",
    "        'subpanel',\n",
    "    ]\n",
    "    dfs = []\n",
    "    for device in data:\n",
    "        # ignore devices\n",
    "        if any(ignored_device in device.lower() for ignored_device in ignored_devices):\n",
    "            continue\n",
    "        if device == \"aggregate\":\n",
    "            continue\n",
    "        # preprocess device name\n",
    "        device_name = preprocess_string(device)\n",
    "        \n",
    "        df = data[device]\n",
    "        df = df.resample(\"8s\").mean()\n",
    "\n",
    "        # rename column to standardized device name\n",
    "        df.columns = [device_name]\n",
    "        if df.max().max() < 2:\n",
    "            print(\"device with zeros: \", device_name)\n",
    "            continue\n",
    "\n",
    "        time_diffs = df.index.to_series().diff()\n",
    "        median_interval = time_diffs.median()\n",
    "\n",
    "        # if there is less than 3 days of data drop the device\n",
    "        if len(df) < (3*24 * 60 * 60) / median_interval.total_seconds():\n",
    "            print(\"less than 3 days of data for device: \", device_name)\n",
    "            continue\n",
    "        df.dropna(inplace=True)\n",
    "        dfs.append(df)\n",
    "\n",
    "    # concatenate all dataframes\n",
    "    df = pd.concat(dfs, axis=1)\n",
    "\n",
    "    # handle missing values\n",
    "    df = df.ffill(limit=6)\n",
    "    df.fillna(0, inplace=True)\n",
    "\n",
    "    # handle negative values\n",
    "    df[df<0] = 0\n",
    "\n",
    "    df[\"aggregate\"] = df.sum(axis=1)\n",
    "    # df.drop(columns=[\"aggregate\"], inplace=True)\n",
    "\n",
    "    # df.rename(columns={\"sum_ideal\": \"aggregate\"}, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "    # treshold in watts\n",
    "    treshold = 5\n",
    "    if values == 0:\n",
    "        # put 1 if device is on and 0 if device is off\n",
    "        for c in df.columns:\n",
    "            if c == \"aggregate\":\n",
    "                continue\n",
    "            # if power is less than treshold device is off\n",
    "            df[c] = (df[c] > treshold).astype(int)\n",
    "\n",
    "    # find duplicate columns\n",
    "    column_counts = Counter(df.columns)\n",
    "    duplicates = [col for col, count in column_counts.items() if count > 1]\n",
    "    # Sum duplicate columns\n",
    "    for duplicate in duplicates:\n",
    "        duplicate_cols = [col for i, col in enumerate(df.columns) if col == duplicate]\n",
    "        df[duplicate] = df[duplicate_cols].sum(axis=1)\n",
    "        # Drop other duplicate columns if needed\n",
    "        df = df.loc[:, ~df.columns.duplicated(keep='last')]\n",
    "    \n",
    "    \n",
    "    return df\n",
    "    \n",
    "\n",
    "\n",
    "def process_dataset(dataset_path):\n",
    "    data = pd.read_pickle(dataset_path)\n",
    "    # print(dataset_path)\n",
    "    for house in data:\n",
    "        data[house] = process_dictionary(data[house], house)\n",
    "        \n",
    "    return data\n",
    "\n",
    "\n",
    "def get_data(path : str, labels_path : str, values=0):\n",
    "        \n",
    "    # path = \"./Energy_graph/data/processed_watts/\"\n",
    "    dataset_paths = [os.path.join(path, dataset) for dataset in os.listdir(path) if dataset.endswith('.pkl')]\n",
    "        \n",
    "    cpu_count = int(os.cpu_count() / 2)\n",
    "    data_dict = {}\n",
    "\n",
    "    with tqdm(total=len(dataset_paths), desc=\"Processing datasets\", unit=\"dataset\") as progress_bar:\n",
    "        with concurrent.futures.ProcessPoolExecutor(max_workers=cpu_count) as executor:\n",
    "            futures = {executor.submit(process_dataset, dataset_path): dataset_path for dataset_path in dataset_paths}\n",
    "            \n",
    "            for future in concurrent.futures.as_completed(futures):\n",
    "                dataset_path = futures[future]\n",
    "                try:\n",
    "                    processed_data = future.result()\n",
    "                    data_dict.update(processed_data)\n",
    "                except Exception as e:\n",
    "                    print(f\"Dataset {dataset_path} generated an exception: {e}\")\n",
    "                \n",
    "                progress_bar.update(1)\n",
    "\n",
    "    labels = pd.read_pickle(labels_path)\n",
    "    labels.sort()\n",
    "\n",
    "    return data_dict\n",
    "\n",
    "def create_windows(data : dict, labels_path: str, save_path : str, time_window=2700, upper_bound=pd.Timedelta(seconds=32), max_gap = pd.Timedelta(seconds=3600)):\n",
    "    \"\"\"Creates windows of time_window seconds from the data and discards windows with gaps of more than 1h or 15 gaps of 32 seconds or more\"\"\"\n",
    "    \n",
    "    labels = pd.read_pickle(labels_path)\n",
    "    # windows = []\n",
    "    X_Y = [] # list of tuples (X, Y)\n",
    "    skip_count_1 = 0\n",
    "    skip_count_2 = 0\n",
    "    skip_count_3 = 0\n",
    "    total_count = 0\n",
    "\n",
    "    for df in data.values():\n",
    "        print(len(df[\"aggregate\"]))\n",
    "        for i in range(0, len(df) - time_window, time_window + 1):\n",
    "            window = df.iloc[i:i + time_window]\n",
    "            total_count += 1\n",
    "            # if there is a gap of more than max_gap skip the window\n",
    "            time_diffs = window.index.to_series().diff().dropna()\n",
    "            if  (time_diffs >= max_gap).any():\n",
    "                skip_count_1 += 1\n",
    "                continue\n",
    "            # if there are more than 15 gaps of upper_bound or more skip the window\n",
    "            if len(time_diffs[time_diffs > upper_bound]) > 15:\n",
    "                skip_count_2 += 1\n",
    "                continue\n",
    "\n",
    "            x = window[\"aggregate\"].values\n",
    "            # if there is a value bigger than 50000 skip the window\n",
    "            if (x > 50000).any():\n",
    "                skip_count_3 += 1\n",
    "                continue\n",
    "            devices = [False] * len(labels)\n",
    "            # check if device is on in the window\n",
    "            for c in window.columns:\n",
    "                if c == \"aggregate\":\n",
    "                    continue\n",
    "                on = (window[c] > 0)\n",
    "                ix = labels.index(c)\n",
    "                devices[ix] = on.any()\n",
    "\n",
    "            X_Y.append((x, devices))\n",
    "            \n",
    "\n",
    "\n",
    "            # windows.append(window)\n",
    "    print(\"Total windows: \", total_count, \"Skipped windows due to 30min gap: \", skip_count_1, \"Skipped windows due to 15 gaps of 32s or more: \", skip_count_2 ,\"Skipped windows due to values larger than 50k: \", skip_count_3 ,\"Procentage skipped: \", (skip_count_1+skip_count_2+ skip_count_3) / total_count * 100)\n",
    "    return X_Y\n",
    "    # with open(save_path+ f\"/X_Y_wsize{time_window}_upper{int(upper_bound.total_seconds())}_gap{int(max_gap.total_seconds())}_numD{len(labels)}.pkl\", \"wb\") as f:\n",
    "    #     pickle.dump(X_Y, f, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to base folder:  ../../Energy_graph/\n",
      "Path to save windows:  ../../Energy_graph//data/training_data/processed/\n",
      "Time window:  2688 rows |  21504 seconds\n",
      "Upper bound:  0 days 00:00:32\n",
      "Max gap:  0 days 01:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing datasets:  50%|█████     | 5/10 [00:15<00:10,  2.05s/dataset]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "less than 3 days of data for device:  games console\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing datasets: 100%|██████████| 10/10 [02:18<00:00, 13.87s/dataset]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "folder = \"\"\n",
    "# Initialize paths\n",
    "path_to_base = \"../../Energy_graph/\"\n",
    "path = path_to_base + \"/data/processed_watts/\"+folder\n",
    "labels_path = path_to_base + \"/data/labels_new.pkl\"\n",
    "save_path = path_to_base + \"/data/training_data/processed/\"+folder\n",
    "\n",
    "# Initialize parameters\n",
    "time_window = 2688\n",
    "upper_bound = pd.Timedelta(seconds=32)\n",
    "max_gap = pd.Timedelta(seconds=3600)\n",
    "\n",
    "# Print parameters\n",
    "print(\"Path to base folder: \", path_to_base)\n",
    "print(\"Path to save windows: \", save_path)\n",
    "print(\"Time window: \", time_window, \"rows | \", time_window*8, \"seconds\")\n",
    "print(\"Upper bound: \", upper_bound)\n",
    "print(\"Max gap: \", max_gap)\n",
    "\n",
    "# Get data and create windows\n",
    "data = get_data(path, labels_path)\n",
    "# create_windows(data, labels_path, save_path, time_window, upper_bound, max_gap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/64 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HES_1 1152268\n",
      "1152268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/64 [00:00<00:49,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  428 Skipped windows due to 30min gap:  5 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  1.1682242990654206\n",
      "IAWE_1 620447\n",
      "620447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 2/64 [00:01<00:30,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  230 Skipped windows due to 30min gap:  14 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  6.086956521739131\n",
      "DRED_1 1657798\n",
      "1657798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 3/64 [00:02<00:43,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  616 Skipped windows due to 30min gap:  0 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  0.0\n",
      "HEART_33 1004400\n",
      "1004400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 4/64 [00:02<00:40,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  373 Skipped windows due to 30min gap:  0 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  0.0\n",
      "HEART_7 1004400\n",
      "1004400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 6/64 [00:03<00:27,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  373 Skipped windows due to 30min gap:  0 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  0.0\n",
      "REDD_1 358273\n",
      "358273\n",
      "Total windows:  133 Skipped windows due to 30min gap:  5 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  3.7593984962406015\n",
      "REDD_2 148341\n",
      "148341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 8/64 [00:03<00:16,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  55 Skipped windows due to 30min gap:  3 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  5.454545454545454\n",
      "REDD_3 192499\n",
      "192499\n",
      "Total windows:  71 Skipped windows due to 30min gap:  9 Skipped windows due to 15 gaps of 32s or more:  1 Skipped windows due to values larger than 50k:  0 Procentage skipped:  14.084507042253522\n",
      "REDD_4 272058\n",
      "272058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 9/64 [00:03<00:13,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  101 Skipped windows due to 30min gap:  6 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  5.9405940594059405\n",
      "REDD_5 39395\n",
      "39395\n",
      "Total windows:  14 Skipped windows due to 30min gap:  4 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  28.57142857142857\n",
      "REDD_6 152445\n",
      "152445\n",
      "Total windows:  56 Skipped windows due to 30min gap:  4 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  7.142857142857142\n",
      "DEDDIAG_8 4500232\n",
      "4500232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 12/64 [00:05<00:24,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  1673 Skipped windows due to 30min gap:  0 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  0.0\n",
      "ECO_1 2494800\n",
      "2494800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 13/64 [00:06<00:30,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  927 Skipped windows due to 30min gap:  1 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  0.10787486515641855\n",
      "ECO_6 1998000\n",
      "1998000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 14/64 [00:07<00:32,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  743 Skipped windows due to 30min gap:  2 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  0.2691790040376851\n",
      "ECO_2 2592000\n",
      "2592000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 15/64 [00:08<00:39,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  963 Skipped windows due to 30min gap:  2 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  0.20768431983385255\n",
      "ECO_5 2354400\n",
      "2354400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 16/64 [00:10<00:42,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  875 Skipped windows due to 30min gap:  1 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  0.1142857142857143\n",
      "ECO_4 2106000\n",
      "2106000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 17/64 [00:10<00:39,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  783 Skipped windows due to 30min gap:  3 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  0.38314176245210724\n",
      "ECO_3 1047600\n",
      "1047600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 18/64 [00:11<00:32,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  389 Skipped windows due to 30min gap:  2 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  0.5141388174807198\n",
      "ENERTALK_1 1211429\n",
      "1211429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 20/64 [00:11<00:22,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  450 Skipped windows due to 30min gap:  14 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  3.111111111111111\n",
      "ENERTALK_18 509433\n",
      "509433\n",
      "Total windows:  189 Skipped windows due to 30min gap:  1 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  0.5291005291005291\n",
      "ENERTALK_12 1282152\n",
      "1282152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 21/64 [00:12<00:22,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  476 Skipped windows due to 30min gap:  6 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  1.2605042016806722\n",
      "ENERTALK_20 647946\n",
      "647946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 23/64 [00:12<00:14,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  240 Skipped windows due to 30min gap:  1 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  0.4166666666666667\n",
      "ENERTALK_15 495183\n",
      "495183\n",
      "Total windows:  184 Skipped windows due to 30min gap:  1 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  0.5434782608695652\n",
      "ENERTALK_6 464668\n",
      "464668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 24/64 [00:12<00:12,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  172 Skipped windows due to 30min gap:  1 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  0.5813953488372093\n",
      "ENERTALK_8 657789\n",
      "657789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 26/64 [00:13<00:09,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  244 Skipped windows due to 30min gap:  1 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  0.4098360655737705\n",
      "ENERTALK_2 334755\n",
      "334755\n",
      "Total windows:  124 Skipped windows due to 30min gap:  0 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  0.0\n",
      "ENERTALK_11 322716\n",
      "322716\n",
      "Total windows:  120 Skipped windows due to 30min gap:  0 Skipped windows due to 15 gaps of 32s or more:  1 Skipped windows due to values larger than 50k:  0 Procentage skipped:  0.8333333333333334\n",
      "ENERTALK_16 767570\n",
      "767570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 28/64 [00:13<00:07,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  285 Skipped windows due to 30min gap:  4 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  1.4035087719298245\n",
      "ENERTALK_5 617543\n",
      "617543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 30/64 [00:14<00:07,  4.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  229 Skipped windows due to 30min gap:  1 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  0.43668122270742354\n",
      "ENERTALK_7 657441\n",
      "657441\n",
      "Total windows:  244 Skipped windows due to 30min gap:  1 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  0.4098360655737705\n",
      "ENERTALK_14 1062395\n",
      "1062395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 31/64 [00:14<00:07,  4.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  395 Skipped windows due to 30min gap:  10 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  2.5316455696202533\n",
      "ENERTALK_13 947873\n",
      "947873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 33/64 [00:14<00:07,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  352 Skipped windows due to 30min gap:  4 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  1.1363636363636365\n",
      "ENERTALK_19 637122\n",
      "637122\n",
      "Total windows:  236 Skipped windows due to 30min gap:  2 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  0.847457627118644\n",
      "ENERTALK_21 657552\n",
      "657552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 34/64 [00:15<00:07,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  244 Skipped windows due to 30min gap:  1 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  0.4098360655737705\n",
      "ENERTALK_0 936253\n",
      "936253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 35/64 [00:15<00:08,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  348 Skipped windows due to 30min gap:  6 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  1.7241379310344827\n",
      "ENERTALK_4 906831\n",
      "906831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 36/64 [00:15<00:08,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  337 Skipped windows due to 30min gap:  7 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  2.0771513353115725\n",
      "ENERTALK_17 912460\n",
      "912460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 37/64 [00:16<00:09,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  339 Skipped windows due to 30min gap:  7 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  2.0648967551622417\n",
      "ENERTALK_10 1249051\n",
      "1249051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 38/64 [00:16<00:09,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  464 Skipped windows due to 30min gap:  8 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  1.7241379310344827\n",
      "ENERTALK_3 1215991\n",
      "1215991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 39/64 [00:17<00:08,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  452 Skipped windows due to 30min gap:  11 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  2.433628318584071\n",
      "ENERTALK_9 1293445\n",
      "1293445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 40/64 [00:17<00:09,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  481 Skipped windows due to 30min gap:  4 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  0.8316008316008316\n",
      "REFIT_13 4075515\n",
      "4075515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 41/64 [00:19<00:18,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  1515 Skipped windows due to 30min gap:  35 Skipped windows due to 15 gaps of 32s or more:  124 Skipped windows due to values larger than 50k:  0 Procentage skipped:  10.495049504950495\n",
      "REFIT_6 5246422\n",
      "5246422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 42/64 [00:21<00:30,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  1951 Skipped windows due to 30min gap:  22 Skipped windows due to 15 gaps of 32s or more:  32 Skipped windows due to values larger than 50k:  0 Procentage skipped:  2.7678113787801126\n",
      "REFIT_1 6003014\n",
      "6003014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 43/64 [00:24<00:37,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  2232 Skipped windows due to 30min gap:  25 Skipped windows due to 15 gaps of 32s or more:  13 Skipped windows due to values larger than 50k:  0 Procentage skipped:  1.702508960573477\n",
      "REFIT_21 4770403\n",
      "4770403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 44/64 [00:27<00:38,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  1774 Skipped windows due to 30min gap:  18 Skipped windows due to 15 gaps of 32s or more:  5 Skipped windows due to values larger than 50k:  0 Procentage skipped:  1.2965050732807215\n",
      "REFIT_8 5346837\n",
      "5346837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 45/64 [00:29<00:41,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  1988 Skipped windows due to 30min gap:  18 Skipped windows due to 15 gaps of 32s or more:  11 Skipped windows due to values larger than 50k:  0 Procentage skipped:  1.4587525150905434\n",
      "REFIT_9 5161252\n",
      "5161252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 46/64 [00:33<00:46,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  1919 Skipped windows due to 30min gap:  16 Skipped windows due to 15 gaps of 32s or more:  9 Skipped windows due to values larger than 50k:  0 Procentage skipped:  1.3027618551328817\n",
      "REFIT_20 4651687\n",
      "4651687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 47/64 [00:35<00:43,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  1729 Skipped windows due to 30min gap:  12 Skipped windows due to 15 gaps of 32s or more:  8 Skipped windows due to values larger than 50k:  0 Procentage skipped:  1.156737998843262\n",
      "REFIT_7 5758682\n",
      "5758682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 48/64 [00:38<00:41,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  2141 Skipped windows due to 30min gap:  24 Skipped windows due to 15 gaps of 32s or more:  10 Skipped windows due to values larger than 50k:  0 Procentage skipped:  1.5880429705744978\n",
      "REFIT_15 5262277\n",
      "5262277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 49/64 [00:41<00:40,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  1956 Skipped windows due to 30min gap:  30 Skipped windows due to 15 gaps of 32s or more:  9 Skipped windows due to values larger than 50k:  0 Procentage skipped:  1.9938650306748467\n",
      "REFIT_12 4884120\n",
      "4884120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 50/64 [00:43<00:34,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  1816 Skipped windows due to 30min gap:  16 Skipped windows due to 15 gaps of 32s or more:  43 Skipped windows due to values larger than 50k:  0 Procentage skipped:  3.248898678414097\n",
      "REFIT_4 5881600\n",
      "5881600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 51/64 [00:45<00:32,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  2187 Skipped windows due to 30min gap:  40 Skipped windows due to 15 gaps of 32s or more:  27 Skipped windows due to values larger than 50k:  0 Procentage skipped:  3.063557384545039\n",
      "REFIT_3 5858072\n",
      "5858072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 52/64 [00:48<00:31,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  2178 Skipped windows due to 30min gap:  20 Skipped windows due to 15 gaps of 32s or more:  11 Skipped windows due to values larger than 50k:  0 Procentage skipped:  1.423324150596878\n",
      "REFIT_18 4488860\n",
      "4488860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 53/64 [00:51<00:27,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  1669 Skipped windows due to 30min gap:  16 Skipped windows due to 15 gaps of 32s or more:  4 Skipped windows due to values larger than 50k:  0 Procentage skipped:  1.1983223487118035\n",
      "REFIT_11 3745057\n",
      "3745057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 54/64 [00:53<00:23,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  1392 Skipped windows due to 30min gap:  15 Skipped windows due to 15 gaps of 32s or more:  8 Skipped windows due to values larger than 50k:  0 Procentage skipped:  1.6522988505747127\n",
      "REFIT_16 4829646\n",
      "4829646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 55/64 [00:55<00:20,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  1796 Skipped windows due to 30min gap:  32 Skipped windows due to 15 gaps of 32s or more:  6 Skipped windows due to values larger than 50k:  0 Procentage skipped:  2.1158129175946545\n",
      "REFIT_17 4733420\n",
      "4733420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 56/64 [00:57<00:18,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  1760 Skipped windows due to 30min gap:  17 Skipped windows due to 15 gaps of 32s or more:  8 Skipped windows due to values larger than 50k:  0 Procentage skipped:  1.4204545454545454\n",
      "REFIT_10 5573669\n",
      "5573669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 57/64 [01:00<00:17,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  2072 Skipped windows due to 30min gap:  32 Skipped windows due to 15 gaps of 32s or more:  51 Skipped windows due to values larger than 50k:  0 Procentage skipped:  4.005791505791506\n",
      "REFIT_19 4720415\n",
      "4720415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 58/64 [01:02<00:14,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  1755 Skipped windows due to 30min gap:  15 Skipped windows due to 15 gaps of 32s or more:  20 Skipped windows due to values larger than 50k:  0 Procentage skipped:  1.9943019943019942\n",
      "REFIT_2 4999158\n",
      "4999158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 59/64 [01:05<00:12,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  1859 Skipped windows due to 30min gap:  33 Skipped windows due to 15 gaps of 32s or more:  8 Skipped windows due to values larger than 50k:  0 Procentage skipped:  2.205486820871436\n",
      "REFIT_5 6287475\n",
      "6287475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 60/64 [01:08<00:11,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  2338 Skipped windows due to 30min gap:  33 Skipped windows due to 15 gaps of 32s or more:  31 Skipped windows due to values larger than 50k:  0 Procentage skipped:  2.737382378100941\n",
      "UKDALE_5 1425706\n",
      "1425706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 61/64 [01:10<00:07,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  530 Skipped windows due to 30min gap:  2 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  0.37735849056603776\n",
      "UKDALE_2 2156879\n",
      "2156879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 62/64 [01:12<00:04,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  802 Skipped windows due to 30min gap:  8 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  0.997506234413965\n",
      "UKDALE_1 17064863\n",
      "17064863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [01:32<00:00,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  6346 Skipped windows due to 30min gap:  35 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  0.5515285219035614\n",
      "UKDALE_3 396227\n",
      "396227\n",
      "Total windows:  147 Skipped windows due to 30min gap:  7 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  4.761904761904762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# data.keys()\n",
    "processed = {}\n",
    "\n",
    "for key in tqdm(data.keys()):\n",
    "    # if \"UKDALE\" not in key: \n",
    "    #     continue\n",
    "    print(key, len(data[key]))\n",
    "    processed[key] = create_windows({key : data[key]}, labels_path, save_path, time_window, upper_bound, max_gap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aggregate</th>\n",
       "      <th>kettle</th>\n",
       "      <th>projector</th>\n",
       "      <th>laptop</th>\n",
       "      <th>electric space heater</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-02-27 20:35:12</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-27 20:35:20</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-27 20:35:28</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-27 20:35:36</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-27 20:35:44</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-04-08 05:14:32</th>\n",
       "      <td>176.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-04-08 05:14:40</th>\n",
       "      <td>174.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-04-08 05:14:48</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-04-08 05:14:56</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-04-08 05:15:04</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>425100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     aggregate  kettle  projector  laptop  \\\n",
       "0                                                           \n",
       "2013-02-27 20:35:12        5.0       0          0       0   \n",
       "2013-02-27 20:35:20        4.0       0          1       0   \n",
       "2013-02-27 20:35:28        5.0       0          1       0   \n",
       "2013-02-27 20:35:36        4.0       0          0       0   \n",
       "2013-02-27 20:35:44        4.0       0          0       0   \n",
       "...                        ...     ...        ...     ...   \n",
       "2013-04-08 05:14:32      176.0       0          0       0   \n",
       "2013-04-08 05:14:40      174.0       0          0       0   \n",
       "2013-04-08 05:14:48        0.0       0          0       0   \n",
       "2013-04-08 05:14:56        0.0       1          0       0   \n",
       "2013-04-08 05:15:04        0.0       0          0       0   \n",
       "\n",
       "                     electric space heater  \n",
       "0                                           \n",
       "2013-02-27 20:35:12                      0  \n",
       "2013-02-27 20:35:20                      0  \n",
       "2013-02-27 20:35:28                      0  \n",
       "2013-02-27 20:35:36                      0  \n",
       "2013-02-27 20:35:44                      0  \n",
       "...                                    ...  \n",
       "2013-04-08 05:14:32                      0  \n",
       "2013-04-08 05:14:40                      0  \n",
       "2013-04-08 05:14:48                      0  \n",
       "2013-04-08 05:14:56                      0  \n",
       "2013-04-08 05:15:04                      0  \n",
       "\n",
       "[425100 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_devices(data):\n",
    "\n",
    "    devices = set()\n",
    "    real_str = \" \"\n",
    "    for key in data.keys():\n",
    "        if key == \"aggregate\":\n",
    "            continue\n",
    "        real_str+= key + \", \"\n",
    "        devices.add(preprocess_string(key))\n",
    "        \n",
    "\n",
    "    return list(devices), real_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"../../Energy_graph/data/training_data/real_house.pkl\", \"wb\") as f:\n",
    "    pickle.dump(processed, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HES_1\n",
      "2\n",
      "14/14 [==============================] - 1s 41ms/step\n",
      "14/14 [==============================] - 1s 25ms/step\n",
      "14/14 [==============================] - 1s 25ms/step\n",
      "14/14 [==============================] - 1s 25ms/step\n",
      "14/14 [==============================] - 1s 26ms/step\n",
      "0.9336485220415739 1.0 0.8800236406619385\n",
      "IAWE_1\n",
      "2\n",
      "7/7 [==============================] - 1s 88ms/step\n",
      "7/7 [==============================] - 0s 26ms/step\n",
      "7/7 [==============================] - 0s 25ms/step\n",
      "7/7 [==============================] - 0s 26ms/step\n",
      "7/7 [==============================] - 0s 26ms/step\n",
      "0.5008752495756639 0.6483688948976613 0.46766169154228854\n",
      "DRED_1\n",
      "2\n",
      "20/20 [==============================] - 1s 37ms/step\n",
      "20/20 [==============================] - 1s 26ms/step\n",
      "20/20 [==============================] - 0s 25ms/step\n",
      "20/20 [==============================] - 1s 26ms/step\n",
      "20/20 [==============================] - 0s 25ms/step\n",
      "0.3613230390192975 0.6204464870610003 0.32207407407407407\n",
      "HEART_33\n",
      "2\n",
      "12/12 [==============================] - 1s 58ms/step\n",
      "12/12 [==============================] - 0s 26ms/step\n",
      "12/12 [==============================] - 0s 25ms/step\n",
      "12/12 [==============================] - 0s 26ms/step\n",
      "12/12 [==============================] - 0s 26ms/step\n",
      "0.3430030937477516 0.33018970189701896 0.36829268292682926\n",
      "HEART_7\n",
      "2\n",
      "12/12 [==============================] - 0s 25ms/step\n",
      "12/12 [==============================] - 0s 25ms/step\n",
      "12/12 [==============================] - 0s 26ms/step\n",
      "12/12 [==============================] - 0s 26ms/step\n",
      "12/12 [==============================] - 0s 25ms/step\n",
      "0.35986203191925475 0.35865287188359446 0.3611342785654712\n",
      "REDD_1\n",
      "2\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 26ms/step\n",
      "4/4 [==============================] - 0s 26ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "0.19309986010022545 0.4746600741656366 0.16563658838071693\n",
      "REDD_2\n",
      "2\n",
      "2/2 [==============================] - 0s 361ms/step\n",
      "2/2 [==============================] - 0s 25ms/step\n",
      "2/2 [==============================] - 0s 24ms/step\n",
      "2/2 [==============================] - 0s 25ms/step\n",
      "2/2 [==============================] - 0s 25ms/step\n",
      "0.48504702660240756 0.582089552238806 0.43656716417910446\n",
      "REDD_3\n",
      "2\n",
      "2/2 [==============================] - 0s 467ms/step\n",
      "2/2 [==============================] - 0s 25ms/step\n",
      "2/2 [==============================] - 0s 25ms/step\n",
      "2/2 [==============================] - 0s 25ms/step\n",
      "2/2 [==============================] - 0s 25ms/step\n",
      "0.19243143563985396 0.43884892086330934 0.1630695443645084\n",
      "REDD_4\n",
      "2\n",
      "3/3 [==============================] - 1s 254ms/step\n",
      "3/3 [==============================] - 0s 24ms/step\n",
      "3/3 [==============================] - 0s 25ms/step\n",
      "3/3 [==============================] - 0s 26ms/step\n",
      "3/3 [==============================] - 0s 27ms/step\n",
      "0.09473283976124885 0.37109375 0.05859375\n",
      "REDD_5\n",
      "2\n",
      "1/1 [==============================] - 0s 253ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "0.4062575794324521 0.4838709677419355 0.3709677419354839\n",
      "REDD_6\n",
      "2\n",
      "2/2 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 25ms/step\n",
      "2/2 [==============================] - 0s 25ms/step\n",
      "2/2 [==============================] - 0s 25ms/step\n",
      "2/2 [==============================] - 0s 25ms/step\n",
      "0.19418426691153964 0.3501683501683502 0.18518518518518517\n",
      "DEDDIAG_8\n",
      "2\n",
      "53/53 [==============================] - 2s 30ms/step\n",
      "53/53 [==============================] - 1s 26ms/step\n",
      "53/53 [==============================] - 1s 25ms/step\n",
      "53/53 [==============================] - 1s 26ms/step\n",
      "53/53 [==============================] - 1s 25ms/step\n",
      "0.5356829900571298 0.8939638012865683 0.43100065402223675\n",
      "ECO_1\n",
      "2\n",
      "29/29 [==============================] - 1s 42ms/step\n",
      "29/29 [==============================] - 1s 25ms/step\n",
      "29/29 [==============================] - 1s 25ms/step\n",
      "29/29 [==============================] - 1s 25ms/step\n",
      "29/29 [==============================] - 1s 26ms/step\n",
      "0.27352528289181305 0.8616935142537381 0.22764227642276422\n",
      "ECO_6\n",
      "2\n",
      "24/24 [==============================] - 1s 32ms/step\n",
      "24/24 [==============================] - 1s 26ms/step\n",
      "24/24 [==============================] - 1s 25ms/step\n",
      "24/24 [==============================] - 1s 25ms/step\n",
      "24/24 [==============================] - 1s 25ms/step\n",
      "0.45390835202627133 0.6848777000471161 0.3463541666666667\n",
      "ECO_2\n",
      "2\n",
      "31/31 [==============================] - 1s 29ms/step\n",
      "31/31 [==============================] - 1s 25ms/step\n",
      "31/31 [==============================] - 1s 25ms/step\n",
      "31/31 [==============================] - 1s 25ms/step\n",
      "31/31 [==============================] - 1s 25ms/step\n",
      "0.2957932328210172 0.6231134045085699 0.278561209891682\n",
      "ECO_5\n",
      "2\n",
      "28/28 [==============================] - 1s 25ms/step\n",
      "28/28 [==============================] - 1s 25ms/step\n",
      "28/28 [==============================] - 1s 25ms/step\n",
      "28/28 [==============================] - 1s 25ms/step\n",
      "28/28 [==============================] - 1s 25ms/step\n",
      "0.47195018658088017 0.9077831547647703 0.43652371485373476\n",
      "ECO_4\n",
      "2\n",
      "25/25 [==============================] - 1s 36ms/step\n",
      "25/25 [==============================] - 1s 25ms/step\n",
      "25/25 [==============================] - 1s 25ms/step\n",
      "25/25 [==============================] - 1s 25ms/step\n",
      "25/25 [==============================] - 1s 25ms/step\n",
      "0.7032456460306385 0.7452192998889746 0.6678032148075986\n",
      "ECO_3\n",
      "2\n",
      "13/13 [==============================] - 0s 37ms/step\n",
      "13/13 [==============================] - 0s 26ms/step\n",
      "13/13 [==============================] - 0s 25ms/step\n",
      "13/13 [==============================] - 0s 25ms/step\n",
      "13/13 [==============================] - 0s 26ms/step\n",
      "0.6029031141997384 0.7598817009248773 0.6286644951140065\n",
      "ENERTALK_1\n",
      "2\n",
      "14/14 [==============================] - 0s 26ms/step\n",
      "14/14 [==============================] - 0s 26ms/step\n",
      "14/14 [==============================] - 0s 25ms/step\n",
      "14/14 [==============================] - 0s 25ms/step\n",
      "14/14 [==============================] - 0s 25ms/step\n",
      "0.5368382177333908 0.9717026819888461 0.4714537963507946\n",
      "ENERTALK_18\n",
      "2\n",
      "6/6 [==============================] - 1s 108ms/step\n",
      "6/6 [==============================] - 0s 25ms/step\n",
      "6/6 [==============================] - 0s 25ms/step\n",
      "6/6 [==============================] - 0s 25ms/step\n",
      "6/6 [==============================] - 0s 25ms/step\n",
      "0.6620204606809102 0.75 0.5997340425531915\n",
      "ENERTALK_12\n",
      "2\n",
      "15/15 [==============================] - 1s 51ms/step\n",
      "15/15 [==============================] - 0s 25ms/step\n",
      "15/15 [==============================] - 0s 25ms/step\n",
      "15/15 [==============================] - 0s 25ms/step\n",
      "15/15 [==============================] - 0s 25ms/step\n",
      "0.4739489736147738 0.5833426086316169 0.44888108819657746\n",
      "ENERTALK_20\n",
      "2\n",
      "8/8 [==============================] - 0s 67ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "0.31736878506109273 0.33426573426573425 0.3020979020979021\n",
      "ENERTALK_15\n",
      "2\n",
      "6/6 [==============================] - 1s 99ms/step\n",
      "6/6 [==============================] - 0s 25ms/step\n",
      "6/6 [==============================] - 0s 25ms/step\n",
      "6/6 [==============================] - 0s 25ms/step\n",
      "6/6 [==============================] - 0s 25ms/step\n",
      "0.938832021005673 0.9875956027108486 0.8947368421052632\n",
      "ENERTALK_6\n",
      "2\n",
      "6/6 [==============================] - 0s 74ms/step\n",
      "6/6 [==============================] - 0s 25ms/step\n",
      "6/6 [==============================] - 0s 26ms/step\n",
      "6/6 [==============================] - 0s 25ms/step\n",
      "6/6 [==============================] - 0s 25ms/step\n",
      "0.47444418120802656 0.7590144230769231 0.43345543345543347\n",
      "ENERTALK_8\n",
      "2\n",
      "8/8 [==============================] - 1s 72ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "0.3234914276434333 0.5 0.24074074074074073\n",
      "ENERTALK_2\n",
      "2\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 26ms/step\n",
      "4/4 [==============================] - 0s 26ms/step\n",
      "0.6806172047162045 0.9927098186492077 0.6247464503042597\n",
      "ENERTALK_11\n",
      "2\n",
      "4/4 [==============================] - 0s 26ms/step\n",
      "4/4 [==============================] - 0s 27ms/step\n",
      "4/4 [==============================] - 0s 26ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "0.7878276003276004 1.0 0.6722689075630253\n",
      "ENERTALK_16\n",
      "2\n",
      "9/9 [==============================] - 1s 75ms/step\n",
      "9/9 [==============================] - 0s 25ms/step\n",
      "9/9 [==============================] - 0s 25ms/step\n",
      "9/9 [==============================] - 0s 25ms/step\n",
      "9/9 [==============================] - 0s 26ms/step\n",
      "0.9436090225563909 1.0 0.8932384341637011\n",
      "ENERTALK_5\n",
      "2\n",
      "8/8 [==============================] - 0s 45ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "0.4966494157471601 0.5063011015911874 0.511578947368421\n",
      "ENERTALK_7\n",
      "2\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "0.5 0.5 0.5\n",
      "ENERTALK_14\n",
      "2\n",
      "13/13 [==============================] - 0s 26ms/step\n",
      "13/13 [==============================] - 0s 26ms/step\n",
      "13/13 [==============================] - 0s 25ms/step\n",
      "13/13 [==============================] - 0s 25ms/step\n",
      "13/13 [==============================] - 0s 26ms/step\n",
      "0.15347721822541965 1.0 0.08311688311688312\n",
      "ENERTALK_13\n",
      "2\n",
      "11/11 [==============================] - 0s 25ms/step\n",
      "11/11 [==============================] - 0s 25ms/step\n",
      "11/11 [==============================] - 0s 25ms/step\n",
      "11/11 [==============================] - 0s 25ms/step\n",
      "11/11 [==============================] - 0s 25ms/step\n",
      "0.3365146100483498 0.3501006036217304 0.323943661971831\n",
      "ENERTALK_19\n",
      "2\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "0.6481948714749804 0.9740255257239991 0.48577680525164113\n",
      "ENERTALK_21\n",
      "2\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "0.33072191433779696 0.5159235668789809 0.2791932059447983\n",
      "ENERTALK_0\n",
      "2\n",
      "11/11 [==============================] - 0s 25ms/step\n",
      "11/11 [==============================] - 0s 25ms/step\n",
      "11/11 [==============================] - 0s 25ms/step\n",
      "11/11 [==============================] - 0s 26ms/step\n",
      "11/11 [==============================] - 0s 25ms/step\n",
      "0.5085194757098893 0.6464675913862539 0.4950805008944544\n",
      "ENERTALK_4\n",
      "2\n",
      "11/11 [==============================] - 0s 25ms/step\n",
      "11/11 [==============================] - 0s 26ms/step\n",
      "11/11 [==============================] - 0s 26ms/step\n",
      "11/11 [==============================] - 0s 26ms/step\n",
      "11/11 [==============================] - 0s 25ms/step\n",
      "0.7128795064755322 0.9353220825833164 0.6495934959349593\n",
      "ENERTALK_17\n",
      "2\n",
      "11/11 [==============================] - 0s 25ms/step\n",
      "11/11 [==============================] - 0s 25ms/step\n",
      "11/11 [==============================] - 0s 26ms/step\n",
      "11/11 [==============================] - 0s 26ms/step\n",
      "11/11 [==============================] - 0s 26ms/step\n",
      "0.5552453930852128 0.7818407279385825 0.5315822388993121\n",
      "ENERTALK_10\n",
      "2\n",
      "15/15 [==============================] - 0s 26ms/step\n",
      "15/15 [==============================] - 0s 25ms/step\n",
      "15/15 [==============================] - 0s 26ms/step\n",
      "15/15 [==============================] - 0s 26ms/step\n",
      "15/15 [==============================] - 0s 26ms/step\n",
      "0.4207670310715854 1.0 0.3534675615212528\n",
      "ENERTALK_3\n",
      "2\n",
      "14/14 [==============================] - 0s 25ms/step\n",
      "14/14 [==============================] - 0s 26ms/step\n",
      "14/14 [==============================] - 0s 26ms/step\n",
      "14/14 [==============================] - 0s 25ms/step\n",
      "14/14 [==============================] - 0s 25ms/step\n",
      "0.04211619543650794 0.4965277777777778 0.02199074074074074\n",
      "ENERTALK_9\n",
      "2\n",
      "15/15 [==============================] - 0s 26ms/step\n",
      "15/15 [==============================] - 0s 26ms/step\n",
      "15/15 [==============================] - 0s 25ms/step\n",
      "15/15 [==============================] - 0s 25ms/step\n",
      "15/15 [==============================] - 0s 26ms/step\n",
      "0.4397902574645901 0.9538688210745934 0.40801354401805867\n",
      "REFIT_13\n",
      "2\n",
      "43/43 [==============================] - 1s 25ms/step\n",
      "43/43 [==============================] - 1s 26ms/step\n",
      "43/43 [==============================] - 1s 25ms/step\n",
      "43/43 [==============================] - 1s 25ms/step\n",
      "43/43 [==============================] - 1s 25ms/step\n",
      "0.4794494784860013 0.7986656579340571 0.40770725388601037\n",
      "REFIT_6\n",
      "2\n",
      "60/60 [==============================] - 2s 26ms/step\n",
      "60/60 [==============================] - 2s 26ms/step\n",
      "60/60 [==============================] - 2s 26ms/step\n",
      "60/60 [==============================] - 2s 26ms/step\n",
      "60/60 [==============================] - 2s 26ms/step\n",
      "0.6749540826097389 0.9081763593824688 0.593030242339275\n",
      "REFIT_1\n",
      "2\n",
      "69/69 [==============================] - 2s 30ms/step\n",
      "69/69 [==============================] - 2s 26ms/step\n",
      "69/69 [==============================] - 2s 25ms/step\n",
      "69/69 [==============================] - 2s 25ms/step\n",
      "69/69 [==============================] - 2s 26ms/step\n",
      "0.3980972921759798 0.766385631188681 0.4018416677324466\n",
      "REFIT_21\n",
      "2\n",
      "55/55 [==============================] - 1s 25ms/step\n",
      "55/55 [==============================] - 1s 26ms/step\n",
      "55/55 [==============================] - 1s 25ms/step\n",
      "55/55 [==============================] - 1s 26ms/step\n",
      "55/55 [==============================] - 1s 26ms/step\n",
      "0.45505766917916557 0.6217043220527281 0.4354744808849214\n",
      "REFIT_8\n",
      "2\n",
      "62/62 [==============================] - 2s 26ms/step\n",
      "62/62 [==============================] - 2s 26ms/step\n",
      "62/62 [==============================] - 2s 25ms/step\n",
      "62/62 [==============================] - 2s 25ms/step\n",
      "62/62 [==============================] - 2s 25ms/step\n",
      "0.6186423292351364 0.897914435512884 0.5729982887507881\n",
      "REFIT_9\n",
      "2\n",
      "60/60 [==============================] - 2s 28ms/step\n",
      "60/60 [==============================] - 2s 26ms/step\n",
      "60/60 [==============================] - 2s 26ms/step\n",
      "60/60 [==============================] - 2s 25ms/step\n",
      "60/60 [==============================] - 2s 25ms/step\n",
      "0.498968870074634 0.903633554551245 0.4430954272098037\n",
      "REFIT_20\n",
      "2\n",
      "54/54 [==============================] - 2s 30ms/step\n",
      "54/54 [==============================] - 1s 25ms/step\n",
      "54/54 [==============================] - 1s 26ms/step\n",
      "54/54 [==============================] - 1s 26ms/step\n",
      "54/54 [==============================] - 1s 26ms/step\n",
      "0.6125393778774827 0.8743209111549864 0.5311355311355311\n",
      "REFIT_7\n",
      "2\n",
      "66/66 [==============================] - 2s 32ms/step\n",
      "66/66 [==============================] - 2s 26ms/step\n",
      "66/66 [==============================] - 2s 26ms/step\n",
      "66/66 [==============================] - 2s 26ms/step\n",
      "66/66 [==============================] - 2s 25ms/step\n",
      "0.6184004394121984 0.8309242965030035 0.5740226986128626\n",
      "REFIT_15\n",
      "2\n",
      "60/60 [==============================] - 2s 25ms/step\n",
      "60/60 [==============================] - 2s 25ms/step\n",
      "60/60 [==============================] - 2s 25ms/step\n",
      "60/60 [==============================] - 2s 25ms/step\n",
      "60/60 [==============================] - 2s 25ms/step\n",
      "0.4571135315464248 0.8047035226950325 0.4426062980699463\n",
      "REFIT_12\n",
      "2\n",
      "55/55 [==============================] - 1s 26ms/step\n",
      "55/55 [==============================] - 1s 26ms/step\n",
      "55/55 [==============================] - 1s 25ms/step\n",
      "55/55 [==============================] - 1s 25ms/step\n",
      "55/55 [==============================] - 1s 26ms/step\n",
      "0.6213138032576755 0.9043113210512488 0.5349623482403565\n",
      "REFIT_4\n",
      "2\n",
      "67/67 [==============================] - 2s 26ms/step\n",
      "67/67 [==============================] - 2s 26ms/step\n",
      "67/67 [==============================] - 2s 25ms/step\n",
      "67/67 [==============================] - 2s 25ms/step\n",
      "67/67 [==============================] - 2s 26ms/step\n",
      "0.5927398444822197 0.8935679968195096 0.511986301369863\n",
      "REFIT_3\n",
      "2\n",
      "68/68 [==============================] - 2s 25ms/step\n",
      "68/68 [==============================] - 2s 25ms/step\n",
      "68/68 [==============================] - 2s 25ms/step\n",
      "68/68 [==============================] - 2s 25ms/step\n",
      "68/68 [==============================] - 2s 25ms/step\n",
      "0.5835016399019964 0.742024950596074 0.5790172642762285\n",
      "REFIT_18\n",
      "2\n",
      "52/52 [==============================] - 2s 31ms/step\n",
      "52/52 [==============================] - 1s 26ms/step\n",
      "52/52 [==============================] - 1s 25ms/step\n",
      "52/52 [==============================] - 1s 26ms/step\n",
      "52/52 [==============================] - 1s 25ms/step\n",
      "0.6613141886259535 0.9273352337435147 0.5542554673352834\n",
      "REFIT_11\n",
      "2\n",
      "43/43 [==============================] - 1s 25ms/step\n",
      "43/43 [==============================] - 1s 25ms/step\n",
      "43/43 [==============================] - 1s 25ms/step\n",
      "43/43 [==============================] - 1s 25ms/step\n",
      "43/43 [==============================] - 1s 26ms/step\n",
      "0.3239436741091002 0.7806991503168546 0.28835462058602557\n",
      "REFIT_16\n",
      "2\n",
      "55/55 [==============================] - 1s 26ms/step\n",
      "55/55 [==============================] - 1s 26ms/step\n",
      "55/55 [==============================] - 1s 25ms/step\n",
      "55/55 [==============================] - 1s 26ms/step\n",
      "55/55 [==============================] - 1s 26ms/step\n",
      "0.608615766294815 0.6987664035047385 0.5841446453407511\n",
      "REFIT_17\n",
      "2\n",
      "55/55 [==============================] - 1s 26ms/step\n",
      "55/55 [==============================] - 1s 26ms/step\n",
      "55/55 [==============================] - 1s 26ms/step\n",
      "55/55 [==============================] - 1s 25ms/step\n",
      "55/55 [==============================] - 1s 25ms/step\n",
      "0.6129264919242996 0.9148831072099401 0.5414779631061527\n",
      "REFIT_10\n",
      "2\n",
      "63/63 [==============================] - 2s 25ms/step\n",
      "63/63 [==============================] - 2s 25ms/step\n",
      "63/63 [==============================] - 2s 25ms/step\n",
      "63/63 [==============================] - 2s 25ms/step\n",
      "63/63 [==============================] - 2s 25ms/step\n",
      "0.49508534801038906 0.7048704588249881 0.47951558876578204\n",
      "REFIT_19\n",
      "2\n",
      "54/54 [==============================] - 1s 25ms/step\n",
      "54/54 [==============================] - 1s 25ms/step\n",
      "54/54 [==============================] - 1s 25ms/step\n",
      "54/54 [==============================] - 1s 25ms/step\n",
      "54/54 [==============================] - 1s 26ms/step\n",
      "0.47783858611386104 0.6254716616733725 0.41051616015436565\n",
      "REFIT_2\n",
      "2\n",
      "57/57 [==============================] - 2s 33ms/step\n",
      "57/57 [==============================] - 1s 26ms/step\n",
      "57/57 [==============================] - 1s 26ms/step\n",
      "57/57 [==============================] - 1s 26ms/step\n",
      "57/57 [==============================] - 1s 26ms/step\n",
      "0.4822822485346139 0.7896359941103305 0.4353133839511687\n",
      "REFIT_5\n",
      "2\n",
      "72/72 [==============================] - 2s 27ms/step\n",
      "72/72 [==============================] - 2s 25ms/step\n",
      "72/72 [==============================] - 2s 25ms/step\n",
      "72/72 [==============================] - 2s 26ms/step\n",
      "72/72 [==============================] - 2s 25ms/step\n",
      "0.5289473319012725 0.7802312454689498 0.4613081873970962\n",
      "UKDALE_5\n",
      "2\n",
      "17/17 [==============================] - 0s 25ms/step\n",
      "17/17 [==============================] - 0s 25ms/step\n",
      "17/17 [==============================] - 0s 25ms/step\n",
      "17/17 [==============================] - 0s 25ms/step\n",
      "17/17 [==============================] - 0s 25ms/step\n",
      "0.29220143640157703 0.5050456606805548 0.24193294506532348\n",
      "UKDALE_2\n",
      "2\n",
      "25/25 [==============================] - 1s 25ms/step\n",
      "25/25 [==============================] - 1s 25ms/step\n",
      "25/25 [==============================] - 1s 25ms/step\n",
      "25/25 [==============================] - 1s 26ms/step\n",
      "25/25 [==============================] - 1s 25ms/step\n",
      "0.2287783570121012 0.2753419158712448 0.2076704895794796\n",
      "UKDALE_1\n",
      "2\n",
      "198/198 [==============================] - 5s 26ms/step\n",
      "198/198 [==============================] - 5s 26ms/step\n",
      "198/198 [==============================] - 5s 25ms/step\n",
      "198/198 [==============================] - 5s 25ms/step\n",
      "198/198 [==============================] - 5s 25ms/step\n",
      "0.1896290030041717 0.4496575532812503 0.1608097535532664\n",
      "UKDALE_3\n",
      "2\n",
      "5/5 [==============================] - 0s 25ms/step\n",
      "5/5 [==============================] - 0s 26ms/step\n",
      "5/5 [==============================] - 0s 26ms/step\n",
      "5/5 [==============================] - 0s 26ms/step\n",
      "5/5 [==============================] - 0s 26ms/step\n",
      "0.033344139304404205 0.2980132450331126 0.017660044150110375\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "labels = pd.read_pickle(labels_path)\n",
    "\n",
    "for f in os.listdir(\"./models/test_IDEAL/\"):\n",
    "        if \"last\" in f:\n",
    "            model = tf.keras.models.load_model(\"./models/test_IDEAL/\"+f, custom_objects={'F1Score': NUK.F1Score, \"WeightedF1\": NUK.WeightedF1Score(class_weighs_pre)})\n",
    "            models.append(model)\n",
    "\n",
    "for h in processed:\n",
    "    print(h)\n",
    "    df = processed[h]\n",
    "    curr_devices, real_str = get_devices(data[h])\n",
    "    X = np.array([i[0] for i in df])\n",
    "    y = np.array([i[1] for i in df])\n",
    "    X= normalize(X)\n",
    "    print(len(X.shape))\n",
    "\n",
    "    if len(X.shape) !=2 or X.shape[1] != 2688:\n",
    "        print(\"wrong shape\", X.shape)\n",
    "        continue\n",
    "    \n",
    "    model_predictions = []\n",
    "    for m in models:\n",
    "            y_pred = m.predict(X)\n",
    "            model_predictions.append(y_pred)\n",
    "\n",
    "\n",
    "    y_pred_avg = np.mean(model_predictions, axis=0)\n",
    "    y_pred_tf = np.where(y_pred_avg > 0.3, 1, 0)\n",
    "\n",
    "    y_pred_num_devices = np.sum(y_pred_tf, axis=1)\n",
    "    y_real_num_devices = np.sum(y, axis=1)\n",
    "\n",
    "    # print(\"average number of devices misspredcited: \", np.mean(y_pred_num_devices - y_real_num_devices)\t)\n",
    "\n",
    "    res = metrics.classification_report(y, y_pred_tf, target_names=labels, zero_division=0, output_dict=True)\n",
    "    print(res[\"weighted avg\"][\"f1-score\"], res[\"weighted avg\"][\"precision\"], res[\"weighted avg\"][\"recall\"])\n",
    "\n",
    "    # barplot y_pred_tf\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.bar(labels, y_pred_tf.sum(axis=0))\n",
    "    # plt.title(h + real_str + \"f1: \"+ str(res[\"weighted avg\"][\"f1-score\"]) + \"precision: \"+ str(res[\"weighted avg\"][\"precision\"]) + \"recall: \"+ str(res[\"weighted avg\"][\"recall\"]))\n",
    "    plt.title(h + \" f1: \"+ str(res[\"weighted avg\"][\"f1-score\"])[:5] + \" average number of devices misspredcited: \" + str(np.mean(y_pred_num_devices - y_real_num_devices))[:5]\t)\n",
    "\n",
    "    # Get current axis\n",
    "    ax = plt.gca()\n",
    "\n",
    "    # Loop through label list and set the color to red for highlighted labels\n",
    "    for label in ax.get_xticklabels():\n",
    "        if label.get_text() in curr_devices:\n",
    "            label.set_color('red')\n",
    "\n",
    "    # Rotate all labels\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.savefig(f\"./plots/real_ideal/{h}_barplot.svg\", format=\"svg\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "[[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "pc\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Closing remaining open files:/tmp/nilmtk-zbuuzryk.h5...done\n"
     ]
    }
   ],
   "source": [
    "tb = pd.read_pickle(\"../../Energy_graph/data/tracebase/devices_data.pkl\")\n",
    "device = \"washing machine\"\n",
    "from random import randint\n",
    "i = randint(0, len(tb[device])-1)\n",
    "offset = randint(0, len(tb[device][i])-2688)\n",
    "x = tb[device][i][offset:offset+2668].copy()\n",
    "x[x<5] = 0\n",
    "plt.plot(x)\n",
    "x = x.values.reshape(1, -1)\n",
    "# print(x.values.reshape(1, -1)[0])\n",
    "model_predictions = []\n",
    "for m in models:\n",
    "    y_pred = m.predict(x)\n",
    "    model_predictions.append(y_pred)\n",
    "    \n",
    "y_pred_avg = np.mean(model_predictions, axis=0)\n",
    "y_pred_tf = np.where(y_pred_avg > 0.3, 1, 0)\n",
    "print(y_pred_tf)\n",
    "for i in range(len(labels)):\n",
    "    if y_pred_tf[0][i] == 1:\n",
    "        print(labels[i])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "def preprocess_string(string : str) -> str:\n",
    "    string = string.lower().strip()\n",
    "    string = re.sub(' +', ' ', string)\n",
    "    string = string.replace(\"_\", \" \")\n",
    "    string = string.replace(\"-\", \" \")\n",
    "    string = string.replace(\"&\", \" \")\n",
    "    string = string.split(\"(\")[0]\n",
    "    string = string.split(\"#\")[0]\n",
    "\n",
    "    string = string.strip()\n",
    "\n",
    "    # handle known synoynms\n",
    "    synonyms = {\n",
    "        \"refrigerator\": \"fridge\",\n",
    "        \"vaccumcleaner\": \"vacuum cleaner\",\n",
    "        \"breadmaker\": \"bread maker\",\n",
    "      \n",
    "        \n",
    "    }\n",
    "    if \"freezer\" in string:\n",
    "        string = \"fridge\"\n",
    "\n",
    "    if string in synonyms:\n",
    "        string = synonyms[string]\n",
    "\n",
    "    if 'hi fi' in string:\n",
    "        string = \"audio system\"\n",
    "\n",
    "    if \"router\" in string:\n",
    "        string = \"router\"\n",
    "\n",
    "    if \"treadmill\" in string:\n",
    "        string = \"running machine\"\n",
    "        \n",
    "\n",
    "    if \"laptop\" in string:\n",
    "        string = \"laptop\"\n",
    "    \n",
    "    if \"server\" in string:\n",
    "        string = \"server\"\n",
    "\n",
    "    if \"monitor\" in string and not \"baby\" in string:\n",
    "        string = \"monitor\"\n",
    "    # special cases\n",
    "    if \"computer\" in string and \"charger\" not in string:\n",
    "        string = \"pc\"\n",
    "\n",
    "    if \"tv\" in string:\n",
    "        string = \"television\"\n",
    "\n",
    "    if \"television\" in string:\n",
    "        string = \"television\"\n",
    "\n",
    "    if \"macbook\" in string:\n",
    "        string = \"laptop\"\n",
    "        \n",
    "    if \"car charger\" == string:\n",
    "        string = \"ev\"\n",
    "    \n",
    "    if \"toast\" in string:\n",
    "        string = \"toaster\"\n",
    "    \n",
    "    if \"modem\" in string:\n",
    "        string = \"router\"\n",
    "\n",
    "    # we treat all audio devices as speakers so subwoofer is also a speaker\n",
    "    if \"subwoofer\" in string:\n",
    "        string = \"speaker\"\n",
    "\n",
    "    if \"speaker\" in string:\n",
    "        string = \"speaker\"\n",
    "\n",
    "    if \"iron\" in string and \"soldering\" not in string:\n",
    "        string = \"iron\"\n",
    "\n",
    "    \n",
    "    if \"coffeemachine\" in string:\n",
    "        string = \"coffee machine\"\n",
    "    if \"coffee maker\" in string:\n",
    "        string = \"coffee machine\"\n",
    "\n",
    "    if \"dishwasher\" in string:\n",
    "        string = \"dish washer\"\n",
    "    if \"air conditioner\" in string:\n",
    "        string = \"ac\"\n",
    "\n",
    "    if \"air conditioning\" in string:\n",
    "        string = \"ac\"\n",
    "    \n",
    "    string = re.sub(' +', ' ', string)\n",
    "    string = re.sub(r'\\d+', '', string)\n",
    "    return string.strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3125/3125 [==============================] - 80s 25ms/step\n",
      "3125/3125 [==============================] - 81s 26ms/step\n",
      "3125/3125 [==============================] - 81s 26ms/step\n",
      "3125/3125 [==============================] - 80s 26ms/step\n",
      "3125/3125 [==============================] - 80s 25ms/step\n",
      "Ensemble:  0.05498499229837306 0.11609638926021774 0.08664122375031907\n",
      "Single_0:  0.05454351664771011 0.11638884656663885 0.07865223102832133\n",
      "Single_1:  0.049593168530481076 0.1060938875113711 0.07316602436792201\n",
      "Single_2:  0.05078556918896599 0.11523552292479254 0.07438628821885059\n",
      "Single_3:  0.05283913267450157 0.11186682159508442 0.0734636193274852\n",
      "Single_4:  0.052719927047926246 0.1114511583901698 0.07810809296418277\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>microwave</th>\n",
       "      <td>0.161126</td>\n",
       "      <td>0.593877</td>\n",
       "      <td>0.253480</td>\n",
       "      <td>12772.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>air exchanger</th>\n",
       "      <td>0.145669</td>\n",
       "      <td>0.014225</td>\n",
       "      <td>0.025919</td>\n",
       "      <td>13005.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combination microwave</th>\n",
       "      <td>0.165685</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.094123</td>\n",
       "      <td>12840.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>router</th>\n",
       "      <td>0.133913</td>\n",
       "      <td>0.006010</td>\n",
       "      <td>0.011503</td>\n",
       "      <td>12813.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water purifier</th>\n",
       "      <td>0.856909</td>\n",
       "      <td>0.121826</td>\n",
       "      <td>0.213324</td>\n",
       "      <td>12879.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stove</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro avg</th>\n",
       "      <td>0.165996</td>\n",
       "      <td>0.086641</td>\n",
       "      <td>0.113856</td>\n",
       "      <td>803105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.114437</td>\n",
       "      <td>0.085215</td>\n",
       "      <td>0.054144</td>\n",
       "      <td>803105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.116096</td>\n",
       "      <td>0.086641</td>\n",
       "      <td>0.054985</td>\n",
       "      <td>803105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samples avg</th>\n",
       "      <td>0.145674</td>\n",
       "      <td>0.081627</td>\n",
       "      <td>0.097161</td>\n",
       "      <td>803105.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       precision    recall  f1-score   support\n",
       "microwave               0.161126  0.593877  0.253480   12772.0\n",
       "air exchanger           0.145669  0.014225  0.025919   13005.0\n",
       "combination microwave   0.165685  0.065732  0.094123   12840.0\n",
       "router                  0.133913  0.006010  0.011503   12813.0\n",
       "water purifier          0.856909  0.121826  0.213324   12879.0\n",
       "...                          ...       ...       ...       ...\n",
       "stove                   0.000000  0.000000  0.000000   12640.0\n",
       "micro avg               0.165996  0.086641  0.113856  803105.0\n",
       "macro avg               0.114437  0.085215  0.054144  803105.0\n",
       "weighted avg            0.116096  0.086641  0.054985  803105.0\n",
       "samples avg             0.145674  0.081627  0.097161  803105.0\n",
       "\n",
       "[68 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder = \"\"\n",
    "path_to_base = \"../../Energy_graph/\"\n",
    "path = path_to_base + \"/data/processed_watts/\"+folder\n",
    "labels_path = path_to_base + \"/data/labels_new.pkl\"\n",
    "save_path = path_to_base + \"/data/training_data/processed/\"+folder\n",
    "\n",
    "models = []\n",
    "labels = pd.read_pickle(labels_path)\n",
    "\n",
    "for f in os.listdir(\"./models/bfloat_normalized/\"):\n",
    "        if \"last\" in f:\n",
    "            model = tf.keras.models.load_model(\"./models/bfloat_normalized/\"+f, custom_objects={'F1Score': NUK.F1Score, \"WeightedF1\": NUK.WeightedF1Score(class_weighs_pre)})\n",
    "            models.append(model)\n",
    "\n",
    "\n",
    "X= normalize(X)\n",
    "print(len(X.shape))\n",
    "\n",
    "if len(X.shape) !=2 or X.shape[1] != 2688:\n",
    "    print(\"wrong shape\", X.shape)\n",
    "\n",
    "model_predictions = []\n",
    "for m in models:\n",
    "        y_pred = m.predict(X)\n",
    "        model_predictions.append(y_pred)\n",
    "\n",
    "\n",
    "\n",
    "y_pred_avg = np.mean(model_predictions, axis=0)\n",
    "y_pred_tf = np.where(y_pred_avg > 0.3, 1, 0)\n",
    "\n",
    "y_pred_num_devices = np.sum(y_pred_tf, axis=1)\n",
    "y_real_num_devices = np.sum(y, axis=1)\n",
    "\n",
    "# print(\"average number of devices misspredcited: \", np.mean(y_pred_num_devices - y_real_num_devices)\t)\n",
    "path = \"../../Energy_graph/data/results/test\"\n",
    "# check if directory exsits\n",
    "if not os.path.exists(f\"{path}\"):\n",
    "    os.makedirs(f\"{path}\")\n",
    "\n",
    "\n",
    "res = metrics.classification_report(y, y_pred_tf, target_names=labels, zero_division=0, output_dict=True)\n",
    "df = pd.DataFrame(res).T\n",
    "\n",
    "df.to_csv(f\"{path}/ensemble.csv\")\n",
    "\n",
    "print(\"Ensemble: \", res[\"weighted avg\"][\"f1-score\"], res[\"weighted avg\"][\"precision\"], res[\"weighted avg\"][\"recall\"])\n",
    "for i, p in enumerate(model_predictions):\n",
    "    y_pred_tf = np.where(p > 0.3, 1, 0)\n",
    "    single = metrics.classification_report(y, y_pred_tf, target_names=labels, zero_division=0, output_dict=True)\n",
    "    df = pd.DataFrame(single).T\n",
    "    df.to_csv(f\"{path}/single_{i}.csv\")\n",
    "    print(f\"Single_{i}: \", single[\"weighted avg\"][\"f1-score\"], single[\"weighted avg\"][\"precision\"], single[\"weighted avg\"][\"recall\"])\n",
    "\n",
    "# # barplot y_pred_tf\n",
    "# plt.figure(figsize=(20,10))\n",
    "# plt.bar(labels, y_pred_tf.sum(axis=0))\n",
    "# # plt.title(h + real_str + \"f1: \"+ str(res[\"weighted avg\"][\"f1-score\"]) + \"precision: \"+ str(res[\"weighted avg\"][\"precision\"]) + \"recall: \"+ str(res[\"weighted avg\"][\"recall\"]))\n",
    "# plt.title(\" f1: \"+ str(res[\"weighted avg\"][\"f1-score\"])[:5] + \" average number of devices misspredcited: \" + str(np.mean(y_pred_num_devices - y_real_num_devices))[:5]\t)\n",
    "\n",
    "# # Get current axis\n",
    "# ax = plt.gca()\n",
    "\n",
    "# # Loop through label list and set the color to red for highlighted labels\n",
    "# for label in ax.get_xticklabels():\n",
    "#     if label.get_text() in curr_devices:\n",
    "#         label.set_color('red')\n",
    "\n",
    "# # Rotate all labels\n",
    "# plt.xticks(rotation=90)\n",
    "# plt.savefig(f\"./plots/real_ideal/test_barplot.svg\", format=\"svg\")\n",
    "# plt.close()\n",
    "pd.DataFrame(res).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"\"\n",
    "path_to_base = \"../../Energy_graph/\"\n",
    "path = path_to_base + \"/data/processed_watts/\"+folder\n",
    "labels_path = path_to_base + \"/data/labels_new.pkl\"\n",
    "save_path = path_to_base + \"/data/training_data/processed/\"+folder\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)\n",
    "X_test= normalize(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations, permutations, combinations_with_replacement\n",
    "\n",
    "def comb_ix(nm_devices : int):\n",
    "    \"\"\"Returns all possible combinations of indexes for a given number of devices\"\"\"\n",
    "    models = [0,1,2,3,4,5,6,7,8,9]\n",
    "\n",
    "   \n",
    "    return list(combinations(models, nm_devices))\n",
    "    \n",
    "\n",
    "\n",
    "ixs = comb_ix(4)\n",
    "for i in ixs:\n",
    "    for j in i:\n",
    "        print(j)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 16s 25ms/step\n",
      "625/625 [==============================] - 16s 25ms/step\n",
      "625/625 [==============================] - 16s 25ms/step\n",
      "625/625 [==============================] - 17s 25ms/step\n",
      "625/625 [==============================] - 16s 25ms/step\n",
      "625/625 [==============================] - 16s 25ms/step\n",
      "625/625 [==============================] - 16s 25ms/step\n",
      "625/625 [==============================] - 16s 25ms/step\n",
      "625/625 [==============================] - 16s 25ms/step\n",
      "625/625 [==============================] - 16s 25ms/step\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "models = []\n",
    "labels = pd.read_pickle(labels_path)\n",
    "\n",
    "for f in os.listdir(\"./models/bfloat_10models/\"):\n",
    "        if \"last\" in f:\n",
    "            model = tf.keras.models.load_model(\"./models/bfloat_10models/\"+f, custom_objects={'F1Score': NUK.F1Score, \"WeightedF1\": NUK.WeightedF1Score(class_weighs_pre)})\n",
    "            models.append(model)\n",
    "\n",
    "\n",
    "\n",
    "# print(len(X.shape))\n",
    "\n",
    "# if len(X.shape) !=2 or X.shape[1] != 2688:\n",
    "#     print(\"wrong shape\", X.shape)\n",
    "\n",
    "model_predictions = []\n",
    "for m in models:\n",
    "        y_pred = m.predict(X_test)\n",
    "        model_predictions.append(y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000e+00, 0.0000e+00, 3.9444e-03, ..., 2.1327e-04, 0.0000e+00,\n",
       "        0.0000e+00],\n",
       "       [2.5511e-04, 1.2245e-02, 2.2006e-04, ..., 1.3571e-03, 7.4348e-03,\n",
       "        1.0000e+00],\n",
       "       [2.1327e-04, 1.3635e-01, 1.2751e-03, ..., 9.8572e-03, 0.0000e+00,\n",
       "        1.0000e+00],\n",
       "       ...,\n",
       "       [4.9114e-05, 6.0156e-01, 3.0060e-03, ..., 5.6000e-03, 9.9609e-01,\n",
       "        7.4921e-03],\n",
       "       [5.4216e-04, 2.9743e-05, 1.2751e-03, ..., 0.0000e+00, 1.1292e-02,\n",
       "        1.6868e-04],\n",
       "       [0.0000e+00, 1.5488e-03, 1.8101e-03, ..., 1.9264e-04, 2.5501e-03,\n",
       "        0.0000e+00]], dtype=float16)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_predictions[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(1, 11):\n",
    "    ixs = comb_ix(i)\n",
    "    num_models = []\n",
    "    for c in ixs:\n",
    "        model_preds = []\n",
    "        for ix in c:\n",
    "            model_preds.append(model_predictions[ix])\n",
    "\n",
    "        y_pred_avg = np.mean(model_preds, axis=0)\n",
    "        y_pred_tf = np.where(y_pred_avg > 0.3, 1, 0)\n",
    "        res = pd.DataFrame(metrics.classification_report(y_test, y_pred_tf, target_names=labels, zero_division=0, output_dict=True)).T\n",
    "        num_models.append(res)\n",
    "    for j in range(len(ixs)):\n",
    "        if j == 0:\n",
    "            df = num_models[j]\n",
    "        else:\n",
    "            df = df + num_models[j]\n",
    "\n",
    "    df = df / len(ixs)\n",
    "    \n",
    "    if not os.path.exists(f\"./results/ensemble_size/\"):\n",
    "        os.makedirs(f\"./results/ensemble_size/\")\n",
    "    df.to_csv(f\"./results/ensemble_size/ensemble_{i}.csv\")        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6132653705922293"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./results/ensemble_size/ensemble_9.csv\")\n",
    "df.iloc[-1][\"f1-score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"ensemble_10.csv\"\n",
    "s.split(\".\")[0].split(\"_\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.52475732066064,\n",
       " 0.5429123868426358,\n",
       " 0.5610001311667624,\n",
       " 0.5885157999613718,\n",
       " 0.594929888884552,\n",
       " 0.6007234317445148,\n",
       " 0.6074799677840642,\n",
       " 0.6106276702850365,\n",
       " 0.6132653705922293,\n",
       " 0.6157832451348068]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "data = {}\n",
    "for i,f in enumerate(os.listdir(\"./results/ensemble_size/\")):\n",
    "    if f.endswith(\".csv\"):\n",
    "        df = pd.read_csv(\"./results/ensemble_size/\"+f)\n",
    "        data[f.split(\".\")[0].split(\"_\")[1]]= df.iloc[-1][\"f1-score\"]\n",
    "res = []\n",
    "\n",
    "for i in range(1, 11):\n",
    "    res.append(data[str(i)])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Closing remaining open files:/tmp/nilmtk-otyx702b.h5...done\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Example data - replace this with your actual 'res' data\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot([1, 2, 3, 4, 5, 6 , 7, 8 ,9, 10], res)  # Explicitly setting x-values from 1 to 5\n",
    "plt.xticks([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])  # Setting x-ticks\n",
    "plt.xlabel(\"Number of models\")\n",
    "plt.ylabel(\"F1-score\")\n",
    "plt.title(\"Ensemble size vs F1-score\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "data = pd.read_pickle(\"../../Energy_graph/data/training_data/synthetic/X_Y_wsize2688_numW_50001_upper32_gap3600_numD64_ideal.pkl\")\n",
    "\n",
    "X = np.array([i[0] for i in data])\n",
    "y = np.array([i[1] for i in data])\n",
    "\n",
    "X = normalize(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       ...,\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, len(X)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "real:   dryer\n",
      "pred:   pc television\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ix = randint(0, len(X)-1)\n",
    "# x = X[ix]\n",
    "\n",
    "predictions = []\n",
    "for m in models:\n",
    "    y_pred = m.predict(X[ix].reshape(1, -1))\n",
    "    predictions.append(y_pred)\n",
    "\n",
    "y_pred_avg = np.mean(predictions, axis=0)\n",
    "y_pred_tf = np.where(y_pred_avg > 0.3, 1, 0)\n",
    "\n",
    "labels = pd.read_pickle(labels_path)\n",
    "pred = \"\"\n",
    "real = \"\"\n",
    "for i in range(len(labels)):\n",
    "    if y[ix][i] == 1:\n",
    "        real+=\" \" + str(labels[i])\n",
    "    if y_pred_tf[0][i] == 1:\n",
    "        pred+= \" \" + str(labels[i])\n",
    "plt.plot(X[ix])\n",
    "plt.show()\n",
    "\n",
    "print()\n",
    "print(\"real: \", real)\n",
    "print(\"pred: \", pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
