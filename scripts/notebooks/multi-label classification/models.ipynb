{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... By downloading and using the CUDA Toolkit conda packages, you accept the terms and conditions of the CUDA End User License Agreement (EULA): https://docs.nvidia.com/cuda/eula/index.html\n",
      "\n",
      "By downloading and using the cuDNN conda packages, you accept the terms and conditions of the NVIDIA cuDNN EULA -\n",
      "  https://docs.nvidia.com/deeplearning/cudnn/sla/index.html\n",
      "\n",
      "done\n",
      "\u001b[33mWARNING: Skipping nilmtk as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping nilm_metadata as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting git+https://github.com/nilmtk/nilmtk@master\n",
      "  Cloning https://github.com/nilmtk/nilmtk (to revision master) to /tmp/pip-req-build-ot9r2dgv\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/nilmtk/nilmtk /tmp/pip-req-build-ot9r2dgv\n",
      "  Resolved https://github.com/nilmtk/nilmtk to commit b2c514479cef478cab872cb635056da08d5352a1\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: nilmtk\n",
      "  Building wheel for nilmtk (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nilmtk: filename=nilmtk-0.4.0.dev1+git.b2c5144-py3-none-any.whl size=279177 sha256=e515eb3da48ed15433c9cde73ab2c0b5511c1a2a0b342e0816d51b24055ae9cb\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-61qfitsc/wheels/05/a4/8e/b767c3d1714f61fd30ec991c25780be8cc04c474da8205aeee\n",
      "Successfully built nilmtk\n",
      "Installing collected packages: nilmtk\n",
      "Successfully installed nilmtk-0.4.0.dev1+git.b2c5144\n",
      "Collecting git+https://github.com/nilmtk/nilm_metadata@master\n",
      "  Cloning https://github.com/nilmtk/nilm_metadata (to revision master) to /tmp/pip-req-build-sgwb8sfg\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/nilmtk/nilm_metadata /tmp/pip-req-build-sgwb8sfg\n",
      "  Resolved https://github.com/nilmtk/nilm_metadata to commit 7ed4bab9062d04cb35c6b6000b451715dc5ab4af\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: nilm-metadata\n",
      "  Building wheel for nilm-metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nilm-metadata: filename=nilm_metadata-0.2.5-py3-none-any.whl size=24340 sha256=8993596dc6def3df5c334c2d98d267ed4fb44392406e76381bbf6f9d0c2ffed4\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-d9l7wq36/wheels/7e/2f/7f/e41975c202542dbc11228875ff8473ed4cb95e04a274222bb7\n",
      "Successfully built nilm-metadata\n",
      "Installing collected packages: nilm-metadata\n",
      "Successfully installed nilm-metadata-0.2.5\n"
     ]
    }
   ],
   "source": [
    "#!rm -r /home/jovyan/.local/share/jupyter/kernels/nilmtk\n",
    "!mamba install tensorflow-gpu==2.10 -y -q\n",
    "#!mamba install tensorflow-gpu==2.11.0 -y -q\n",
    "!pip uninstall -y -q nilmtk nilm_metadata\n",
    "#!pip install -q pandas networkx tables scikit-learn hmmlearn pyyaml matplotlib==3.1.3 xgboost pyts\n",
    "# Trick to install NILM regardless of its dependencies\n",
    "#!pip install --no-cache -U git+https://github.com/nilmtk/nilm_metadata.git\n",
    "#!pip install --no-cache -U git+https://github.com/nilmtk/nilmtk.git@0.4.3\n",
    "!python3 -m pip install --no-deps git+https://github.com/nilmtk/nilmtk@master\n",
    "!python3 -m pip install --no-deps git+https://github.com/nilmtk/nilm_metadata@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-06 07:38:46.932210: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA A100 80GB PCIe MIG 3g.40gb, compute capability 8.0\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from nilmtk import DataSet\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from joblib import Memory\n",
    "import pickle\n",
    "from pprint import pprint\n",
    "\n",
    "#from nilmtk import DataSet\n",
    "import multiprocessing as mp\n",
    "\n",
    "from typing import Dict\n",
    "\n",
    "!pip install -q scikit-learn-intelex\n",
    "#from sklearnex import patch_sklearn\n",
    "#patch_sklearn()\n",
    "\n",
    "from sklearn import pipeline, metrics, linear_model, model_selection, multioutput, tree, ensemble, neural_network\n",
    "!pip install xgboost -q\n",
    "import xgboost as xgb\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import cross_val_predict, train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "import numpy as np\n",
    "#import graphviz\n",
    "import keras\n",
    "from sklearn.utils import class_weight\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#from ann_visualizer.visualize import ann_viz\n",
    "from matplotlib import pyplot as plt \n",
    "from sklearn.metrics import multilabel_confusion_matrix, classification_report, confusion_matrix\n",
    "# GPU goes brrrrrrrrrrrrrrrrrrrr\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "!pip3 install tqdm -q\n",
    "from tqdm import tqdm\n",
    "import NUK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HolyDataset_UKD = pickle.load(open('./datasets/HolyDatasetDALE.pkl', 'rb'))\n",
    "HolyDataset_REF = pickle.load(open('./datasets/HolyDataset.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the data for the neural network\n",
    "\n",
    "for dataset in "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "epochs = 20\n",
    "window_size = 2550\n",
    "batch_size = 256\n",
    "NmDevices = 96\n",
    "# table_of_options = [1,2,3,4]\n",
    "k = 0.5\n",
    "# Define a learning rate scheduler function\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "test_size = 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# x_UKD, y_UKD, labels_UKD = HolyDataset_UKD[0], HolyDataset_UKD[2], HolyDataset_UKD[4]\n",
    "# class_weights_UKD = NUK.class_weights_tool(y_UKD)\n",
    "\n",
    "# x_REF, y_REF, labels_REF = HolyDataset_REF[0], HolyDataset_REF[2], HolyDataset_REF[4]\n",
    "# class_weights_REF = NUK.class_weights_tool(y_REF)\n",
    "\n",
    "\n",
    "# # For UKD dataset\n",
    "# x_train_UKD, x_test_UKD, y_train_UKD, y_test_UKD = train_test_split(x_UKD, y_UKD, test_size=test_size, random_state=RANDOM_SEED)\n",
    "\n",
    "# # For REF dataset\n",
    "# x_train_REF, x_test_REF, y_train_REF, y_test_REF = train_test_split(x_REF, y_REF, test_size=test_size, random_state=RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"../../Energy_graph/data/processed_all_X_Y.pkl\")\n",
    "labels = pd.read_pickle(\"../../Energy_graph/labeles.pkl\")\n",
    "# Separate the tuples into X and y\n",
    "X = np.array([i[0] for i in data])\n",
    "y = np.array([i[1] for i in data])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train indices: [    0     1     2 ... 50074 50075 50076] Test indices: [    4     6     7 ... 50066 50067 50073]\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "157/157 [==============================] - 16s 58ms/step - loss: 0.1437 - F1Score: 0.0146 - WeightedF1: 0.2117 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "157/157 [==============================] - 7s 41ms/step - loss: 0.0811 - F1Score: 0.0142 - WeightedF1: 0.2120 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "157/157 [==============================] - 6s 41ms/step - loss: 0.0812 - F1Score: 0.0130 - WeightedF1: 0.1939 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "157/157 [==============================] - 6s 41ms/step - loss: 0.0812 - F1Score: 0.0135 - WeightedF1: 0.2007 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0812 - F1Score: 0.0139 - WeightedF1: 0.2069 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0811 - F1Score: 0.0140 - WeightedF1: 0.2088 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "157/157 [==============================] - 7s 43ms/step - loss: 0.0812 - F1Score: 0.0136 - WeightedF1: 0.2029 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0811 - F1Score: 0.0133 - WeightedF1: 0.1981 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0811 - F1Score: 0.0142 - WeightedF1: 0.2113 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0811 - F1Score: 0.0139 - WeightedF1: 0.2080 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0811 - F1Score: 0.0142 - WeightedF1: 0.2126 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "157/157 [==============================] - 7s 41ms/step - loss: 0.0810 - F1Score: 0.0145 - WeightedF1: 0.2170 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0810 - F1Score: 0.0145 - WeightedF1: 0.2162 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "157/157 [==============================] - 7s 43ms/step - loss: 0.0810 - F1Score: 0.0147 - WeightedF1: 0.2190 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "157/157 [==============================] - 6s 41ms/step - loss: 0.0810 - F1Score: 0.0147 - WeightedF1: 0.2190 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0810 - F1Score: 0.0146 - WeightedF1: 0.2176 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0810 - F1Score: 0.0147 - WeightedF1: 0.2190 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0810 - F1Score: 0.0144 - WeightedF1: 0.2154 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0810 - F1Score: 0.0147 - WeightedF1: 0.2189 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "157/157 [==============================] - 7s 43ms/step - loss: 0.0810 - F1Score: 0.0147 - WeightedF1: 0.2190 - lr: 1.1036e-04\n",
      "313/313 [==============================] - 2s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [02:26, 146.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train indices: [    2     3     4 ... 50074 50075 50076] Test indices: [    0     1    11 ... 50063 50065 50070]\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "157/157 [==============================] - 9s 41ms/step - loss: 0.1406 - F1Score: 0.0136 - WeightedF1: 0.1939 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "157/157 [==============================] - 6s 41ms/step - loss: 0.0810 - F1Score: 0.0132 - WeightedF1: 0.1957 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "157/157 [==============================] - 6s 41ms/step - loss: 0.0810 - F1Score: 0.0131 - WeightedF1: 0.1937 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "157/157 [==============================] - 6s 41ms/step - loss: 0.0810 - F1Score: 0.0137 - WeightedF1: 0.2032 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "157/157 [==============================] - 6s 41ms/step - loss: 0.0810 - F1Score: 0.0142 - WeightedF1: 0.2093 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0810 - F1Score: 0.0133 - WeightedF1: 0.1965 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0810 - F1Score: 0.0142 - WeightedF1: 0.2108 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "157/157 [==============================] - 7s 43ms/step - loss: 0.0810 - F1Score: 0.0134 - WeightedF1: 0.1988 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0809 - F1Score: 0.0140 - WeightedF1: 0.2073 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0808 - F1Score: 0.0141 - WeightedF1: 0.2081 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0804 - F1Score: 0.0126 - WeightedF1: 0.1862 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0802 - F1Score: 0.0140 - WeightedF1: 0.2009 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "157/157 [==============================] - 6s 41ms/step - loss: 0.0736 - F1Score: 0.0231 - WeightedF1: 0.2998 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0700 - F1Score: 0.0272 - WeightedF1: 0.3376 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "157/157 [==============================] - 7s 43ms/step - loss: 0.0683 - F1Score: 0.0282 - WeightedF1: 0.3440 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0671 - F1Score: 0.0310 - WeightedF1: 0.3694 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0658 - F1Score: 0.0361 - WeightedF1: 0.4075 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "157/157 [==============================] - 6s 41ms/step - loss: 0.0644 - F1Score: 0.0418 - WeightedF1: 0.4420 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "157/157 [==============================] - 6s 41ms/step - loss: 0.0631 - F1Score: 0.0476 - WeightedF1: 0.4804 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "157/157 [==============================] - 6s 41ms/step - loss: 0.0617 - F1Score: 0.0536 - WeightedF1: 0.5098 - lr: 1.1036e-04\n",
      "313/313 [==============================] - 2s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [04:42, 140.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train indices: [    0     1     2 ... 50072 50073 50074] Test indices: [    3     8    14 ... 50068 50075 50076]\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "157/157 [==============================] - 12s 58ms/step - loss: 0.1356 - F1Score: 0.0143 - WeightedF1: 0.2096 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0811 - F1Score: 0.0130 - WeightedF1: 0.1945 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0811 - F1Score: 0.0138 - WeightedF1: 0.2068 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "157/157 [==============================] - 7s 43ms/step - loss: 0.0809 - F1Score: 0.0130 - WeightedF1: 0.1953 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0806 - F1Score: 0.0131 - WeightedF1: 0.1964 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0789 - F1Score: 0.0152 - WeightedF1: 0.2178 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0759 - F1Score: 0.0203 - WeightedF1: 0.2759 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0680 - F1Score: 0.0314 - WeightedF1: 0.3717 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "157/157 [==============================] - 7s 43ms/step - loss: 0.0651 - F1Score: 0.0419 - WeightedF1: 0.4248 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0618 - F1Score: 0.0560 - WeightedF1: 0.5073 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0580 - F1Score: 0.0690 - WeightedF1: 0.5578 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "157/157 [==============================] - 6s 41ms/step - loss: 0.0547 - F1Score: 0.0813 - WeightedF1: 0.5895 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0526 - F1Score: 0.0888 - WeightedF1: 0.6104 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0513 - F1Score: 0.0927 - WeightedF1: 0.6219 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0488 - F1Score: 0.1016 - WeightedF1: 0.6455 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "157/157 [==============================] - 7s 43ms/step - loss: 0.0474 - F1Score: 0.1078 - WeightedF1: 0.6601 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0460 - F1Score: 0.1107 - WeightedF1: 0.6710 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0449 - F1Score: 0.1163 - WeightedF1: 0.6826 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "157/157 [==============================] - 6s 41ms/step - loss: 0.0437 - F1Score: 0.1202 - WeightedF1: 0.6926 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "157/157 [==============================] - 6s 41ms/step - loss: 0.0425 - F1Score: 0.1242 - WeightedF1: 0.7017 - lr: 1.1036e-04\n",
      "313/313 [==============================] - 2s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [07:04, 141.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train indices: [    0     1     2 ... 50074 50075 50076] Test indices: [    5    15    18 ... 50069 50071 50072]\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "157/157 [==============================] - 9s 42ms/step - loss: 0.1321 - F1Score: 0.0134 - WeightedF1: 0.1957 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "157/157 [==============================] - 6s 41ms/step - loss: 0.0812 - F1Score: 0.0128 - WeightedF1: 0.1913 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "157/157 [==============================] - 6s 41ms/step - loss: 0.0809 - F1Score: 0.0126 - WeightedF1: 0.1880 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "157/157 [==============================] - 6s 41ms/step - loss: 0.0806 - F1Score: 0.0120 - WeightedF1: 0.1789 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0791 - F1Score: 0.0157 - WeightedF1: 0.2236 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0752 - F1Score: 0.0215 - WeightedF1: 0.2825 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0679 - F1Score: 0.0325 - WeightedF1: 0.3795 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0649 - F1Score: 0.0426 - WeightedF1: 0.4303 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0614 - F1Score: 0.0567 - WeightedF1: 0.5088 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0576 - F1Score: 0.0694 - WeightedF1: 0.5584 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0545 - F1Score: 0.0820 - WeightedF1: 0.5911 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0521 - F1Score: 0.0884 - WeightedF1: 0.6119 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0495 - F1Score: 0.0993 - WeightedF1: 0.6391 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0472 - F1Score: 0.1097 - WeightedF1: 0.6625 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0454 - F1Score: 0.1187 - WeightedF1: 0.6788 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "157/157 [==============================] - 7s 43ms/step - loss: 0.0443 - F1Score: 0.1271 - WeightedF1: 0.6894 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0427 - F1Score: 0.1340 - WeightedF1: 0.7044 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "157/157 [==============================] - 6s 41ms/step - loss: 0.0417 - F1Score: 0.1410 - WeightedF1: 0.7144 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0405 - F1Score: 0.1473 - WeightedF1: 0.7257 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0391 - F1Score: 0.1536 - WeightedF1: 0.7372 - lr: 1.1036e-04\n",
      "313/313 [==============================] - 2s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [09:22, 139.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train indices: [    0     1     3 ... 50073 50075 50076] Test indices: [    2     9    10 ... 50058 50062 50074]\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "157/157 [==============================] - 9s 42ms/step - loss: 0.1369 - F1Score: 0.0138 - WeightedF1: 0.1996 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "157/157 [==============================] - 6s 41ms/step - loss: 0.0811 - F1Score: 0.0138 - WeightedF1: 0.2053 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0810 - F1Score: 0.0136 - WeightedF1: 0.2031 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0810 - F1Score: 0.0135 - WeightedF1: 0.2018 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0811 - F1Score: 0.0129 - WeightedF1: 0.1921 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "157/157 [==============================] - 7s 41ms/step - loss: 0.0810 - F1Score: 0.0138 - WeightedF1: 0.2051 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "157/157 [==============================] - 6s 41ms/step - loss: 0.0810 - F1Score: 0.0137 - WeightedF1: 0.2034 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0809 - F1Score: 0.0135 - WeightedF1: 0.2005 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0803 - F1Score: 0.0133 - WeightedF1: 0.1974 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0772 - F1Score: 0.0188 - WeightedF1: 0.2503 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "157/157 [==============================] - 6s 41ms/step - loss: 0.0709 - F1Score: 0.0254 - WeightedF1: 0.3209 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0677 - F1Score: 0.0286 - WeightedF1: 0.3515 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "157/157 [==============================] - 7s 43ms/step - loss: 0.0660 - F1Score: 0.0344 - WeightedF1: 0.3926 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "157/157 [==============================] - 6s 41ms/step - loss: 0.0639 - F1Score: 0.0423 - WeightedF1: 0.4387 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0621 - F1Score: 0.0493 - WeightedF1: 0.4749 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0607 - F1Score: 0.0578 - WeightedF1: 0.5109 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0588 - F1Score: 0.0655 - WeightedF1: 0.5413 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "157/157 [==============================] - 6s 41ms/step - loss: 0.0571 - F1Score: 0.0719 - WeightedF1: 0.5610 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0554 - F1Score: 0.0784 - WeightedF1: 0.5831 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0542 - F1Score: 0.0833 - WeightedF1: 0.5947 - lr: 1.1036e-04\n",
      "313/313 [==============================] - 2s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [11:39, 139.90s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "evaluation_results = []\n",
    "\n",
    "for train_index, test_index in tqdm(kf.split(X)):\n",
    "    print(\"Train indices:\", train_index, \"Test indices:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    model = NUK.PC0(NmDevices, window_size, 'gru', 128, k)\n",
    "    model.build((len(y_train) + len(y_test), window_size, 1))\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003), loss='binary_crossentropy', metrics=[NUK.F1Score, NUK.WeightedF1Score(NUK.class_weights_tool(y_test))])\n",
    "    lr_scheduler = LearningRateScheduler(scheduler)\n",
    "    # for class weights\n",
    "    # model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, class_weight=class_weights_UKD, callbacks=[lr_scheduler])\n",
    "    model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=[lr_scheduler])\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_tf = (y_pred > 0.5)\n",
    "    report = metrics.classification_report(y_test, y_pred_tf, target_names=labels, zero_division=0, output_dict=True)\n",
    "\n",
    "    # report_DF = NUK.ClassificationReportToDF(report, labels)\n",
    "    # report_DF.rename(columns={report_DF.columns[0]: \"device\"}, inplace=True)\n",
    "    evaluation_results.append(report)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>air conditioning</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>air exchanger</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>air exhaust</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>air handling unit</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>audio amplifier</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whirlpool bath</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro avg</th>\n",
       "      <td>0.709449</td>\n",
       "      <td>0.562119</td>\n",
       "      <td>0.624601</td>\n",
       "      <td>35019.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.143554</td>\n",
       "      <td>0.080099</td>\n",
       "      <td>0.090262</td>\n",
       "      <td>35019.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.606036</td>\n",
       "      <td>0.562119</td>\n",
       "      <td>0.551371</td>\n",
       "      <td>35019.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samples avg</th>\n",
       "      <td>0.618426</td>\n",
       "      <td>0.511375</td>\n",
       "      <td>0.535569</td>\n",
       "      <td>35019.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   precision    recall  f1-score  support\n",
       "air conditioning    0.000000  0.000000  0.000000      9.0\n",
       "air exchanger       0.000000  0.000000  0.000000      0.0\n",
       "air exhaust         0.000000  0.000000  0.000000      0.0\n",
       "air handling unit   0.200000  0.040000  0.066667      3.4\n",
       "audio amplifier     0.000000  0.000000  0.000000      0.0\n",
       "...                      ...       ...       ...      ...\n",
       "whirlpool bath      0.000000  0.000000  0.000000      0.0\n",
       "micro avg           0.709449  0.562119  0.624601  35019.6\n",
       "macro avg           0.143554  0.080099  0.090262  35019.6\n",
       "weighted avg        0.606036  0.562119  0.551371  35019.6\n",
       "samples avg         0.618426  0.511375  0.535569  35019.6\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "for i in range(len(evaluation_results)):\n",
    "    if i == 0:\n",
    "        df = pd.DataFrame(evaluation_results[i]).T\n",
    "    else:\n",
    "        df = df + pd.DataFrame(evaluation_results[i]).T\n",
    "\n",
    "\n",
    "df = df / 5\n",
    "df.to_csv(f\"../../Energy_graph/data/results/w_size{window_size}_epochs{epochs}_batch_size{batch_size}_k{k}.csv\")\n",
    "    \n",
    "# evaluation_results+ evaluation_results[1].to_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-01 08:10:38.150396: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-01 08:10:38.455398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38336 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe MIG 3g.40gb, pci bus id: 0000:e1:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU enabled\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-01 08:10:43.322695: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8800\n",
      "2023-09-01 08:10:43.827673: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-09-01 08:10:43.828457: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-09-01 08:10:43.828475: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2023-09-01 08:10:43.828882: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-09-01 08:10:43.828933: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 50s 62ms/step - loss: inf - F1Score: 0.6688 - WeightedF1: 0.7045 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 27s 46ms/step - loss: inf - F1Score: 0.7756 - WeightedF1: 0.7925 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 27s 45ms/step - loss: inf - F1Score: 0.7574 - WeightedF1: 0.7678 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 27s 45ms/step - loss: inf - F1Score: 0.7574 - WeightedF1: 0.7678 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 27s 45ms/step - loss: inf - F1Score: 0.7575 - WeightedF1: 0.7678 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 27s 45ms/step - loss: inf - F1Score: 0.7575 - WeightedF1: 0.7678 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 27s 45ms/step - loss: inf - F1Score: 0.7575 - WeightedF1: 0.7678 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 27s 45ms/step - loss: inf - F1Score: 0.7576 - WeightedF1: 0.7679 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 27s 45ms/step - loss: inf - F1Score: 0.7574 - WeightedF1: 0.7678 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 27s 45ms/step - loss: inf - F1Score: 0.7575 - WeightedF1: 0.7678 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 27s 45ms/step - loss: inf - F1Score: 0.7576 - WeightedF1: 0.7679 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 27s 45ms/step - loss: inf - F1Score: 0.7575 - WeightedF1: 0.7679 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 27s 45ms/step - loss: inf - F1Score: 0.7576 - WeightedF1: 0.7680 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 27s 45ms/step - loss: inf - F1Score: 0.7574 - WeightedF1: 0.7678 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 27s 45ms/step - loss: inf - F1Score: 0.7575 - WeightedF1: 0.7679 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 27s 45ms/step - loss: inf - F1Score: 0.7576 - WeightedF1: 0.7679 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 27s 45ms/step - loss: inf - F1Score: 0.7576 - WeightedF1: 0.7680 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 27s 45ms/step - loss: inf - F1Score: 0.7575 - WeightedF1: 0.7678 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 27s 45ms/step - loss: inf - F1Score: 0.7575 - WeightedF1: 0.7678 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 27s 45ms/step - loss: inf - F1Score: 0.7576 - WeightedF1: 0.7679 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 4s 4ms/step\n",
      "3000/3000 [==============================] - 13s 4ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 29s 46ms/step - loss: inf - F1Score: 0.6514 - WeightedF1: 0.6662 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 28s 46ms/step - loss: inf - F1Score: 0.7598 - WeightedF1: 0.7687 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 28s 46ms/step - loss: inf - F1Score: 0.7930 - WeightedF1: 0.8008 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 27s 46ms/step - loss: inf - F1Score: 0.8195 - WeightedF1: 0.8267 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 28s 46ms/step - loss: inf - F1Score: 0.8371 - WeightedF1: 0.8438 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 28s 46ms/step - loss: inf - F1Score: 0.8527 - WeightedF1: 0.8588 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "423/600 [====================>.........] - ETA: 8s - loss: inf - F1Score: 0.8622 - WeightedF1: 0.8679"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "Train on UKD, evaluate on REF\n",
    "\"\"\"\n",
    "evaluation_results_UKD_UKD, evaluation_results_UKD_REF, evaluation_results_REF_UKD, evaluation_results_REF_REF = [], [], [], []\n",
    "\n",
    "\n",
    "model = NUK.PC0(NmDevices, window_size, 'gru', 128, k)\n",
    "model.build((len(y_train_UKD) + len(y_test_UKD), window_size, 1))\n",
    "#model.summary()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003), loss='binary_crossentropy', metrics=[NUK.F1Score, NUK.WeightedF1Score(NUK.class_weights_tool(y_test_UKD))])\n",
    "lr_scheduler = LearningRateScheduler(scheduler)\n",
    "model.fit(x_train_UKD, y_train_UKD, batch_size=batch_size, epochs=epochs, class_weight=class_weights_UKD, callbacks=[lr_scheduler])\n",
    "\n",
    "# Evaluate the model on the UKD dataset\n",
    "y_pred_UKD = model.predict(x_test_UKD)\n",
    "y_pred_tf_UKD = (y_pred_UKD > 0.5)\n",
    "report_UKD = metrics.classification_report(y_test_UKD, y_pred_tf_UKD, target_names=labels_UKD, zero_division=0)\n",
    "# I prefer to save class. reports in pandas dataframes so i use this function\n",
    "report_UKD_DF = NUK.ClassificationReportToDF(report_UKD, labels_UKD)\n",
    "report_UKD_DF.rename(columns={report_UKD_DF.columns[0]: \"device\"}, inplace=True)\n",
    "evaluation_results_UKD_UKD.append(report_UKD_DF)\n",
    "\n",
    "# Evaluate the model on the REF dataset\n",
    "y_pred_REF = model.predict(x_REF)\n",
    "y_pred_tf_REF = (y_pred_REF > 0.5)\n",
    "report_REF = metrics.classification_report(y_REF, y_pred_tf_REF, target_names=labels_REF, zero_division=0)\n",
    "# I prefer to save class. reports in pandas dataframes so i use this function\n",
    "report_REF_DF = NUK.ClassificationReportToDF(report_REF, labels_REF)\n",
    "report_REF_DF.rename(columns={report_REF_DF.columns[0]: \"device\"}, inplace = True)\n",
    "evaluation_results_UKD_REF.append(report_REF_DF)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Train on REF, evaluate on UKD\n",
    "\"\"\"\n",
    "\n",
    "# x_train_REF, x_val_REF = x_REF[train_idx], x_REF[val_idx]  # Swap 'x_train_UKD' with 'x_train_REF' and 'x_val_UKD' with 'x_val_REF'\n",
    "# y_train_REF, y_val_REF = y_REF[train_idx], y_REF[val_idx]  # Swap 'y_train_UKD' with 'y_train_REF' and 'y_val_UKD' with 'y_val_REF'\n",
    "\n",
    "\n",
    "model = NUK.PC0(NmDevices, window_size, 'gru', 128, k)\n",
    "model.build((len(y_train_REF) + len(y_test_REF), window_size, 1))  # Swap 'y_train_UKD' with 'y_train_REF'\n",
    "#model.summary()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003), loss='binary_crossentropy', metrics=[NUK.F1Score, NUK.WeightedF1Score(NUK.class_weights_tool(y_test_REF))])  # Swap 'y_test_UKD' with 'y_test_REF'\n",
    "lr_scheduler = LearningRateScheduler(scheduler)\n",
    "model.fit(x_train_REF, y_train_REF, batch_size=batch_size, epochs=epochs, class_weight=class_weights_REF, callbacks=[lr_scheduler])  # Swap 'x_train_UKD' with 'x_train_REF' and 'y_train_UKD' with 'y_train_REF'\n",
    "\n",
    "# Evaluate the model on the REF dataset  # Swap 'UKD' with 'REF'\n",
    "y_pred_REF = model.predict(x_test_REF)  # Swap 'x_val_UKD' with 'x_val_REF'\n",
    "y_pred_tf_REF = (y_pred_REF > 0.5)\n",
    "report_REF = metrics.classification_report(y_test_REF, y_pred_tf_REF, target_names=labels_REF, zero_division=0)  # Swap 'y_val_UKD' with 'y_val_REF'\n",
    "# I prefer to save class. reports in pandas dataframes so i use this function\n",
    "report_REF_DF = NUK.ClassificationReportToDF(report_REF, labels_REF)\n",
    "report_REF_DF.rename(columns={report_REF_DF.columns[0]: \"device\"}, inplace=True)\n",
    "evaluation_results_REF_REF.append(report_REF_DF)  # Swap 'evaluation_results_UKD_REF' with 'evaluation_results_REF_REF'\n",
    "\n",
    "# Evaluate the model on the UKD dataset  # Swap 'REF' with 'UKD'\n",
    "y_pred_UKD = model.predict(x_UKD)  # Swap 'x_REF' with 'x_UKD'\n",
    "y_pred_tf_UKD = (y_pred_UKD > 0.5)\n",
    "report_UKD = metrics.classification_report(y_UKD, y_pred_tf_UKD, target_names=labels_UKD, zero_division=0)  # Swap 'y_REF' with 'y_UKD'\n",
    "# I prefer to save class. reports in pandas dataframes so i use this function\n",
    "report_UKD_DF = NUK.ClassificationReportToDF(report_UKD, labels_UKD)\n",
    "report_UKD_DF.rename(columns={report_UKD_DF.columns[0]: \"device\"}, inplace=True)\n",
    "evaluation_results_REF_UKD.append(report_UKD_DF)  # Swap 'evaluation_results_UKD_UKD' with 'evaluation_results_REF_UKD'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n****************************** UKD_UKD:\\n\",evaluation_results_UKD_UKD,\"\\n************************ UKD_REF: \\n\", evaluation_results_UKD_REF,\"\\n******************************REF_UKD:\\n\", evaluation_results_REF_UKD,\"\\n******************************REF_REF:\\n\", evaluation_results_REF_REF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Create folder name\n",
    "folder_name = f\"./results/epochs_{epochs}_wsize_{window_size}_devices_{NmDevices}\"\n",
    "\n",
    "# Create the folder if it does not exist\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# Save DataFrames to the newly created folder\n",
    "evaluation_results_REF_UKD[0].to_csv(os.path.join(folder_name, 'evaluation_results_REF_UKD.csv'))\n",
    "evaluation_results_REF_REF[0].to_csv(os.path.join(folder_name, 'evaluation_results_REF_REF.csv'))\n",
    "evaluation_results_UKD_UKD[0].to_csv(os.path.join(folder_name, 'evaluation_results_UKD_UKD.csv'))\n",
    "evaluation_results_UKD_REF[0].to_csv(os.path.join(folder_name, 'evaluation_results_UKD_REF.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[0.000e+00],\n",
       "         [0.000e+00],\n",
       "         [0.000e+00],\n",
       "         ...,\n",
       "         [0.000e+00],\n",
       "         [0.000e+00],\n",
       "         [0.000e+00]],\n",
       " \n",
       "        [[0.000e+00],\n",
       "         [0.000e+00],\n",
       "         [0.000e+00],\n",
       "         ...,\n",
       "         [0.000e+00],\n",
       "         [0.000e+00],\n",
       "         [0.000e+00]],\n",
       " \n",
       "        [[0.000e+00],\n",
       "         [1.000e+00],\n",
       "         [0.000e+00],\n",
       "         ...,\n",
       "         [2.753e+03],\n",
       "         [2.811e+03],\n",
       "         [2.741e+03]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.000e+00],\n",
       "         [0.000e+00],\n",
       "         [0.000e+00],\n",
       "         ...,\n",
       "         [0.000e+00],\n",
       "         [0.000e+00],\n",
       "         [0.000e+00]],\n",
       " \n",
       "        [[0.000e+00],\n",
       "         [0.000e+00],\n",
       "         [0.000e+00],\n",
       "         ...,\n",
       "         [0.000e+00],\n",
       "         [0.000e+00],\n",
       "         [0.000e+00]],\n",
       " \n",
       "        [[0.000e+00],\n",
       "         [0.000e+00],\n",
       "         [0.000e+00],\n",
       "         ...,\n",
       "         [0.000e+00],\n",
       "         [0.000e+00],\n",
       "         [0.000e+00]]]),\n",
       " array([[[69.],\n",
       "         [ 0.],\n",
       "         [68.],\n",
       "         ...,\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       " \n",
       "        [[ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         ...,\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       " \n",
       "        [[ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         ...,\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         ...,\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       " \n",
       "        [[ 1.],\n",
       "         [ 0.],\n",
       "         [ 1.],\n",
       "         ...,\n",
       "         [77.],\n",
       "         [ 0.],\n",
       "         [78.]],\n",
       " \n",
       "        [[ 2.],\n",
       "         [ 2.],\n",
       "         [ 2.],\n",
       "         ...,\n",
       "         [ 2.],\n",
       "         [ 2.],\n",
       "         [ 2.]]]),\n",
       " array([[False, False,  True, False, False],\n",
       "        [False, False, False, False,  True],\n",
       "        [ True, False,  True,  True,  True],\n",
       "        ...,\n",
       "        [ True, False,  True,  True,  True],\n",
       "        [ True, False, False, False, False],\n",
       "        [ True,  True,  True, False,  True]]),\n",
       " array([[ True, False, False, False, False],\n",
       "        [False, False,  True, False,  True],\n",
       "        [False, False, False,  True, False],\n",
       "        ...,\n",
       "        [ True,  True, False, False,  True],\n",
       "        [ True,  True, False,  True,  True],\n",
       "        [ True, False,  True,  True, False]]),\n",
       " ('fridge', 'washing machine', 'dish washer', 'microwave', 'kettle')]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Closing remaining open files:/tmp/nilmtk-y9m5ck38.h5...done\n"
     ]
    }
   ],
   "source": [
    "HolyDataset_REF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
