{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48aa7f4b-b582-4810-8dcc-dc6bd4268a01",
   "metadata": {
    "tags": []
   },
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ff4bf7d-85c7-4aa2-b558-fd7f4699fb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1696d2b-c0aa-401d-a3ef-6edee09d8f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/nilmtk/nilmtk@master\n",
      "  Cloning https://github.com/nilmtk/nilmtk (to revision master) to /tmp/pip-req-build-clkaifm6\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/nilmtk/nilmtk /tmp/pip-req-build-clkaifm6\n",
      "  Resolved https://github.com/nilmtk/nilmtk to commit b2c514479cef478cab872cb635056da08d5352a1\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: nilmtk\n",
      "  Building wheel for nilmtk (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nilmtk: filename=nilmtk-0.4.0.dev1+git.b2c5144-py3-none-any.whl size=279177 sha256=29994a99ea18b245d56b08e7857540b4aceb4ca72dd978921f733f1f46269c16\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-1qc8ji5f/wheels/05/a4/8e/b767c3d1714f61fd30ec991c25780be8cc04c474da8205aeee\n",
      "Successfully built nilmtk\n",
      "Installing collected packages: nilmtk\n",
      "Successfully installed nilmtk-0.4.0.dev1+git.b2c5144\n",
      "Collecting git+https://github.com/nilmtk/nilm_metadata@master\n",
      "  Cloning https://github.com/nilmtk/nilm_metadata (to revision master) to /tmp/pip-req-build-b4sfefqd\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/nilmtk/nilm_metadata /tmp/pip-req-build-b4sfefqd\n",
      "  Resolved https://github.com/nilmtk/nilm_metadata to commit 7ed4bab9062d04cb35c6b6000b451715dc5ab4af\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: nilm-metadata\n",
      "  Building wheel for nilm-metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nilm-metadata: filename=nilm_metadata-0.2.5-py3-none-any.whl size=24340 sha256=e10ee401faaabd0644347ba3161404d7147834976dfe49185c5493f9a5720f62\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-3ffv_ebv/wheels/7e/2f/7f/e41975c202542dbc11228875ff8473ed4cb95e04a274222bb7\n",
      "Successfully built nilm-metadata\n",
      "Installing collected packages: nilm-metadata\n",
      "Successfully installed nilm-metadata-0.2.5\n"
     ]
    }
   ],
   "source": [
    "#!rm -r /home/jovyan/.local/share/jupyter/kernels/nilmtk\n",
    "!mamba install tensorflow-gpu==2.10 -y -q\n",
    "#!mamba install tensorflow-gpu==2.11.0 -y -q\n",
    "!pip uninstall -y -q nilmtk nilm_metadata\n",
    "#!pip install -q pandas networkx tables scikit-learn hmmlearn pyyaml matplotlib==3.1.3 xgboost pyts\n",
    "# Trick to install NILM regardless of its dependencies\n",
    "#!pip install --no-cache -U git+https://github.com/nilmtk/nilm_metadata.git\n",
    "#!pip install --no-cache -U git+https://github.com/nilmtk/nilmtk.git@0.4.3\n",
    "!python3 -m pip install --no-deps git+https://github.com/nilmtk/nilmtk@master\n",
    "!python3 -m pip install --no-deps git+https://github.com/nilmtk/nilm_metadata@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7c6e6ff-bf68-4741-bf10-cd4eb3e45b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from nilmtk import DataSet\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from joblib import Memory\n",
    "import pickle\n",
    "from pprint import pprint\n",
    "\n",
    "#from nilmtk import DataSet\n",
    "import multiprocessing as mp\n",
    "\n",
    "from typing import Dict\n",
    "\n",
    "!pip install -q scikit-learn-intelex\n",
    "#from sklearnex import patch_sklearn\n",
    "#patch_sklearn()\n",
    "\n",
    "from sklearn import pipeline, metrics, linear_model, model_selection, multioutput, tree, ensemble, neural_network\n",
    "!pip install xgboost -q\n",
    "import xgboost as xgb\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "#import graphviz\n",
    "import keras\n",
    "from sklearn.utils import class_weight\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#from ann_visualizer.visualize import ann_viz\n",
    "from matplotlib import pyplot as plt \n",
    "from sklearn.metrics import multilabel_confusion_matrix, classification_report, confusion_matrix\n",
    "# GPU goes brrrrrrrrrrrrrrrrrrrr\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "!pip3 install tqdm -q\n",
    "from tqdm import tqdm\n",
    "import NUK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69bd62cf-00ac-49a0-b125-e4f6e690b97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = Memory(location='./cache')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c635d17d-7e45-486b-a272-35c5e1d4bebc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12402ec5-e91a-4b91-8db6-38067b914910",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@memory.cache\n",
    "#def load_refit_dataset():\n",
    "#    try:\n",
    "#        dataset = DataSet('./refit.hdf5')\n",
    "#\n",
    "#        samples = []\n",
    "#        for building_idx, building in dataset.buildings.items():\n",
    "#            for meter in building.elec.all_meters():\n",
    "#\n",
    "#                data = list(meter.load())\n",
    "#                assert len(data) == 1\n",
    "#\n",
    "#                assert len(meter.appliances) < 2\n",
    "#\n",
    "#                # TODO: Poglej s kje jemlje sample Jakob.\n",
    "#                sample = (building_idx, list([a.type['type'] for a in meter.appliances]), data, meter.good_sections())\n",
    "#\n",
    "#                samples.append(sample)\n",
    "#                \n",
    "#        return samples\n",
    "#\n",
    "#    except Exception as e:\n",
    "#        dataset.store.close()\n",
    "#        raise e\n",
    "#        \n",
    "#dataset = load_refit_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d40039f-9e11-4606-a268-c91f9b63f4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling __main__--tmp-ipykernel-2415464166.load_ukdale_dataset...\n",
      "load_ukdale_dataset()\n",
      "____________________________________________load_ukdale_dataset - 410.2s, 6.8min\n"
     ]
    }
   ],
   "source": [
    "@memory.cache\n",
    "\n",
    "def load_ukdale_dataset():\n",
    "    try:\n",
    "        dataset = DataSet('./ukdale.hdf5')\n",
    "\n",
    "        samples = []\n",
    "        for building_idx, building in dataset.buildings.items():\n",
    "            for meter in building.elec.all_meters():\n",
    "\n",
    "                data = list(meter.load())\n",
    "                assert len(data) == 1\n",
    "\n",
    "                #assert len(meter.appliances) < 2\n",
    "\n",
    "                # TODO: Poglej s kje jemlje sample Jakob.\n",
    "                sample = (building_idx, list([a.type['type'] for a in meter.appliances]), data, meter.good_sections())\n",
    "\n",
    "                samples.append(sample)\n",
    "                \n",
    "        return samples\n",
    "\n",
    "    except Exception as e:\n",
    "        dataset.store.close()\n",
    "        raise e\n",
    "        \n",
    "dataset = load_ukdale_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2452232b-da25-4c65-a8a0-8f858c56f6f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n@memory.cache\\n\\ndef load_iawe_dataset():\\n    try:\\n        dataset = DataSet('iawe.h5')\\n\\n        samples = []\\n        for building_idx, building in dataset.buildings.items():\\n            for meter in building.elec.all_meters():\\n\\n                data = list(meter.load())\\n                assert len(data) == 1\\n\\n                sample = (building_idx, list([a.type['type'] for a in meter.appliances]), data, meter.good_sections())\\n\\n                samples.append(sample)\\n                \\n        return samples\\n\\n    except Exception as e:\\n        dataset.store.close()\\n        raise e\\n        \\ndataset = load_iawe_dataset()\\n\\n#deletes useless columns from the IAWE dataset\\n#anze told me that the more for loops you use, the better programmer you are\\nfor i in range(len(dataset)):\\n    for j in range (len(dataset[i][2])):\\n        for column in dataset[i][2][j].keys():\\n            \\n            if (column[0]=='power' and column[1]=='apparent'): del dataset[i][2][j]['power', 'apparent']\\n            if (column[0]=='power' and column[1]=='reactive'): del dataset[i][2][j]['power', 'reactive']\\n            if (column[0]=='current'): del dataset[i][2][j]['current',         '']\\n            if (column[0]=='frequency'): del dataset[i][2][j]['frequency',       '']\\n            if (column[0]=='voltage'): del dataset[i][2][j]['voltage',       '']\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "@memory.cache\n",
    "\n",
    "def load_iawe_dataset():\n",
    "    try:\n",
    "        dataset = DataSet('iawe.h5')\n",
    "\n",
    "        samples = []\n",
    "        for building_idx, building in dataset.buildings.items():\n",
    "            for meter in building.elec.all_meters():\n",
    "\n",
    "                data = list(meter.load())\n",
    "                assert len(data) == 1\n",
    "\n",
    "                sample = (building_idx, list([a.type['type'] for a in meter.appliances]), data, meter.good_sections())\n",
    "\n",
    "                samples.append(sample)\n",
    "                \n",
    "        return samples\n",
    "\n",
    "    except Exception as e:\n",
    "        dataset.store.close()\n",
    "        raise e\n",
    "        \n",
    "dataset = load_iawe_dataset()\n",
    "\n",
    "#deletes useless columns from the IAWE dataset\n",
    "#anze told me that the more for loops you use, the better programmer you are\n",
    "for i in range(len(dataset)):\n",
    "    for j in range (len(dataset[i][2])):\n",
    "        for column in dataset[i][2][j].keys():\n",
    "            \n",
    "            if (column[0]=='power' and column[1]=='apparent'): del dataset[i][2][j]['power', 'apparent']\n",
    "            if (column[0]=='power' and column[1]=='reactive'): del dataset[i][2][j]['power', 'reactive']\n",
    "            if (column[0]=='current'): del dataset[i][2][j]['current',         '']\n",
    "            if (column[0]=='frequency'): del dataset[i][2][j]['frequency',       '']\n",
    "            if (column[0]=='voltage'): del dataset[i][2][j]['voltage',       '']\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d913f6b4-831f-4056-b4ce-75514b4b4dd0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n@memory.cache\\ndef load_eco_dataset():\\n    try:\\n        dataset = DataSet(\\'eco-Copy1.h5\\')\\n        samples = []\\n        #print(dataset.buildings.items())\\n        for building_idx, building in dataset.buildings.items():\\n            print(building_idx, building)\\n            #if(building_idx!=1): #purely da pridemo do buildinga 2 ki povzroča error hitreje\\n            for meter in building.elec.all_meters():\\n                #print(meter)\\n                #print(meter.instance())\\n                if(13<=meter.instance()<=14 and building_idx==2):\\n                    print(\"Skipped\",meter)\\n                else:\\n                        if(1<=meter.instance()<=3 and building_idx==4):\\n                            pass\\n                        else:\\n                            print(\"Works on\", meter)\\n                            data = list(meter.load())\\n                            assert len(data) == 1\\n                            sample = (building_idx, list([a.type[\\'type\\'] for a in meter.appliances]), data, meter.good_sections())\\n\\n                            samples.append(sample)\\n                       \\n                        #assert len(meter.appliances) < 2\\n\\n                        # TODO: Poglej s kje jemlje sample Jakob.\\n                        \\n        return samples\\n\\n    except Exception as e:\\n        dataset.store.close()\\n        raise e\\n#universal cleanup of useless data, more clauses should be added if using different datasets        \\ndataset = load_eco_dataset()\\nfor i in range(len(dataset)):\\n    for j in range (len(dataset[i][2])):\\n        for column in dataset[i][2][j].keys():\\n            if (column[0]==\\'power\\' and column[1]==\\'apparent\\'): del dataset[i][2][j][\\'power\\', \\'apparent\\']\\n            if (column[0]==\\'power\\' and column[1]==\\'reactive\\'): del dataset[i][2][j][\\'power\\', \\'reactive\\']\\n            if (column[0]==\\'current\\'): del dataset[i][2][j][\\'current\\',         \\'\\']\\n            if (column[0]==\\'frequency\\'): del dataset[i][2][j][\\'frequency\\',       \\'\\']\\n            if (column[0]==\\'voltage\\'): del dataset[i][2][j][\\'voltage\\',       \\'\\']\\n            if (column[0]==\\'phase_angle\\'): del dataset[i][2][j][\\'phase_angle\\',       \\'\\']\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "@memory.cache\n",
    "def load_eco_dataset():\n",
    "    try:\n",
    "        dataset = DataSet('eco-Copy1.h5')\n",
    "        samples = []\n",
    "        #print(dataset.buildings.items())\n",
    "        for building_idx, building in dataset.buildings.items():\n",
    "            print(building_idx, building)\n",
    "            #if(building_idx!=1): #purely da pridemo do buildinga 2 ki povzroča error hitreje\n",
    "            for meter in building.elec.all_meters():\n",
    "                #print(meter)\n",
    "                #print(meter.instance())\n",
    "                if(13<=meter.instance()<=14 and building_idx==2):\n",
    "                    print(\"Skipped\",meter)\n",
    "                else:\n",
    "                        if(1<=meter.instance()<=3 and building_idx==4):\n",
    "                            pass\n",
    "                        else:\n",
    "                            print(\"Works on\", meter)\n",
    "                            data = list(meter.load())\n",
    "                            assert len(data) == 1\n",
    "                            sample = (building_idx, list([a.type['type'] for a in meter.appliances]), data, meter.good_sections())\n",
    "\n",
    "                            samples.append(sample)\n",
    "                       \n",
    "                        #assert len(meter.appliances) < 2\n",
    "\n",
    "                        # TODO: Poglej s kje jemlje sample Jakob.\n",
    "                        \n",
    "        return samples\n",
    "\n",
    "    except Exception as e:\n",
    "        dataset.store.close()\n",
    "        raise e\n",
    "#universal cleanup of useless data, more clauses should be added if using different datasets        \n",
    "dataset = load_eco_dataset()\n",
    "for i in range(len(dataset)):\n",
    "    for j in range (len(dataset[i][2])):\n",
    "        for column in dataset[i][2][j].keys():\n",
    "            if (column[0]=='power' and column[1]=='apparent'): del dataset[i][2][j]['power', 'apparent']\n",
    "            if (column[0]=='power' and column[1]=='reactive'): del dataset[i][2][j]['power', 'reactive']\n",
    "            if (column[0]=='current'): del dataset[i][2][j]['current',         '']\n",
    "            if (column[0]=='frequency'): del dataset[i][2][j]['frequency',       '']\n",
    "            if (column[0]=='voltage'): del dataset[i][2][j]['voltage',       '']\n",
    "            if (column[0]=='phase_angle'): del dataset[i][2][j]['phase_angle',       '']\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c6d4e8c-f4b6-4759-9488-e2c5e5729f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n@memory.cache\\ndef load_eco_dataset():\\n    try:\\n        dataset = DataSet(\\'eco.h5\\')\\n        samples = []\\n        #print(dataset.buildings.items())\\n        for building_idx, building in dataset.buildings.items():\\n            print(building_idx, building)\\n            #if(building_idx!=1): #purely da pridemo do buildinga 2 ki povzroča error hitreje\\n            for meter in building.elec.all_meters():\\n                #print(meter)\\n                #print(meter.instance())\\n                if(13<=meter.instance()<=14 and building_idx==2):\\n                    print(\"preskocil\",meter)\\n                else:\\n                        if(1<=meter.instance()<=3 and building_idx==4):\\n                            pass\\n                        else:\\n                            print(\"dela na\", meter)\\n                            data = list(meter.load())\\n                            assert len(data) == 1\\n                            sample = (building_idx, list([a.type[\\'type\\'] for a in meter.appliances]), data, meter.good_sections())\\n                            samples.append(sample)\\n                        #assert len(meter.appliances) < 2\\n                        # TODO: Poglej s kje jemlje sample Jakob.\\n        return samples\\n    except Exception as e:\\n        dataset.store.close()\\n        raise e\\n#for i in range(5):        \\n#    try: \\ndataset = load_eco_dataset()\\n#    except: \\n#        print(\"haha\")\\n#        continue\\nfor i in range(len(dataset)):\\n    for j in range (len(dataset[i][2])):\\n        for stolpec in dataset[i][2][j].keys():\\n            if (stolpec[0]==\\'power\\' and stolpec[1]==\\'apparent\\'): del dataset[i][2][j][\\'power\\', \\'apparent\\']\\n            if (stolpec[0]==\\'power\\' and stolpec[1]==\\'reactive\\'): del dataset[i][2][j][\\'power\\', \\'reactive\\']\\n            if (stolpec[0]==\\'current\\'): del dataset[i][2][j][\\'current\\',         \\'\\']\\n            if (stolpec[0]==\\'frequency\\'): del dataset[i][2][j][\\'frequency\\',       \\'\\']\\n            if (stolpec[0]==\\'voltage\\'): del dataset[i][2][j][\\'voltage\\',       \\'\\']\\n            if (stolpec[0]==\\'phase_angle\\'): del dataset[i][2][j][\\'phase_angle\\',       \\'\\']\\n#print(dataset[0])\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "@memory.cache\n",
    "def load_eco_dataset():\n",
    "    try:\n",
    "        dataset = DataSet('eco.h5')\n",
    "        samples = []\n",
    "        #print(dataset.buildings.items())\n",
    "        for building_idx, building in dataset.buildings.items():\n",
    "            print(building_idx, building)\n",
    "            #if(building_idx!=1): #purely da pridemo do buildinga 2 ki povzroča error hitreje\n",
    "            for meter in building.elec.all_meters():\n",
    "                #print(meter)\n",
    "                #print(meter.instance())\n",
    "                if(13<=meter.instance()<=14 and building_idx==2):\n",
    "                    print(\"preskocil\",meter)\n",
    "                else:\n",
    "                        if(1<=meter.instance()<=3 and building_idx==4):\n",
    "                            pass\n",
    "                        else:\n",
    "                            print(\"dela na\", meter)\n",
    "                            data = list(meter.load())\n",
    "                            assert len(data) == 1\n",
    "                            sample = (building_idx, list([a.type['type'] for a in meter.appliances]), data, meter.good_sections())\n",
    "                            samples.append(sample)\n",
    "                        #assert len(meter.appliances) < 2\n",
    "                        # TODO: Poglej s kje jemlje sample Jakob.\n",
    "        return samples\n",
    "    except Exception as e:\n",
    "        dataset.store.close()\n",
    "        raise e\n",
    "#for i in range(5):        \n",
    "#    try: \n",
    "dataset = load_eco_dataset()\n",
    "#    except: \n",
    "#        print(\"haha\")\n",
    "#        continue\n",
    "for i in range(len(dataset)):\n",
    "    for j in range (len(dataset[i][2])):\n",
    "        for stolpec in dataset[i][2][j].keys():\n",
    "            if (stolpec[0]=='power' and stolpec[1]=='apparent'): del dataset[i][2][j]['power', 'apparent']\n",
    "            if (stolpec[0]=='power' and stolpec[1]=='reactive'): del dataset[i][2][j]['power', 'reactive']\n",
    "            if (stolpec[0]=='current'): del dataset[i][2][j]['current',         '']\n",
    "            if (stolpec[0]=='frequency'): del dataset[i][2][j]['frequency',       '']\n",
    "            if (stolpec[0]=='voltage'): del dataset[i][2][j]['voltage',       '']\n",
    "            if (stolpec[0]=='phase_angle'): del dataset[i][2][j]['phase_angle',       '']\n",
    "#print(dataset[0])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aeab311a-1ed4-4e31-a5c0-7939f5499d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncount = 0\\nincluded_device_tab = [3,4,8,10,11,60,64,65,66,67,101,102,105,106,107]\\n#print(\"########################\")\\nfor i in range(len(included_device_tab)):\\n    #print(\"house: \", dataset[included_device_tab[i]][0])\\n    #print(\"device: \", dataset[included_device_tab[i]][1])\\n    if i < 54:\\n        nm_samples = round(len(dataset[included_device_tab[i]][2][0].values)/5)\\n        #print(\"length: \", nm_samples)\\n        count += nm_samples\\n    else: \\n        nm_samples = round(len(dataset[included_device_tab[i]][2][0].values))\\n        #print(\"length: \", nm_samples)\\n        count += nm_samples\\n    #print(i)\\n    #print(\"########################\")\\nprint(\"||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\\nprint(\"Number of samples: \", count)\\nprint(\"||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "count = 0\n",
    "included_device_tab = [3,4,8,10,11,60,64,65,66,67,101,102,105,106,107]\n",
    "#print(\"########################\")\n",
    "for i in range(len(included_device_tab)):\n",
    "    #print(\"house: \", dataset[included_device_tab[i]][0])\n",
    "    #print(\"device: \", dataset[included_device_tab[i]][1])\n",
    "    if i < 54:\n",
    "        nm_samples = round(len(dataset[included_device_tab[i]][2][0].values)/5)\n",
    "        #print(\"length: \", nm_samples)\n",
    "        count += nm_samples\n",
    "    else: \n",
    "        nm_samples = round(len(dataset[included_device_tab[i]][2][0].values))\n",
    "        #print(\"length: \", nm_samples)\n",
    "        count += nm_samples\n",
    "    #print(i)\n",
    "    #print(\"########################\")\n",
    "print(\"||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\n",
    "print(\"Number of samples: \", count)\n",
    "print(\"||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2548961a-1b93-49db-9779-5edbb95b006d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boiler 1164\n",
      "solar thermal pumping station 1161\n",
      "laptop computer 1443\n",
      "washer dryer 457\n",
      "dish washer 193\n",
      "television 635\n",
      "light 5771\n",
      "HTPC 120\n",
      "kettle 3621\n",
      "toaster 232\n",
      "fridge freezer 764\n",
      "microwave 554\n",
      "computer monitor 1344\n",
      "audio system 1364\n",
      "breadmaker 110\n",
      "audio amplifier 107\n",
      "broadband router 407\n",
      "soldering iron 195\n",
      "ethernet switch 1361\n",
      "vacuum cleaner 468\n",
      "tablet computer charger 61\n",
      "active subwoofer 30\n",
      "radio 245\n",
      "wireless phone charger 457\n",
      "mobile phone charger 121\n",
      "coffee maker 349\n",
      "hair dryer 567\n",
      "hair straighteners 442\n",
      "clothes iron 79\n",
      "oven 461\n",
      "computer 40\n",
      "baby monitor 59\n",
      "charger 654\n",
      "desktop computer 1339\n",
      "fan 112\n",
      "printer 1090\n",
      "immersion heater 1035\n",
      "active speaker 59\n",
      "external hard disk 10\n",
      "rice cooker 86\n",
      "running machine 83\n",
      "washing machine 128\n",
      "fridge 8\n",
      "games console 9\n",
      "modem 34\n",
      "cooker 45\n",
      "electric space heater 10\n",
      "projector 9\n",
      "freezer 6\n",
      "network attached storage 2\n",
      "server computer 44\n",
      "set top box 62\n",
      "electric oven 6\n",
      "electric stove 6\n"
     ]
    }
   ],
   "source": [
    "def data_preparation(dataset):\n",
    "    X = defaultdict(lambda: [])\n",
    "\n",
    "    for (idx, appliances, data, good_sections) in dataset:\n",
    "        if not appliances:\n",
    "            continue\n",
    "            \n",
    "        appliance = appliances[0]\n",
    "        data = data[0]\n",
    "    \n",
    "        samples = [data[good.start:good.end] for good in good_sections]\n",
    "        X[appliance].extend(samples)\n",
    "        \n",
    "    for appliance, samples in X.items():\n",
    "        print(appliance, len(samples))\n",
    "        \n",
    "    return X\n",
    "\n",
    "prepared_data  = data_preparation(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e63de74-d349-4fbf-ae42-fd9ad8ef2375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boiler 804\n",
      "solar thermal pumping station 785\n",
      "laptop computer 1260\n",
      "washer dryer 167\n",
      "dish washer 68\n",
      "television 200\n",
      "light 861\n",
      "HTPC 75\n",
      "kettle 847\n",
      "toaster 156\n",
      "fridge freezer 601\n",
      "microwave 185\n",
      "computer monitor 1212\n",
      "audio system 100\n",
      "breadmaker 33\n",
      "audio amplifier 64\n",
      "broadband router 19\n",
      "soldering iron 8\n",
      "ethernet switch 105\n",
      "vacuum cleaner 465\n",
      "tablet computer charger 28\n",
      "active subwoofer 22\n",
      "radio 44\n",
      "wireless phone charger 42\n",
      "mobile phone charger 41\n",
      "coffee maker 94\n",
      "hair dryer 558\n",
      "hair straighteners 433\n",
      "clothes iron 78\n",
      "oven 116\n",
      "computer 31\n",
      "baby monitor 15\n",
      "charger 92\n",
      "desktop computer 750\n",
      "fan 51\n",
      "printer 363\n",
      "immersion heater 975\n",
      "active speaker 16\n",
      "external hard disk 7\n",
      "rice cooker 12\n",
      "running machine 22\n",
      "washing machine 39\n",
      "fridge 8\n",
      "games console 3\n",
      "modem 13\n",
      "cooker 11\n",
      "electric space heater 7\n",
      "projector 8\n",
      "freezer 5\n",
      "network attached storage 2\n",
      "server computer 19\n",
      "set top box 19\n",
      "electric oven 5\n",
      "electric stove 4\n"
     ]
    }
   ],
   "source": [
    "processed_data = {}\n",
    "\n",
    "for appliance, samples in prepared_data.items():\n",
    "    processed_samples = []\n",
    "    for sample in samples:\n",
    "        sample = sample.resample('7s').ffill(limit=1).fillna(0)\n",
    "        \n",
    "        # It should contain at least one sample\n",
    "        if len(sample) < 2:\n",
    "            continue\n",
    "        \n",
    "        # TODO: Filter < 20W (Poglej Blažev članek\n",
    "        if not np.any(sample.to_numpy() > 20):\n",
    "            continue\n",
    "            \n",
    "        processed_samples.append(sample)\n",
    "        \n",
    "    \n",
    "    processed_data[appliance] = list(processed_samples)\n",
    "    \n",
    "    #processed_data[appliance] = list([s.resample('7s').ffill(limit=1).fillna(0) for s in samples])\n",
    "    \n",
    "processed_data.pop('unknown', None);\n",
    "\n",
    "for k, v in processed_data.items():\n",
    "    print(k, len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81eaa186-38c6-4e8e-a081-6377e72e463c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_appliance_augmentator(augmentator, *args, **kwargs):\n",
    "    X, y, labels = next(augmentator(processed_data, *args, **kwargs))\n",
    "\n",
    "    f, ax = plt.subplots()\n",
    "    ax.set_title('Augmented time-series')\n",
    "    ax.plot(X)\n",
    "    f.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    n_appliances = kwargs.get('n_appliances_per_sample', None)\n",
    "    f, ax = plt.subplots()\n",
    "\n",
    "    \n",
    "    print('Number of positive datapoints per appliance')\n",
    "    for mask, label in zip(y, labels):\n",
    "        if np.sum(mask) == 0:\n",
    "            continue\n",
    "        \n",
    "        print(f'{label}:\\t {np.sum(mask)}')\n",
    "        \n",
    "\n",
    "        tmp = X.copy()\n",
    "        tmp[~mask] = 0\n",
    "        ax.plot(tmp, linestyle=None, marker='.', label=label, alpha=0.5)\n",
    "        #ax.plot(np.ma.masked_where(mask, np.full_like(X, idx)), marker='.', label=label)\n",
    "    \n",
    "\n",
    "    f.legend(title='markers based on mask')\n",
    "    f.show()\n",
    "    \n",
    "from typing import Iterator, List, Tuple\n",
    "\n",
    "def appliance_augmentator(dataset:Dict[str,list], sample_length:int, n_appliances_per_sample:int, random_state:int=None) -> Iterator[Tuple[np.ndarray, np.ndarray, List[str]]]:\n",
    "    \n",
    "    # Initialize seeded random number generator\n",
    "    rng = np.random.default_rng(seed=random_state)\n",
    "    \n",
    "    # How many appliances are mixed together\n",
    "    N = n_appliances_per_sample\n",
    "    \n",
    "    # Sample length / Window size\n",
    "    L = sample_length\n",
    "    \n",
    "    # Noise floor\n",
    "    NOISE_FLOOR = 20.0\n",
    "    \n",
    "    # Get all available appliances\n",
    "    appliance_names = tuple(dataset.keys())\n",
    "    \n",
    "    # How many appliances are there?\n",
    "    n_appliances = len(appliance_names)\n",
    "    print(\"Number of appliances: \", n_appliances)\n",
    "    # Start endless generator of samples\n",
    "    while True:\n",
    "        # pre-allocate array for time series\n",
    "        series = np.zeros(L, dtype=np.float64)\n",
    "        \n",
    "        # pre-allocate boolean array for masks\n",
    "        labels = np.zeros((n_appliances, L), dtype=bool)\n",
    "        \n",
    "        # Select N random appliances (no replace, because same appliance should not appear twice in the same sample)\n",
    "        # TODO: Relax this limitation in the future, for cases where multiple of same appliances are in the same household\n",
    "        for appliance_idx in rng.choice(n_appliances, size=N, replace=False):\n",
    "            appliance_name = appliance_names[appliance_idx]\n",
    "\n",
    "            # Pick random sample of a selected appliance\n",
    "            n_available_samples = len(dataset[appliance_name])\n",
    "            sample_idx = rng.choice(n_available_samples)\n",
    "            \n",
    "            # retrieve sample as NumPy array with appropriate dimensions\n",
    "            sample_series = dataset[appliance_name][sample_idx].iloc[:].to_numpy().squeeze(axis=-1)\n",
    "            \n",
    "            # If sample is too short (shorter than L), give padding on both sides.\n",
    "            if len(sample_series) <= L:\n",
    "                padding = L // 2\n",
    "                sample_series = np.pad(sample_series, (padding, padding), mode='constant', constant_values=0)\n",
    "            \n",
    "            \n",
    "            # The total length of sample time-series\n",
    "            sample_len = len(sample_series)\n",
    "            \n",
    "            # Sanity check(s)\n",
    "            assert sample_len >= L, f'Sample length should be equal or larger than L: {sample_len} >= {L}'\n",
    "            \n",
    "            sample_offset = rng.choice(sample_len - L)\n",
    "            \n",
    "            sample = sample_series[sample_offset:sample_offset+L]\n",
    "            \n",
    "            # TODO: Currently, we ignore device in idle state (x =< NOISE_FLOOR)\n",
    "            mask = sample > NOISE_FLOOR  # find samples that are above noise floor\n",
    "            \n",
    "            series[:] += sample\n",
    "            labels[appliance_idx, :] |= mask  # logical ORing the mask\n",
    "            \n",
    "        # Add random (constant) offset\n",
    "        #series += rng.random() * (NOISE_FLOOR)\n",
    "            \n",
    "        # There has to be two samples present. Even though we combined two subsets, one or both could be empty.\n",
    "        # Workaround until area of interest is implemented.\n",
    "        if not (np.sum([(np.any(label) > 0) for label in labels]) == N):\n",
    "            continue\n",
    "            \n",
    "        yield series, labels, appliance_names\n",
    "        \n",
    "        \n",
    "        \n",
    "import multiprocessing as mp\n",
    "\n",
    "\n",
    "\n",
    "def process(random_state):\n",
    "    # Initialize internal seeded random number generator\n",
    "    rng = np.random.default_rng(seed=random_state)\n",
    "    \n",
    "    # Try to generate valid sample\n",
    "    #while True:\n",
    "    # pre-allocate array for time series\n",
    "    series = np.zeros(L, dtype=np.float64)\n",
    "\n",
    "    # pre-allocate boolean array for masks\n",
    "    labels = np.zeros((n_appliances, L), dtype=bool)\n",
    "\n",
    "    # Select N random appliances (no replace, because same appliance should not appear twice in the same sample)\n",
    "    # TODO: Relax this limitation in the future, for cases where multiple of same appliances are in the same household\n",
    "    # h\n",
    "    for appliance_idx in rng.choice(n_appliances, size=N, replace=False):\n",
    "        appliance_name = appliance_names[appliance_idx]\n",
    "\n",
    "        # Pick random sample of a selected appliance\n",
    "        n_available_samples = len(dataset[appliance_name])\n",
    "        sample_idx = rng.choice(n_available_samples)\n",
    "\n",
    "        # retrieve sample as NumPy array with appropriate dimensions\n",
    "        sample_series = dataset[appliance_name][sample_idx].iloc[:].to_numpy().squeeze(axis=-1)\n",
    "\n",
    "        # If sample is too short (shorter than L), give padding on both sides.\n",
    "        if len(sample_series) <= L:\n",
    "            padding = L // 2\n",
    "            sample_series = np.pad(sample_series, (padding, padding), mode='constant', constant_values=0)\n",
    "\n",
    "\n",
    "        # The total length of sample time-series\n",
    "        sample_len = len(sample_series)\n",
    "\n",
    "        # Sanity check(s)\n",
    "        assert sample_len >= L, f'Sample length should be equal or larger than L: {sample_len} >= {L}'\n",
    "\n",
    "        while True:\n",
    "            sample_offset = rng.choice(sample_len - L)\n",
    "            sample = sample_series[sample_offset:sample_offset+L]\n",
    "            \n",
    "            # TODO: Currently, we ignore device in idle state (x =< NOISE_FLOOR)\n",
    "            mask = sample > NOISE_FLOOR  # find samples that are above noise floor\n",
    "            \n",
    "            if np.any(mask):\n",
    "                break\n",
    "\n",
    "\n",
    "\n",
    "        series[:] += sample\n",
    "        labels[appliance_idx, :] |= mask  # logical ORing the mask\n",
    "\n",
    "    # Add random (constant) offset\n",
    "    #series += rng.random() * (NOISE_FLOOR)\n",
    "\n",
    "    # There has to be two samples present. Even though we combined two subsets, one or both could be empty.\n",
    "    # Workaround until area of interest is implemented.\n",
    "    #if (np.sum([(np.any(label) > 0) for label in labels]) == N):\n",
    "    #    break\n",
    "\n",
    "    return series, labels, appliance_names\n",
    "            \n",
    "\n",
    "\n",
    "def parallel_appliance_augmentator(_dataset:Dict[str,list], sample_length:int, n_appliances_per_sample:int, n_samples:int, random_state:int=None) -> list:\n",
    "    import sys\n",
    "    \n",
    "    global N, L, NOISE_FLOOR, appliance_names, n_appliances, dataset\n",
    "    \n",
    "    dataset = _dataset\n",
    "\n",
    "    # How many appliances are mixed together\n",
    "    N = n_appliances_per_sample\n",
    "\n",
    "    # Sample length / Window size\n",
    "    L = sample_length\n",
    "\n",
    "    # Noise floor\n",
    "    NOISE_FLOOR = 20.0\n",
    "\n",
    "    # Get all available appliances\n",
    "    appliance_names = tuple(dataset.keys())\n",
    "\n",
    "    # How many appliances are there?\n",
    "    n_appliances = len(appliance_names)\n",
    "    \n",
    "    # if random_state is not defined, generate it on the fly\n",
    "    if random_state == None:\n",
    "        random_state = np.random.randint(0, sys.maxsize)\n",
    "    \n",
    "            \n",
    "    with mp.Pool() as pool:\n",
    "        outputs = pool.map(process, np.arange(n_samples) + random_state)\n",
    "        \n",
    "    return tuple(outputs)\n",
    "\n",
    "\n",
    "#samples = parallel_appliance_augmentator(processed_data, sample_length=128, n_appliances_per_sample=14, n_samples=256, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "350eaea5-875c-4eac-ba5f-2ec37ed97863",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def DevicesDataXY(number_of_datasets: int, \n",
    "                  number_of_devices_in_datasets: int, \n",
    "                  number_of_all_devices: int):\n",
    "    \n",
    "    # This function uses processed_data and shapes it into two lists \n",
    "    # one of them contains data from devices (dataX_Y) and one of them names of devices (devicesX_Y).\n",
    "    # Lists contain multiple datasets specified with number_of_datasets, all of which have \n",
    "    # the same number of devices in them, specified by number_of_devices_in_datasets.\n",
    "    # We choose devices for datasets randomly, thus we have to specify the number of all devices in the REFIT (22) or UKDALE dataset (54).\n",
    "    \n",
    "    # we extract the dictionary processed_data into a list AllTable\n",
    "    AllTable = [[k,v] for k,v in processed_data.items()]\n",
    "    \n",
    "    devicesX_Y = []\n",
    "    dataX_Y = []\n",
    "    \n",
    "    # for loop goes over all datasets\n",
    "    for i in range(0,number_of_datasets):    \n",
    "        devicesY = []\n",
    "        dataY = []\n",
    "        j = 0\n",
    "        \n",
    "        # while loop goes over all devices in datasets\n",
    "        while j < number_of_devices_in_datasets:\n",
    "            \n",
    "            # we get a random number with random library\n",
    "            random_number = random.randrange(number_of_all_devices)\n",
    "            \n",
    "            # we use the random number to get a random device and random data that belongs to it from AllTable\n",
    "            random_device = AllTable[random_number][0]\n",
    "            random_data = AllTable[random_number][1]\n",
    "            \n",
    "            # we append the device and its data if it doesn't already exist \n",
    "            # and thus avoid having the same device more then once in the same dataset\n",
    "            if random_device not in devicesY:\n",
    "                devicesY.append(random_device)\n",
    "                dataY.append(random_data)\n",
    "                j += 1\n",
    "        \n",
    "        devicesX_Y.append(devicesY)\n",
    "        dataX_Y.append(dataY)\n",
    "    \n",
    "    return devicesX_Y, dataX_Y\n",
    "\n",
    "\n",
    "def DevicesDataHoly5(dataset_name: list):\n",
    "    \n",
    "    # This function does the same as DevicesDataXY except it makes only one dataset\n",
    "    # and the dataset doesn't have randomly selected devices, but it has particular 5 devices:\n",
    "    # Fridge, Washing Machine, Dish Washer, Microwave, Kettle.\n",
    "    \n",
    "    # we extract the dictionary processed_data into a list AllTable\n",
    "    AllTable=[[k,v] for k,v in processed_data.items()]\n",
    "    \n",
    "    devicesX_Y, dataX_Y, devicesY, dataY = [], [], [], []\n",
    "    \n",
    "    # the holy 5 devices are in this order in our processed_data from refit\n",
    "    if dataset_name == \"refit\": nm_div = [0,3,4,11,12]\n",
    "    \n",
    "    # the holy 5 devices are in this order in our processed_data from uk-dale\n",
    "    elif dataset_name == \"uk-dale\": nm_div = [42,41,4,11,8]\n",
    "    \n",
    "    else: \n",
    "        print(\"Wrong name of the dataset, write either refit or uk-dale\") \n",
    "    \n",
    "    # we go over the AllTable and append devices and data for the holy 5 devices\n",
    "    for i in range(5):\n",
    "        number = nm_div[i]\n",
    "        device = AllTable[number][0]\n",
    "        data = AllTable[number][1]\n",
    "        devicesY.append(device)\n",
    "        dataY.append(data)\n",
    "    \n",
    "    # we make a useless step because it works better with other functions that way\n",
    "    devicesX_Y.append(devicesY)\n",
    "    dataX_Y.append(dataY)\n",
    "    \n",
    "    return devicesX_Y, dataX_Y\n",
    "\n",
    "\n",
    "def ListsToDictlist(devices: list, data: list, number_of_devices: int):\n",
    "    \n",
    "    # This function takes lists from DevicesDataXY or DevicesDataHoly5 and\n",
    "    # turns each of the sublists into a dictionary and then appends those dicitonaries into a list. \n",
    "    \n",
    "    Dictlist=[]\n",
    "    \n",
    "    # we make dictionaries out of lists that we input and append them to list of dictionaries (Dictlist)\n",
    "    for i in range(0,number_of_devices):\n",
    "        dictionary=dict(zip(devices[i], data[i]))\n",
    "        Dictlist.append(dictionary)\n",
    "        \n",
    "    return Dictlist\n",
    "\n",
    "\n",
    "def Generate4(Dictlist: list, \n",
    "              sample_length: int, \n",
    "              n_appliances_per_sample: int, \n",
    "              dataset_number: int):\n",
    "    \n",
    "    # This function generates x_train, x_test, y_train, y_test, labels datasets \n",
    "    # using the appliance_augmentator function and the Dictlist\n",
    "    \n",
    "    X, Y, labels = [], [], None\n",
    "    \n",
    "    generator = appliance_augmentator(Dictlist[dataset_number], \n",
    "                                      sample_length=sample_length, \n",
    "                                      n_appliances_per_sample=n_appliances_per_sample, \n",
    "                                      random_state=0xDEADBEEF)\n",
    "    \n",
    "    for idx, (_x, _y, labels) in zip(range(120_000), generator):\n",
    "        X.append(_x), Y.append(_y)\n",
    "        \n",
    "    X, Y = np.asarray(X), np.asarray(Y)\n",
    "    y = np.any(Y, axis=-1) > 0\n",
    "    sample_weight = np.sum(Y, axis=-1) / 128\n",
    "    \n",
    "    # split into train test sets\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    \n",
    "    # adds the needed dimension\n",
    "    x_train = np.expand_dims(x_train, -1)\n",
    "    x_test = np.expand_dims(x_test, -1)\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test, labels\n",
    "\n",
    "\n",
    "def Generate4Upgraded(Dictlist: list, \n",
    "              sample_length: int, \n",
    "              n_appliances_per_sample: int, \n",
    "              dataset_number: int,\n",
    "              number_of_generated_samples: int\n",
    "                     ):\n",
    "    \n",
    "    # This function does the same as Generate4 except here we can specify the number of all generated samples. \n",
    "    \n",
    "    X, Y, labels = [], [], None\n",
    "    \n",
    "    generator = parallel_appliance_augmentator(Dictlist[dataset_number], \n",
    "                                      sample_length=sample_length, \n",
    "                                      n_appliances_per_sample=n_appliances_per_sample,\n",
    "                                      n_samples=number_of_generated_samples,\n",
    "                                      random_state=0xDEADBEEF)\n",
    "    \n",
    "    for idx, (_x, _y, labels) in zip(range(number_of_generated_samples), generator):\n",
    "        X.append(_x), Y.append(_y)\n",
    "        \n",
    "    X, Y = np.asarray(X), np.asarray(Y)\n",
    "    y = np.any(Y, axis=-1) > 0\n",
    "    sample_weight = np.sum(Y, axis=-1) / 128\n",
    "    \n",
    "    # split into train test sets\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    \n",
    "    # add the needed dimension\n",
    "    x_train = np.expand_dims(x_train, -1)\n",
    "    x_test = np.expand_dims(x_test, -1)\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test, labels\n",
    "\n",
    "\n",
    "def GenerateRandom4(Dictlist: list, \n",
    "              sample_length: int,  \n",
    "              dataset_number: int,\n",
    "              table_of_options: list,\n",
    "              number_of_generated_samples: int\n",
    "              ):\n",
    "    # This function generates x_train, x_test, y_train, y_test, labels; datasets. \n",
    "    # Datasets consist of equal parts of options from table of options.\n",
    "    # EX: If you have table_of_options = [1,2,3,4] the dataset will be 1/4 data with 1 active device, 1/4 data with 2 active devices, ...\n",
    "    # Dataset is mixed so that samples are randomly dispersed throughout the dataset\n",
    "    \n",
    "    # First we calculate the number of samples that needs to be generated for each of the datasets that will be mixed into one\n",
    "    number_of_generated_samples = number_of_generated_samples / len(table_of_options)\n",
    "    number_of_generated_samples = int(number_of_generated_samples)\n",
    "    \n",
    "    # we introduce np.arrays in appropriate shape by making them as the first dataset with table_of_options[0] active devices\n",
    "    x_tr, x_te, y_tr, y_te, labels = Generate4Upgraded(Dictlist,\n",
    "                                                        sample_length,\n",
    "                                                        table_of_options[0],\n",
    "                                                        dataset_number,\n",
    "                                                        number_of_generated_samples)\n",
    "    \n",
    "    # we rename them for later use if len(table_of_options) > 1\n",
    "    x_train = x_tr\n",
    "    x_test = x_te\n",
    "    y_train = y_tr\n",
    "    y_test = y_te\n",
    "    \n",
    "    # loading bar\n",
    "    #print(\"|>_____|\")\n",
    "    print(\"1 AD\")\n",
    "    \n",
    "    # we make the rest of the datasets and append them to the first one\n",
    "    for i in range(1,len(table_of_options)):\n",
    "        n_appliances_per_sample = table_of_options[i]\n",
    "        x_tr, x_te, y_tr, y_te, lab = Generate4Upgraded(Dictlist,\n",
    "                                                        sample_length,\n",
    "                                                        n_appliances_per_sample,\n",
    "                                                        dataset_number,\n",
    "                                                        number_of_generated_samples)\n",
    "        x_train = numpy.append(x_train, x_tr, axis=0)\n",
    "        x_test = numpy.append(x_test, x_te, axis=0)\n",
    "        y_train = numpy.append(y_train, y_tr, axis=0)\n",
    "        y_test = numpy.append(y_test, y_te, axis=0)\n",
    "        print(f\"{i+1} AD\")\n",
    "        \n",
    "    # we print out the final shapes before returning new datasets\n",
    "    print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
    "        \n",
    "    # loading bar\n",
    "    print(\"|->____|\")\n",
    "    \n",
    "    # Now that we have a dataset that consists of len(table_of_options) datasets with different numbers of active devices,\n",
    "    # we just have to make the final dataset that will be made of exactly the same samples but in a random order.\n",
    "    \n",
    "    # To do so first introduce new tables  \n",
    "    tm_train, tm_test = [], []\n",
    "    \n",
    "    # We adjust the number_of_generated_samples back to its original value\n",
    "    number_of_generated_samples = int(number_of_generated_samples*len(table_of_options))\n",
    "    #print(\"number_of_generated_samples: \", number_of_generated_samples)\n",
    "    \n",
    "    # we fill tables with integers in order 1,2,3,4,5,6...\n",
    "    \n",
    "    #for m in range(1,int(number_of_generated_samples*0.8)):\n",
    "    #print(\"range(1,\",int(math.floor((number_of_generated_samples*0.8)/len(table_of_options))*len(table_of_options)-1),\")\")\n",
    "    for m in range(1,int(math.floor((number_of_generated_samples*0.8)/len(table_of_options))*len(table_of_options)-1)):\n",
    "        tm_train.append(m)\n",
    "    \n",
    "    #for n in range(1,int(number_of_generated_samples*0.2)):\n",
    "    #print(\"range(1,\",int(math.floor((number_of_generated_samples*0.2)/len(table_of_options))*len(table_of_options)-1),\")\")\n",
    "    for n in range(1,int(math.floor((number_of_generated_samples*0.2)/len(table_of_options))*len(table_of_options)-1)):\n",
    "        tm_test.append(n)\n",
    "    \n",
    "    # we shuffle the order of those integers so that it is random\n",
    "    random.shuffle(tm_train)\n",
    "    random.shuffle(tm_test)\n",
    "    \n",
    "    # loading bar\n",
    "    print(\"|-->___|\")\n",
    "    \n",
    "    # we introduce np.arrays in an appropriate shape by assigning the first sample of the final datasets to be the first samples of the first datasest\n",
    "    x_train_random = np.expand_dims(x_train[0], axis=0)\n",
    "    x_test_random = np.expand_dims(x_test[0], axis=0)\n",
    "    y_train_random = np.expand_dims(y_train[0], axis=0)\n",
    "    y_test_random = np.expand_dims(y_test[0], axis=0)\n",
    "    \n",
    "    # loading bar\n",
    "    print(\"|--->__|\")\n",
    "    \n",
    "    # we append to the arrays by using random order of tm_train\n",
    "    # to make x and y array in the same random order (because we move the same random row in x and y train dataset)\n",
    "    \n",
    "     \n",
    "    # we also split x : y = 80 : 20\n",
    "    #for g in range(0,int(number_of_generated_samples*0.8-1)):\n",
    "    #print(\"range(0,\",int(number_of_generated_samples*0.8-1),\")\")\n",
    "    #print(\"range(0,\",int(math.floor((number_of_generated_samples*0.8)/len(table_of_options))*len(table_of_options)-3),\")\")\n",
    "    for g in range(0,int(math.floor((number_of_generated_samples*0.8)/len(table_of_options))*len(table_of_options)-3)):\n",
    "        \n",
    "        # we add the needed dimension ex: (256, 1) -> (1, 256, 1)\n",
    "        x_applicable = np.expand_dims(x_train[tm_train[g]], axis=0)\n",
    "        y_applicable = np.expand_dims(y_train[tm_train[g]], axis=0)\n",
    "        \n",
    "        # we append the applicable lists to the dataset\n",
    "        x_train_random = numpy.append(x_train_random, x_applicable, axis=0)\n",
    "        y_train_random = numpy.append(y_train_random, y_applicable, axis=0)\n",
    "        \n",
    "        # we print out a message for every 10k appended to preserve your sanity\n",
    "        if g % 10_000 == 0: print(\"k*10k: \", g)\n",
    "        \n",
    "        if g > 95980: print(\"g je \", g)\n",
    "    # loading bar\n",
    "    print(\"|---->_|\")    \n",
    "    \n",
    "    # we append to the arrays by using random order of tm_test\n",
    "    # to make the array in the same random order    \n",
    "    #for h in range(0,int(number_of_generated_samples*0.2-1)): \n",
    "    #print(\"range(0,\",int(math.floor((number_of_generated_samples*0.2)/len(table_of_options))*len(table_of_options)-3),\")\")\n",
    "    for h in range(0,int(math.floor((number_of_generated_samples*0.2)/len(table_of_options))*len(table_of_options)-3)): \n",
    "        \n",
    "        # we add the needed dimension ex: (256, 1) -> (1, 256, 1)\n",
    "        x_app = np.expand_dims(x_test[tm_test[h]],axis=0)\n",
    "        y_app = np.expand_dims(y_test[tm_test[h]],axis=0)\n",
    "        \n",
    "        # we append the applicable lists to the dataset\n",
    "        x_test_random = numpy.append(x_test_random, x_app, axis=0)\n",
    "        y_test_random = numpy.append(y_test_random, y_app, axis=0)\n",
    "        \n",
    "        # we print out a message for every 10k appended to preserve your sanity\n",
    "        if h%10_000==0: print(\"k*10k: \", h)\n",
    "        \n",
    "    # loading bar\n",
    "    print(\"|----->|\")    \n",
    "    \n",
    "    # we print out the final shapes before returning new datasets\n",
    "    print(x_train_random.shape, x_test_random.shape, y_train_random.shape, y_test_random.shape)\n",
    "    \n",
    "    return x_train_random, x_test_random, y_train_random, y_test_random, labels\n",
    "\n",
    "\n",
    "def class_weights_tool(y_test):\n",
    "    \n",
    "    # This function returns class weights for each device in a prticular dataset in a form of a dicitionary.\n",
    "    # It does so by simply counting how many times the device is present througout the dataset.\n",
    "    \n",
    "    # inspired by ronnie coleman\n",
    "    light_weight, nums = [], []\n",
    "    \n",
    "    # this for loop goes over the collumns of the y_test dataset\n",
    "    for j in range(0,len(y_test[0])):             \n",
    "        \n",
    "        count=0\n",
    "        \n",
    "        # gives 0,1,2,3,4,5,6....\n",
    "        nums.append(j)\n",
    "        \n",
    "        # this loop goes over the rows in the y_test dataset\n",
    "        for i in range(0,len(y_test)):\n",
    "            \n",
    "            # we count Trues in the whole column of y_test dataset\n",
    "            if y_test[i][j] == True: count+=1     \n",
    "        \n",
    "        # we append Trues for the column of y_test dataset to the list light_weight\n",
    "        light_weight.append(count)\n",
    "        \n",
    "    # makes the dictionary    \n",
    "    class_weights_dictionary = dict(zip(nums, light_weight))             \n",
    "    \n",
    "    return class_weights_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a22e9f-7236-4d46-a3aa-ebfc5a435ce4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "407244dc-69e4-4aef-90a7-b1b32409ad02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "import math\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Flatten, Dense, Input, GRU, BatchNormalization, LSTM, Bidirectional, AveragePooling1D\n",
    "from keras.layers import Conv1D, Conv1DTranspose, LocallyConnected1D, SeparableConv1D, ConvLSTM1D\n",
    "from keras.layers import MaxPooling1D, Dropout\n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "from keras.layers import GlobalAveragePooling1D\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras import backend as K\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "#from keras.applications.imagenet_utils import _obtain_input_shape\n",
    "#from keras.engine.topology import get_source_inputs\n",
    "\n",
    "\n",
    "#WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "#WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "\n",
    "def VGG19_1D(classes,\n",
    "             window_size,\n",
    "             gru,\n",
    "             gru_num,\n",
    "             include_top=True,\n",
    "             input_tensor=None,\n",
    "              pooling=None):\n",
    "\n",
    "    # Determine proper input shape\n",
    "    input_shape = (window_size,1)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "    # Block 1\n",
    "    x = Conv1D(64, (3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
    "    x = Conv1D(64, (3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "    x = MaxPooling1D((2), strides=(2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv1D(128, (3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "    x = Conv1D(128, (3), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "    x = MaxPooling1D((2), strides=(2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv1D(256, (3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "    x = Conv1D(256, (3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "    x = Conv1D(256, (3), activation='relu', padding='same', name='block3_conv3')(x)\n",
    "    x = Conv1D(256, (3), activation='relu', padding='same', name='block3_conv4')(x)\n",
    "    x = MaxPooling1D((2), strides=(2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv1D(512, (3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    x = Conv1D(512, (3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "    x = Conv1D(512, (3), activation='relu', padding='same', name='block4_conv3')(x)\n",
    "    x = Conv1D(512, (3), activation='relu', padding='same', name='block4_conv4')(x)\n",
    "    x = MaxPooling1D((2), strides=(2), name='block4_pool')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv1D(512, (3), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "    x = Conv1D(512, (3), activation='relu', padding='same', name='block5_conv2')(x)\n",
    "    x = Conv1D(512, (3), activation='relu', padding='same', name='block5_conv3')(x)\n",
    "    x = Conv1D(512, (3), activation='relu', padding='same', name='block5_conv4')(x)\n",
    "    x = MaxPooling1D((2), strides=(2), name='block5_pool')(x)\n",
    "    \n",
    "    # GRU layer, btw GRU stands for Gated Recurrent Units\n",
    "    if gru == True:\n",
    "        print(\"GRU enabled\")\n",
    "        x = GRU(gru_num, activation='tanh', recurrent_activation='sigmoid')(x)\n",
    "\n",
    "    if include_top:\n",
    "        # Classification block\n",
    "        x = Flatten(name='flatten')(x)\n",
    "        x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "        x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "        x = Dense(classes, activation='sigmoid', name='predictions')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = GlobalAveragePooling1D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = GlobalMaxPooling1D()(x)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "    # Create model.\n",
    "    model = Model(inputs, x, name='vgg19_1D')\n",
    "    return model\n",
    "\n",
    "def VGG11_1D(classes,\n",
    "             window_size,\n",
    "             include_top=True,\n",
    "             input_tensor=None,\n",
    "              pooling=None):\n",
    "\n",
    "    # Determine proper input shape\n",
    "    input_shape = (window_size,1)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "    # Block 1\n",
    "    x = Conv1D(64, (3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
    "    x = MaxPooling1D((2), strides=(2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv1D(128, (3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "    x = MaxPooling1D((2), strides=(2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv1D(256, (3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "    x = Conv1D(256, (3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "    x = MaxPooling1D((2), strides=(2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv1D(512, (3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    x = Conv1D(512, (3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "    x = MaxPooling1D((2), strides=(2), name='block4_pool')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv1D(512, (3), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "    x = Conv1D(512, (3), activation='relu', padding='same', name='block5_conv2')(x)\n",
    "    x = MaxPooling1D((2), strides=(2), name='block5_pool')(x)\n",
    "\n",
    "    if include_top:\n",
    "        # Classification block\n",
    "        x = Flatten(name='flatten')(x)\n",
    "        x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "        x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "        x = Dense(classes, activation='sigmoid', name='predictions')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = GlobalAveragePooling1D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = GlobalMaxPooling1D()(x)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "    # Create model.\n",
    "    model = Model(inputs, x, name='vgg11_1D')\n",
    "    return model\n",
    "\n",
    "def LOL(classes,\n",
    "             window_size,\n",
    "             method,\n",
    "             method_num,\n",
    "             include_top=True,\n",
    "             input_tensor=None,\n",
    "              pooling=None):\n",
    "\n",
    "    # Determine proper input shape\n",
    "    input_shape = (window_size,1)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "            \n",
    "    # Block 1\n",
    "    x = Conv1D(64, (3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
    "    x = Conv1D(64, (3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "    x = AveragePooling1D((2), strides=(2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv1D(128, (3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "    x = Conv1D(128, (3), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "    x = AveragePooling1D((2), strides=(2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv1D(256, (3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "    x = Conv1D(256, (3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "    x = AveragePooling1D((2), strides=(2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv1D(512, (3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    x = Conv1D(512, (3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "    x = AveragePooling1D((2), strides=(2), name='block4_pool')(x)\n",
    "    \n",
    "    # GRU layer, btw GRU stands for Gated Recurrent Units; https://en.wikipedia.org/wiki/Gated_recurrent_unit\n",
    "    if method == 'gru':\n",
    "        print(\"GRU enabled\")\n",
    "        x = GRU(method_num, activation='tanh', recurrent_activation='sigmoid')(x)\n",
    "        \n",
    "    # LSTM layer, btw LSTM stands for long short-term memory; https://en.wikipedia.org/wiki/Long_short-term_memory    \n",
    "    if method == 'lstm':\n",
    "        print(\"LSTM enabled\")\n",
    "        x = LSTM(method_num, activation='tanh', recurrent_activation='sigmoid')(x)\n",
    "    \n",
    "    if include_top:\n",
    "        # Classification block\n",
    "        x = Flatten(name='flatten')(x)\n",
    "        x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "        x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "        x = Dense(classes, activation='sigmoid', name='predictions')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = GlobalAveragePooling1D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = GlobalMaxPooling1D()(x)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "    # Create model.\n",
    "    model = Model(inputs, x, name='LOL')\n",
    "    return model\n",
    "\n",
    "\n",
    "def LOL2(classes,\n",
    "             window_size,\n",
    "             method,\n",
    "             method_num,\n",
    "             include_top=True,\n",
    "             input_tensor=None,\n",
    "              pooling=None):\n",
    "\n",
    "    # Determine proper input shape\n",
    "    input_shape = (window_size,1)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "    # Block 1\n",
    "    x = Conv1D(64, (3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
    "    x = Conv1D(64, (3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "    x = AveragePooling1D((2), strides=(2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv1D(128, (3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "    x = Conv1D(128, (3), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "    x = AveragePooling1D((2), strides=(2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv1D(256, (3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "    x = Conv1D(256, (3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "    x = AveragePooling1D((2), strides=(2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv1D(512, (3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    x = Conv1D(512, (3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "    x = AveragePooling1D((2), strides=(2), name='block4_pool')(x)\n",
    "    \n",
    "    # Block 5\n",
    "    x = Conv1DTranspose(512, (3), activation='relu', padding='same', name='block5_tran_conv1')(x)\n",
    "    #x = Conv1DTranspose(512, (3), activation='relu', padding='same', name='block5_tran_conv2')(x)\n",
    "    x = AveragePooling1D((2), strides=(2), name='block5_pool')(x)\n",
    "    \n",
    "    # GRU layer, btw GRU stands for Gated Recurrent Units; https://en.wikipedia.org/wiki/Gated_recurrent_unit\n",
    "    if method == 'gru':\n",
    "        print(\"GRU enabled\")\n",
    "        x = GRU(method_num, activation='tanh', recurrent_activation='sigmoid')(x)                \n",
    "        \n",
    "    if method == 'gru2':\n",
    "        print(\"GRU enabled\")\n",
    "        x = GRU(method_num,activation='tanh',recurrent_activation='sigmoid',reset_after=True)(x)        \n",
    "        \n",
    "    if method == 'bigru':\n",
    "        print(\"Bi-GRU enabled\")\n",
    "        x = Bidirectional(GRU(method_num, activation='tanh', recurrent_activation='sigmoid'))(x)\n",
    "        \n",
    "    if method == 'lstm':\n",
    "        print(\"LSTM enabled\")\n",
    "        x = LSTM(method_num, activation='tanh', recurrent_activation='sigmoid')(x)\n",
    "    \n",
    "    # LSTM layer, btw LSTM stands for long short-term memory; https://en.wikipedia.org/wiki/Long_short-term_memory\n",
    "    if include_top:\n",
    "        # Classification block\n",
    "        x = Flatten(name='flatten')(x)\n",
    "        x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "        x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "        x = Dense(classes, activation='sigmoid', name='predictions')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = GlobalAveragePooling1D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = GlobalMaxPooling1D()(x)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "    # Create model.\n",
    "    model = Model(inputs, x, name='LOL2')\n",
    "    return model\n",
    "\n",
    "\n",
    "def LOL3(classes,\n",
    "             window_size,\n",
    "             method,\n",
    "             method_num,\n",
    "             include_top=True,\n",
    "             input_tensor=None,\n",
    "              pooling=None):\n",
    "\n",
    "    # Determine proper input shape\n",
    "    input_shape = (window_size,1)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "    # Block 1\n",
    "    x = Conv1D(64, (3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
    "    x = Conv1D(64, (3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "    x = MaxPooling1D((2), strides=(2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv1D(128, (3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "    x = Conv1D(128, (3), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "    x = MaxPooling1D((2), strides=(2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv1D(256, (3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "    x = Conv1D(256, (3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "    x = Conv1D(256, (3), activation='relu', padding='same', name='block3_conv3')(x)\n",
    "    x = Conv1D(256, (3), activation='relu', padding='same', name='block3_conv4')(x)\n",
    "    x = MaxPooling1D((2), strides=(2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv1D(512, (3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    x = Conv1D(512, (3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "    x = Conv1D(512, (3), activation='relu', padding='same', name='block4_conv3')(x)\n",
    "    x = Conv1D(512, (3), activation='relu', padding='same', name='block4_conv4')(x)\n",
    "    x = MaxPooling1D((2), strides=(2), name='block4_pool')(x)\n",
    "    \n",
    "    # Block 5\n",
    "    x = Conv1DTranspose(512, (3), activation='relu', padding='same', name='block5_tran_conv1')(x)\n",
    "    x = Conv1DTranspose(512, (3), activation='relu', padding='same', name='block5_tran_conv2')(x)\n",
    "    x = Conv1DTranspose(512, (3), activation='relu', padding='same', name='block5_tran_conv3')(x)\n",
    "    x = Conv1DTranspose(512, (3), activation='relu', padding='same', name='block5_tran_conv4')(x)\n",
    "    x = AveragePooling1D((2), strides=(2), name='block5_pool')(x)\n",
    "    \n",
    "    # GRU layer, btw GRU stands for Gated Recurrent Units; https://en.wikipedia.org/wiki/Gated_recurrent_unit\n",
    "    if method == 'gru':\n",
    "        print(\"GRU enabled\")\n",
    "        x = GRU(method_num, activation='tanh', recurrent_activation='sigmoid')(x)                \n",
    "        \n",
    "    if method == 'gru2':\n",
    "        print(\"GRU enabled\")\n",
    "        x = GRU(method_num,activation='tanh',recurrent_activation='sigmoid',reset_after=True)(x)        \n",
    "        \n",
    "    if method == 'bigru':\n",
    "        print(\"Bi-GRU enabled\")\n",
    "        x = Bidirectional(GRU(method_num, activation='tanh', recurrent_activation='sigmoid'))(x)\n",
    "        \n",
    "    if method == 'lstm':\n",
    "        print(\"LSTM enabled\")\n",
    "        x = LSTM(method_num, activation='tanh', recurrent_activation='sigmoid')(x)\n",
    "    \n",
    "    # LSTM layer, btw LSTM stands for long short-term memory; https://en.wikipedia.org/wiki/Long_short-term_memory\n",
    "    if include_top:\n",
    "        # Classification block\n",
    "        x = Flatten(name='flatten')(x)\n",
    "        x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "        x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "        x = Dense(classes, activation='sigmoid', name='predictions')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = GlobalAveragePooling1D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = GlobalMaxPooling1D()(x)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "    # Create model.\n",
    "    model = Model(inputs, x, name='LOL3')\n",
    "    return model\n",
    "\n",
    "def TEST(koef, classes,\n",
    "             window_size,\n",
    "             method,\n",
    "             method_num,\n",
    "             include_top=True,\n",
    "             input_tensor=None,\n",
    "              pooling=None):\n",
    "    k = koef\n",
    "    # Determine proper input shape\n",
    "    input_shape = (window_size,1)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "    # Block 1\n",
    "    x = Conv1D(64*k, (3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
    "    x = Conv1D(64*k, (3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "    x = MaxPooling1D((2), strides=(2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv1D(128*k, (3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "    x = Conv1D(128*k, (3), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "    x = MaxPooling1D((2), strides=(2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv1D(256*k, (3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "    x = Conv1D(256*k, (3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "    x = Conv1D(256*k, (3), activation='relu', padding='same', name='block3_conv3')(x)\n",
    "    x = Conv1D(256*k, (3), activation='relu', padding='same', name='block3_conv4')(x)\n",
    "    x = MaxPooling1D((2), strides=(2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv1D(512*k, (3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    x = Conv1D(512*k, (3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "    x = Conv1D(512*k, (3), activation='relu', padding='same', name='block4_conv3')(x)\n",
    "    x = Conv1D(512*k, (3), activation='relu', padding='same', name='block4_conv4')(x)\n",
    "    x = MaxPooling1D((2), strides=(2), name='block4_pool')(x)\n",
    "    \n",
    "    # Block 5\n",
    "    x = Conv1DTranspose(512*k, (3), activation='relu', padding='same', name='block5_tran_conv1')(x)\n",
    "    x = Conv1DTranspose(512*k, (3), activation='relu', padding='same', name='block5_tran_conv2')(x)\n",
    "    x = Conv1DTranspose(512*k, (3), activation='relu', padding='same', name='block5_tran_conv3')(x)\n",
    "    x = Conv1DTranspose(512*k, (3), activation='relu', padding='same', name='block5_tran_conv4')(x)\n",
    "    x = AveragePooling1D((2), strides=(2), name='block5_pool')(x)\n",
    "    \n",
    "    # GRU layer, btw GRU stands for Gated Recurrent Units; https://en.wikipedia.org/wiki/Gated_recurrent_unit\n",
    "    if method == 'gru':\n",
    "        print(\"GRU enabled\")\n",
    "        x = GRU(method_num, activation='tanh', recurrent_activation='sigmoid')(x)                \n",
    "        \n",
    "    if method == 'gru2':\n",
    "        print(\"GRU enabled\")\n",
    "        x = GRU(method_num,activation='tanh',recurrent_activation='sigmoid',reset_after=True)(x)        \n",
    "        \n",
    "    if method == 'bigru':\n",
    "        print(\"Bi-GRU enabled\")\n",
    "        x = Bidirectional(GRU(method_num, activation='tanh', recurrent_activation='sigmoid'))(x)\n",
    "        \n",
    "    if method == 'lstm':\n",
    "        print(\"LSTM enabled\")\n",
    "        x = LSTM(method_num, activation='tanh', recurrent_activation='sigmoid')(x)\n",
    "    \n",
    "    # LSTM layer, btw LSTM stands for long short-term memory; https://en.wikipedia.org/wiki/Long_short-term_memory\n",
    "    if include_top:\n",
    "        # Classification block\n",
    "        x = Flatten(name='flatten')(x)\n",
    "        x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "        x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "        x = Dense(classes, activation='sigmoid', name='predictions')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = GlobalAveragePooling1D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = GlobalMaxPooling1D()(x)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "    # Create model.\n",
    "    model = Model(inputs, x, name=f'TEST')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84772dbd-6318-4aac-9f83-58ec9da1811a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "           TANONI MODEL\n",
    "\"\"\"\n",
    "from keras.layers import Conv1D, BatchNormalization, Activation, Dropout, Bidirectional, MaxPooling1D, GRU, Dense\n",
    "\n",
    "def Tanoni():\n",
    "    model = keras.Sequential([\n",
    "        \n",
    "        # Tanoni block 1\n",
    "        layers.Conv1D(filters=32, kernel_size=(3), padding='same', input_shape=(2550,1)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        \n",
    "        # Tanoni block 2\n",
    "        layers.Conv1D(filters=64, kernel_size=(3), padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        \n",
    "        # Tanoni block 3\n",
    "        layers.Conv1D(filters=128, kernel_size=(3), padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        \n",
    "        # Tanoni block 4\n",
    "        layers.Conv1D(filters=256, kernel_size=(3), padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        \n",
    "        # Tanoni block 5\n",
    "        layers.Conv1D(filters=512, kernel_size=(3), padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        \n",
    "        # BiGRU\n",
    "        layers.Bidirectional(GRU(64)),\n",
    "        \n",
    "        # FCL - Sigmoid\n",
    "        layers.Dense(5, activation='sigmoid')\n",
    "        \n",
    "        #layers.MaxPooling1D(1),\n",
    "        \n",
    "        #layers.Activation(activations.sigmoid)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525ddb2a-9693-457c-a0a4-ee841ad84484",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Holy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903e1c26-e086-45d6-986f-1142f15b900a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2863379a-3e7e-4010-b19b-eec55b66ad54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of appliances:  5\n",
      "|>_____|\n",
      "Number of appliances:  5\n",
      "Number of appliances:  5\n",
      "Number of appliances:  5\n",
      "(96000, 2550, 1) (24000, 2550, 1) (96000, 5) (24000, 5)\n",
      "|->____|\n",
      "|-->___|\n",
      "|--->__|\n",
      "k*10k:  0\n",
      "k*10k:  10000\n",
      "k*10k:  20000\n",
      "k*10k:  30000\n",
      "k*10k:  40000\n",
      "k*10k:  50000\n",
      "k*10k:  60000\n",
      "k*10k:  70000\n",
      "k*10k:  80000\n",
      "k*10k:  90000\n",
      "g je  95981\n",
      "g je  95982\n",
      "g je  95983\n",
      "g je  95984\n",
      "g je  95985\n",
      "g je  95986\n",
      "g je  95987\n",
      "g je  95988\n",
      "g je  95989\n",
      "g je  95990\n",
      "g je  95991\n",
      "g je  95992\n",
      "g je  95993\n",
      "g je  95994\n",
      "g je  95995\n",
      "g je  95996\n",
      "|---->_|\n",
      "k*10k:  0\n",
      "k*10k:  10000\n",
      "k*10k:  20000\n",
      "|----->|\n",
      "(95998, 2550, 1) (23998, 2550, 1) (95998, 5) (23998, 5)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "                MAKES THE HOLY DATASET\n",
    "\"\"\"\n",
    "devices, data = DevicesDataHoly5(\"uk-dale\")\n",
    "dictlist=ListsToDictlist(devices,data,1)\n",
    "x_train, x_test, y_train, y_test, labels = GenerateRandom4(dictlist, 2550, 0, [1,2,3,4], 120_000)\n",
    "HolyDataset = [x_train, x_test, y_train, y_test, labels]\n",
    "pickle.dump(HolyDataset, open('./datasets/rawTS/HolyDatasetDALE.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cf9f62-2db1-437f-88c0-fe5962368f56",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Refit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "483ec991-692c-4690-b690-0192fa0ea6e0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-15 07:19:51.560341: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-15 07:19:51.893975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38282 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe MIG 3g.40gb, pci bus id: 0000:e1:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU enabled\n",
      "Model: \"LOL2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 2550, 1)]         0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv1D)       (None, 2550, 64)          256       \n",
      "                                                                 \n",
      " block1_conv2 (Conv1D)       (None, 2550, 64)          12352     \n",
      "                                                                 \n",
      " block1_pool (AveragePooling  (None, 1275, 64)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " block2_conv1 (Conv1D)       (None, 1275, 128)         24704     \n",
      "                                                                 \n",
      " block2_conv2 (Conv1D)       (None, 1275, 128)         49280     \n",
      "                                                                 \n",
      " block2_pool (AveragePooling  (None, 637, 128)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " block3_conv1 (Conv1D)       (None, 637, 256)          98560     \n",
      "                                                                 \n",
      " block3_conv2 (Conv1D)       (None, 637, 256)          196864    \n",
      "                                                                 \n",
      " block3_pool (AveragePooling  (None, 318, 256)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " block4_conv1 (Conv1D)       (None, 318, 512)          393728    \n",
      "                                                                 \n",
      " block4_conv2 (Conv1D)       (None, 318, 512)          786944    \n",
      "                                                                 \n",
      " block4_pool (AveragePooling  (None, 159, 512)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " block5_tran_conv1 (Conv1DTr  (None, 159, 512)         786944    \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_pool (AveragePooling  (None, 79, 512)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 64)                110976    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              266240    \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 5)                 20485     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,528,645\n",
      "Trainable params: 19,528,645\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-15 07:19:58.789392: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8401\n",
      "2023-02-15 07:19:59.390608: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-02-15 07:19:59.391424: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-02-15 07:19:59.391440: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2023-02-15 07:19:59.392039: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-02-15 07:19:59.392088: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 36s 32ms/step - loss: inf - accuracy: 0.5117\n",
      "Epoch 2/20\n",
      "750/750 [==============================] - 24s 32ms/step - loss: inf - accuracy: 0.5134\n",
      "Epoch 3/20\n",
      "750/750 [==============================] - 24s 32ms/step - loss: inf - accuracy: 0.5489\n",
      "Epoch 4/20\n",
      "750/750 [==============================] - 24s 31ms/step - loss: inf - accuracy: 0.5790\n",
      "Epoch 5/20\n",
      "750/750 [==============================] - 24s 31ms/step - loss: inf - accuracy: 0.6027\n",
      "Epoch 6/20\n",
      "750/750 [==============================] - 23s 31ms/step - loss: inf - accuracy: 0.6214\n",
      "Epoch 7/20\n",
      "750/750 [==============================] - 24s 31ms/step - loss: inf - accuracy: 0.6307\n",
      "Epoch 8/20\n",
      "750/750 [==============================] - 23s 31ms/step - loss: inf - accuracy: 0.6413\n",
      "Epoch 9/20\n",
      "750/750 [==============================] - 23s 31ms/step - loss: inf - accuracy: 0.6539\n",
      "Epoch 10/20\n",
      "750/750 [==============================] - 23s 31ms/step - loss: inf - accuracy: 0.6595\n",
      "Epoch 11/20\n",
      "750/750 [==============================] - 23s 31ms/step - loss: inf - accuracy: 0.6703\n",
      "Epoch 12/20\n",
      "750/750 [==============================] - 23s 31ms/step - loss: inf - accuracy: 0.6777\n",
      "Epoch 13/20\n",
      "750/750 [==============================] - 23s 31ms/step - loss: inf - accuracy: 0.6963\n",
      "Epoch 14/20\n",
      "750/750 [==============================] - 23s 31ms/step - loss: inf - accuracy: 0.7064\n",
      "Epoch 15/20\n",
      "750/750 [==============================] - 23s 31ms/step - loss: inf - accuracy: 0.7197\n",
      "Epoch 16/20\n",
      "750/750 [==============================] - 23s 31ms/step - loss: inf - accuracy: 0.7291\n",
      "Epoch 17/20\n",
      "750/750 [==============================] - 23s 31ms/step - loss: inf - accuracy: 0.7436\n",
      "Epoch 18/20\n",
      "750/750 [==============================] - 23s 31ms/step - loss: inf - accuracy: 0.7533\n",
      "Epoch 19/20\n",
      "750/750 [==============================] - 23s 31ms/step - loss: inf - accuracy: 0.7643\n",
      "Epoch 20/20\n",
      "750/750 [==============================] - 23s 31ms/step - loss: inf - accuracy: 0.7763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 11). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/rawTS/HolyDataset/LOL2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/rawTS/HolyDataset/LOL2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 4s 4ms/step\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         fridge       0.95      0.92      0.94     14772\n",
      "washing machine       0.90      0.89      0.89     10509\n",
      "    dish washer       0.88      0.88      0.88     10465\n",
      "      microwave       0.91      0.88      0.89     11878\n",
      "         kettle       0.98      0.93      0.95     12376\n",
      "\n",
      "      micro avg       0.92      0.90      0.91     60000\n",
      "      macro avg       0.92      0.90      0.91     60000\n",
      "   weighted avg       0.92      0.90      0.91     60000\n",
      "    samples avg       0.94      0.92      0.92     60000\n",
      "\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "               USES THE HOLY DATASET, OUR\n",
    "\"\"\"\n",
    "\n",
    "iteration = 10\n",
    "date = \"22.9.2022\"\n",
    "epochs = 20\n",
    "net_name = 'VGG191D'\n",
    "window_size = 2550\n",
    "batch_size = 128\n",
    "NmDevices = 5\n",
    "table_of_options = [1,2,3,4]\n",
    "gru = True\n",
    "gru_num = 64\n",
    "\n",
    "\n",
    "\n",
    "HolyDataset = pickle.load(open('./datasets/rawTS/HolyDataset.pkl', 'rb'))\n",
    "\n",
    "\"\"\"\n",
    "# sanity checks\n",
    "print(HolyDataset[0].shape, HolyDataset[1].shape, HolyDataset[2].shape, HolyDataset[3].shape, HolyDataset[4])\n",
    "for i in range(10):\n",
    "    print(HolyDataset[3][i])\n",
    "\"\"\"\n",
    "x_train = HolyDataset[0]\n",
    "x_test = HolyDataset[1]\n",
    "y_train = HolyDataset[2]\n",
    "y_test = HolyDataset[3]\n",
    "labels = HolyDataset[4]\n",
    "\n",
    "class_weights = class_weights_tool(y_test)\n",
    "\n",
    "# |||||||||||||||||||||||||||||||| DL ||||||||||||||||||||||||||||||||\n",
    "#model = VGG19_1D(NmDevices, window_size, gru, gru_num)\n",
    "model = LOL2(NmDevices, window_size, 'gru', 64)\n",
    "model.build((len(y_train)+len(y_test),window_size,1))\n",
    "model.summary()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, class_weight=class_weights)\n",
    "# |||||||||||||||||||||||||||||||| save ||||||||||||||||||||||||||||||||\n",
    "model.save(f'./models/rawTS/HolyDataset/LOL2/')\n",
    "#SaveData = [y_test, x_test, labels]\n",
    "#pickle.dump(SaveData, open(f'./datasets/rawTS/| iter ({iteration}) [{date}] |/{net_name}_HolyDataset_{epochs}ep_W{window_size}_opt{table_of_options}.pkl', 'wb'))\n",
    "# |||||||||||||||||||||||||||||||| prediction ||||||||||||||||||||||||||||||||\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_tf = (y_pred > 0.5)\n",
    "print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\n",
    "print(metrics.classification_report(y_test, y_pred_tf, target_names=labels, zero_division=0))\n",
    "print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1c39ba0-add8-4af1-908c-09a4269dd27c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-14 07:46:10.904563: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-14 07:46:11.422586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38282 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe MIG 3g.40gb, pci bus id: 0000:e1:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 2550, 32)          128       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 2550, 32)         128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 2550, 32)          0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2550, 32)          0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 2550, 64)          6208      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 2550, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 2550, 64)          0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 2550, 64)          0         \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 2550, 128)         24704     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 2550, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 2550, 128)         0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 2550, 128)         0         \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 2550, 256)         98560     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 2550, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 2550, 256)         0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 2550, 256)         0         \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 2550, 512)         393728    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 2550, 512)        2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 2550, 512)         0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 2550, 512)         0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 128)              221952    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 749,893\n",
      "Trainable params: 747,909\n",
      "Non-trainable params: 1,984\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-14 07:46:17.329817: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8401\n",
      "2023-02-14 07:46:18.303500: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-02-14 07:46:18.304302: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-02-14 07:46:18.304319: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2023-02-14 07:46:18.304855: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-02-14 07:46:18.304896: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 229s 271ms/step - loss: inf - accuracy: 0.5599\n",
      "Epoch 2/20\n",
      "750/750 [==============================] - 204s 272ms/step - loss: inf - accuracy: 0.5847\n",
      "Epoch 3/20\n",
      "100/750 [===>..........................] - ETA: 2:57 - loss: inf - accuracy: 0.5768"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function UniquePtr.__del__ at 0x7f56915683a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/c_api_util.py\", line 70, in __del__\n",
      "    def __del__(self):\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[1;32m     25\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.002\u001b[39m),loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 26\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# |||||||||||||||||||||||||||||||| save ||||||||||||||||||||||||||||||||\u001b[39;00m\n\u001b[1;32m     28\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./models/rawTS/HolyDataset/Tanoni/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "               USES THE HOLY DATASET, TANONI'S\n",
    "\"\"\"\n",
    "\n",
    "HolyDataset = pickle.load(open('./datasets/rawTS/HolyDataset.pkl', 'rb'))\n",
    "\n",
    "\"\"\"\n",
    "# sanity checks\n",
    "print(HolyDataset[0].shape, HolyDataset[1].shape, HolyDataset[2].shape, HolyDataset[3].shape, HolyDataset[4])\n",
    "for i in range(10):\n",
    "    print(HolyDataset[3][i])\n",
    "\"\"\"\n",
    "x_train = HolyDataset[0]\n",
    "x_test = HolyDataset[1]\n",
    "y_train = HolyDataset[2]\n",
    "y_test = HolyDataset[3]\n",
    "labels = HolyDataset[4]\n",
    "\n",
    "class_weights = class_weights_tool(y_test)\n",
    "\n",
    "# |||||||||||||||||||||||||||||||| DL ||||||||||||||||||||||||||||||||\n",
    "model = Tanoni()\n",
    "model.build((len(y_train)+len(y_test),2550,1))\n",
    "model.summary()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.002),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=128, epochs=20, class_weight=class_weights)\n",
    "# |||||||||||||||||||||||||||||||| save ||||||||||||||||||||||||||||||||\n",
    "model.save(f'./models/rawTS/HolyDataset/Tanoni/')\n",
    "# |||||||||||||||||||||||||||||||| prediction ||||||||||||||||||||||||||||||||\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_tf = (y_pred > 0.5)\n",
    "print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\n",
    "print(metrics.classification_report(y_test, y_pred_tf, target_names=labels, zero_division=0))\n",
    "print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fddb3258-6352-4044-a5b3-f2dd335871f7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg11_1D\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 2550, 1)]         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv1D)        (None, 2550, 64)          256       \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling1D)   (None, 1275, 64)          0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv1D)        (None, 1275, 128)         24704     \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling1D)   (None, 637, 128)          0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv1D)        (None, 637, 256)          98560     \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv1D)        (None, 637, 256)          196864    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling1D)   (None, 318, 256)          0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv1D)        (None, 318, 512)          393728    \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv1D)        (None, 318, 512)          786944    \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling1D)   (None, 159, 512)          0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv1D)        (None, 159, 512)          786944    \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv1D)        (None, 159, 512)          786944    \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling1D)   (None, 79, 512)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 40448)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              165679104 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 5)                 20485     \n",
      "=================================================================\n",
      "Total params: 185,555,845\n",
      "Trainable params: 185,555,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "750/750 [==============================] - 34s 44ms/step - loss: inf - accuracy: 0.3392\n",
      "Epoch 2/20\n",
      "667/750 [=========================>....] - ETA: 3s - loss: 5191.0645 - accuracy: 0.4377"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_43/143634480.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;31m# |||||||||||||||||||||||||||||||| save ||||||||||||||||||||||||||||||||\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'./models/rawTS/HolyDataset/VGG11'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "               USES THE HOLY DATASET, VGG11\n",
    "\"\"\"\n",
    "\n",
    "iteration = 10\n",
    "date = \"22.9.2022\"\n",
    "epochs = 20\n",
    "net_name = 'VGG191D'\n",
    "window_size = 2550\n",
    "batch_size = 128\n",
    "NmDevices = 5\n",
    "table_of_options = [1,2,3,4]\n",
    "gru = True\n",
    "gru_num = 64\n",
    "\n",
    "\n",
    "\n",
    "HolyDataset = pickle.load(open('./datasets/rawTS/HolyDataset.pkl', 'rb'))\n",
    "\n",
    "\"\"\"\n",
    "# sanity checks\n",
    "print(HolyDataset[0].shape, HolyDataset[1].shape, HolyDataset[2].shape, HolyDataset[3].shape, HolyDataset[4])\n",
    "for i in range(10):\n",
    "    print(HolyDataset[3][i])\n",
    "\"\"\"\n",
    "x_train = HolyDataset[0]\n",
    "x_test = HolyDataset[1]\n",
    "y_train = HolyDataset[2]\n",
    "y_test = HolyDataset[3]\n",
    "labels = HolyDataset[4]\n",
    "\n",
    "class_weights = class_weights_tool(y_test)\n",
    "\n",
    "# |||||||||||||||||||||||||||||||| DL ||||||||||||||||||||||||||||||||\n",
    "#model = VGG19_1D(NmDevices, window_size, gru, gru_num)\n",
    "#model = LOL2(NmDevices, window_size, 'gru', 64)\n",
    "model = VGG11_1D(NmDevices, window_size)\n",
    "model.build((len(y_train)+len(y_test),window_size,1))\n",
    "model.summary()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, class_weight=class_weights)\n",
    "# |||||||||||||||||||||||||||||||| save ||||||||||||||||||||||||||||||||\n",
    "model.save(f'./models/rawTS/HolyDataset/VGG11')\n",
    "#SaveData = [y_test, x_test, labels]\n",
    "#pickle.dump(SaveData, open(f'./datasets/rawTS/| iter ({iteration}) [{date}] |/{net_name}_HolyDataset_{epochs}ep_W{window_size}_opt{table_of_options}.pkl', 'wb'))\n",
    "# |||||||||||||||||||||||||||||||| prediction ||||||||||||||||||||||||||||||||\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_tf = (y_pred > 0.5)\n",
    "print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\n",
    "print(metrics.classification_report(y_test, y_pred_tf, target_names=labels, zero_division=0))\n",
    "print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "65ac6f98-0605-44ad-86f1-44ba1d39d632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU enabled\n",
      "Model: \"LOL3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         [(None, 2550, 1)]         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv1D)        (None, 2550, 64)          256       \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv1D)        (None, 2550, 64)          12352     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling1D)   (None, 1275, 64)          0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv1D)        (None, 1275, 128)         24704     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv1D)        (None, 1275, 128)         49280     \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling1D)   (None, 637, 128)          0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv1D)        (None, 637, 256)          98560     \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv1D)        (None, 637, 256)          196864    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv1D)        (None, 637, 256)          196864    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv1D)        (None, 637, 256)          196864    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling1D)   (None, 318, 256)          0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv1D)        (None, 318, 512)          393728    \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv1D)        (None, 318, 512)          786944    \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv1D)        (None, 318, 512)          786944    \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv1D)        (None, 318, 512)          786944    \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling1D)   (None, 159, 512)          0         \n",
      "_________________________________________________________________\n",
      "block5_tran_conv1 (Conv1DTra (None, 159, 512)          786944    \n",
      "_________________________________________________________________\n",
      "block5_tran_conv2 (Conv1DTra (None, 159, 512)          786944    \n",
      "_________________________________________________________________\n",
      "block5_tran_conv3 (Conv1DTra (None, 159, 512)          786944    \n",
      "_________________________________________________________________\n",
      "block5_tran_conv4 (Conv1DTra (None, 159, 512)          786944    \n",
      "_________________________________________________________________\n",
      "block5_pool (AveragePooling1 (None, 79, 512)           0         \n",
      "_________________________________________________________________\n",
      "gru_6 (GRU)                  (None, 64)                110976    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              266240    \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 5)                 20485     \n",
      "=================================================================\n",
      "Total params: 23,857,093\n",
      "Trainable params: 23,857,093\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "750/750 [==============================] - 41s 50ms/step - loss: 7462.1172 - accuracy: 0.5063\n",
      "Epoch 2/20\n",
      "750/750 [==============================] - 38s 50ms/step - loss: 5852.5864 - accuracy: 0.5349\n",
      "Epoch 3/20\n",
      "750/750 [==============================] - 38s 50ms/step - loss: 5034.9707 - accuracy: 0.5734\n",
      "Epoch 4/20\n",
      "750/750 [==============================] - 38s 50ms/step - loss: 4512.7202 - accuracy: 0.5885\n",
      "Epoch 5/20\n",
      "750/750 [==============================] - 38s 50ms/step - loss: 4085.7681 - accuracy: 0.6019\n",
      "Epoch 6/20\n",
      "750/750 [==============================] - 38s 50ms/step - loss: 3786.8987 - accuracy: 0.6038 2s - l\n",
      "Epoch 7/20\n",
      "750/750 [==============================] - 38s 50ms/step - loss: 3506.3867 - accuracy: 0.6041\n",
      "Epoch 8/20\n",
      "750/750 [==============================] - 38s 50ms/step - loss: 3276.5894 - accuracy: 0.6121\n",
      "Epoch 9/20\n",
      "750/750 [==============================] - 38s 50ms/step - loss: 3105.0640 - accuracy: 0.6310\n",
      "Epoch 10/20\n",
      "750/750 [==============================] - 38s 50ms/step - loss: 2920.1641 - accuracy: 0.6378\n",
      "Epoch 11/20\n",
      "750/750 [==============================] - 38s 50ms/step - loss: 2759.9253 - accuracy: 0.6482\n",
      "Epoch 12/20\n",
      "750/750 [==============================] - 38s 50ms/step - loss: 2629.5012 - accuracy: 0.6521\n",
      "Epoch 13/20\n",
      "750/750 [==============================] - 38s 50ms/step - loss: 2488.9827 - accuracy: 0.6674\n",
      "Epoch 14/20\n",
      "750/750 [==============================] - 38s 51ms/step - loss: 2351.8533 - accuracy: 0.6814\n",
      "Epoch 15/20\n",
      "750/750 [==============================] - 38s 50ms/step - loss: 2246.0293 - accuracy: 0.6977\n",
      "Epoch 16/20\n",
      "750/750 [==============================] - 38s 50ms/step - loss: 2153.4866 - accuracy: 0.7026\n",
      "Epoch 17/20\n",
      "750/750 [==============================] - 38s 50ms/step - loss: 2061.9241 - accuracy: 0.7122\n",
      "Epoch 18/20\n",
      "750/750 [==============================] - 38s 50ms/step - loss: 1966.4547 - accuracy: 0.7222\n",
      "Epoch 19/20\n",
      "750/750 [==============================] - 38s 50ms/step - loss: 1870.9653 - accuracy: 0.7230\n",
      "Epoch 20/20\n",
      "750/750 [==============================] - 38s 50ms/step - loss: 1759.7906 - accuracy: 0.7409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_46_layer_call_and_return_conditional_losses, gru_cell_46_layer_call_fn, gru_cell_46_layer_call_fn, gru_cell_46_layer_call_and_return_conditional_losses, gru_cell_46_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/rawTS/HolyDataset/LOL3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/rawTS/HolyDataset/LOL3/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         fridge       0.93      0.92      0.93     14772\n",
      "washing machine       0.92      0.86      0.89     10509\n",
      "    dish washer       0.92      0.84      0.88     10465\n",
      "      microwave       0.91      0.88      0.90     11878\n",
      "         kettle       0.96      0.94      0.95     12376\n",
      "\n",
      "      micro avg       0.93      0.89      0.91     60000\n",
      "      macro avg       0.93      0.89      0.91     60000\n",
      "   weighted avg       0.93      0.89      0.91     60000\n",
      "    samples avg       0.94      0.91      0.92     60000\n",
      "\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "               USES THE HOLY DATASET, OUR\n",
    "\"\"\"\n",
    "\n",
    "iteration = 10\n",
    "date = \"22.9.2022\"\n",
    "epochs = 20\n",
    "net_name = 'VGG191D'\n",
    "window_size = 2550\n",
    "batch_size = 128\n",
    "NmDevices = 5\n",
    "table_of_options = [1,2,3,4]\n",
    "gru = True\n",
    "gru_num = 64\n",
    "\n",
    "\n",
    "\n",
    "HolyDataset = pickle.load(open('./datasets/rawTS/HolyDataset.pkl', 'rb'))\n",
    "\n",
    "\"\"\"\n",
    "# sanity checks\n",
    "print(HolyDataset[0].shape, HolyDataset[1].shape, HolyDataset[2].shape, HolyDataset[3].shape, HolyDataset[4])\n",
    "for i in range(10):\n",
    "    print(HolyDataset[3][i])\n",
    "\"\"\"\n",
    "x_train = HolyDataset[0]\n",
    "x_test = HolyDataset[1]\n",
    "y_train = HolyDataset[2]\n",
    "y_test = HolyDataset[3]\n",
    "labels = HolyDataset[4]\n",
    "\n",
    "class_weights = class_weights_tool(y_test)\n",
    "\n",
    "# |||||||||||||||||||||||||||||||| DL ||||||||||||||||||||||||||||||||\n",
    "#model = VGG19_1D(NmDevices, window_size, gru, gru_num)\n",
    "model = LOL3(NmDevices, window_size, 'gru', 64)\n",
    "model.build((len(y_train)+len(y_test),window_size,1))\n",
    "model.summary()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, class_weight=class_weights)\n",
    "# |||||||||||||||||||||||||||||||| save ||||||||||||||||||||||||||||||||\n",
    "model.save(f'./models/rawTS/HolyDataset/LOL3')\n",
    "#SaveData = [y_test, x_test, labels]\n",
    "#pickle.dump(SaveData, open(f'./datasets/rawTS/| iter ({iteration}) [{date}] |/{net_name}_HolyDataset_{epochs}ep_W{window_size}_opt{table_of_options}.pkl', 'wb'))\n",
    "# |||||||||||||||||||||||||||||||| prediction ||||||||||||||||||||||||||||||||\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_tf = (y_pred > 0.5)\n",
    "print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\n",
    "print(metrics.classification_report(y_test, y_pred_tf, target_names=labels, zero_division=0))\n",
    "print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bebdeb-8675-4634-98f5-ffca3121bae0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## UK-DALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d011518-043a-4b3e-8af2-7f2f4599d0fa",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU enabled\n",
      "Model: \"LOL2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 2550, 1)]         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv1D)        (None, 2550, 64)          256       \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv1D)        (None, 2550, 64)          12352     \n",
      "_________________________________________________________________\n",
      "block1_pool (AveragePooling1 (None, 1275, 64)          0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv1D)        (None, 1275, 128)         24704     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv1D)        (None, 1275, 128)         49280     \n",
      "_________________________________________________________________\n",
      "block2_pool (AveragePooling1 (None, 637, 128)          0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv1D)        (None, 637, 256)          98560     \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv1D)        (None, 637, 256)          196864    \n",
      "_________________________________________________________________\n",
      "block3_pool (AveragePooling1 (None, 318, 256)          0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv1D)        (None, 318, 512)          393728    \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv1D)        (None, 318, 512)          786944    \n",
      "_________________________________________________________________\n",
      "block4_pool (AveragePooling1 (None, 159, 512)          0         \n",
      "_________________________________________________________________\n",
      "block5_tran_conv1 (Conv1DTra (None, 159, 512)          786944    \n",
      "_________________________________________________________________\n",
      "block5_pool (AveragePooling1 (None, 79, 512)           0         \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 64)                110976    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              266240    \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 5)                 20485     \n",
      "=================================================================\n",
      "Total params: 19,528,645\n",
      "Trainable params: 19,528,645\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "750/750 [==============================] - 25s 32ms/step - loss: 7260.7915 - accuracy: 0.6463\n",
      "Epoch 2/20\n",
      "750/750 [==============================] - 24s 32ms/step - loss: 5795.1108 - accuracy: 0.7803\n",
      "Epoch 3/20\n",
      "750/750 [==============================] - 24s 31ms/step - loss: 4840.8740 - accuracy: 0.8035\n",
      "Epoch 4/20\n",
      "750/750 [==============================] - 24s 32ms/step - loss: 3983.6616 - accuracy: 0.8050\n",
      "Epoch 5/20\n",
      "750/750 [==============================] - 24s 32ms/step - loss: 3415.4895 - accuracy: 0.8132\n",
      "Epoch 6/20\n",
      "750/750 [==============================] - 24s 32ms/step - loss: 2956.2529 - accuracy: 0.8164\n",
      "Epoch 7/20\n",
      "750/750 [==============================] - 25s 33ms/step - loss: 2686.8350 - accuracy: 0.8335\n",
      "Epoch 8/20\n",
      "750/750 [==============================] - 25s 33ms/step - loss: 2477.4197 - accuracy: 0.8404\n",
      "Epoch 9/20\n",
      "750/750 [==============================] - 25s 33ms/step - loss: 2321.1917 - accuracy: 0.8478\n",
      "Epoch 10/20\n",
      "750/750 [==============================] - 25s 33ms/step - loss: 2203.4426 - accuracy: 0.8544\n",
      "Epoch 11/20\n",
      "750/750 [==============================] - 25s 33ms/step - loss: 2102.0955 - accuracy: 0.8591\n",
      "Epoch 12/20\n",
      "750/750 [==============================] - 25s 33ms/step - loss: 2001.3198 - accuracy: 0.8579\n",
      "Epoch 13/20\n",
      "750/750 [==============================] - 25s 33ms/step - loss: 1935.6245 - accuracy: 0.8642\n",
      "Epoch 14/20\n",
      "750/750 [==============================] - 25s 33ms/step - loss: 1859.1915 - accuracy: 0.8686\n",
      "Epoch 15/20\n",
      "750/750 [==============================] - 25s 33ms/step - loss: 1795.3110 - accuracy: 0.8681\n",
      "Epoch 16/20\n",
      "750/750 [==============================] - 25s 33ms/step - loss: 1736.3452 - accuracy: 0.8719\n",
      "Epoch 17/20\n",
      "750/750 [==============================] - 24s 32ms/step - loss: 1679.8473 - accuracy: 0.8830\n",
      "Epoch 18/20\n",
      "750/750 [==============================] - 24s 32ms/step - loss: 1634.2876 - accuracy: 0.8842\n",
      "Epoch 19/20\n",
      "750/750 [==============================] - 24s 31ms/step - loss: 1592.5317 - accuracy: 0.8837\n",
      "Epoch 20/20\n",
      "750/750 [==============================] - 24s 32ms/step - loss: 1526.0071 - accuracy: 0.9026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_5_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn, gru_cell_5_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/rawTS/HolyDataset/LOL2_DALE/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/rawTS/HolyDataset/LOL2_DALE/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         fridge       1.00      1.00      1.00     15058\n",
      "washing machine       0.93      0.91      0.92     12498\n",
      "    dish washer       0.91      0.82      0.87      7843\n",
      "      microwave       0.98      0.94      0.96     11228\n",
      "         kettle       0.92      0.95      0.93     13368\n",
      "\n",
      "      micro avg       0.95      0.93      0.94     59995\n",
      "      macro avg       0.95      0.92      0.93     59995\n",
      "   weighted avg       0.95      0.93      0.94     59995\n",
      "    samples avg       0.96      0.95      0.95     59995\n",
      "\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "               USES THE HOLY DATASET, OUR\n",
    "\"\"\"\n",
    "\n",
    "iteration = 10\n",
    "date = \"22.9.2022\"\n",
    "epochs = 20\n",
    "net_name = 'VGG191D'\n",
    "window_size = 2550\n",
    "batch_size = 128\n",
    "NmDevices = 5\n",
    "table_of_options = [1,2,3,4]\n",
    "gru = True\n",
    "gru_num = 64\n",
    "\n",
    "\n",
    "\n",
    "HolyDataset = pickle.load(open('./datasets/rawTS/HolyDatasetDALE.pkl', 'rb'))\n",
    "\n",
    "\"\"\"\n",
    "# sanity checks\n",
    "print(HolyDataset[0].shape, HolyDataset[1].shape, HolyDataset[2].shape, HolyDataset[3].shape, HolyDataset[4])\n",
    "for i in range(10):\n",
    "    print(HolyDataset[3][i])\n",
    "\"\"\"\n",
    "x_train = HolyDataset[0]\n",
    "x_test = HolyDataset[1]\n",
    "y_train = HolyDataset[2]\n",
    "y_test = HolyDataset[3]\n",
    "labels = HolyDataset[4]\n",
    "\n",
    "class_weights = class_weights_tool(y_test)\n",
    "\n",
    "# |||||||||||||||||||||||||||||||| DL ||||||||||||||||||||||||||||||||\n",
    "#model = VGG19_1D(NmDevices, window_size, gru, gru_num)\n",
    "model = LOL2(NmDevices, window_size, 'gru', 64)\n",
    "model.build((len(y_train)+len(y_test),window_size,1))\n",
    "model.summary()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, class_weight=class_weights)\n",
    "# |||||||||||||||||||||||||||||||| save ||||||||||||||||||||||||||||||||\n",
    "model.save(f'./models/rawTS/HolyDataset/LOL2_DALE')\n",
    "#SaveData = [y_test, x_test, labels]\n",
    "#pickle.dump(SaveData, open(f'./datasets/rawTS/| iter ({iteration}) [{date}] |/{net_name}_HolyDataset_{epochs}ep_W{window_size}_opt{table_of_options}.pkl', 'wb'))\n",
    "# |||||||||||||||||||||||||||||||| prediction ||||||||||||||||||||||||||||||||\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_tf = (y_pred > 0.5)\n",
    "print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\n",
    "print(metrics.classification_report(y_test, y_pred_tf, target_names=labels, zero_division=0))\n",
    "print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5c8c303-391c-4c0e-b0f0-4a9eda3721a0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_5 (Conv1D)            (None, 2550, 32)          128       \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 2550, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 2550, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 2550, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 2550, 64)          6208      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 2550, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 2550, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2550, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 2550, 128)         24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 2550, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 2550, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 2550, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 2550, 256)         98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 2550, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 2550, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 2550, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 2550, 512)         393728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 2550, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 2550, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 2550, 512)         0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 128)               221952    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 749,893\n",
      "Trainable params: 747,909\n",
      "Non-trainable params: 1,984\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "750/750 [==============================] - 202s 265ms/step - loss: 5933.2495 - accuracy: 0.7554\n",
      "Epoch 2/20\n",
      "750/750 [==============================] - 199s 266ms/step - loss: 3329.4734 - accuracy: 0.8181\n",
      "Epoch 3/20\n",
      "750/750 [==============================] - 199s 265ms/step - loss: 2956.6423 - accuracy: 0.8277\n",
      "Epoch 4/20\n",
      "750/750 [==============================] - 200s 266ms/step - loss: 2729.4128 - accuracy: 0.8298\n",
      "Epoch 5/20\n",
      "750/750 [==============================] - 201s 267ms/step - loss: 2602.9790 - accuracy: 0.8395\n",
      "Epoch 6/20\n",
      "750/750 [==============================] - 200s 266ms/step - loss: 2504.6111 - accuracy: 0.8437\n",
      "Epoch 7/20\n",
      "750/750 [==============================] - 200s 267ms/step - loss: 2457.9861 - accuracy: 0.8352\n",
      "Epoch 8/20\n",
      "750/750 [==============================] - 200s 267ms/step - loss: 2374.4521 - accuracy: 0.8429\n",
      "Epoch 9/20\n",
      "750/750 [==============================] - 200s 266ms/step - loss: 2323.3452 - accuracy: 0.8420\n",
      "Epoch 10/20\n",
      "750/750 [==============================] - 200s 266ms/step - loss: 2272.9858 - accuracy: 0.8463\n",
      "Epoch 11/20\n",
      "750/750 [==============================] - 201s 268ms/step - loss: 2233.0435 - accuracy: 0.8468\n",
      "Epoch 12/20\n",
      "750/750 [==============================] - 201s 268ms/step - loss: 2189.0608 - accuracy: 0.8504\n",
      "Epoch 13/20\n",
      "750/750 [==============================] - 200s 267ms/step - loss: 2137.6772 - accuracy: 0.8563\n",
      "Epoch 14/20\n",
      "750/750 [==============================] - 200s 267ms/step - loss: 2115.0103 - accuracy: 0.8555\n",
      "Epoch 15/20\n",
      "750/750 [==============================] - 200s 266ms/step - loss: 2069.7537 - accuracy: 0.8597\n",
      "Epoch 16/20\n",
      "750/750 [==============================] - 202s 269ms/step - loss: 2050.6406 - accuracy: 0.8580\n",
      "Epoch 17/20\n",
      "750/750 [==============================] - 202s 270ms/step - loss: 2010.8307 - accuracy: 0.8643\n",
      "Epoch 18/20\n",
      "750/750 [==============================] - 204s 272ms/step - loss: 1994.0969 - accuracy: 0.8654\n",
      "Epoch 19/20\n",
      "750/750 [==============================] - 201s 268ms/step - loss: 1964.5562 - accuracy: 0.8632\n",
      "Epoch 20/20\n",
      "750/750 [==============================] - 201s 268ms/step - loss: 1939.9624 - accuracy: 0.8674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_7_layer_call_and_return_conditional_losses, gru_cell_7_layer_call_fn, gru_cell_8_layer_call_and_return_conditional_losses, gru_cell_8_layer_call_fn, gru_cell_7_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/rawTS/HolyDataset/Tanoni_DALE/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/rawTS/HolyDataset/Tanoni_DALE/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         fridge       1.00      1.00      1.00     15058\n",
      "washing machine       0.73      0.90      0.81     12498\n",
      "    dish washer       0.93      0.79      0.86      7843\n",
      "      microwave       0.69      0.95      0.80     11228\n",
      "         kettle       0.83      0.90      0.86     13368\n",
      "\n",
      "      micro avg       0.82      0.92      0.87     59995\n",
      "      macro avg       0.84      0.91      0.87     59995\n",
      "   weighted avg       0.84      0.92      0.87     59995\n",
      "    samples avg       0.81      0.91      0.84     59995\n",
      "\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "               USES THE HOLY DATASET, TANONI'S\n",
    "\"\"\"\n",
    "\n",
    "HolyDataset = pickle.load(open('./datasets/rawTS/HolyDatasetDALE.pkl', 'rb'))\n",
    "\n",
    "\"\"\"\n",
    "# sanity checks\n",
    "print(HolyDataset[0].shape, HolyDataset[1].shape, HolyDataset[2].shape, HolyDataset[3].shape, HolyDataset[4])\n",
    "for i in range(10):\n",
    "    print(HolyDataset[3][i])\n",
    "\"\"\"\n",
    "x_train = HolyDataset[0]\n",
    "x_test = HolyDataset[1]\n",
    "y_train = HolyDataset[2]\n",
    "y_test = HolyDataset[3]\n",
    "labels = HolyDataset[4]\n",
    "\n",
    "class_weights = class_weights_tool(y_test)\n",
    "\n",
    "# |||||||||||||||||||||||||||||||| DL ||||||||||||||||||||||||||||||||\n",
    "model = Tanoni()\n",
    "model.build((len(y_train)+len(y_test),2550,1))\n",
    "model.summary()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.002),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=128, epochs=20, class_weight=class_weights)\n",
    "# |||||||||||||||||||||||||||||||| save ||||||||||||||||||||||||||||||||\n",
    "model.save(f'./models/rawTS/HolyDataset/Tanoni_DALE')\n",
    "# |||||||||||||||||||||||||||||||| prediction ||||||||||||||||||||||||||||||||\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_tf = (y_pred > 0.5)\n",
    "print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\n",
    "print(metrics.classification_report(y_test, y_pred_tf, target_names=labels, zero_division=0))\n",
    "print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3fcbdbc4-5690-4617-86d1-f59c14cf195e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg11_1D\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 2550, 1)]         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv1D)        (None, 2550, 64)          256       \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling1D)   (None, 1275, 64)          0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv1D)        (None, 1275, 128)         24704     \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling1D)   (None, 637, 128)          0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv1D)        (None, 637, 256)          98560     \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv1D)        (None, 637, 256)          196864    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling1D)   (None, 318, 256)          0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv1D)        (None, 318, 512)          393728    \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv1D)        (None, 318, 512)          786944    \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling1D)   (None, 159, 512)          0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv1D)        (None, 159, 512)          786944    \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv1D)        (None, 159, 512)          786944    \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling1D)   (None, 79, 512)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 40448)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              165679104 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 5)                 20485     \n",
      "=================================================================\n",
      "Total params: 185,555,845\n",
      "Trainable params: 185,555,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "750/750 [==============================] - 42s 55ms/step - loss: inf - accuracy: 0.6179\n",
      "Epoch 2/20\n",
      "750/750 [==============================] - 34s 46ms/step - loss: 3871.7830 - accuracy: 0.6893\n",
      "Epoch 3/20\n",
      "750/750 [==============================] - 34s 46ms/step - loss: 2971.5698 - accuracy: 0.7508\n",
      "Epoch 4/20\n",
      "750/750 [==============================] - 36s 48ms/step - loss: 2152.3850 - accuracy: 0.8115\n",
      "Epoch 5/20\n",
      "750/750 [==============================] - 40s 53ms/step - loss: 1376.1382 - accuracy: 0.8549\n",
      "Epoch 6/20\n",
      "750/750 [==============================] - 40s 54ms/step - loss: 904.2589 - accuracy: 0.8876\n",
      "Epoch 7/20\n",
      "750/750 [==============================] - 36s 48ms/step - loss: 636.3572 - accuracy: 0.9064\n",
      "Epoch 8/20\n",
      "750/750 [==============================] - 34s 46ms/step - loss: 479.3971 - accuracy: 0.9191\n",
      "Epoch 9/20\n",
      "750/750 [==============================] - 34s 46ms/step - loss: 398.6691 - accuracy: 0.9269\n",
      "Epoch 10/20\n",
      "750/750 [==============================] - 34s 46ms/step - loss: 340.8808 - accuracy: 0.9337\n",
      "Epoch 11/20\n",
      "750/750 [==============================] - 34s 46ms/step - loss: 287.2234 - accuracy: 0.9392\n",
      "Epoch 12/20\n",
      "750/750 [==============================] - 34s 46ms/step - loss: 227.5007 - accuracy: 0.9485\n",
      "Epoch 13/20\n",
      "750/750 [==============================] - 34s 46ms/step - loss: 228.3923 - accuracy: 0.9474\n",
      "Epoch 14/20\n",
      "750/750 [==============================] - 34s 46ms/step - loss: 198.8227 - accuracy: 0.9517\n",
      "Epoch 15/20\n",
      "750/750 [==============================] - 34s 46ms/step - loss: 180.1510 - accuracy: 0.9552\n",
      "Epoch 16/20\n",
      "750/750 [==============================] - 34s 46ms/step - loss: 161.4441 - accuracy: 0.9605\n",
      "Epoch 17/20\n",
      "750/750 [==============================] - 34s 46ms/step - loss: 158.3882 - accuracy: 0.9593\n",
      "Epoch 18/20\n",
      "750/750 [==============================] - 34s 46ms/step - loss: 146.1696 - accuracy: 0.9632\n",
      "Epoch 19/20\n",
      "750/750 [==============================] - 34s 46ms/step - loss: 121.4904 - accuracy: 0.9664\n",
      "Epoch 20/20\n",
      "750/750 [==============================] - 34s 46ms/step - loss: 119.8902 - accuracy: 0.9681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-06 13:10:43.422822: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/rawTS/HolyDataset/VGG11_DALE/assets\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         fridge       0.99      0.99      0.99     15058\n",
      "washing machine       0.87      0.87      0.87     12498\n",
      "    dish washer       0.84      0.79      0.81      7843\n",
      "      microwave       0.91      0.86      0.88     11228\n",
      "         kettle       0.87      0.91      0.89     13368\n",
      "\n",
      "      micro avg       0.90      0.90      0.90     59995\n",
      "      macro avg       0.90      0.88      0.89     59995\n",
      "   weighted avg       0.90      0.90      0.90     59995\n",
      "    samples avg       0.92      0.91      0.91     59995\n",
      "\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "               USES THE HOLY DATASET, VGG11\n",
    "\"\"\"\n",
    "\n",
    "iteration = 10\n",
    "date = \"22.9.2022\"\n",
    "epochs = 20\n",
    "net_name = 'VGG191D'\n",
    "window_size = 2550\n",
    "batch_size = 128\n",
    "NmDevices = 5\n",
    "table_of_options = [1,2,3,4]\n",
    "gru = True\n",
    "gru_num = 64\n",
    "\n",
    "\n",
    "\n",
    "HolyDataset = pickle.load(open('./datasets/rawTS/HolyDatasetDALE.pkl', 'rb'))\n",
    "\n",
    "\"\"\"\n",
    "# sanity checks\n",
    "print(HolyDataset[0].shape, HolyDataset[1].shape, HolyDataset[2].shape, HolyDataset[3].shape, HolyDataset[4])\n",
    "for i in range(10):\n",
    "    print(HolyDataset[3][i])\n",
    "\"\"\"\n",
    "x_train = HolyDataset[0]\n",
    "x_test = HolyDataset[1]\n",
    "y_train = HolyDataset[2]\n",
    "y_test = HolyDataset[3]\n",
    "labels = HolyDataset[4]\n",
    "\n",
    "class_weights = class_weights_tool(y_test)\n",
    "\n",
    "# |||||||||||||||||||||||||||||||| DL ||||||||||||||||||||||||||||||||\n",
    "#model = VGG19_1D(NmDevices, window_size, gru, gru_num)\n",
    "#model = LOL2(NmDevices, window_size, 'gru', 64)\n",
    "model = VGG11_1D(NmDevices, window_size)\n",
    "model.build((len(y_train)+len(y_test),window_size,1))\n",
    "model.summary()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, class_weight=class_weights)\n",
    "# |||||||||||||||||||||||||||||||| save ||||||||||||||||||||||||||||||||\n",
    "model.save(f'./models/rawTS/HolyDataset/VGG11_DALE')\n",
    "#SaveData = [y_test, x_test, labels]\n",
    "#pickle.dump(SaveData, open(f'./datasets/rawTS/| iter ({iteration}) [{date}] |/{net_name}_HolyDataset_{epochs}ep_W{window_size}_opt{table_of_options}.pkl', 'wb'))\n",
    "# |||||||||||||||||||||||||||||||| prediction ||||||||||||||||||||||||||||||||\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_tf = (y_pred > 0.5)\n",
    "print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\n",
    "print(metrics.classification_report(y_test, y_pred_tf, target_names=labels, zero_division=0))\n",
    "print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c17483f-d623-4f19-abec-5c5a5c573706",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU enabled\n",
      "Model: \"LOL3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 2550, 1)]         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv1D)        (None, 2550, 64)          256       \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv1D)        (None, 2550, 64)          12352     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling1D)   (None, 1275, 64)          0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv1D)        (None, 1275, 128)         24704     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv1D)        (None, 1275, 128)         49280     \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling1D)   (None, 637, 128)          0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv1D)        (None, 637, 256)          98560     \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv1D)        (None, 637, 256)          196864    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv1D)        (None, 637, 256)          196864    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv1D)        (None, 637, 256)          196864    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling1D)   (None, 318, 256)          0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv1D)        (None, 318, 512)          393728    \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv1D)        (None, 318, 512)          786944    \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv1D)        (None, 318, 512)          786944    \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv1D)        (None, 318, 512)          786944    \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling1D)   (None, 159, 512)          0         \n",
      "_________________________________________________________________\n",
      "block5_tran_conv1 (Conv1DTra (None, 159, 512)          786944    \n",
      "_________________________________________________________________\n",
      "block5_tran_conv2 (Conv1DTra (None, 159, 512)          786944    \n",
      "_________________________________________________________________\n",
      "block5_tran_conv3 (Conv1DTra (None, 159, 512)          786944    \n",
      "_________________________________________________________________\n",
      "block5_tran_conv4 (Conv1DTra (None, 159, 512)          786944    \n",
      "_________________________________________________________________\n",
      "block5_pool (AveragePooling1 (None, 79, 512)           0         \n",
      "_________________________________________________________________\n",
      "gru_4 (GRU)                  (None, 64)                110976    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              266240    \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 5)                 20485     \n",
      "=================================================================\n",
      "Total params: 23,857,093\n",
      "Trainable params: 23,857,093\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "750/750 [==============================] - 42s 51ms/step - loss: 7444.0376 - accuracy: 0.6369\n",
      "Epoch 2/20\n",
      "750/750 [==============================] - 39s 51ms/step - loss: 6444.0288 - accuracy: 0.7556\n",
      "Epoch 3/20\n",
      "750/750 [==============================] - 38s 51ms/step - loss: 5908.7432 - accuracy: 0.7915\n",
      "Epoch 4/20\n",
      "750/750 [==============================] - 38s 51ms/step - loss: 4662.0127 - accuracy: 0.7933\n",
      "Epoch 5/20\n",
      "750/750 [==============================] - 38s 51ms/step - loss: 3675.3762 - accuracy: 0.7910\n",
      "Epoch 6/20\n",
      "750/750 [==============================] - 38s 51ms/step - loss: 3179.4929 - accuracy: 0.8005\n",
      "Epoch 7/20\n",
      "750/750 [==============================] - 38s 51ms/step - loss: 2852.8372 - accuracy: 0.8163\n",
      "Epoch 8/20\n",
      "750/750 [==============================] - 38s 51ms/step - loss: 2618.2095 - accuracy: 0.8224\n",
      "Epoch 9/20\n",
      "750/750 [==============================] - 38s 51ms/step - loss: 2451.7427 - accuracy: 0.8353\n",
      "Epoch 10/20\n",
      "750/750 [==============================] - 38s 51ms/step - loss: 2324.4060 - accuracy: 0.8442\n",
      "Epoch 11/20\n",
      "750/750 [==============================] - 38s 51ms/step - loss: 2186.1282 - accuracy: 0.8543\n",
      "Epoch 12/20\n",
      "750/750 [==============================] - 38s 51ms/step - loss: 2100.4685 - accuracy: 0.8555\n",
      "Epoch 13/20\n",
      "750/750 [==============================] - 38s 51ms/step - loss: 2018.2338 - accuracy: 0.8619\n",
      "Epoch 14/20\n",
      "750/750 [==============================] - 38s 51ms/step - loss: 1961.6812 - accuracy: 0.8686\n",
      "Epoch 15/20\n",
      "750/750 [==============================] - 40s 54ms/step - loss: 1898.0641 - accuracy: 0.8720\n",
      "Epoch 16/20\n",
      "750/750 [==============================] - 38s 51ms/step - loss: 1851.0099 - accuracy: 0.8798\n",
      "Epoch 17/20\n",
      "750/750 [==============================] - 38s 51ms/step - loss: 1798.8080 - accuracy: 0.8852\n",
      "Epoch 18/20\n",
      "750/750 [==============================] - 38s 51ms/step - loss: 1762.1560 - accuracy: 0.8901\n",
      "Epoch 19/20\n",
      "750/750 [==============================] - 38s 51ms/step - loss: 1705.4939 - accuracy: 0.8879\n",
      "Epoch 20/20\n",
      "750/750 [==============================] - 38s 51ms/step - loss: 1663.8658 - accuracy: 0.8983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_35_layer_call_and_return_conditional_losses, gru_cell_35_layer_call_fn, gru_cell_35_layer_call_fn, gru_cell_35_layer_call_and_return_conditional_losses, gru_cell_35_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/rawTS/HolyDataset/LOL3.1_DALE/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/rawTS/HolyDataset/LOL3.1_DALE/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         fridge       1.00      1.00      1.00     15058\n",
      "washing machine       0.94      0.88      0.91     12498\n",
      "    dish washer       0.95      0.79      0.86      7843\n",
      "      microwave       0.98      0.93      0.95     11228\n",
      "         kettle       0.94      0.92      0.93     13368\n",
      "\n",
      "      micro avg       0.96      0.92      0.94     59995\n",
      "      macro avg       0.96      0.90      0.93     59995\n",
      "   weighted avg       0.96      0.92      0.94     59995\n",
      "    samples avg       0.97      0.93      0.94     59995\n",
      "\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "               USES THE HOLY DATASET, OUR\n",
    "\"\"\"\n",
    "\n",
    "iteration = 10\n",
    "date = \"22.9.2022\"\n",
    "epochs = 20\n",
    "net_name = 'VGG191D'\n",
    "window_size = 2550\n",
    "batch_size = 128\n",
    "NmDevices = 5\n",
    "table_of_options = [1,2,3,4]\n",
    "gru = True\n",
    "gru_num = 64\n",
    "\n",
    "\n",
    "\n",
    "HolyDataset = pickle.load(open('./datasets/rawTS/HolyDatasetDALE.pkl', 'rb'))\n",
    "\n",
    "\"\"\"\n",
    "# sanity checks\n",
    "print(HolyDataset[0].shape, HolyDataset[1].shape, HolyDataset[2].shape, HolyDataset[3].shape, HolyDataset[4])\n",
    "for i in range(10):\n",
    "    print(HolyDataset[3][i])\n",
    "\"\"\"\n",
    "x_train = HolyDataset[0]\n",
    "x_test = HolyDataset[1]\n",
    "y_train = HolyDataset[2]\n",
    "y_test = HolyDataset[3]\n",
    "labels = HolyDataset[4]\n",
    "\n",
    "class_weights = class_weights_tool(y_test)\n",
    "\n",
    "# |||||||||||||||||||||||||||||||| DL ||||||||||||||||||||||||||||||||\n",
    "#model = VGG19_1D(NmDevices, window_size, gru, gru_num)\n",
    "#model = LOL2(NmDevices, window_size, 'gru', 64)\n",
    "model = LOL3(NmDevices, window_size, 'gru', 64)\n",
    "model.build((len(y_train)+len(y_test),window_size,1))\n",
    "model.summary()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, class_weight=class_weights)\n",
    "# |||||||||||||||||||||||||||||||| save ||||||||||||||||||||||||||||||||\n",
    "model.save(f'./models/rawTS/HolyDataset/LOL3.1_DALE')\n",
    "#SaveData = [y_test, x_test, labels]\n",
    "#pickle.dump(SaveData, open(f'./datasets/rawTS/| iter ({iteration}) [{date}] |/{net_name}_HolyDataset_{epochs}ep_W{window_size}_opt{table_of_options}.pkl', 'wb'))\n",
    "# |||||||||||||||||||||||||||||||| prediction ||||||||||||||||||||||||||||||||\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_tf = (y_pred > 0.5)\n",
    "print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\n",
    "print(metrics.classification_report(y_test, y_pred_tf, target_names=labels, zero_division=0))\n",
    "print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba532bb6-99b9-423b-871a-f70353fb6753",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU enabled\n",
      "Model: \"LOL4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 2550, 1)]         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv1D)        (None, 2550, 64)          256       \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv1D)        (None, 2550, 64)          12352     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling1D)   (None, 1275, 64)          0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv1D)        (None, 1275, 128)         24704     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv1D)        (None, 1275, 128)         49280     \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling1D)   (None, 637, 128)          0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv1D)        (None, 637, 256)          98560     \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv1D)        (None, 637, 256)          196864    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv1D)        (None, 637, 256)          196864    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv1D)        (None, 637, 256)          196864    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling1D)   (None, 318, 256)          0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv1D)        (None, 318, 512)          393728    \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv1D)        (None, 318, 512)          786944    \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv1D)        (None, 318, 512)          786944    \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv1D)        (None, 318, 512)          786944    \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling1D)   (None, 159, 512)          0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv1D)        (None, 159, 1028)         1580036   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv1D)        (None, 159, 1028)         3171380   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv1D)        (None, 159, 1028)         3171380   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv1D)        (None, 159, 1028)         3171380   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling1D)   (None, 79, 1028)          0         \n",
      "_________________________________________________________________\n",
      "block6_tran_conv1 (Conv1DTra (None, 79, 512)           1579520   \n",
      "_________________________________________________________________\n",
      "block6_tran_conv2 (Conv1DTra (None, 79, 512)           786944    \n",
      "_________________________________________________________________\n",
      "block6_tran_conv3 (Conv1DTra (None, 79, 512)           786944    \n",
      "_________________________________________________________________\n",
      "block6_tran_conv4 (Conv1DTra (None, 79, 512)           786944    \n",
      "_________________________________________________________________\n",
      "block6_pool (AveragePooling1 (None, 39, 512)           0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 64)                110976    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              266240    \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 5)                 20485     \n",
      "=================================================================\n",
      "Total params: 35,743,845\n",
      "Trainable params: 35,743,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "750/750 [==============================] - 78s 88ms/step - loss: 6551.8433 - accuracy: 0.7166\n",
      "Epoch 2/20\n",
      "750/750 [==============================] - 59s 78ms/step - loss: 4304.7139 - accuracy: 0.7688\n",
      "Epoch 3/20\n",
      "750/750 [==============================] - 59s 78ms/step - loss: 3283.1057 - accuracy: 0.7805\n",
      "Epoch 4/20\n",
      "750/750 [==============================] - 59s 79ms/step - loss: 2827.2476 - accuracy: 0.7990\n",
      "Epoch 5/20\n",
      "750/750 [==============================] - 59s 78ms/step - loss: 2646.3757 - accuracy: 0.7950\n",
      "Epoch 6/20\n",
      "750/750 [==============================] - 62s 83ms/step - loss: 2401.1816 - accuracy: 0.8114\n",
      "Epoch 7/20\n",
      "750/750 [==============================] - 59s 78ms/step - loss: 2272.5828 - accuracy: 0.8253\n",
      "Epoch 8/20\n",
      "750/750 [==============================] - 59s 79ms/step - loss: 2184.2551 - accuracy: 0.8326\n",
      "Epoch 9/20\n",
      "750/750 [==============================] - 59s 78ms/step - loss: 2060.4246 - accuracy: 0.8400\n",
      "Epoch 10/20\n",
      "750/750 [==============================] - 62s 82ms/step - loss: 1965.3983 - accuracy: 0.8449\n",
      "Epoch 11/20\n",
      "750/750 [==============================] - 59s 78ms/step - loss: 1887.3108 - accuracy: 0.8519\n",
      "Epoch 12/20\n",
      "750/750 [==============================] - 59s 78ms/step - loss: 1859.2999 - accuracy: 0.8400\n",
      "Epoch 13/20\n",
      "750/750 [==============================] - 61s 82ms/step - loss: 1795.3127 - accuracy: 0.8556\n",
      "Epoch 14/20\n",
      "750/750 [==============================] - 59s 78ms/step - loss: 1739.2335 - accuracy: 0.8564\n",
      "Epoch 15/20\n",
      "750/750 [==============================] - 75s 101ms/step - loss: 1696.9325 - accuracy: 0.8584\n",
      "Epoch 16/20\n",
      "750/750 [==============================] - 68s 90ms/step - loss: 1625.5386 - accuracy: 0.8783\n",
      "Epoch 17/20\n",
      "750/750 [==============================] - 59s 78ms/step - loss: 1617.3517 - accuracy: 0.8676\n",
      "Epoch 18/20\n",
      "750/750 [==============================] - 59s 78ms/step - loss: 1547.0164 - accuracy: 0.8823\n",
      "Epoch 19/20\n",
      "750/750 [==============================] - 59s 78ms/step - loss: 1506.9283 - accuracy: 0.8906\n",
      "Epoch 20/20\n",
      "750/750 [==============================] - 59s 78ms/step - loss: 1450.7576 - accuracy: 0.8925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_15_layer_call_and_return_conditional_losses, gru_cell_15_layer_call_fn, gru_cell_15_layer_call_fn, gru_cell_15_layer_call_and_return_conditional_losses, gru_cell_15_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/rawTS/HolyDataset/LOL3_DALE/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/rawTS/HolyDataset/LOL3_DALE/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         fridge       1.00      0.99      1.00     15058\n",
      "washing machine       0.94      0.90      0.92     12498\n",
      "    dish washer       0.91      0.86      0.89      7843\n",
      "      microwave       0.99      0.94      0.96     11228\n",
      "         kettle       0.94      0.92      0.93     13368\n",
      "\n",
      "      micro avg       0.96      0.93      0.95     59995\n",
      "      macro avg       0.96      0.92      0.94     59995\n",
      "   weighted avg       0.96      0.93      0.95     59995\n",
      "    samples avg       0.97      0.94      0.95     59995\n",
      "\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "               USES THE HOLY DATASET, OUR\n",
    "\"\"\"\n",
    "\n",
    "iteration = 10\n",
    "date = \"22.9.2022\"\n",
    "epochs = 20\n",
    "net_name = 'VGG191D'\n",
    "window_size = 2550\n",
    "batch_size = 128\n",
    "NmDevices = 5\n",
    "table_of_options = [1,2,3,4]\n",
    "gru = True\n",
    "gru_num = 64\n",
    "\n",
    "\n",
    "\n",
    "HolyDataset = pickle.load(open('./datasets/rawTS/HolyDatasetDALE.pkl', 'rb'))\n",
    "\n",
    "\"\"\"\n",
    "# sanity checks\n",
    "print(HolyDataset[0].shape, HolyDataset[1].shape, HolyDataset[2].shape, HolyDataset[3].shape, HolyDataset[4])\n",
    "for i in range(10):\n",
    "    print(HolyDataset[3][i])\n",
    "\"\"\"\n",
    "x_train = HolyDataset[0]\n",
    "x_test = HolyDataset[1]\n",
    "y_train = HolyDataset[2]\n",
    "y_test = HolyDataset[3]\n",
    "labels = HolyDataset[4]\n",
    "\n",
    "class_weights = class_weights_tool(y_test)\n",
    "\n",
    "# |||||||||||||||||||||||||||||||| DL ||||||||||||||||||||||||||||||||\n",
    "#model = VGG19_1D(NmDevices, window_size, gru, gru_num)\n",
    "#model = LOL2(NmDevices, window_size, 'gru', 64)\n",
    "model = LOL4(NmDevices, window_size, 'gru', 64)\n",
    "model.build((len(y_train)+len(y_test),window_size,1))\n",
    "model.summary()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, class_weight=class_weights)\n",
    "# |||||||||||||||||||||||||||||||| save ||||||||||||||||||||||||||||||||\n",
    "model.save(f'./models/rawTS/HolyDataset/LOL4_DALE')\n",
    "#SaveData = [y_test, x_test, labels]\n",
    "#pickle.dump(SaveData, open(f'./datasets/rawTS/| iter ({iteration}) [{date}] |/{net_name}_HolyDataset_{epochs}ep_W{window_size}_opt{table_of_options}.pkl', 'wb'))\n",
    "# |||||||||||||||||||||||||||||||| prediction ||||||||||||||||||||||||||||||||\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_tf = (y_pred > 0.5)\n",
    "print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\n",
    "print(metrics.classification_report(y_test, y_pred_tf, target_names=labels, zero_division=0))\n",
    "print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ef5ab9-0cc4-4192-b29a-d10ac5114f95",
   "metadata": {
    "tags": []
   },
   "source": [
    "# K-Fold experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "43b33c80-d6fd-4e97-9761-00b7e2ffc678",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using koef 0.1\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 12s 17ms/step - loss: inf - F1Score: 0.6751 - WeightedF1: 0.7004 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8090 - WeightedF1: 0.8258 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8337 - WeightedF1: 0.8498 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8497 - WeightedF1: 0.8651 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8584 - WeightedF1: 0.8737 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8663 - WeightedF1: 0.8815 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8707 - WeightedF1: 0.8858 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8758 - WeightedF1: 0.8905 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8799 - WeightedF1: 0.8944 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8832 - WeightedF1: 0.8975 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.8727 - WeightedF1: 0.8893 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.8503 - WeightedF1: 0.8710 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.8738 - WeightedF1: 0.8892 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8823 - WeightedF1: 0.8964 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.8906 - WeightedF1: 0.9043 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8941 - WeightedF1: 0.9075 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8962 - WeightedF1: 0.9095 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8981 - WeightedF1: 0.9110 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.9007 - WeightedF1: 0.9134 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.9024 - WeightedF1: 0.9149 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 3s 5ms/step\n",
      "3000/3000 [==============================] - 14s 5ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 12s 17ms/step - loss: inf - F1Score: 0.6722 - WeightedF1: 0.7024 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8119 - WeightedF1: 0.8276 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8323 - WeightedF1: 0.8478 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8487 - WeightedF1: 0.8644 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8593 - WeightedF1: 0.8752 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8674 - WeightedF1: 0.8833 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8737 - WeightedF1: 0.8894 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8776 - WeightedF1: 0.8931 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.8810 - WeightedF1: 0.8962 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8851 - WeightedF1: 0.9001 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8886 - WeightedF1: 0.9033 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8909 - WeightedF1: 0.9055 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 11s 18ms/step - loss: inf - F1Score: 0.8939 - WeightedF1: 0.9082 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 11s 18ms/step - loss: inf - F1Score: 0.8973 - WeightedF1: 0.9111 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.9000 - WeightedF1: 0.9136 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.9016 - WeightedF1: 0.9150 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.9036 - WeightedF1: 0.9167 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.9054 - WeightedF1: 0.9183 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.9073 - WeightedF1: 0.9200 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.9092 - WeightedF1: 0.9217 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 3s 4ms/step\n",
      "3000/3000 [==============================] - 12s 4ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 12s 16ms/step - loss: inf - F1Score: 0.6784 - WeightedF1: 0.7077 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.8067 - WeightedF1: 0.8243 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8317 - WeightedF1: 0.8485 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8468 - WeightedF1: 0.8637 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8593 - WeightedF1: 0.8756 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8679 - WeightedF1: 0.8841 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8742 - WeightedF1: 0.8898 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.8781 - WeightedF1: 0.8935 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.8829 - WeightedF1: 0.8978 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.8851 - WeightedF1: 0.8998 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8896 - WeightedF1: 0.9039 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8934 - WeightedF1: 0.9073 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8966 - WeightedF1: 0.9104 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.9003 - WeightedF1: 0.9135 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.9027 - WeightedF1: 0.9157 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.9045 - WeightedF1: 0.9173 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.9072 - WeightedF1: 0.9196 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.9090 - WeightedF1: 0.9213 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.9112 - WeightedF1: 0.9231 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.9130 - WeightedF1: 0.9247 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 3s 5ms/step\n",
      "3000/3000 [==============================] - 13s 4ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 12s 17ms/step - loss: inf - F1Score: 0.6727 - WeightedF1: 0.6971 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.8133 - WeightedF1: 0.8284 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.8335 - WeightedF1: 0.8489 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.8508 - WeightedF1: 0.8657 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8609 - WeightedF1: 0.8757 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.8679 - WeightedF1: 0.8827 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.8739 - WeightedF1: 0.8885 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.8783 - WeightedF1: 0.8928 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.8818 - WeightedF1: 0.8962 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8847 - WeightedF1: 0.8990 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.8889 - WeightedF1: 0.9027 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.8919 - WeightedF1: 0.9055 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8940 - WeightedF1: 0.9076 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8974 - WeightedF1: 0.9106 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8996 - WeightedF1: 0.9127 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.9019 - WeightedF1: 0.9148 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 9s 16ms/step - loss: inf - F1Score: 0.9039 - WeightedF1: 0.9165 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.9060 - WeightedF1: 0.9184 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.9076 - WeightedF1: 0.9198 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.9098 - WeightedF1: 0.9218 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 3s 5ms/step\n",
      "3000/3000 [==============================] - 14s 5ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 12s 17ms/step - loss: inf - F1Score: 0.6687 - WeightedF1: 0.6911 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8069 - WeightedF1: 0.8222 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8334 - WeightedF1: 0.8491 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8531 - WeightedF1: 0.8690 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8643 - WeightedF1: 0.8806 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8729 - WeightedF1: 0.8889 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8779 - WeightedF1: 0.8939 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8818 - WeightedF1: 0.8975 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8872 - WeightedF1: 0.9024 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8914 - WeightedF1: 0.9062 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 11s 18ms/step - loss: inf - F1Score: 0.8961 - WeightedF1: 0.9106 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8986 - WeightedF1: 0.9128 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 11s 18ms/step - loss: inf - F1Score: 0.9021 - WeightedF1: 0.9160 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.9047 - WeightedF1: 0.9182 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.9071 - WeightedF1: 0.9204 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.9105 - WeightedF1: 0.9234 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.9123 - WeightedF1: 0.9250 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.9153 - WeightedF1: 0.9276 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.9170 - WeightedF1: 0.9291 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.9190 - WeightedF1: 0.9309 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 3s 5ms/step\n",
      "3000/3000 [==============================] - 13s 4ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 13s 16ms/step - loss: inf - F1Score: 0.6058 - WeightedF1: 0.6210 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.7055 - WeightedF1: 0.7152 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.7396 - WeightedF1: 0.7486 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.7656 - WeightedF1: 0.7735 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.7809 - WeightedF1: 0.7880 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.7925 - WeightedF1: 0.7992 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8017 - WeightedF1: 0.8082 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.8082 - WeightedF1: 0.8145 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.8151 - WeightedF1: 0.8213 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8215 - WeightedF1: 0.8277 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8273 - WeightedF1: 0.8334 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.8341 - WeightedF1: 0.8400 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.8387 - WeightedF1: 0.8445 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8429 - WeightedF1: 0.8485 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.8475 - WeightedF1: 0.8529 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.8513 - WeightedF1: 0.8567 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.8542 - WeightedF1: 0.8594 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8569 - WeightedF1: 0.8621 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.8601 - WeightedF1: 0.8652 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8628 - WeightedF1: 0.8678 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 3s 4ms/step\n",
      "3000/3000 [==============================] - 13s 4ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 11s 16ms/step - loss: inf - F1Score: 0.6062 - WeightedF1: 0.6215 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 9s 16ms/step - loss: inf - F1Score: 0.7057 - WeightedF1: 0.7157 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.7485 - WeightedF1: 0.7566 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 9s 15ms/step - loss: inf - F1Score: 0.7784 - WeightedF1: 0.7854 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 9s 16ms/step - loss: inf - F1Score: 0.7920 - WeightedF1: 0.7987 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.8018 - WeightedF1: 0.8082 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.8102 - WeightedF1: 0.8165 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.8170 - WeightedF1: 0.8231 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 9s 16ms/step - loss: inf - F1Score: 0.8235 - WeightedF1: 0.8294 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.8291 - WeightedF1: 0.8350 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 9s 16ms/step - loss: inf - F1Score: 0.8351 - WeightedF1: 0.8409 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 9s 16ms/step - loss: inf - F1Score: 0.8413 - WeightedF1: 0.8469 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 9s 16ms/step - loss: inf - F1Score: 0.8462 - WeightedF1: 0.8517 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.8505 - WeightedF1: 0.8559 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.8546 - WeightedF1: 0.8598 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.8582 - WeightedF1: 0.8633 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.8616 - WeightedF1: 0.8666 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 9s 16ms/step - loss: inf - F1Score: 0.8636 - WeightedF1: 0.8686 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 9s 16ms/step - loss: inf - F1Score: 0.8673 - WeightedF1: 0.8721 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.8701 - WeightedF1: 0.8749 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 2s 3ms/step\n",
      "3000/3000 [==============================] - 14s 5ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 12s 16ms/step - loss: inf - F1Score: 0.6132 - WeightedF1: 0.6301 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.7189 - WeightedF1: 0.7298 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.7432 - WeightedF1: 0.7526 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.7652 - WeightedF1: 0.7734 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.7828 - WeightedF1: 0.7898 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.7953 - WeightedF1: 0.8018 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8024 - WeightedF1: 0.8087 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.8096 - WeightedF1: 0.8155 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8145 - WeightedF1: 0.8204 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8195 - WeightedF1: 0.8250 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.8240 - WeightedF1: 0.8295 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.8292 - WeightedF1: 0.8345 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.8327 - WeightedF1: 0.8381 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.8367 - WeightedF1: 0.8419 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 10s 17ms/step - loss: inf - F1Score: 0.8404 - WeightedF1: 0.8456 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.8439 - WeightedF1: 0.8490 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.8473 - WeightedF1: 0.8522 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 9s 16ms/step - loss: inf - F1Score: 0.8508 - WeightedF1: 0.8556 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.8532 - WeightedF1: 0.8580 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.8557 - WeightedF1: 0.8604 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 3s 4ms/step\n",
      "3000/3000 [==============================] - 13s 4ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 11s 15ms/step - loss: inf - F1Score: 0.6226 - WeightedF1: 0.6385 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 9s 15ms/step - loss: inf - F1Score: 0.7314 - WeightedF1: 0.7416 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 9s 15ms/step - loss: inf - F1Score: 0.7588 - WeightedF1: 0.7674 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 9s 15ms/step - loss: inf - F1Score: 0.7751 - WeightedF1: 0.7828 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 9s 15ms/step - loss: inf - F1Score: 0.7856 - WeightedF1: 0.7928 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 9s 15ms/step - loss: inf - F1Score: 0.7944 - WeightedF1: 0.8011 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 9s 15ms/step - loss: inf - F1Score: 0.8021 - WeightedF1: 0.8086 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 9s 15ms/step - loss: inf - F1Score: 0.8075 - WeightedF1: 0.8138 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 9s 15ms/step - loss: inf - F1Score: 0.8128 - WeightedF1: 0.8189 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 9s 15ms/step - loss: inf - F1Score: 0.8160 - WeightedF1: 0.8221 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 9s 15ms/step - loss: inf - F1Score: 0.8212 - WeightedF1: 0.8270 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 9s 15ms/step - loss: inf - F1Score: 0.8265 - WeightedF1: 0.8323 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 9s 15ms/step - loss: inf - F1Score: 0.8300 - WeightedF1: 0.8356 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 9s 15ms/step - loss: inf - F1Score: 0.8354 - WeightedF1: 0.8409 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 9s 15ms/step - loss: inf - F1Score: 0.8387 - WeightedF1: 0.8440 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 9s 15ms/step - loss: inf - F1Score: 0.8414 - WeightedF1: 0.8467 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 9s 15ms/step - loss: inf - F1Score: 0.8453 - WeightedF1: 0.8505 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 9s 15ms/step - loss: inf - F1Score: 0.8477 - WeightedF1: 0.8528 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 9s 15ms/step - loss: inf - F1Score: 0.8502 - WeightedF1: 0.8553 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 9s 15ms/step - loss: inf - F1Score: 0.8529 - WeightedF1: 0.8578 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 3s 4ms/step\n",
      "3000/3000 [==============================] - 13s 4ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 11s 15ms/step - loss: inf - F1Score: 0.6116 - WeightedF1: 0.6264 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 9s 16ms/step - loss: inf - F1Score: 0.7224 - WeightedF1: 0.7332 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 9s 16ms/step - loss: inf - F1Score: 0.7455 - WeightedF1: 0.7554 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 10s 16ms/step - loss: inf - F1Score: 0.7630 - WeightedF1: 0.7720 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 9s 15ms/step - loss: inf - F1Score: 0.7755 - WeightedF1: 0.7838 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 9s 16ms/step - loss: inf - F1Score: 0.7866 - WeightedF1: 0.7941 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 9s 15ms/step - loss: inf - F1Score: 0.7953 - WeightedF1: 0.8023 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 9s 15ms/step - loss: inf - F1Score: 0.8013 - WeightedF1: 0.8080 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 9s 15ms/step - loss: inf - F1Score: 0.8077 - WeightedF1: 0.8140 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 9s 15ms/step - loss: inf - F1Score: 0.8134 - WeightedF1: 0.8196 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 9s 15ms/step - loss: inf - F1Score: 0.8185 - WeightedF1: 0.8246 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 9s 15ms/step - loss: inf - F1Score: 0.8236 - WeightedF1: 0.8294 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 9s 15ms/step - loss: inf - F1Score: 0.8288 - WeightedF1: 0.8345 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 9s 16ms/step - loss: inf - F1Score: 0.8334 - WeightedF1: 0.8391 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 9s 16ms/step - loss: inf - F1Score: 0.8370 - WeightedF1: 0.8426 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 9s 15ms/step - loss: inf - F1Score: 0.8404 - WeightedF1: 0.8459 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 9s 15ms/step - loss: inf - F1Score: 0.8442 - WeightedF1: 0.8497 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 9s 15ms/step - loss: inf - F1Score: 0.8473 - WeightedF1: 0.8527 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 9s 15ms/step - loss: inf - F1Score: 0.8497 - WeightedF1: 0.8550 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 9s 15ms/step - loss: inf - F1Score: 0.8520 - WeightedF1: 0.8572 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 2s 3ms/step\n",
      "3000/3000 [==============================] - 13s 4ms/step\n",
      "Fold 1 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.87    0.92      0.89    11706\n",
      "1  washing machine       0.90    0.75      0.82     8507\n",
      "2      dish washer       0.83    0.73      0.78     8309\n",
      "3        microwave       0.88    0.82      0.85     9549\n",
      "4           kettle       0.96    0.89      0.92     9949\n",
      "5        micro avg       0.89    0.83      0.86    48020\n",
      "6        macro avg       0.89    0.82      0.85    48020\n",
      "7     weighted avg       0.89    0.83      0.86    48020\n",
      "8      samples avg       0.89    0.84      0.85    48020\n",
      "-------------------------------------------------\n",
      "Fold 1 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.99      0.96    60539\n",
      "1  washing machine       0.74    0.55      0.63    49848\n",
      "2      dish washer       0.55    0.73      0.63    31498\n",
      "3        microwave       0.63    0.93      0.75    45078\n",
      "4           kettle       0.73    0.82      0.77    53030\n",
      "5        micro avg       0.72    0.82      0.77   239993\n",
      "6        macro avg       0.71    0.81      0.75   239993\n",
      "7     weighted avg       0.74    0.82      0.77   239993\n",
      "8      samples avg       0.71    0.80      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 2 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.89    0.90      0.90    11903\n",
      "1  washing machine       0.88    0.76      0.82     8383\n",
      "2      dish washer       0.81    0.77      0.79     8279\n",
      "3        microwave       0.86    0.82      0.84     9584\n",
      "4           kettle       0.95    0.91      0.93     9899\n",
      "5        micro avg       0.88    0.84      0.86    48048\n",
      "6        macro avg       0.88    0.83      0.85    48048\n",
      "7     weighted avg       0.88    0.84      0.86    48048\n",
      "8      samples avg       0.89    0.85      0.86    48048\n",
      "-------------------------------------------------\n",
      "Fold 2 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.99      0.96    60539\n",
      "1  washing machine       0.62    0.69      0.66    49848\n",
      "2      dish washer       0.51    0.76      0.61    31498\n",
      "3        microwave       0.62    0.95      0.75    45078\n",
      "4           kettle       0.83    0.74      0.79    53030\n",
      "5        micro avg       0.71    0.83      0.77   239993\n",
      "6        macro avg       0.70    0.83      0.75   239993\n",
      "7     weighted avg       0.73    0.83      0.77   239993\n",
      "8      samples avg       0.69    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 3 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.85    0.92      0.88    11755\n",
      "1  washing machine       0.91    0.74      0.82     8482\n",
      "2      dish washer       0.82    0.71      0.76     8145\n",
      "3        microwave       0.88    0.73      0.80     9633\n",
      "4           kettle       0.95    0.90      0.92     9989\n",
      "5        micro avg       0.88    0.81      0.84    48004\n",
      "6        macro avg       0.88    0.80      0.84    48004\n",
      "7     weighted avg       0.88    0.81      0.84    48004\n",
      "8      samples avg       0.89    0.82      0.84    48004\n",
      "-------------------------------------------------\n",
      "Fold 3 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.98      0.94    60539\n",
      "1  washing machine       0.61    0.72      0.66    49848\n",
      "2      dish washer       0.62    0.68      0.65    31498\n",
      "3        microwave       0.66    0.85      0.74    45078\n",
      "4           kettle       0.77    0.76      0.77    53030\n",
      "5        micro avg       0.72    0.82      0.77   239993\n",
      "6        macro avg       0.71    0.80      0.75   239993\n",
      "7     weighted avg       0.73    0.82      0.77   239993\n",
      "8      samples avg       0.69    0.80      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 4 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.88    0.90      0.89    11880\n",
      "1  washing machine       0.90    0.75      0.82     8396\n",
      "2      dish washer       0.85    0.68      0.75     8215\n",
      "3        microwave       0.88    0.73      0.80     9566\n",
      "4           kettle       0.95    0.90      0.92    10018\n",
      "5        micro avg       0.89    0.80      0.85    48075\n",
      "6        macro avg       0.89    0.79      0.84    48075\n",
      "7     weighted avg       0.89    0.80      0.84    48075\n",
      "8      samples avg       0.90    0.82      0.84    48075\n",
      "-------------------------------------------------\n",
      "Fold 4 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.99      0.96    60539\n",
      "1  washing machine       0.59    0.75      0.66    49848\n",
      "2      dish washer       0.75    0.62      0.68    31498\n",
      "3        microwave       0.59    0.92      0.72    45078\n",
      "4           kettle       0.91    0.71      0.80    53030\n",
      "5        micro avg       0.74    0.82      0.78   239993\n",
      "6        macro avg       0.76    0.80      0.76   239993\n",
      "7     weighted avg       0.77    0.82      0.78   239993\n",
      "8      samples avg       0.72    0.81      0.74   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 5 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.88    0.90      0.89    11798\n",
      "1  washing machine       0.91    0.73      0.81     8396\n",
      "2      dish washer       0.84    0.69      0.75     8174\n",
      "3        microwave       0.85    0.79      0.82     9484\n",
      "4           kettle       0.96    0.87      0.91    10001\n",
      "5        micro avg       0.89    0.81      0.84    47853\n",
      "6        macro avg       0.89    0.79      0.84    47853\n",
      "7     weighted avg       0.89    0.81      0.84    47853\n",
      "8      samples avg       0.89    0.82      0.84    47853\n",
      "-------------------------------------------------\n",
      "Fold 5 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.98      0.96    60539\n",
      "1  washing machine       0.62    0.68      0.65    49848\n",
      "2      dish washer       0.70    0.64      0.67    31498\n",
      "3        microwave       0.57    0.96      0.72    45078\n",
      "4           kettle       0.85    0.72      0.78    53030\n",
      "5        micro avg       0.73    0.81      0.77   239993\n",
      "6        macro avg       0.74    0.80      0.75   239993\n",
      "7     weighted avg       0.75    0.81      0.77   239993\n",
      "8      samples avg       0.70    0.80      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Using koef 0.3\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 19s 26ms/step - loss: inf - F1Score: 0.6466 - WeightedF1: 0.6833 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.7679 - WeightedF1: 0.7907 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8214 - WeightedF1: 0.8378 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8505 - WeightedF1: 0.8660 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8645 - WeightedF1: 0.8790 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8765 - WeightedF1: 0.8903 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8846 - WeightedF1: 0.8975 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8945 - WeightedF1: 0.9058 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8993 - WeightedF1: 0.9102 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9028 - WeightedF1: 0.9135 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9089 - WeightedF1: 0.9192 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9133 - WeightedF1: 0.9231 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9175 - WeightedF1: 0.9271 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9208 - WeightedF1: 0.9299 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9242 - WeightedF1: 0.9330 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9280 - WeightedF1: 0.9364 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9301 - WeightedF1: 0.9383 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9325 - WeightedF1: 0.9407 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9350 - WeightedF1: 0.9428 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9365 - WeightedF1: 0.9444 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 3s 5ms/step\n",
      "3000/3000 [==============================] - 14s 5ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 19s 25ms/step - loss: inf - F1Score: 0.6556 - WeightedF1: 0.6893 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.7957 - WeightedF1: 0.8122 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8400 - WeightedF1: 0.8557 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 16s 26ms/step - loss: inf - F1Score: 0.8610 - WeightedF1: 0.8759 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 15s 26ms/step - loss: inf - F1Score: 0.8712 - WeightedF1: 0.8858 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8781 - WeightedF1: 0.8923 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8845 - WeightedF1: 0.8985 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8901 - WeightedF1: 0.9035 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8957 - WeightedF1: 0.9082 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8847 - WeightedF1: 0.9007 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.8717 - WeightedF1: 0.8917 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.8718 - WeightedF1: 0.8918 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.8718 - WeightedF1: 0.8917 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.8717 - WeightedF1: 0.8917 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.8718 - WeightedF1: 0.8917 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.8718 - WeightedF1: 0.8918 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.8718 - WeightedF1: 0.8917 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.8718 - WeightedF1: 0.8918 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.8718 - WeightedF1: 0.8917 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.8718 - WeightedF1: 0.8918 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 3s 4ms/step\n",
      "3000/3000 [==============================] - 13s 4ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 17s 25ms/step - loss: inf - F1Score: 0.6600 - WeightedF1: 0.6884 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.7835 - WeightedF1: 0.7998 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.8353 - WeightedF1: 0.8513 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8580 - WeightedF1: 0.8734 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8709 - WeightedF1: 0.8854 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8783 - WeightedF1: 0.8925 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8841 - WeightedF1: 0.8979 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8888 - WeightedF1: 0.9021 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8936 - WeightedF1: 0.9061 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9006 - WeightedF1: 0.9120 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9059 - WeightedF1: 0.9167 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9104 - WeightedF1: 0.9208 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9144 - WeightedF1: 0.9244 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9173 - WeightedF1: 0.9270 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9208 - WeightedF1: 0.9302 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9237 - WeightedF1: 0.9328 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9266 - WeightedF1: 0.9355 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9291 - WeightedF1: 0.9378 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9314 - WeightedF1: 0.9398 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9338 - WeightedF1: 0.9420 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 3s 4ms/step\n",
      "3000/3000 [==============================] - 13s 4ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 18s 27ms/step - loss: inf - F1Score: 0.6500 - WeightedF1: 0.6846 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.7765 - WeightedF1: 0.7971 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8310 - WeightedF1: 0.8474 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8521 - WeightedF1: 0.8677 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8667 - WeightedF1: 0.8815 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8748 - WeightedF1: 0.8893 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8816 - WeightedF1: 0.8958 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8878 - WeightedF1: 0.9013 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8939 - WeightedF1: 0.9067 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8993 - WeightedF1: 0.9113 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9050 - WeightedF1: 0.9162 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9101 - WeightedF1: 0.9207 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9141 - WeightedF1: 0.9244 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9169 - WeightedF1: 0.9270 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9209 - WeightedF1: 0.9306 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9235 - WeightedF1: 0.9329 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9259 - WeightedF1: 0.9351 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9286 - WeightedF1: 0.9376 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9311 - WeightedF1: 0.9399 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9331 - WeightedF1: 0.9416 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 3s 5ms/step\n",
      "3000/3000 [==============================] - 15s 5ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 17s 25ms/step - loss: inf - F1Score: 0.6627 - WeightedF1: 0.6943 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.7929 - WeightedF1: 0.8099 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8393 - WeightedF1: 0.8557 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8673 - WeightedF1: 0.8824 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8841 - WeightedF1: 0.8969 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 16s 27ms/step - loss: inf - F1Score: 0.8936 - WeightedF1: 0.9053 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 17s 28ms/step - loss: inf - F1Score: 0.8999 - WeightedF1: 0.9111 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 17s 29ms/step - loss: inf - F1Score: 0.9036 - WeightedF1: 0.9145 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 16s 27ms/step - loss: inf - F1Score: 0.9092 - WeightedF1: 0.9195 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 16s 27ms/step - loss: inf - F1Score: 0.9134 - WeightedF1: 0.9235 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 17s 28ms/step - loss: inf - F1Score: 0.9190 - WeightedF1: 0.9285 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 16s 26ms/step - loss: inf - F1Score: 0.9223 - WeightedF1: 0.9315 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 16s 27ms/step - loss: inf - F1Score: 0.9254 - WeightedF1: 0.9343 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 16s 27ms/step - loss: inf - F1Score: 0.9283 - WeightedF1: 0.9370 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 15s 26ms/step - loss: inf - F1Score: 0.9310 - WeightedF1: 0.9393 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 16s 26ms/step - loss: inf - F1Score: 0.9337 - WeightedF1: 0.9418 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9360 - WeightedF1: 0.9439 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 16s 26ms/step - loss: inf - F1Score: 0.9386 - WeightedF1: 0.9463 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 16s 27ms/step - loss: inf - F1Score: 0.9409 - WeightedF1: 0.9483 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 16s 27ms/step - loss: inf - F1Score: 0.9423 - WeightedF1: 0.9496 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 2s 3ms/step\n",
      "3000/3000 [==============================] - 13s 4ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 17s 25ms/step - loss: inf - F1Score: 0.6202 - WeightedF1: 0.6344 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 15s 26ms/step - loss: inf - F1Score: 0.7477 - WeightedF1: 0.7559 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 15s 26ms/step - loss: inf - F1Score: 0.7930 - WeightedF1: 0.7993 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 15s 26ms/step - loss: inf - F1Score: 0.8121 - WeightedF1: 0.8181 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 16s 26ms/step - loss: inf - F1Score: 0.8273 - WeightedF1: 0.8331 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 15s 26ms/step - loss: inf - F1Score: 0.8381 - WeightedF1: 0.8437 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 16s 26ms/step - loss: inf - F1Score: 0.8480 - WeightedF1: 0.8535 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8565 - WeightedF1: 0.8618 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 16s 26ms/step - loss: inf - F1Score: 0.8635 - WeightedF1: 0.8685 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8700 - WeightedF1: 0.8748 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 16s 26ms/step - loss: inf - F1Score: 0.8770 - WeightedF1: 0.8815 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 16s 26ms/step - loss: inf - F1Score: 0.8838 - WeightedF1: 0.8881 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 16s 27ms/step - loss: inf - F1Score: 0.8905 - WeightedF1: 0.8945 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 16s 26ms/step - loss: inf - F1Score: 0.8969 - WeightedF1: 0.9006 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 16s 26ms/step - loss: inf - F1Score: 0.9017 - WeightedF1: 0.9052 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9070 - WeightedF1: 0.9102 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9116 - WeightedF1: 0.9148 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9160 - WeightedF1: 0.9189 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9206 - WeightedF1: 0.9234 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 16s 26ms/step - loss: inf - F1Score: 0.9246 - WeightedF1: 0.9272 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 3s 4ms/step\n",
      "3000/3000 [==============================] - 14s 4ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 17s 25ms/step - loss: inf - F1Score: 0.6092 - WeightedF1: 0.6260 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.7213 - WeightedF1: 0.7327 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 16s 26ms/step - loss: inf - F1Score: 0.7609 - WeightedF1: 0.7694 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.7808 - WeightedF1: 0.7881 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.7972 - WeightedF1: 0.8038 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8109 - WeightedF1: 0.8170 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.8225 - WeightedF1: 0.8283 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8322 - WeightedF1: 0.8380 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8418 - WeightedF1: 0.8476 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8499 - WeightedF1: 0.8555 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8597 - WeightedF1: 0.8650 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8663 - WeightedF1: 0.8714 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8719 - WeightedF1: 0.8768 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8786 - WeightedF1: 0.8833 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8843 - WeightedF1: 0.8887 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8899 - WeightedF1: 0.8941 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.8949 - WeightedF1: 0.8990 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8997 - WeightedF1: 0.9035 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9040 - WeightedF1: 0.9077 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.9077 - WeightedF1: 0.9112 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 4s 6ms/step\n",
      "3000/3000 [==============================] - 10s 3ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 20s 26ms/step - loss: inf - F1Score: 0.6217 - WeightedF1: 0.6378 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 16s 27ms/step - loss: inf - F1Score: 0.7457 - WeightedF1: 0.7550 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 15s 26ms/step - loss: inf - F1Score: 0.7751 - WeightedF1: 0.7827 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 16s 26ms/step - loss: inf - F1Score: 0.7924 - WeightedF1: 0.7991 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 16s 26ms/step - loss: inf - F1Score: 0.8071 - WeightedF1: 0.8133 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8232 - WeightedF1: 0.8292 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 16s 26ms/step - loss: inf - F1Score: 0.8356 - WeightedF1: 0.8415 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8382 - WeightedF1: 0.8447 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.8232 - WeightedF1: 0.8315 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.8232 - WeightedF1: 0.8316 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.8232 - WeightedF1: 0.8316 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.8232 - WeightedF1: 0.8316 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.8232 - WeightedF1: 0.8316 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.8230 - WeightedF1: 0.8314 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8234 - WeightedF1: 0.8318 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.8232 - WeightedF1: 0.8316 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.8232 - WeightedF1: 0.8315 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.8233 - WeightedF1: 0.8317 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.8232 - WeightedF1: 0.8315 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.8231 - WeightedF1: 0.8315 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 3s 4ms/step\n",
      "3000/3000 [==============================] - 15s 5ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 18s 25ms/step - loss: inf - F1Score: 0.6187 - WeightedF1: 0.6346 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.7450 - WeightedF1: 0.7542 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.7742 - WeightedF1: 0.7819 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 16s 26ms/step - loss: inf - F1Score: 0.7948 - WeightedF1: 0.8018 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8111 - WeightedF1: 0.8176 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8246 - WeightedF1: 0.8308 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8348 - WeightedF1: 0.8409 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8450 - WeightedF1: 0.8509 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8510 - WeightedF1: 0.8568 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 15s 26ms/step - loss: inf - F1Score: 0.8591 - WeightedF1: 0.8647 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8659 - WeightedF1: 0.8711 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8714 - WeightedF1: 0.8765 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8778 - WeightedF1: 0.8827 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.8831 - WeightedF1: 0.8878 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.8886 - WeightedF1: 0.8930 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.8928 - WeightedF1: 0.8969 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8981 - WeightedF1: 0.9021 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.9022 - WeightedF1: 0.9059 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.9057 - WeightedF1: 0.9093 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9101 - WeightedF1: 0.9135 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 3s 4ms/step\n",
      "3000/3000 [==============================] - 14s 5ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 17s 25ms/step - loss: inf - F1Score: 0.6219 - WeightedF1: 0.6372 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.7384 - WeightedF1: 0.7479 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.7729 - WeightedF1: 0.7805 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.7954 - WeightedF1: 0.8021 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 16s 26ms/step - loss: inf - F1Score: 0.8102 - WeightedF1: 0.8166 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8231 - WeightedF1: 0.8293 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8357 - WeightedF1: 0.8416 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8441 - WeightedF1: 0.8498 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8516 - WeightedF1: 0.8570 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8581 - WeightedF1: 0.8634 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8658 - WeightedF1: 0.8708 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 15s 26ms/step - loss: inf - F1Score: 0.8719 - WeightedF1: 0.8767 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 16s 26ms/step - loss: inf - F1Score: 0.8774 - WeightedF1: 0.8820 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 15s 26ms/step - loss: inf - F1Score: 0.8832 - WeightedF1: 0.8876 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8886 - WeightedF1: 0.8928 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8934 - WeightedF1: 0.8974 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8982 - WeightedF1: 0.9020 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9033 - WeightedF1: 0.9069 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9067 - WeightedF1: 0.9102 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9112 - WeightedF1: 0.9144 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 3s 4ms/step\n",
      "3000/3000 [==============================] - 14s 5ms/step\n",
      "Fold 1 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.87    0.92      0.89    11706\n",
      "1  washing machine       0.90    0.75      0.82     8507\n",
      "2      dish washer       0.83    0.73      0.78     8309\n",
      "3        microwave       0.88    0.82      0.85     9549\n",
      "4           kettle       0.96    0.89      0.92     9949\n",
      "5        micro avg       0.89    0.83      0.86    48020\n",
      "6        macro avg       0.89    0.82      0.85    48020\n",
      "7     weighted avg       0.89    0.83      0.86    48020\n",
      "8      samples avg       0.89    0.84      0.85    48020\n",
      "-------------------------------------------------\n",
      "Fold 1 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.99      0.96    60539\n",
      "1  washing machine       0.74    0.55      0.63    49848\n",
      "2      dish washer       0.55    0.73      0.63    31498\n",
      "3        microwave       0.63    0.93      0.75    45078\n",
      "4           kettle       0.73    0.82      0.77    53030\n",
      "5        micro avg       0.72    0.82      0.77   239993\n",
      "6        macro avg       0.71    0.81      0.75   239993\n",
      "7     weighted avg       0.74    0.82      0.77   239993\n",
      "8      samples avg       0.71    0.80      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 2 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.89    0.90      0.90    11903\n",
      "1  washing machine       0.88    0.76      0.82     8383\n",
      "2      dish washer       0.81    0.77      0.79     8279\n",
      "3        microwave       0.86    0.82      0.84     9584\n",
      "4           kettle       0.95    0.91      0.93     9899\n",
      "5        micro avg       0.88    0.84      0.86    48048\n",
      "6        macro avg       0.88    0.83      0.85    48048\n",
      "7     weighted avg       0.88    0.84      0.86    48048\n",
      "8      samples avg       0.89    0.85      0.86    48048\n",
      "-------------------------------------------------\n",
      "Fold 2 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.99      0.96    60539\n",
      "1  washing machine       0.62    0.69      0.66    49848\n",
      "2      dish washer       0.51    0.76      0.61    31498\n",
      "3        microwave       0.62    0.95      0.75    45078\n",
      "4           kettle       0.83    0.74      0.79    53030\n",
      "5        micro avg       0.71    0.83      0.77   239993\n",
      "6        macro avg       0.70    0.83      0.75   239993\n",
      "7     weighted avg       0.73    0.83      0.77   239993\n",
      "8      samples avg       0.69    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 3 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.85    0.92      0.88    11755\n",
      "1  washing machine       0.91    0.74      0.82     8482\n",
      "2      dish washer       0.82    0.71      0.76     8145\n",
      "3        microwave       0.88    0.73      0.80     9633\n",
      "4           kettle       0.95    0.90      0.92     9989\n",
      "5        micro avg       0.88    0.81      0.84    48004\n",
      "6        macro avg       0.88    0.80      0.84    48004\n",
      "7     weighted avg       0.88    0.81      0.84    48004\n",
      "8      samples avg       0.89    0.82      0.84    48004\n",
      "-------------------------------------------------\n",
      "Fold 3 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.98      0.94    60539\n",
      "1  washing machine       0.61    0.72      0.66    49848\n",
      "2      dish washer       0.62    0.68      0.65    31498\n",
      "3        microwave       0.66    0.85      0.74    45078\n",
      "4           kettle       0.77    0.76      0.77    53030\n",
      "5        micro avg       0.72    0.82      0.77   239993\n",
      "6        macro avg       0.71    0.80      0.75   239993\n",
      "7     weighted avg       0.73    0.82      0.77   239993\n",
      "8      samples avg       0.69    0.80      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 4 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.88    0.90      0.89    11880\n",
      "1  washing machine       0.90    0.75      0.82     8396\n",
      "2      dish washer       0.85    0.68      0.75     8215\n",
      "3        microwave       0.88    0.73      0.80     9566\n",
      "4           kettle       0.95    0.90      0.92    10018\n",
      "5        micro avg       0.89    0.80      0.85    48075\n",
      "6        macro avg       0.89    0.79      0.84    48075\n",
      "7     weighted avg       0.89    0.80      0.84    48075\n",
      "8      samples avg       0.90    0.82      0.84    48075\n",
      "-------------------------------------------------\n",
      "Fold 4 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.99      0.96    60539\n",
      "1  washing machine       0.59    0.75      0.66    49848\n",
      "2      dish washer       0.75    0.62      0.68    31498\n",
      "3        microwave       0.59    0.92      0.72    45078\n",
      "4           kettle       0.91    0.71      0.80    53030\n",
      "5        micro avg       0.74    0.82      0.78   239993\n",
      "6        macro avg       0.76    0.80      0.76   239993\n",
      "7     weighted avg       0.77    0.82      0.78   239993\n",
      "8      samples avg       0.72    0.81      0.74   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 5 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.88    0.90      0.89    11798\n",
      "1  washing machine       0.91    0.73      0.81     8396\n",
      "2      dish washer       0.84    0.69      0.75     8174\n",
      "3        microwave       0.85    0.79      0.82     9484\n",
      "4           kettle       0.96    0.87      0.91    10001\n",
      "5        micro avg       0.89    0.81      0.84    47853\n",
      "6        macro avg       0.89    0.79      0.84    47853\n",
      "7     weighted avg       0.89    0.81      0.84    47853\n",
      "8      samples avg       0.89    0.82      0.84    47853\n",
      "-------------------------------------------------\n",
      "Fold 5 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.98      0.96    60539\n",
      "1  washing machine       0.62    0.68      0.65    49848\n",
      "2      dish washer       0.70    0.64      0.67    31498\n",
      "3        microwave       0.57    0.96      0.72    45078\n",
      "4           kettle       0.85    0.72      0.78    53030\n",
      "5        micro avg       0.73    0.81      0.77   239993\n",
      "6        macro avg       0.74    0.80      0.75   239993\n",
      "7     weighted avg       0.75    0.81      0.77   239993\n",
      "8      samples avg       0.70    0.80      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 6 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.91      0.92    11828\n",
      "1  washing machine       0.91    0.82      0.86     8389\n",
      "2      dish washer       0.89    0.80      0.85     8207\n",
      "3        microwave       0.92    0.85      0.89     9542\n",
      "4           kettle       0.96    0.93      0.95     9968\n",
      "5        micro avg       0.93    0.87      0.90    47934\n",
      "6        macro avg       0.93    0.86      0.89    47934\n",
      "7     weighted avg       0.93    0.87      0.90    47934\n",
      "8      samples avg       0.93    0.88      0.90    47934\n",
      "-------------------------------------------------\n",
      "Fold 6 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.95    0.92      0.94    60539\n",
      "1  washing machine       0.60    0.70      0.65    49848\n",
      "2      dish washer       0.57    0.70      0.62    31498\n",
      "3        microwave       0.69    0.92      0.79    45078\n",
      "4           kettle       0.77    0.73      0.75    53030\n",
      "5        micro avg       0.72    0.80      0.76   239993\n",
      "6        macro avg       0.71    0.79      0.75   239993\n",
      "7     weighted avg       0.74    0.80      0.77   239993\n",
      "8      samples avg       0.69    0.78      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 7 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.91      0.91    11670\n",
      "1  washing machine       0.90    0.82      0.86     8394\n",
      "2      dish washer       0.87    0.78      0.82     8254\n",
      "3        microwave       0.89    0.85      0.87     9554\n",
      "4           kettle       0.96    0.92      0.94     9928\n",
      "5        micro avg       0.91    0.86      0.88    47800\n",
      "6        macro avg       0.91    0.86      0.88    47800\n",
      "7     weighted avg       0.91    0.86      0.88    47800\n",
      "8      samples avg       0.92    0.88      0.89    47800\n",
      "-------------------------------------------------\n",
      "Fold 7 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.98      0.96    60539\n",
      "1  washing machine       0.56    0.83      0.67    49848\n",
      "2      dish washer       0.71    0.65      0.67    31498\n",
      "3        microwave       0.63    0.90      0.74    45078\n",
      "4           kettle       0.80    0.73      0.76    53030\n",
      "5        micro avg       0.72    0.84      0.77   239993\n",
      "6        macro avg       0.73    0.82      0.76   239993\n",
      "7     weighted avg       0.74    0.84      0.78   239993\n",
      "8      samples avg       0.68    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 8 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.84      0.89    11782\n",
      "1  washing machine       0.63    0.91      0.74     8527\n",
      "2      dish washer       0.93    0.60      0.73     8269\n",
      "3        microwave       0.87    0.80      0.83     9595\n",
      "4           kettle       0.94    0.89      0.92     9911\n",
      "5        micro avg       0.84    0.81      0.83    48084\n",
      "6        macro avg       0.86    0.81      0.82    48084\n",
      "7     weighted avg       0.87    0.81      0.83    48084\n",
      "8      samples avg       0.84    0.83      0.82    48084\n",
      "-------------------------------------------------\n",
      "Fold 8 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.96    0.98      0.97    60539\n",
      "1  washing machine       0.57    0.85      0.68    49848\n",
      "2      dish washer       0.90    0.57      0.70    31498\n",
      "3        microwave       0.62    0.91      0.74    45078\n",
      "4           kettle       0.78    0.78      0.78    53030\n",
      "5        micro avg       0.73    0.84      0.78   239993\n",
      "6        macro avg       0.77    0.82      0.77   239993\n",
      "7     weighted avg       0.77    0.84      0.79   239993\n",
      "8      samples avg       0.72    0.84      0.75   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 9 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.93      0.92    11834\n",
      "1  washing machine       0.91    0.80      0.85     8478\n",
      "2      dish washer       0.85    0.79      0.82     8188\n",
      "3        microwave       0.93    0.83      0.87     9619\n",
      "4           kettle       0.96    0.93      0.94    10086\n",
      "5        micro avg       0.91    0.86      0.89    48205\n",
      "6        macro avg       0.91    0.85      0.88    48205\n",
      "7     weighted avg       0.91    0.86      0.89    48205\n",
      "8      samples avg       0.92    0.88      0.89    48205\n",
      "-------------------------------------------------\n",
      "Fold 9 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.89      0.90    60539\n",
      "1  washing machine       0.57    0.81      0.67    49848\n",
      "2      dish washer       0.58    0.71      0.64    31498\n",
      "3        microwave       0.67    0.85      0.75    45078\n",
      "4           kettle       0.86    0.72      0.78    53030\n",
      "5        micro avg       0.72    0.81      0.76   239993\n",
      "6        macro avg       0.72    0.80      0.75   239993\n",
      "7     weighted avg       0.74    0.81      0.76   239993\n",
      "8      samples avg       0.69    0.78      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 10 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.93      0.92    11928\n",
      "1  washing machine       0.90    0.81      0.85     8376\n",
      "2      dish washer       0.87    0.79      0.82     8204\n",
      "3        microwave       0.88    0.86      0.87     9506\n",
      "4           kettle       0.95    0.92      0.94     9963\n",
      "5        micro avg       0.91    0.87      0.89    47977\n",
      "6        macro avg       0.90    0.86      0.88    47977\n",
      "7     weighted avg       0.91    0.87      0.89    47977\n",
      "8      samples avg       0.92    0.88      0.89    47977\n",
      "-------------------------------------------------\n",
      "Fold 10 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.99      0.95    60539\n",
      "1  washing machine       0.58    0.80      0.67    49848\n",
      "2      dish washer       0.67    0.65      0.66    31498\n",
      "3        microwave       0.65    0.91      0.76    45078\n",
      "4           kettle       0.78    0.77      0.78    53030\n",
      "5        micro avg       0.72    0.84      0.78   239993\n",
      "6        macro avg       0.72    0.82      0.76   239993\n",
      "7     weighted avg       0.74    0.84      0.78   239993\n",
      "8      samples avg       0.70    0.82      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Using koef 0.5\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 23s 30ms/step - loss: inf - F1Score: 0.6644 - WeightedF1: 0.6998 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.7892 - WeightedF1: 0.8059 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8199 - WeightedF1: 0.8356 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8406 - WeightedF1: 0.8558 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.8590 - WeightedF1: 0.8734 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8689 - WeightedF1: 0.8834 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.8789 - WeightedF1: 0.8929 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8887 - WeightedF1: 0.9016 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.8990 - WeightedF1: 0.9102 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.9053 - WeightedF1: 0.9161 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 16s 26ms/step - loss: inf - F1Score: 0.9118 - WeightedF1: 0.9221 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.9171 - WeightedF1: 0.9270 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.9210 - WeightedF1: 0.9305 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.9253 - WeightedF1: 0.9345 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.9291 - WeightedF1: 0.9379 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9321 - WeightedF1: 0.9407 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9357 - WeightedF1: 0.9438 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.9381 - WeightedF1: 0.9461 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.9410 - WeightedF1: 0.9487 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.9441 - WeightedF1: 0.9515 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 3s 4ms/step\n",
      "3000/3000 [==============================] - 11s 4ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 17s 24ms/step - loss: inf - F1Score: 0.6400 - WeightedF1: 0.6769 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.7397 - WeightedF1: 0.7663 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.7925 - WeightedF1: 0.8118 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.8253 - WeightedF1: 0.8415 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.8498 - WeightedF1: 0.8654 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.8648 - WeightedF1: 0.8797 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.8786 - WeightedF1: 0.8919 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 16s 26ms/step - loss: inf - F1Score: 0.8895 - WeightedF1: 0.9012 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 16s 26ms/step - loss: inf - F1Score: 0.8953 - WeightedF1: 0.9066 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 16s 27ms/step - loss: inf - F1Score: 0.8995 - WeightedF1: 0.9103 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 16s 26ms/step - loss: inf - F1Score: 0.9049 - WeightedF1: 0.9155 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9096 - WeightedF1: 0.9199 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 16s 26ms/step - loss: inf - F1Score: 0.9134 - WeightedF1: 0.9235 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 15s 26ms/step - loss: inf - F1Score: 0.9188 - WeightedF1: 0.9286 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 16s 27ms/step - loss: inf - F1Score: 0.9226 - WeightedF1: 0.9321 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 16s 26ms/step - loss: inf - F1Score: 0.9261 - WeightedF1: 0.9352 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 16s 26ms/step - loss: inf - F1Score: 0.9284 - WeightedF1: 0.9374 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 15s 26ms/step - loss: inf - F1Score: 0.9318 - WeightedF1: 0.9403 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 15s 26ms/step - loss: inf - F1Score: 0.9340 - WeightedF1: 0.9424 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 16s 26ms/step - loss: inf - F1Score: 0.9362 - WeightedF1: 0.9444 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 3s 4ms/step\n",
      "3000/3000 [==============================] - 13s 4ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 17s 25ms/step - loss: inf - F1Score: 0.6530 - WeightedF1: 0.6868 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.7477 - WeightedF1: 0.7722 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8003 - WeightedF1: 0.8187 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8417 - WeightedF1: 0.8579 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 15s 26ms/step - loss: inf - F1Score: 0.8630 - WeightedF1: 0.8779 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 16s 26ms/step - loss: inf - F1Score: 0.8749 - WeightedF1: 0.8888 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 16s 26ms/step - loss: inf - F1Score: 0.8863 - WeightedF1: 0.8993 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 16s 26ms/step - loss: inf - F1Score: 0.8938 - WeightedF1: 0.9057 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 15s 26ms/step - loss: inf - F1Score: 0.9000 - WeightedF1: 0.9111 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 15s 26ms/step - loss: inf - F1Score: 0.9055 - WeightedF1: 0.9161 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 15s 26ms/step - loss: inf - F1Score: 0.9108 - WeightedF1: 0.9211 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 15s 26ms/step - loss: inf - F1Score: 0.9142 - WeightedF1: 0.9243 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 15s 26ms/step - loss: inf - F1Score: 0.9200 - WeightedF1: 0.9295 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9235 - WeightedF1: 0.9326 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.9262 - WeightedF1: 0.9351 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9297 - WeightedF1: 0.9382 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9321 - WeightedF1: 0.9404 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.9342 - WeightedF1: 0.9423 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9371 - WeightedF1: 0.9451 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 15s 26ms/step - loss: inf - F1Score: 0.9397 - WeightedF1: 0.9474 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 2s 3ms/step\n",
      "3000/3000 [==============================] - 11s 4ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 24s 30ms/step - loss: inf - F1Score: 0.6629 - WeightedF1: 0.6911 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 16s 26ms/step - loss: inf - F1Score: 0.7835 - WeightedF1: 0.8023 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 16s 26ms/step - loss: inf - F1Score: 0.8349 - WeightedF1: 0.8505 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 16s 27ms/step - loss: inf - F1Score: 0.8607 - WeightedF1: 0.8755 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8735 - WeightedF1: 0.8876 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8754 - WeightedF1: 0.8914 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.8607 - WeightedF1: 0.8817 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.8606 - WeightedF1: 0.8817 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8608 - WeightedF1: 0.8817 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.8607 - WeightedF1: 0.8817 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8606 - WeightedF1: 0.8816 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8607 - WeightedF1: 0.8817 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8606 - WeightedF1: 0.8816 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.8607 - WeightedF1: 0.8817 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.8607 - WeightedF1: 0.8817 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8607 - WeightedF1: 0.8817 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8606 - WeightedF1: 0.8816 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.8607 - WeightedF1: 0.8817 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.8607 - WeightedF1: 0.8817 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.8607 - WeightedF1: 0.8817 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 3s 5ms/step\n",
      "3000/3000 [==============================] - 9s 3ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 17s 25ms/step - loss: inf - F1Score: 0.6414 - WeightedF1: 0.6780 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 15s 26ms/step - loss: inf - F1Score: 0.7553 - WeightedF1: 0.7765 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 15s 26ms/step - loss: inf - F1Score: 0.7892 - WeightedF1: 0.8070 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8183 - WeightedF1: 0.8348 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8456 - WeightedF1: 0.8611 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.8621 - WeightedF1: 0.8770 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8745 - WeightedF1: 0.8888 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8851 - WeightedF1: 0.8980 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8938 - WeightedF1: 0.9054 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8999 - WeightedF1: 0.9111 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9062 - WeightedF1: 0.9169 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 15s 26ms/step - loss: inf - F1Score: 0.9117 - WeightedF1: 0.9219 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9154 - WeightedF1: 0.9253 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9200 - WeightedF1: 0.9294 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9239 - WeightedF1: 0.9330 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 16s 26ms/step - loss: inf - F1Score: 0.9272 - WeightedF1: 0.9359 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 16s 26ms/step - loss: inf - F1Score: 0.9309 - WeightedF1: 0.9392 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9336 - WeightedF1: 0.9416 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9358 - WeightedF1: 0.9437 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9387 - WeightedF1: 0.9464 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 3s 4ms/step\n",
      "3000/3000 [==============================] - 13s 4ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 17s 24ms/step - loss: inf - F1Score: 0.6289 - WeightedF1: 0.6444 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.7427 - WeightedF1: 0.7520 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.7725 - WeightedF1: 0.7803 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.7968 - WeightedF1: 0.8036 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8152 - WeightedF1: 0.8214 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8321 - WeightedF1: 0.8380 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8435 - WeightedF1: 0.8493 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8538 - WeightedF1: 0.8594 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.8609 - WeightedF1: 0.8661 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.8677 - WeightedF1: 0.8726 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.8769 - WeightedF1: 0.8815 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.8835 - WeightedF1: 0.8878 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8900 - WeightedF1: 0.8941 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.8965 - WeightedF1: 0.9003 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.9026 - WeightedF1: 0.9062 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9081 - WeightedF1: 0.9114 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9131 - WeightedF1: 0.9162 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9180 - WeightedF1: 0.9209 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.9238 - WeightedF1: 0.9264 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.9281 - WeightedF1: 0.9305 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 3s 4ms/step\n",
      "3000/3000 [==============================] - 13s 4ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 16s 24ms/step - loss: inf - F1Score: 0.6115 - WeightedF1: 0.6285 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.7277 - WeightedF1: 0.7386 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.7613 - WeightedF1: 0.7698 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.7871 - WeightedF1: 0.7942 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.8065 - WeightedF1: 0.8131 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.8255 - WeightedF1: 0.8318 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.8395 - WeightedF1: 0.8455 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.8500 - WeightedF1: 0.8557 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.8589 - WeightedF1: 0.8643 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.8679 - WeightedF1: 0.8730 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.8769 - WeightedF1: 0.8816 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.8846 - WeightedF1: 0.8891 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.8920 - WeightedF1: 0.8960 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.8988 - WeightedF1: 0.9025 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.9053 - WeightedF1: 0.9086 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.9119 - WeightedF1: 0.9148 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.9177 - WeightedF1: 0.9204 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.9221 - WeightedF1: 0.9246 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.9271 - WeightedF1: 0.9294 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.9314 - WeightedF1: 0.9335 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 2s 3ms/step\n",
      "3000/3000 [==============================] - 12s 4ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 16s 24ms/step - loss: inf - F1Score: 0.6170 - WeightedF1: 0.6327 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.7422 - WeightedF1: 0.7514 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.7804 - WeightedF1: 0.7876 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.7947 - WeightedF1: 0.8019 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 14s 23ms/step - loss: inf - F1Score: 0.7949 - WeightedF1: 0.8024 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.8148 - WeightedF1: 0.8212 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.8318 - WeightedF1: 0.8379 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.8459 - WeightedF1: 0.8519 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.8561 - WeightedF1: 0.8617 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.8640 - WeightedF1: 0.8693 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.8736 - WeightedF1: 0.8786 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.8817 - WeightedF1: 0.8862 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 14s 23ms/step - loss: inf - F1Score: 0.8885 - WeightedF1: 0.8927 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.8966 - WeightedF1: 0.9005 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 14s 23ms/step - loss: inf - F1Score: 0.9022 - WeightedF1: 0.9057 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 14s 23ms/step - loss: inf - F1Score: 0.9082 - WeightedF1: 0.9115 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.9141 - WeightedF1: 0.9171 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.9190 - WeightedF1: 0.9218 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.9242 - WeightedF1: 0.9267 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 14s 23ms/step - loss: inf - F1Score: 0.9287 - WeightedF1: 0.9311 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 3s 4ms/step\n",
      "3000/3000 [==============================] - 10s 3ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 16s 24ms/step - loss: inf - F1Score: 0.6228 - WeightedF1: 0.6385 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.7408 - WeightedF1: 0.7502 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.7715 - WeightedF1: 0.7789 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.7925 - WeightedF1: 0.7993 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.8111 - WeightedF1: 0.8173 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 14s 23ms/step - loss: inf - F1Score: 0.8286 - WeightedF1: 0.8345 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 14s 23ms/step - loss: inf - F1Score: 0.8431 - WeightedF1: 0.8489 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 14s 23ms/step - loss: inf - F1Score: 0.8536 - WeightedF1: 0.8591 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 14s 23ms/step - loss: inf - F1Score: 0.8611 - WeightedF1: 0.8663 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.8697 - WeightedF1: 0.8746 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 14s 23ms/step - loss: inf - F1Score: 0.8793 - WeightedF1: 0.8836 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 14s 23ms/step - loss: inf - F1Score: 0.8868 - WeightedF1: 0.8908 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.8945 - WeightedF1: 0.8981 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9005 - WeightedF1: 0.9039 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.9067 - WeightedF1: 0.9098 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.9130 - WeightedF1: 0.9158 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.9181 - WeightedF1: 0.9206 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9228 - WeightedF1: 0.9251 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.9275 - WeightedF1: 0.9296 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.9331 - WeightedF1: 0.9349 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 3s 5ms/step\n",
      "3000/3000 [==============================] - 14s 5ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 20s 25ms/step - loss: inf - F1Score: 0.6291 - WeightedF1: 0.6423 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.7533 - WeightedF1: 0.7616 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.7980 - WeightedF1: 0.8052 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.8223 - WeightedF1: 0.8291 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 15s 25ms/step - loss: inf - F1Score: 0.8391 - WeightedF1: 0.8454 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.8523 - WeightedF1: 0.8581 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.8618 - WeightedF1: 0.8672 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 14s 23ms/step - loss: inf - F1Score: 0.8711 - WeightedF1: 0.8760 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.8793 - WeightedF1: 0.8838 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.8848 - WeightedF1: 0.8892 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.8923 - WeightedF1: 0.8963 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.8997 - WeightedF1: 0.9033 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.9063 - WeightedF1: 0.9095 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.9127 - WeightedF1: 0.9157 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.9183 - WeightedF1: 0.9211 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.9248 - WeightedF1: 0.9274 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.9296 - WeightedF1: 0.9319 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.9346 - WeightedF1: 0.9368 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 15s 24ms/step - loss: inf - F1Score: 0.9396 - WeightedF1: 0.9416 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 14s 24ms/step - loss: inf - F1Score: 0.9441 - WeightedF1: 0.9458 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 4s 4ms/step\n",
      "3000/3000 [==============================] - 13s 4ms/step\n",
      "Fold 1 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.87    0.92      0.89    11706\n",
      "1  washing machine       0.90    0.75      0.82     8507\n",
      "2      dish washer       0.83    0.73      0.78     8309\n",
      "3        microwave       0.88    0.82      0.85     9549\n",
      "4           kettle       0.96    0.89      0.92     9949\n",
      "5        micro avg       0.89    0.83      0.86    48020\n",
      "6        macro avg       0.89    0.82      0.85    48020\n",
      "7     weighted avg       0.89    0.83      0.86    48020\n",
      "8      samples avg       0.89    0.84      0.85    48020\n",
      "-------------------------------------------------\n",
      "Fold 1 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.99      0.96    60539\n",
      "1  washing machine       0.74    0.55      0.63    49848\n",
      "2      dish washer       0.55    0.73      0.63    31498\n",
      "3        microwave       0.63    0.93      0.75    45078\n",
      "4           kettle       0.73    0.82      0.77    53030\n",
      "5        micro avg       0.72    0.82      0.77   239993\n",
      "6        macro avg       0.71    0.81      0.75   239993\n",
      "7     weighted avg       0.74    0.82      0.77   239993\n",
      "8      samples avg       0.71    0.80      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 2 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.89    0.90      0.90    11903\n",
      "1  washing machine       0.88    0.76      0.82     8383\n",
      "2      dish washer       0.81    0.77      0.79     8279\n",
      "3        microwave       0.86    0.82      0.84     9584\n",
      "4           kettle       0.95    0.91      0.93     9899\n",
      "5        micro avg       0.88    0.84      0.86    48048\n",
      "6        macro avg       0.88    0.83      0.85    48048\n",
      "7     weighted avg       0.88    0.84      0.86    48048\n",
      "8      samples avg       0.89    0.85      0.86    48048\n",
      "-------------------------------------------------\n",
      "Fold 2 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.99      0.96    60539\n",
      "1  washing machine       0.62    0.69      0.66    49848\n",
      "2      dish washer       0.51    0.76      0.61    31498\n",
      "3        microwave       0.62    0.95      0.75    45078\n",
      "4           kettle       0.83    0.74      0.79    53030\n",
      "5        micro avg       0.71    0.83      0.77   239993\n",
      "6        macro avg       0.70    0.83      0.75   239993\n",
      "7     weighted avg       0.73    0.83      0.77   239993\n",
      "8      samples avg       0.69    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 3 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.85    0.92      0.88    11755\n",
      "1  washing machine       0.91    0.74      0.82     8482\n",
      "2      dish washer       0.82    0.71      0.76     8145\n",
      "3        microwave       0.88    0.73      0.80     9633\n",
      "4           kettle       0.95    0.90      0.92     9989\n",
      "5        micro avg       0.88    0.81      0.84    48004\n",
      "6        macro avg       0.88    0.80      0.84    48004\n",
      "7     weighted avg       0.88    0.81      0.84    48004\n",
      "8      samples avg       0.89    0.82      0.84    48004\n",
      "-------------------------------------------------\n",
      "Fold 3 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.98      0.94    60539\n",
      "1  washing machine       0.61    0.72      0.66    49848\n",
      "2      dish washer       0.62    0.68      0.65    31498\n",
      "3        microwave       0.66    0.85      0.74    45078\n",
      "4           kettle       0.77    0.76      0.77    53030\n",
      "5        micro avg       0.72    0.82      0.77   239993\n",
      "6        macro avg       0.71    0.80      0.75   239993\n",
      "7     weighted avg       0.73    0.82      0.77   239993\n",
      "8      samples avg       0.69    0.80      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 4 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.88    0.90      0.89    11880\n",
      "1  washing machine       0.90    0.75      0.82     8396\n",
      "2      dish washer       0.85    0.68      0.75     8215\n",
      "3        microwave       0.88    0.73      0.80     9566\n",
      "4           kettle       0.95    0.90      0.92    10018\n",
      "5        micro avg       0.89    0.80      0.85    48075\n",
      "6        macro avg       0.89    0.79      0.84    48075\n",
      "7     weighted avg       0.89    0.80      0.84    48075\n",
      "8      samples avg       0.90    0.82      0.84    48075\n",
      "-------------------------------------------------\n",
      "Fold 4 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.99      0.96    60539\n",
      "1  washing machine       0.59    0.75      0.66    49848\n",
      "2      dish washer       0.75    0.62      0.68    31498\n",
      "3        microwave       0.59    0.92      0.72    45078\n",
      "4           kettle       0.91    0.71      0.80    53030\n",
      "5        micro avg       0.74    0.82      0.78   239993\n",
      "6        macro avg       0.76    0.80      0.76   239993\n",
      "7     weighted avg       0.77    0.82      0.78   239993\n",
      "8      samples avg       0.72    0.81      0.74   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 5 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.88    0.90      0.89    11798\n",
      "1  washing machine       0.91    0.73      0.81     8396\n",
      "2      dish washer       0.84    0.69      0.75     8174\n",
      "3        microwave       0.85    0.79      0.82     9484\n",
      "4           kettle       0.96    0.87      0.91    10001\n",
      "5        micro avg       0.89    0.81      0.84    47853\n",
      "6        macro avg       0.89    0.79      0.84    47853\n",
      "7     weighted avg       0.89    0.81      0.84    47853\n",
      "8      samples avg       0.89    0.82      0.84    47853\n",
      "-------------------------------------------------\n",
      "Fold 5 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.98      0.96    60539\n",
      "1  washing machine       0.62    0.68      0.65    49848\n",
      "2      dish washer       0.70    0.64      0.67    31498\n",
      "3        microwave       0.57    0.96      0.72    45078\n",
      "4           kettle       0.85    0.72      0.78    53030\n",
      "5        micro avg       0.73    0.81      0.77   239993\n",
      "6        macro avg       0.74    0.80      0.75   239993\n",
      "7     weighted avg       0.75    0.81      0.77   239993\n",
      "8      samples avg       0.70    0.80      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 6 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.91      0.92    11828\n",
      "1  washing machine       0.91    0.82      0.86     8389\n",
      "2      dish washer       0.89    0.80      0.85     8207\n",
      "3        microwave       0.92    0.85      0.89     9542\n",
      "4           kettle       0.96    0.93      0.95     9968\n",
      "5        micro avg       0.93    0.87      0.90    47934\n",
      "6        macro avg       0.93    0.86      0.89    47934\n",
      "7     weighted avg       0.93    0.87      0.90    47934\n",
      "8      samples avg       0.93    0.88      0.90    47934\n",
      "-------------------------------------------------\n",
      "Fold 6 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.95    0.92      0.94    60539\n",
      "1  washing machine       0.60    0.70      0.65    49848\n",
      "2      dish washer       0.57    0.70      0.62    31498\n",
      "3        microwave       0.69    0.92      0.79    45078\n",
      "4           kettle       0.77    0.73      0.75    53030\n",
      "5        micro avg       0.72    0.80      0.76   239993\n",
      "6        macro avg       0.71    0.79      0.75   239993\n",
      "7     weighted avg       0.74    0.80      0.77   239993\n",
      "8      samples avg       0.69    0.78      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 7 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.91      0.91    11670\n",
      "1  washing machine       0.90    0.82      0.86     8394\n",
      "2      dish washer       0.87    0.78      0.82     8254\n",
      "3        microwave       0.89    0.85      0.87     9554\n",
      "4           kettle       0.96    0.92      0.94     9928\n",
      "5        micro avg       0.91    0.86      0.88    47800\n",
      "6        macro avg       0.91    0.86      0.88    47800\n",
      "7     weighted avg       0.91    0.86      0.88    47800\n",
      "8      samples avg       0.92    0.88      0.89    47800\n",
      "-------------------------------------------------\n",
      "Fold 7 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.98      0.96    60539\n",
      "1  washing machine       0.56    0.83      0.67    49848\n",
      "2      dish washer       0.71    0.65      0.67    31498\n",
      "3        microwave       0.63    0.90      0.74    45078\n",
      "4           kettle       0.80    0.73      0.76    53030\n",
      "5        micro avg       0.72    0.84      0.77   239993\n",
      "6        macro avg       0.73    0.82      0.76   239993\n",
      "7     weighted avg       0.74    0.84      0.78   239993\n",
      "8      samples avg       0.68    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 8 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.84      0.89    11782\n",
      "1  washing machine       0.63    0.91      0.74     8527\n",
      "2      dish washer       0.93    0.60      0.73     8269\n",
      "3        microwave       0.87    0.80      0.83     9595\n",
      "4           kettle       0.94    0.89      0.92     9911\n",
      "5        micro avg       0.84    0.81      0.83    48084\n",
      "6        macro avg       0.86    0.81      0.82    48084\n",
      "7     weighted avg       0.87    0.81      0.83    48084\n",
      "8      samples avg       0.84    0.83      0.82    48084\n",
      "-------------------------------------------------\n",
      "Fold 8 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.96    0.98      0.97    60539\n",
      "1  washing machine       0.57    0.85      0.68    49848\n",
      "2      dish washer       0.90    0.57      0.70    31498\n",
      "3        microwave       0.62    0.91      0.74    45078\n",
      "4           kettle       0.78    0.78      0.78    53030\n",
      "5        micro avg       0.73    0.84      0.78   239993\n",
      "6        macro avg       0.77    0.82      0.77   239993\n",
      "7     weighted avg       0.77    0.84      0.79   239993\n",
      "8      samples avg       0.72    0.84      0.75   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 9 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.93      0.92    11834\n",
      "1  washing machine       0.91    0.80      0.85     8478\n",
      "2      dish washer       0.85    0.79      0.82     8188\n",
      "3        microwave       0.93    0.83      0.87     9619\n",
      "4           kettle       0.96    0.93      0.94    10086\n",
      "5        micro avg       0.91    0.86      0.89    48205\n",
      "6        macro avg       0.91    0.85      0.88    48205\n",
      "7     weighted avg       0.91    0.86      0.89    48205\n",
      "8      samples avg       0.92    0.88      0.89    48205\n",
      "-------------------------------------------------\n",
      "Fold 9 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.89      0.90    60539\n",
      "1  washing machine       0.57    0.81      0.67    49848\n",
      "2      dish washer       0.58    0.71      0.64    31498\n",
      "3        microwave       0.67    0.85      0.75    45078\n",
      "4           kettle       0.86    0.72      0.78    53030\n",
      "5        micro avg       0.72    0.81      0.76   239993\n",
      "6        macro avg       0.72    0.80      0.75   239993\n",
      "7     weighted avg       0.74    0.81      0.76   239993\n",
      "8      samples avg       0.69    0.78      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 10 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.93      0.92    11928\n",
      "1  washing machine       0.90    0.81      0.85     8376\n",
      "2      dish washer       0.87    0.79      0.82     8204\n",
      "3        microwave       0.88    0.86      0.87     9506\n",
      "4           kettle       0.95    0.92      0.94     9963\n",
      "5        micro avg       0.91    0.87      0.89    47977\n",
      "6        macro avg       0.90    0.86      0.88    47977\n",
      "7     weighted avg       0.91    0.87      0.89    47977\n",
      "8      samples avg       0.92    0.88      0.89    47977\n",
      "-------------------------------------------------\n",
      "Fold 10 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.99      0.95    60539\n",
      "1  washing machine       0.58    0.80      0.67    49848\n",
      "2      dish washer       0.67    0.65      0.66    31498\n",
      "3        microwave       0.65    0.91      0.76    45078\n",
      "4           kettle       0.78    0.77      0.78    53030\n",
      "5        micro avg       0.72    0.84      0.78   239993\n",
      "6        macro avg       0.72    0.82      0.76   239993\n",
      "7     weighted avg       0.74    0.84      0.78   239993\n",
      "8      samples avg       0.70    0.82      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 11 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.91      0.92    11776\n",
      "1  washing machine       0.92    0.82      0.87     8517\n",
      "2      dish washer       0.86    0.82      0.84     8190\n",
      "3        microwave       0.89    0.87      0.88     9613\n",
      "4           kettle       0.97    0.92      0.95     9969\n",
      "5        micro avg       0.92    0.88      0.90    48065\n",
      "6        macro avg       0.91    0.87      0.89    48065\n",
      "7     weighted avg       0.92    0.88      0.90    48065\n",
      "8      samples avg       0.93    0.89      0.90    48065\n",
      "-------------------------------------------------\n",
      "Fold 11 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.94      0.94    60539\n",
      "1  washing machine       0.57    0.81      0.67    49848\n",
      "2      dish washer       0.62    0.68      0.64    31498\n",
      "3        microwave       0.67    0.90      0.77    45078\n",
      "4           kettle       0.81    0.70      0.75    53030\n",
      "5        micro avg       0.72    0.82      0.76   239993\n",
      "6        macro avg       0.72    0.80      0.75   239993\n",
      "7     weighted avg       0.74    0.82      0.77   239993\n",
      "8      samples avg       0.68    0.79      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 12 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.93      0.93    11825\n",
      "1  washing machine       0.92    0.83      0.87     8448\n",
      "2      dish washer       0.89    0.81      0.85     8210\n",
      "3        microwave       0.91    0.88      0.89     9562\n",
      "4           kettle       0.96    0.94      0.95     9927\n",
      "5        micro avg       0.92    0.88      0.90    47972\n",
      "6        macro avg       0.92    0.88      0.90    47972\n",
      "7     weighted avg       0.92    0.88      0.90    47972\n",
      "8      samples avg       0.93    0.90      0.91    47972\n",
      "-------------------------------------------------\n",
      "Fold 12 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.98      0.96    60539\n",
      "1  washing machine       0.58    0.82      0.68    49848\n",
      "2      dish washer       0.75    0.60      0.66    31498\n",
      "3        microwave       0.64    0.91      0.75    45078\n",
      "4           kettle       0.79    0.75      0.77    53030\n",
      "5        micro avg       0.73    0.83      0.78   239993\n",
      "6        macro avg       0.74    0.81      0.76   239993\n",
      "7     weighted avg       0.75    0.83      0.78   239993\n",
      "8      samples avg       0.71    0.82      0.74   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 13 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.94      0.92    11762\n",
      "1  washing machine       0.89    0.85      0.87     8396\n",
      "2      dish washer       0.83    0.86      0.84     8248\n",
      "3        microwave       0.91    0.86      0.88     9477\n",
      "4           kettle       0.94    0.94      0.94    10024\n",
      "5        micro avg       0.90    0.89      0.89    47907\n",
      "6        macro avg       0.89    0.89      0.89    47907\n",
      "7     weighted avg       0.90    0.89      0.89    47907\n",
      "8      samples avg       0.91    0.91      0.90    47907\n",
      "-------------------------------------------------\n",
      "Fold 13 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.88    0.96      0.92    60539\n",
      "1  washing machine       0.57    0.85      0.68    49848\n",
      "2      dish washer       0.61    0.70      0.65    31498\n",
      "3        microwave       0.65    0.88      0.74    45078\n",
      "4           kettle       0.66    0.83      0.74    53030\n",
      "5        micro avg       0.68    0.86      0.76   239993\n",
      "6        macro avg       0.67    0.84      0.75   239993\n",
      "7     weighted avg       0.69    0.86      0.76   239993\n",
      "8      samples avg       0.65    0.84      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 14 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.93      0.93    11786\n",
      "1  washing machine       0.93    0.82      0.87     8379\n",
      "2      dish washer       0.86    0.85      0.86     8269\n",
      "3        microwave       0.91    0.86      0.89     9574\n",
      "4           kettle       0.98    0.92      0.95     9978\n",
      "5        micro avg       0.92    0.88      0.90    47986\n",
      "6        macro avg       0.92    0.87      0.90    47986\n",
      "7     weighted avg       0.92    0.88      0.90    47986\n",
      "8      samples avg       0.93    0.90      0.90    47986\n",
      "-------------------------------------------------\n",
      "Fold 14 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.99      0.96    60539\n",
      "1  washing machine       0.57    0.78      0.66    49848\n",
      "2      dish washer       0.59    0.70      0.64    31498\n",
      "3        microwave       0.66    0.90      0.76    45078\n",
      "4           kettle       0.85    0.67      0.75    53030\n",
      "5        micro avg       0.72    0.82      0.77   239993\n",
      "6        macro avg       0.72    0.81      0.75   239993\n",
      "7     weighted avg       0.74    0.82      0.77   239993\n",
      "8      samples avg       0.69    0.80      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 15 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.92      0.93    11893\n",
      "1  washing machine       0.91    0.84      0.88     8424\n",
      "2      dish washer       0.86    0.86      0.86     8205\n",
      "3        microwave       0.90    0.88      0.89     9590\n",
      "4           kettle       0.97    0.93      0.95     9958\n",
      "5        micro avg       0.92    0.89      0.90    48070\n",
      "6        macro avg       0.91    0.89      0.90    48070\n",
      "7     weighted avg       0.92    0.89      0.90    48070\n",
      "8      samples avg       0.93    0.91      0.91    48070\n",
      "-------------------------------------------------\n",
      "Fold 15 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.99      0.96    60539\n",
      "1  washing machine       0.59    0.80      0.68    49848\n",
      "2      dish washer       0.60    0.71      0.65    31498\n",
      "3        microwave       0.63    0.93      0.75    45078\n",
      "4           kettle       0.85    0.69      0.76    53030\n",
      "5        micro avg       0.72    0.84      0.77   239993\n",
      "6        macro avg       0.72    0.82      0.76   239993\n",
      "7     weighted avg       0.74    0.84      0.78   239993\n",
      "8      samples avg       0.69    0.82      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Using koef 0.7\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 34s 53ms/step - loss: inf - F1Score: 0.6368 - WeightedF1: 0.6754 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 32s 53ms/step - loss: inf - F1Score: 0.7448 - WeightedF1: 0.7739 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.7844 - WeightedF1: 0.8069 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.8304 - WeightedF1: 0.8464 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 32s 53ms/step - loss: inf - F1Score: 0.8673 - WeightedF1: 0.8813 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 32s 53ms/step - loss: inf - F1Score: 0.8881 - WeightedF1: 0.9001 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 32s 53ms/step - loss: inf - F1Score: 0.8991 - WeightedF1: 0.9101 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 32s 53ms/step - loss: inf - F1Score: 0.9065 - WeightedF1: 0.9168 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 32s 53ms/step - loss: inf - F1Score: 0.9125 - WeightedF1: 0.9224 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.9166 - WeightedF1: 0.9261 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.9211 - WeightedF1: 0.9303 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 32s 53ms/step - loss: inf - F1Score: 0.9247 - WeightedF1: 0.9335 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 32s 53ms/step - loss: inf - F1Score: 0.9288 - WeightedF1: 0.9372 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 32s 53ms/step - loss: inf - F1Score: 0.9319 - WeightedF1: 0.9401 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 32s 53ms/step - loss: inf - F1Score: 0.9346 - WeightedF1: 0.9426 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.9374 - WeightedF1: 0.9451 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.9399 - WeightedF1: 0.9474 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 32s 53ms/step - loss: inf - F1Score: 0.9423 - WeightedF1: 0.9496 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 32s 53ms/step - loss: inf - F1Score: 0.9455 - WeightedF1: 0.9525 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.9479 - WeightedF1: 0.9546 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 4s 5ms/step\n",
      "3000/3000 [==============================] - 16s 5ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 34s 52ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 31s 51ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 31s 51ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 30s 50ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 31s 51ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 30s 51ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 30s 50ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 31s 51ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 31s 51ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 31s 51ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 30s 51ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 30s 51ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 31s 51ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 30s 51ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 31s 51ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.1036e-04\n",
      "600/600 [==============================] - 4s 6ms/step\n",
      "3000/3000 [==============================] - 16s 5ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 33s 52ms/step - loss: inf - F1Score: 0.6322 - WeightedF1: 0.6694 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.7263 - WeightedF1: 0.7568 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 31s 51ms/step - loss: inf - F1Score: 0.7915 - WeightedF1: 0.8116 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 31s 51ms/step - loss: inf - F1Score: 0.8343 - WeightedF1: 0.8508 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.8599 - WeightedF1: 0.8752 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 32s 53ms/step - loss: inf - F1Score: 0.8748 - WeightedF1: 0.8894 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.8866 - WeightedF1: 0.9003 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.8987 - WeightedF1: 0.9107 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 31s 51ms/step - loss: inf - F1Score: 0.9047 - WeightedF1: 0.9159 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.9111 - WeightedF1: 0.9217 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 31s 51ms/step - loss: inf - F1Score: 0.9151 - WeightedF1: 0.9254 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 30s 51ms/step - loss: inf - F1Score: 0.9210 - WeightedF1: 0.9307 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 30s 51ms/step - loss: inf - F1Score: 0.9248 - WeightedF1: 0.9341 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 30s 50ms/step - loss: inf - F1Score: 0.9284 - WeightedF1: 0.9373 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 30s 50ms/step - loss: inf - F1Score: 0.9312 - WeightedF1: 0.9397 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 30s 50ms/step - loss: inf - F1Score: 0.9338 - WeightedF1: 0.9422 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 30s 51ms/step - loss: inf - F1Score: 0.9375 - WeightedF1: 0.9455 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 31s 51ms/step - loss: inf - F1Score: 0.9404 - WeightedF1: 0.9481 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 31s 51ms/step - loss: inf - F1Score: 0.9427 - WeightedF1: 0.9500 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 31s 51ms/step - loss: inf - F1Score: 0.9467 - WeightedF1: 0.9532 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 3s 5ms/step\n",
      "3000/3000 [==============================] - 14s 5ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 37s 58ms/step - loss: inf - F1Score: 0.6528 - WeightedF1: 0.6918 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 31s 51ms/step - loss: inf - F1Score: 0.7733 - WeightedF1: 0.7946 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 30s 51ms/step - loss: inf - F1Score: 0.8214 - WeightedF1: 0.8378 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.8554 - WeightedF1: 0.8702 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.8799 - WeightedF1: 0.8927 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.8954 - WeightedF1: 0.9069 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.9040 - WeightedF1: 0.9148 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.9115 - WeightedF1: 0.9217 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 32s 53ms/step - loss: inf - F1Score: 0.9167 - WeightedF1: 0.9264 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.9225 - WeightedF1: 0.9317 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.9275 - WeightedF1: 0.9361 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 32s 53ms/step - loss: inf - F1Score: 0.9320 - WeightedF1: 0.9402 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 32s 53ms/step - loss: inf - F1Score: 0.9350 - WeightedF1: 0.9430 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.9392 - WeightedF1: 0.9468 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 31s 51ms/step - loss: inf - F1Score: 0.9421 - WeightedF1: 0.9496 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.9453 - WeightedF1: 0.9525 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.9449 - WeightedF1: 0.9520 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.9501 - WeightedF1: 0.9569 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 32s 53ms/step - loss: inf - F1Score: 0.9528 - WeightedF1: 0.9593 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.9555 - WeightedF1: 0.9618 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 4s 6ms/step\n",
      "3000/3000 [==============================] - 17s 6ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 37s 58ms/step - loss: inf - F1Score: 0.6371 - WeightedF1: 0.6764 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 32s 54ms/step - loss: inf - F1Score: 0.7236 - WeightedF1: 0.7530 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 32s 53ms/step - loss: inf - F1Score: 0.7518 - WeightedF1: 0.7760 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.7902 - WeightedF1: 0.8085 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.8244 - WeightedF1: 0.8394 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.8337 - WeightedF1: 0.8487 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.8126 - WeightedF1: 0.8279 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.8128 - WeightedF1: 0.8279 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 31s 51ms/step - loss: inf - F1Score: 0.8126 - WeightedF1: 0.8278 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 31s 51ms/step - loss: inf - F1Score: 0.8126 - WeightedF1: 0.8278 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.8128 - WeightedF1: 0.8280 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.8127 - WeightedF1: 0.8279 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.8127 - WeightedF1: 0.8279 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 31s 51ms/step - loss: inf - F1Score: 0.8127 - WeightedF1: 0.8279 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 31s 51ms/step - loss: inf - F1Score: 0.8126 - WeightedF1: 0.8278 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 31s 51ms/step - loss: inf - F1Score: 0.8127 - WeightedF1: 0.8279 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 31s 51ms/step - loss: inf - F1Score: 0.8127 - WeightedF1: 0.8279 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.8127 - WeightedF1: 0.8279 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 31s 51ms/step - loss: inf - F1Score: 0.8128 - WeightedF1: 0.8280 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 30s 50ms/step - loss: inf - F1Score: 0.8127 - WeightedF1: 0.8279 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 4s 5ms/step\n",
      "3000/3000 [==============================] - 16s 5ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 33s 52ms/step - loss: inf - F1Score: 0.6053 - WeightedF1: 0.6222 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.7318 - WeightedF1: 0.7420 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.7753 - WeightedF1: 0.7833 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.8011 - WeightedF1: 0.8082 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.8213 - WeightedF1: 0.8280 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 31s 51ms/step - loss: inf - F1Score: 0.8401 - WeightedF1: 0.8462 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.8522 - WeightedF1: 0.8579 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.8622 - WeightedF1: 0.8675 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.8699 - WeightedF1: 0.8748 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.8783 - WeightedF1: 0.8828 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.8871 - WeightedF1: 0.8913 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.8943 - WeightedF1: 0.8982 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 32s 53ms/step - loss: inf - F1Score: 0.9023 - WeightedF1: 0.9058 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.9090 - WeightedF1: 0.9122 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.9154 - WeightedF1: 0.9183 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.9206 - WeightedF1: 0.9233 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.9269 - WeightedF1: 0.9292 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.9327 - WeightedF1: 0.9348 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.9384 - WeightedF1: 0.9402 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.9437 - WeightedF1: 0.9452 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 4s 5ms/step\n",
      "3000/3000 [==============================] - 18s 6ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 33s 51ms/step - loss: inf - F1Score: 0.6260 - WeightedF1: 0.6413 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 31s 51ms/step - loss: inf - F1Score: 0.7322 - WeightedF1: 0.7425 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.7656 - WeightedF1: 0.7742 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.7764 - WeightedF1: 0.7844 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 30s 51ms/step - loss: inf - F1Score: 0.7538 - WeightedF1: 0.7627 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 31s 51ms/step - loss: inf - F1Score: 0.7539 - WeightedF1: 0.7628 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 30s 50ms/step - loss: inf - F1Score: 0.7538 - WeightedF1: 0.7627 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 30s 49ms/step - loss: inf - F1Score: 0.7539 - WeightedF1: 0.7628 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 30s 49ms/step - loss: inf - F1Score: 0.7539 - WeightedF1: 0.7628 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 30s 50ms/step - loss: inf - F1Score: 0.7539 - WeightedF1: 0.7628 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 30s 50ms/step - loss: inf - F1Score: 0.7539 - WeightedF1: 0.7627 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 30s 50ms/step - loss: inf - F1Score: 0.7539 - WeightedF1: 0.7627 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 30s 50ms/step - loss: inf - F1Score: 0.7539 - WeightedF1: 0.7628 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 30s 49ms/step - loss: inf - F1Score: 0.7538 - WeightedF1: 0.7627 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 30s 49ms/step - loss: inf - F1Score: 0.7539 - WeightedF1: 0.7628 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 30s 49ms/step - loss: inf - F1Score: 0.7538 - WeightedF1: 0.7627 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 30s 49ms/step - loss: inf - F1Score: 0.7539 - WeightedF1: 0.7628 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 30s 49ms/step - loss: inf - F1Score: 0.7538 - WeightedF1: 0.7627 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 30s 49ms/step - loss: inf - F1Score: 0.7540 - WeightedF1: 0.7628 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 30s 51ms/step - loss: inf - F1Score: 0.7539 - WeightedF1: 0.7628 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 4s 6ms/step\n",
      "3000/3000 [==============================] - 18s 6ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 33s 51ms/step - loss: inf - F1Score: 0.6130 - WeightedF1: 0.6298 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 31s 51ms/step - loss: inf - F1Score: 0.7263 - WeightedF1: 0.7369 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 31s 51ms/step - loss: inf - F1Score: 0.7591 - WeightedF1: 0.7679 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 31s 51ms/step - loss: inf - F1Score: 0.7877 - WeightedF1: 0.7955 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 31s 51ms/step - loss: inf - F1Score: 0.7952 - WeightedF1: 0.8032 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 30s 50ms/step - loss: inf - F1Score: 0.7645 - WeightedF1: 0.7750 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 30s 50ms/step - loss: inf - F1Score: 0.7645 - WeightedF1: 0.7750 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 30s 50ms/step - loss: inf - F1Score: 0.7646 - WeightedF1: 0.7750 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 30s 50ms/step - loss: inf - F1Score: 0.7646 - WeightedF1: 0.7750 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 30s 50ms/step - loss: inf - F1Score: 0.7645 - WeightedF1: 0.7749 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 30s 50ms/step - loss: inf - F1Score: 0.7645 - WeightedF1: 0.7750 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 30s 51ms/step - loss: inf - F1Score: 0.7645 - WeightedF1: 0.7749 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 30s 50ms/step - loss: inf - F1Score: 0.7645 - WeightedF1: 0.7749 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 30s 50ms/step - loss: inf - F1Score: 0.7644 - WeightedF1: 0.7749 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 30s 50ms/step - loss: inf - F1Score: 0.7644 - WeightedF1: 0.7748 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 30s 50ms/step - loss: inf - F1Score: 0.7646 - WeightedF1: 0.7750 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 30s 50ms/step - loss: inf - F1Score: 0.7644 - WeightedF1: 0.7749 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 30s 50ms/step - loss: inf - F1Score: 0.7645 - WeightedF1: 0.7749 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 30s 50ms/step - loss: inf - F1Score: 0.7644 - WeightedF1: 0.7748 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 30s 51ms/step - loss: inf - F1Score: 0.7645 - WeightedF1: 0.7749 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 4s 5ms/step\n",
      "3000/3000 [==============================] - 16s 5ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 33s 51ms/step - loss: inf - F1Score: 0.6146 - WeightedF1: 0.6306 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.7251 - WeightedF1: 0.7362 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.7589 - WeightedF1: 0.7680 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 32s 53ms/step - loss: inf - F1Score: 0.7820 - WeightedF1: 0.7902 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.8050 - WeightedF1: 0.8124 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.8233 - WeightedF1: 0.8301 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.8386 - WeightedF1: 0.8449 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.8502 - WeightedF1: 0.8561 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.8600 - WeightedF1: 0.8654 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.8675 - WeightedF1: 0.8725 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.8775 - WeightedF1: 0.8821 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 32s 53ms/step - loss: inf - F1Score: 0.8854 - WeightedF1: 0.8896 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 32s 53ms/step - loss: inf - F1Score: 0.8934 - WeightedF1: 0.8973 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.9005 - WeightedF1: 0.9041 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.9073 - WeightedF1: 0.9105 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.9134 - WeightedF1: 0.9164 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.9196 - WeightedF1: 0.9223 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.9249 - WeightedF1: 0.9274 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.9311 - WeightedF1: 0.9333 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.9368 - WeightedF1: 0.9387 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 4s 6ms/step\n",
      "3000/3000 [==============================] - 17s 6ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 33s 51ms/step - loss: inf - F1Score: 0.6161 - WeightedF1: 0.6320 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 31s 51ms/step - loss: inf - F1Score: 0.7282 - WeightedF1: 0.7390 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 31s 51ms/step - loss: inf - F1Score: 0.7637 - WeightedF1: 0.7726 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.7934 - WeightedF1: 0.8011 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 31s 51ms/step - loss: inf - F1Score: 0.8144 - WeightedF1: 0.8214 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 31s 51ms/step - loss: inf - F1Score: 0.8306 - WeightedF1: 0.8369 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 31s 51ms/step - loss: inf - F1Score: 0.8439 - WeightedF1: 0.8499 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 31s 51ms/step - loss: inf - F1Score: 0.8527 - WeightedF1: 0.8584 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 31s 51ms/step - loss: inf - F1Score: 0.8615 - WeightedF1: 0.8668 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 31s 51ms/step - loss: inf - F1Score: 0.8689 - WeightedF1: 0.8739 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 31s 51ms/step - loss: inf - F1Score: 0.8780 - WeightedF1: 0.8826 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 31s 51ms/step - loss: inf - F1Score: 0.8866 - WeightedF1: 0.8908 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 31s 51ms/step - loss: inf - F1Score: 0.8936 - WeightedF1: 0.8974 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 31s 51ms/step - loss: inf - F1Score: 0.9007 - WeightedF1: 0.9043 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 31s 51ms/step - loss: inf - F1Score: 0.9068 - WeightedF1: 0.9101 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 31s 51ms/step - loss: inf - F1Score: 0.9135 - WeightedF1: 0.9165 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 31s 52ms/step - loss: inf - F1Score: 0.9186 - WeightedF1: 0.9214 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 31s 51ms/step - loss: inf - F1Score: 0.9248 - WeightedF1: 0.9272 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 31s 51ms/step - loss: inf - F1Score: 0.9302 - WeightedF1: 0.9324 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 31s 51ms/step - loss: inf - F1Score: 0.9355 - WeightedF1: 0.9375 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 4s 5ms/step\n",
      "3000/3000 [==============================] - 16s 5ms/step\n",
      "Fold 1 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.87    0.92      0.89    11706\n",
      "1  washing machine       0.90    0.75      0.82     8507\n",
      "2      dish washer       0.83    0.73      0.78     8309\n",
      "3        microwave       0.88    0.82      0.85     9549\n",
      "4           kettle       0.96    0.89      0.92     9949\n",
      "5        micro avg       0.89    0.83      0.86    48020\n",
      "6        macro avg       0.89    0.82      0.85    48020\n",
      "7     weighted avg       0.89    0.83      0.86    48020\n",
      "8      samples avg       0.89    0.84      0.85    48020\n",
      "-------------------------------------------------\n",
      "Fold 1 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.99      0.96    60539\n",
      "1  washing machine       0.74    0.55      0.63    49848\n",
      "2      dish washer       0.55    0.73      0.63    31498\n",
      "3        microwave       0.63    0.93      0.75    45078\n",
      "4           kettle       0.73    0.82      0.77    53030\n",
      "5        micro avg       0.72    0.82      0.77   239993\n",
      "6        macro avg       0.71    0.81      0.75   239993\n",
      "7     weighted avg       0.74    0.82      0.77   239993\n",
      "8      samples avg       0.71    0.80      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 2 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.89    0.90      0.90    11903\n",
      "1  washing machine       0.88    0.76      0.82     8383\n",
      "2      dish washer       0.81    0.77      0.79     8279\n",
      "3        microwave       0.86    0.82      0.84     9584\n",
      "4           kettle       0.95    0.91      0.93     9899\n",
      "5        micro avg       0.88    0.84      0.86    48048\n",
      "6        macro avg       0.88    0.83      0.85    48048\n",
      "7     weighted avg       0.88    0.84      0.86    48048\n",
      "8      samples avg       0.89    0.85      0.86    48048\n",
      "-------------------------------------------------\n",
      "Fold 2 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.99      0.96    60539\n",
      "1  washing machine       0.62    0.69      0.66    49848\n",
      "2      dish washer       0.51    0.76      0.61    31498\n",
      "3        microwave       0.62    0.95      0.75    45078\n",
      "4           kettle       0.83    0.74      0.79    53030\n",
      "5        micro avg       0.71    0.83      0.77   239993\n",
      "6        macro avg       0.70    0.83      0.75   239993\n",
      "7     weighted avg       0.73    0.83      0.77   239993\n",
      "8      samples avg       0.69    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 3 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.85    0.92      0.88    11755\n",
      "1  washing machine       0.91    0.74      0.82     8482\n",
      "2      dish washer       0.82    0.71      0.76     8145\n",
      "3        microwave       0.88    0.73      0.80     9633\n",
      "4           kettle       0.95    0.90      0.92     9989\n",
      "5        micro avg       0.88    0.81      0.84    48004\n",
      "6        macro avg       0.88    0.80      0.84    48004\n",
      "7     weighted avg       0.88    0.81      0.84    48004\n",
      "8      samples avg       0.89    0.82      0.84    48004\n",
      "-------------------------------------------------\n",
      "Fold 3 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.98      0.94    60539\n",
      "1  washing machine       0.61    0.72      0.66    49848\n",
      "2      dish washer       0.62    0.68      0.65    31498\n",
      "3        microwave       0.66    0.85      0.74    45078\n",
      "4           kettle       0.77    0.76      0.77    53030\n",
      "5        micro avg       0.72    0.82      0.77   239993\n",
      "6        macro avg       0.71    0.80      0.75   239993\n",
      "7     weighted avg       0.73    0.82      0.77   239993\n",
      "8      samples avg       0.69    0.80      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 4 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.88    0.90      0.89    11880\n",
      "1  washing machine       0.90    0.75      0.82     8396\n",
      "2      dish washer       0.85    0.68      0.75     8215\n",
      "3        microwave       0.88    0.73      0.80     9566\n",
      "4           kettle       0.95    0.90      0.92    10018\n",
      "5        micro avg       0.89    0.80      0.85    48075\n",
      "6        macro avg       0.89    0.79      0.84    48075\n",
      "7     weighted avg       0.89    0.80      0.84    48075\n",
      "8      samples avg       0.90    0.82      0.84    48075\n",
      "-------------------------------------------------\n",
      "Fold 4 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.99      0.96    60539\n",
      "1  washing machine       0.59    0.75      0.66    49848\n",
      "2      dish washer       0.75    0.62      0.68    31498\n",
      "3        microwave       0.59    0.92      0.72    45078\n",
      "4           kettle       0.91    0.71      0.80    53030\n",
      "5        micro avg       0.74    0.82      0.78   239993\n",
      "6        macro avg       0.76    0.80      0.76   239993\n",
      "7     weighted avg       0.77    0.82      0.78   239993\n",
      "8      samples avg       0.72    0.81      0.74   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 5 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.88    0.90      0.89    11798\n",
      "1  washing machine       0.91    0.73      0.81     8396\n",
      "2      dish washer       0.84    0.69      0.75     8174\n",
      "3        microwave       0.85    0.79      0.82     9484\n",
      "4           kettle       0.96    0.87      0.91    10001\n",
      "5        micro avg       0.89    0.81      0.84    47853\n",
      "6        macro avg       0.89    0.79      0.84    47853\n",
      "7     weighted avg       0.89    0.81      0.84    47853\n",
      "8      samples avg       0.89    0.82      0.84    47853\n",
      "-------------------------------------------------\n",
      "Fold 5 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.98      0.96    60539\n",
      "1  washing machine       0.62    0.68      0.65    49848\n",
      "2      dish washer       0.70    0.64      0.67    31498\n",
      "3        microwave       0.57    0.96      0.72    45078\n",
      "4           kettle       0.85    0.72      0.78    53030\n",
      "5        micro avg       0.73    0.81      0.77   239993\n",
      "6        macro avg       0.74    0.80      0.75   239993\n",
      "7     weighted avg       0.75    0.81      0.77   239993\n",
      "8      samples avg       0.70    0.80      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 6 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.91      0.92    11828\n",
      "1  washing machine       0.91    0.82      0.86     8389\n",
      "2      dish washer       0.89    0.80      0.85     8207\n",
      "3        microwave       0.92    0.85      0.89     9542\n",
      "4           kettle       0.96    0.93      0.95     9968\n",
      "5        micro avg       0.93    0.87      0.90    47934\n",
      "6        macro avg       0.93    0.86      0.89    47934\n",
      "7     weighted avg       0.93    0.87      0.90    47934\n",
      "8      samples avg       0.93    0.88      0.90    47934\n",
      "-------------------------------------------------\n",
      "Fold 6 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.95    0.92      0.94    60539\n",
      "1  washing machine       0.60    0.70      0.65    49848\n",
      "2      dish washer       0.57    0.70      0.62    31498\n",
      "3        microwave       0.69    0.92      0.79    45078\n",
      "4           kettle       0.77    0.73      0.75    53030\n",
      "5        micro avg       0.72    0.80      0.76   239993\n",
      "6        macro avg       0.71    0.79      0.75   239993\n",
      "7     weighted avg       0.74    0.80      0.77   239993\n",
      "8      samples avg       0.69    0.78      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 7 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.91      0.91    11670\n",
      "1  washing machine       0.90    0.82      0.86     8394\n",
      "2      dish washer       0.87    0.78      0.82     8254\n",
      "3        microwave       0.89    0.85      0.87     9554\n",
      "4           kettle       0.96    0.92      0.94     9928\n",
      "5        micro avg       0.91    0.86      0.88    47800\n",
      "6        macro avg       0.91    0.86      0.88    47800\n",
      "7     weighted avg       0.91    0.86      0.88    47800\n",
      "8      samples avg       0.92    0.88      0.89    47800\n",
      "-------------------------------------------------\n",
      "Fold 7 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.98      0.96    60539\n",
      "1  washing machine       0.56    0.83      0.67    49848\n",
      "2      dish washer       0.71    0.65      0.67    31498\n",
      "3        microwave       0.63    0.90      0.74    45078\n",
      "4           kettle       0.80    0.73      0.76    53030\n",
      "5        micro avg       0.72    0.84      0.77   239993\n",
      "6        macro avg       0.73    0.82      0.76   239993\n",
      "7     weighted avg       0.74    0.84      0.78   239993\n",
      "8      samples avg       0.68    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 8 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.84      0.89    11782\n",
      "1  washing machine       0.63    0.91      0.74     8527\n",
      "2      dish washer       0.93    0.60      0.73     8269\n",
      "3        microwave       0.87    0.80      0.83     9595\n",
      "4           kettle       0.94    0.89      0.92     9911\n",
      "5        micro avg       0.84    0.81      0.83    48084\n",
      "6        macro avg       0.86    0.81      0.82    48084\n",
      "7     weighted avg       0.87    0.81      0.83    48084\n",
      "8      samples avg       0.84    0.83      0.82    48084\n",
      "-------------------------------------------------\n",
      "Fold 8 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.96    0.98      0.97    60539\n",
      "1  washing machine       0.57    0.85      0.68    49848\n",
      "2      dish washer       0.90    0.57      0.70    31498\n",
      "3        microwave       0.62    0.91      0.74    45078\n",
      "4           kettle       0.78    0.78      0.78    53030\n",
      "5        micro avg       0.73    0.84      0.78   239993\n",
      "6        macro avg       0.77    0.82      0.77   239993\n",
      "7     weighted avg       0.77    0.84      0.79   239993\n",
      "8      samples avg       0.72    0.84      0.75   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 9 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.93      0.92    11834\n",
      "1  washing machine       0.91    0.80      0.85     8478\n",
      "2      dish washer       0.85    0.79      0.82     8188\n",
      "3        microwave       0.93    0.83      0.87     9619\n",
      "4           kettle       0.96    0.93      0.94    10086\n",
      "5        micro avg       0.91    0.86      0.89    48205\n",
      "6        macro avg       0.91    0.85      0.88    48205\n",
      "7     weighted avg       0.91    0.86      0.89    48205\n",
      "8      samples avg       0.92    0.88      0.89    48205\n",
      "-------------------------------------------------\n",
      "Fold 9 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.89      0.90    60539\n",
      "1  washing machine       0.57    0.81      0.67    49848\n",
      "2      dish washer       0.58    0.71      0.64    31498\n",
      "3        microwave       0.67    0.85      0.75    45078\n",
      "4           kettle       0.86    0.72      0.78    53030\n",
      "5        micro avg       0.72    0.81      0.76   239993\n",
      "6        macro avg       0.72    0.80      0.75   239993\n",
      "7     weighted avg       0.74    0.81      0.76   239993\n",
      "8      samples avg       0.69    0.78      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 10 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.93      0.92    11928\n",
      "1  washing machine       0.90    0.81      0.85     8376\n",
      "2      dish washer       0.87    0.79      0.82     8204\n",
      "3        microwave       0.88    0.86      0.87     9506\n",
      "4           kettle       0.95    0.92      0.94     9963\n",
      "5        micro avg       0.91    0.87      0.89    47977\n",
      "6        macro avg       0.90    0.86      0.88    47977\n",
      "7     weighted avg       0.91    0.87      0.89    47977\n",
      "8      samples avg       0.92    0.88      0.89    47977\n",
      "-------------------------------------------------\n",
      "Fold 10 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.99      0.95    60539\n",
      "1  washing machine       0.58    0.80      0.67    49848\n",
      "2      dish washer       0.67    0.65      0.66    31498\n",
      "3        microwave       0.65    0.91      0.76    45078\n",
      "4           kettle       0.78    0.77      0.78    53030\n",
      "5        micro avg       0.72    0.84      0.78   239993\n",
      "6        macro avg       0.72    0.82      0.76   239993\n",
      "7     weighted avg       0.74    0.84      0.78   239993\n",
      "8      samples avg       0.70    0.82      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 11 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.91      0.92    11776\n",
      "1  washing machine       0.92    0.82      0.87     8517\n",
      "2      dish washer       0.86    0.82      0.84     8190\n",
      "3        microwave       0.89    0.87      0.88     9613\n",
      "4           kettle       0.97    0.92      0.95     9969\n",
      "5        micro avg       0.92    0.88      0.90    48065\n",
      "6        macro avg       0.91    0.87      0.89    48065\n",
      "7     weighted avg       0.92    0.88      0.90    48065\n",
      "8      samples avg       0.93    0.89      0.90    48065\n",
      "-------------------------------------------------\n",
      "Fold 11 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.94      0.94    60539\n",
      "1  washing machine       0.57    0.81      0.67    49848\n",
      "2      dish washer       0.62    0.68      0.64    31498\n",
      "3        microwave       0.67    0.90      0.77    45078\n",
      "4           kettle       0.81    0.70      0.75    53030\n",
      "5        micro avg       0.72    0.82      0.76   239993\n",
      "6        macro avg       0.72    0.80      0.75   239993\n",
      "7     weighted avg       0.74    0.82      0.77   239993\n",
      "8      samples avg       0.68    0.79      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 12 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.93      0.93    11825\n",
      "1  washing machine       0.92    0.83      0.87     8448\n",
      "2      dish washer       0.89    0.81      0.85     8210\n",
      "3        microwave       0.91    0.88      0.89     9562\n",
      "4           kettle       0.96    0.94      0.95     9927\n",
      "5        micro avg       0.92    0.88      0.90    47972\n",
      "6        macro avg       0.92    0.88      0.90    47972\n",
      "7     weighted avg       0.92    0.88      0.90    47972\n",
      "8      samples avg       0.93    0.90      0.91    47972\n",
      "-------------------------------------------------\n",
      "Fold 12 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.98      0.96    60539\n",
      "1  washing machine       0.58    0.82      0.68    49848\n",
      "2      dish washer       0.75    0.60      0.66    31498\n",
      "3        microwave       0.64    0.91      0.75    45078\n",
      "4           kettle       0.79    0.75      0.77    53030\n",
      "5        micro avg       0.73    0.83      0.78   239993\n",
      "6        macro avg       0.74    0.81      0.76   239993\n",
      "7     weighted avg       0.75    0.83      0.78   239993\n",
      "8      samples avg       0.71    0.82      0.74   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 13 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.94      0.92    11762\n",
      "1  washing machine       0.89    0.85      0.87     8396\n",
      "2      dish washer       0.83    0.86      0.84     8248\n",
      "3        microwave       0.91    0.86      0.88     9477\n",
      "4           kettle       0.94    0.94      0.94    10024\n",
      "5        micro avg       0.90    0.89      0.89    47907\n",
      "6        macro avg       0.89    0.89      0.89    47907\n",
      "7     weighted avg       0.90    0.89      0.89    47907\n",
      "8      samples avg       0.91    0.91      0.90    47907\n",
      "-------------------------------------------------\n",
      "Fold 13 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.88    0.96      0.92    60539\n",
      "1  washing machine       0.57    0.85      0.68    49848\n",
      "2      dish washer       0.61    0.70      0.65    31498\n",
      "3        microwave       0.65    0.88      0.74    45078\n",
      "4           kettle       0.66    0.83      0.74    53030\n",
      "5        micro avg       0.68    0.86      0.76   239993\n",
      "6        macro avg       0.67    0.84      0.75   239993\n",
      "7     weighted avg       0.69    0.86      0.76   239993\n",
      "8      samples avg       0.65    0.84      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 14 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.93      0.93    11786\n",
      "1  washing machine       0.93    0.82      0.87     8379\n",
      "2      dish washer       0.86    0.85      0.86     8269\n",
      "3        microwave       0.91    0.86      0.89     9574\n",
      "4           kettle       0.98    0.92      0.95     9978\n",
      "5        micro avg       0.92    0.88      0.90    47986\n",
      "6        macro avg       0.92    0.87      0.90    47986\n",
      "7     weighted avg       0.92    0.88      0.90    47986\n",
      "8      samples avg       0.93    0.90      0.90    47986\n",
      "-------------------------------------------------\n",
      "Fold 14 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.99      0.96    60539\n",
      "1  washing machine       0.57    0.78      0.66    49848\n",
      "2      dish washer       0.59    0.70      0.64    31498\n",
      "3        microwave       0.66    0.90      0.76    45078\n",
      "4           kettle       0.85    0.67      0.75    53030\n",
      "5        micro avg       0.72    0.82      0.77   239993\n",
      "6        macro avg       0.72    0.81      0.75   239993\n",
      "7     weighted avg       0.74    0.82      0.77   239993\n",
      "8      samples avg       0.69    0.80      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 15 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.92      0.93    11893\n",
      "1  washing machine       0.91    0.84      0.88     8424\n",
      "2      dish washer       0.86    0.86      0.86     8205\n",
      "3        microwave       0.90    0.88      0.89     9590\n",
      "4           kettle       0.97    0.93      0.95     9958\n",
      "5        micro avg       0.92    0.89      0.90    48070\n",
      "6        macro avg       0.91    0.89      0.90    48070\n",
      "7     weighted avg       0.92    0.89      0.90    48070\n",
      "8      samples avg       0.93    0.91      0.91    48070\n",
      "-------------------------------------------------\n",
      "Fold 15 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.99      0.96    60539\n",
      "1  washing machine       0.59    0.80      0.68    49848\n",
      "2      dish washer       0.60    0.71      0.65    31498\n",
      "3        microwave       0.63    0.93      0.75    45078\n",
      "4           kettle       0.85    0.69      0.76    53030\n",
      "5        micro avg       0.72    0.84      0.77   239993\n",
      "6        macro avg       0.72    0.82      0.76   239993\n",
      "7     weighted avg       0.74    0.84      0.78   239993\n",
      "8      samples avg       0.69    0.82      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 16 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.92      0.92    11865\n",
      "1  washing machine       0.92    0.84      0.88     8506\n",
      "2      dish washer       0.90    0.80      0.85     8222\n",
      "3        microwave       0.91    0.87      0.89     9541\n",
      "4           kettle       0.96    0.94      0.95     9954\n",
      "5        micro avg       0.93    0.88      0.90    48088\n",
      "6        macro avg       0.92    0.88      0.90    48088\n",
      "7     weighted avg       0.92    0.88      0.90    48088\n",
      "8      samples avg       0.93    0.90      0.91    48088\n",
      "-------------------------------------------------\n",
      "Fold 16 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.96      0.94    60539\n",
      "1  washing machine       0.57    0.81      0.67    49848\n",
      "2      dish washer       0.67    0.67      0.67    31498\n",
      "3        microwave       0.66    0.90      0.76    45078\n",
      "4           kettle       0.86    0.71      0.78    53030\n",
      "5        micro avg       0.73    0.82      0.77   239993\n",
      "6        macro avg       0.74    0.81      0.76   239993\n",
      "7     weighted avg       0.75    0.82      0.78   239993\n",
      "8      samples avg       0.70    0.80      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 17 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.76      0.84    11794\n",
      "1  washing machine       0.54    0.89      0.67     8394\n",
      "2      dish washer       0.85    0.57      0.68     8120\n",
      "3        microwave       0.86    0.60      0.71     9589\n",
      "4           kettle       0.95    0.82      0.88     9895\n",
      "5        micro avg       0.79    0.73      0.76    47792\n",
      "6        macro avg       0.83    0.73      0.76    47792\n",
      "7     weighted avg       0.84    0.73      0.77    47792\n",
      "8      samples avg       0.77    0.73      0.72    47792\n",
      "-------------------------------------------------\n",
      "Fold 17 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.96    0.96      0.96    60539\n",
      "1  washing machine       0.61    0.76      0.68    49848\n",
      "2      dish washer       0.62    0.65      0.63    31498\n",
      "3        microwave       0.56    0.95      0.70    45078\n",
      "4           kettle       0.88    0.70      0.78    53030\n",
      "5        micro avg       0.72    0.82      0.76   239993\n",
      "6        macro avg       0.73    0.80      0.75   239993\n",
      "7     weighted avg       0.75    0.82      0.77   239993\n",
      "8      samples avg       0.72    0.82      0.74   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 18 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.84      0.87    11818\n",
      "1  washing machine       0.52    0.92      0.67     8432\n",
      "2      dish washer       0.86    0.58      0.69     8328\n",
      "3        microwave       0.91    0.54      0.68     9480\n",
      "4           kettle       0.96    0.84      0.90     9933\n",
      "5        micro avg       0.79    0.75      0.77    47991\n",
      "6        macro avg       0.83    0.74      0.76    47991\n",
      "7     weighted avg       0.84    0.75      0.77    47991\n",
      "8      samples avg       0.77    0.75      0.73    47991\n",
      "-------------------------------------------------\n",
      "Fold 18 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.99      0.95    60539\n",
      "1  washing machine       0.64    0.79      0.71    49848\n",
      "2      dish washer       0.60    0.68      0.64    31498\n",
      "3        microwave       0.69    0.83      0.75    45078\n",
      "4           kettle       0.84    0.71      0.77    53030\n",
      "5        micro avg       0.75    0.82      0.78   239993\n",
      "6        macro avg       0.74    0.80      0.76   239993\n",
      "7     weighted avg       0.76    0.82      0.78   239993\n",
      "8      samples avg       0.75    0.82      0.76   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 19 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.92      0.93    11787\n",
      "1  washing machine       0.90    0.86      0.88     8464\n",
      "2      dish washer       0.88    0.82      0.85     8235\n",
      "3        microwave       0.92    0.86      0.89     9610\n",
      "4           kettle       0.97    0.93      0.95     9992\n",
      "5        micro avg       0.92    0.88      0.90    48088\n",
      "6        macro avg       0.92    0.88      0.90    48088\n",
      "7     weighted avg       0.92    0.88      0.90    48088\n",
      "8      samples avg       0.93    0.90      0.91    48088\n",
      "-------------------------------------------------\n",
      "Fold 19 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.96      0.95    60539\n",
      "1  washing machine       0.57    0.84      0.68    49848\n",
      "2      dish washer       0.53    0.73      0.61    31498\n",
      "3        microwave       0.68    0.83      0.75    45078\n",
      "4           kettle       0.73    0.76      0.74    53030\n",
      "5        micro avg       0.69    0.84      0.76   239993\n",
      "6        macro avg       0.69    0.82      0.75   239993\n",
      "7     weighted avg       0.71    0.84      0.77   239993\n",
      "8      samples avg       0.67    0.82      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 20 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.92      0.93    11778\n",
      "1  washing machine       0.91    0.84      0.87     8368\n",
      "2      dish washer       0.85    0.84      0.85     8217\n",
      "3        microwave       0.91    0.87      0.89     9596\n",
      "4           kettle       0.95    0.93      0.94    10082\n",
      "5        micro avg       0.91    0.89      0.90    48041\n",
      "6        macro avg       0.91    0.88      0.90    48041\n",
      "7     weighted avg       0.91    0.89      0.90    48041\n",
      "8      samples avg       0.93    0.90      0.90    48041\n",
      "-------------------------------------------------\n",
      "Fold 20 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.97      0.95    60539\n",
      "1  washing machine       0.57    0.82      0.67    49848\n",
      "2      dish washer       0.55    0.72      0.62    31498\n",
      "3        microwave       0.65    0.86      0.74    45078\n",
      "4           kettle       0.76    0.77      0.77    53030\n",
      "5        micro avg       0.70    0.84      0.76   239993\n",
      "6        macro avg       0.69    0.83      0.75   239993\n",
      "7     weighted avg       0.71    0.84      0.77   239993\n",
      "8      samples avg       0.67    0.82      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Using koef 0.9\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 54s 73ms/step - loss: inf - F1Score: 0.6244 - WeightedF1: 0.6658 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 39s 64ms/step - loss: inf - F1Score: 0.7125 - WeightedF1: 0.7449 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 39s 65ms/step - loss: inf - F1Score: 0.7514 - WeightedF1: 0.7760 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 39s 64ms/step - loss: inf - F1Score: 0.7836 - WeightedF1: 0.8044 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 39s 65ms/step - loss: inf - F1Score: 0.8199 - WeightedF1: 0.8352 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 39s 65ms/step - loss: inf - F1Score: 0.8429 - WeightedF1: 0.8573 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 39s 64ms/step - loss: inf - F1Score: 0.8628 - WeightedF1: 0.8768 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 39s 65ms/step - loss: inf - F1Score: 0.8807 - WeightedF1: 0.8927 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 39s 65ms/step - loss: inf - F1Score: 0.8912 - WeightedF1: 0.9027 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 39s 64ms/step - loss: inf - F1Score: 0.9000 - WeightedF1: 0.9110 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 39s 65ms/step - loss: inf - F1Score: 0.9070 - WeightedF1: 0.9174 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 39s 65ms/step - loss: inf - F1Score: 0.9136 - WeightedF1: 0.9237 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 39s 64ms/step - loss: inf - F1Score: 0.9196 - WeightedF1: 0.9293 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 39s 64ms/step - loss: inf - F1Score: 0.9241 - WeightedF1: 0.9333 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 39s 65ms/step - loss: inf - F1Score: 0.9277 - WeightedF1: 0.9366 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 39s 65ms/step - loss: inf - F1Score: 0.9308 - WeightedF1: 0.9393 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 39s 65ms/step - loss: inf - F1Score: 0.9334 - WeightedF1: 0.9418 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 39s 64ms/step - loss: inf - F1Score: 0.9363 - WeightedF1: 0.9443 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 39s 65ms/step - loss: inf - F1Score: 0.9386 - WeightedF1: 0.9464 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 39s 65ms/step - loss: inf - F1Score: 0.9411 - WeightedF1: 0.9486 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 5s 6ms/step\n",
      "3000/3000 [==============================] - 19s 6ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 42s 65ms/step - loss: inf - F1Score: 0.6309 - WeightedF1: 0.6719 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 39s 66ms/step - loss: inf - F1Score: 0.7189 - WeightedF1: 0.7514 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 39s 65ms/step - loss: inf - F1Score: 0.7458 - WeightedF1: 0.7759 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 39s 66ms/step - loss: inf - F1Score: 0.7773 - WeightedF1: 0.8025 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 39s 66ms/step - loss: inf - F1Score: 0.8318 - WeightedF1: 0.8475 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 39s 65ms/step - loss: inf - F1Score: 0.8677 - WeightedF1: 0.8813 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 39s 66ms/step - loss: inf - F1Score: 0.8888 - WeightedF1: 0.9007 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 39s 66ms/step - loss: inf - F1Score: 0.9006 - WeightedF1: 0.9112 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 40s 66ms/step - loss: inf - F1Score: 0.9080 - WeightedF1: 0.9182 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 39s 66ms/step - loss: inf - F1Score: 0.9145 - WeightedF1: 0.9243 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 39s 66ms/step - loss: inf - F1Score: 0.9189 - WeightedF1: 0.9283 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 39s 65ms/step - loss: inf - F1Score: 0.9242 - WeightedF1: 0.9332 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 39s 66ms/step - loss: inf - F1Score: 0.9282 - WeightedF1: 0.9368 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 39s 65ms/step - loss: inf - F1Score: 0.9316 - WeightedF1: 0.9399 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 39s 65ms/step - loss: inf - F1Score: 0.9345 - WeightedF1: 0.9426 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 39s 65ms/step - loss: inf - F1Score: 0.9377 - WeightedF1: 0.9455 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 39s 65ms/step - loss: inf - F1Score: 0.9400 - WeightedF1: 0.9476 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 39s 65ms/step - loss: inf - F1Score: 0.9425 - WeightedF1: 0.9499 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 39s 65ms/step - loss: inf - F1Score: 0.9459 - WeightedF1: 0.9529 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 39s 65ms/step - loss: inf - F1Score: 0.9485 - WeightedF1: 0.9553 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 4s 6ms/step\n",
      "3000/3000 [==============================] - 18s 6ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 42s 65ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 38s 63ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 39s 64ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 39s 64ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 39s 64ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 39s 64ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 38s 63ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.1036e-04\n",
      "600/600 [==============================] - 4s 6ms/step\n",
      "3000/3000 [==============================] - 18s 6ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 47s 73ms/step - loss: inf - F1Score: 0.6289 - WeightedF1: 0.6677 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 39s 65ms/step - loss: inf - F1Score: 0.7122 - WeightedF1: 0.7439 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 39s 65ms/step - loss: inf - F1Score: 0.7712 - WeightedF1: 0.7901 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 39s 64ms/step - loss: inf - F1Score: 0.8192 - WeightedF1: 0.8362 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 39s 64ms/step - loss: inf - F1Score: 0.8491 - WeightedF1: 0.8651 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 39s 65ms/step - loss: inf - F1Score: 0.8666 - WeightedF1: 0.8814 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 39s 65ms/step - loss: inf - F1Score: 0.8824 - WeightedF1: 0.8952 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: inf - F1Score: 0.8117 - WeightedF1: 0.8315 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: inf - F1Score: 0.8081 - WeightedF1: 0.8283 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: inf - F1Score: 0.8079 - WeightedF1: 0.8281 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 38s 63ms/step - loss: inf - F1Score: 0.8079 - WeightedF1: 0.8282 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 39s 64ms/step - loss: inf - F1Score: 0.8080 - WeightedF1: 0.8282 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 38s 63ms/step - loss: inf - F1Score: 0.8081 - WeightedF1: 0.8283 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: inf - F1Score: 0.8081 - WeightedF1: 0.8283 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 38s 63ms/step - loss: inf - F1Score: 0.8081 - WeightedF1: 0.8283 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 38s 63ms/step - loss: inf - F1Score: 0.8081 - WeightedF1: 0.8283 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: inf - F1Score: 0.8079 - WeightedF1: 0.8281 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: inf - F1Score: 0.8080 - WeightedF1: 0.8282 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: inf - F1Score: 0.8079 - WeightedF1: 0.8282 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 38s 63ms/step - loss: inf - F1Score: 0.8080 - WeightedF1: 0.8282 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 5s 7ms/step\n",
      "3000/3000 [==============================] - 19s 6ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 41s 65ms/step - loss: inf - F1Score: 0.6414 - WeightedF1: 0.6797 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 39s 64ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 38s 63ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 38s 63ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 38s 63ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.1036e-04\n",
      "600/600 [==============================] - 4s 6ms/step\n",
      "3000/3000 [==============================] - 19s 6ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 41s 64ms/step - loss: inf - F1Score: 0.6195 - WeightedF1: 0.6348 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: inf - F1Score: 0.7471 - WeightedF1: 0.7558 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 39s 65ms/step - loss: inf - F1Score: 0.7854 - WeightedF1: 0.7928 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: inf - F1Score: 0.7933 - WeightedF1: 0.8002 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 38s 63ms/step - loss: inf - F1Score: 0.7808 - WeightedF1: 0.7875 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 38s 63ms/step - loss: inf - F1Score: 0.7809 - WeightedF1: 0.7876 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 37s 62ms/step - loss: inf - F1Score: 0.7809 - WeightedF1: 0.7876 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 38s 63ms/step - loss: inf - F1Score: 0.7809 - WeightedF1: 0.7876 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 37s 62ms/step - loss: inf - F1Score: 0.7809 - WeightedF1: 0.7876 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 37s 62ms/step - loss: inf - F1Score: 0.7810 - WeightedF1: 0.7877 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 37s 62ms/step - loss: inf - F1Score: 0.7809 - WeightedF1: 0.7876 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 37s 62ms/step - loss: inf - F1Score: 0.7810 - WeightedF1: 0.7877 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 38s 63ms/step - loss: inf - F1Score: 0.7810 - WeightedF1: 0.7877 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 37s 62ms/step - loss: inf - F1Score: 0.7808 - WeightedF1: 0.7876 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 37s 62ms/step - loss: inf - F1Score: 0.7809 - WeightedF1: 0.7877 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 37s 62ms/step - loss: inf - F1Score: 0.7809 - WeightedF1: 0.7876 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 37s 62ms/step - loss: inf - F1Score: 0.7809 - WeightedF1: 0.7877 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 38s 63ms/step - loss: inf - F1Score: 0.7810 - WeightedF1: 0.7878 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 37s 62ms/step - loss: inf - F1Score: 0.7809 - WeightedF1: 0.7877 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 37s 62ms/step - loss: inf - F1Score: 0.7808 - WeightedF1: 0.7875 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 4s 6ms/step\n",
      "3000/3000 [==============================] - 19s 6ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 40s 63ms/step - loss: inf - F1Score: 0.6140 - WeightedF1: 0.6303 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 38s 63ms/step - loss: inf - F1Score: 0.7352 - WeightedF1: 0.7457 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 38s 63ms/step - loss: inf - F1Score: 0.7723 - WeightedF1: 0.7811 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: inf - F1Score: 0.8059 - WeightedF1: 0.8135 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 38s 63ms/step - loss: inf - F1Score: 0.8285 - WeightedF1: 0.8354 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: inf - F1Score: 0.8444 - WeightedF1: 0.8507 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 38s 63ms/step - loss: inf - F1Score: 0.8554 - WeightedF1: 0.8611 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 38s 63ms/step - loss: inf - F1Score: 0.8671 - WeightedF1: 0.8723 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 38s 63ms/step - loss: inf - F1Score: 0.8754 - WeightedF1: 0.8801 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: inf - F1Score: 0.8844 - WeightedF1: 0.8888 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: inf - F1Score: 0.8922 - WeightedF1: 0.8962 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: inf - F1Score: 0.8998 - WeightedF1: 0.9034 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: inf - F1Score: 0.9084 - WeightedF1: 0.9116 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: inf - F1Score: 0.9151 - WeightedF1: 0.9181 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 38s 63ms/step - loss: inf - F1Score: 0.9220 - WeightedF1: 0.9246 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: inf - F1Score: 0.9278 - WeightedF1: 0.9302 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: inf - F1Score: 0.9345 - WeightedF1: 0.9366 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: inf - F1Score: 0.9408 - WeightedF1: 0.9426 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 38s 63ms/step - loss: inf - F1Score: 0.9467 - WeightedF1: 0.9482 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: inf - F1Score: 0.9521 - WeightedF1: 0.9535 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 8s 12ms/step\n",
      "3000/3000 [==============================] - 20s 6ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 41s 64ms/step - loss: inf - F1Score: 0.6027 - WeightedF1: 0.6200 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: inf - F1Score: 0.7291 - WeightedF1: 0.7399 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: inf - F1Score: 0.7772 - WeightedF1: 0.7853 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 38s 63ms/step - loss: inf - F1Score: 0.8048 - WeightedF1: 0.8120 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: inf - F1Score: 0.8254 - WeightedF1: 0.8320 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 39s 64ms/step - loss: inf - F1Score: 0.8399 - WeightedF1: 0.8462 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 39s 65ms/step - loss: inf - F1Score: 0.8507 - WeightedF1: 0.8565 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: inf - F1Score: 0.8604 - WeightedF1: 0.8657 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: inf - F1Score: 0.8681 - WeightedF1: 0.8732 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: inf - F1Score: 0.8763 - WeightedF1: 0.8809 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: inf - F1Score: 0.8852 - WeightedF1: 0.8894 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 39s 64ms/step - loss: inf - F1Score: 0.8941 - WeightedF1: 0.8978 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: inf - F1Score: 0.9019 - WeightedF1: 0.9052 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: inf - F1Score: 0.9095 - WeightedF1: 0.9124 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: inf - F1Score: 0.9167 - WeightedF1: 0.9193 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 39s 64ms/step - loss: inf - F1Score: 0.9232 - WeightedF1: 0.9254 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: inf - F1Score: 0.9292 - WeightedF1: 0.9312 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: inf - F1Score: 0.9357 - WeightedF1: 0.9374 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: inf - F1Score: 0.9414 - WeightedF1: 0.9428 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: inf - F1Score: 0.9475 - WeightedF1: 0.9487 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 4s 6ms/step\n",
      "3000/3000 [==============================] - 18s 6ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 41s 63ms/step - loss: inf - F1Score: 0.6250 - WeightedF1: 0.6403 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 38s 63ms/step - loss: inf - F1Score: 0.7401 - WeightedF1: 0.7503 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 38s 63ms/step - loss: inf - F1Score: 0.7692 - WeightedF1: 0.7781 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 38s 63ms/step - loss: inf - F1Score: 0.7944 - WeightedF1: 0.8023 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 38s 63ms/step - loss: inf - F1Score: 0.8128 - WeightedF1: 0.8200 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 38s 63ms/step - loss: inf - F1Score: 0.8279 - WeightedF1: 0.8345 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 38s 63ms/step - loss: inf - F1Score: 0.8393 - WeightedF1: 0.8456 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 37s 62ms/step - loss: inf - F1Score: 0.8336 - WeightedF1: 0.8404 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 38s 63ms/step - loss: inf - F1Score: 0.8336 - WeightedF1: 0.8404 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 37s 62ms/step - loss: inf - F1Score: 0.8338 - WeightedF1: 0.8406 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 37s 62ms/step - loss: inf - F1Score: 0.8336 - WeightedF1: 0.8404 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 38s 63ms/step - loss: inf - F1Score: 0.8336 - WeightedF1: 0.8404 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 38s 63ms/step - loss: inf - F1Score: 0.8338 - WeightedF1: 0.8405 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 38s 63ms/step - loss: inf - F1Score: 0.8337 - WeightedF1: 0.8405 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 38s 63ms/step - loss: inf - F1Score: 0.8337 - WeightedF1: 0.8405 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 37s 62ms/step - loss: inf - F1Score: 0.8338 - WeightedF1: 0.8405 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 37s 62ms/step - loss: inf - F1Score: 0.8337 - WeightedF1: 0.8405 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 37s 62ms/step - loss: inf - F1Score: 0.8336 - WeightedF1: 0.8404 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 37s 62ms/step - loss: inf - F1Score: 0.8336 - WeightedF1: 0.8404 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 37s 62ms/step - loss: inf - F1Score: 0.8337 - WeightedF1: 0.8405 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 4s 6ms/step\n",
      "3000/3000 [==============================] - 19s 6ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 41s 63ms/step - loss: inf - F1Score: 0.6120 - WeightedF1: 0.6278 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 38s 63ms/step - loss: inf - F1Score: 0.7318 - WeightedF1: 0.7424 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: inf - F1Score: 0.7689 - WeightedF1: 0.7774 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: inf - F1Score: 0.7951 - WeightedF1: 0.8029 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: inf - F1Score: 0.8198 - WeightedF1: 0.8269 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: inf - F1Score: 0.8368 - WeightedF1: 0.8431 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: inf - F1Score: 0.8470 - WeightedF1: 0.8530 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: inf - F1Score: 0.8583 - WeightedF1: 0.8637 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 38s 63ms/step - loss: inf - F1Score: 0.8662 - WeightedF1: 0.8713 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 38s 63ms/step - loss: inf - F1Score: 0.8744 - WeightedF1: 0.8791 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 38s 63ms/step - loss: inf - F1Score: 0.8836 - WeightedF1: 0.8879 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 38s 63ms/step - loss: inf - F1Score: 0.8919 - WeightedF1: 0.8958 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: inf - F1Score: 0.9000 - WeightedF1: 0.9035 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 38s 64ms/step - loss: inf - F1Score: 0.9073 - WeightedF1: 0.9104 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 38s 63ms/step - loss: inf - F1Score: 0.9144 - WeightedF1: 0.9172 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 38s 63ms/step - loss: inf - F1Score: 0.9211 - WeightedF1: 0.9236 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 38s 63ms/step - loss: inf - F1Score: 0.9266 - WeightedF1: 0.9290 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 38s 63ms/step - loss: inf - F1Score: 0.9327 - WeightedF1: 0.9347 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 38s 63ms/step - loss: inf - F1Score: 0.9392 - WeightedF1: 0.9410 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 38s 63ms/step - loss: inf - F1Score: 0.9449 - WeightedF1: 0.9464 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 4s 6ms/step\n",
      "3000/3000 [==============================] - 20s 6ms/step\n",
      "Fold 1 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.87    0.92      0.89    11706\n",
      "1  washing machine       0.90    0.75      0.82     8507\n",
      "2      dish washer       0.83    0.73      0.78     8309\n",
      "3        microwave       0.88    0.82      0.85     9549\n",
      "4           kettle       0.96    0.89      0.92     9949\n",
      "5        micro avg       0.89    0.83      0.86    48020\n",
      "6        macro avg       0.89    0.82      0.85    48020\n",
      "7     weighted avg       0.89    0.83      0.86    48020\n",
      "8      samples avg       0.89    0.84      0.85    48020\n",
      "-------------------------------------------------\n",
      "Fold 1 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.99      0.96    60539\n",
      "1  washing machine       0.74    0.55      0.63    49848\n",
      "2      dish washer       0.55    0.73      0.63    31498\n",
      "3        microwave       0.63    0.93      0.75    45078\n",
      "4           kettle       0.73    0.82      0.77    53030\n",
      "5        micro avg       0.72    0.82      0.77   239993\n",
      "6        macro avg       0.71    0.81      0.75   239993\n",
      "7     weighted avg       0.74    0.82      0.77   239993\n",
      "8      samples avg       0.71    0.80      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 2 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.89    0.90      0.90    11903\n",
      "1  washing machine       0.88    0.76      0.82     8383\n",
      "2      dish washer       0.81    0.77      0.79     8279\n",
      "3        microwave       0.86    0.82      0.84     9584\n",
      "4           kettle       0.95    0.91      0.93     9899\n",
      "5        micro avg       0.88    0.84      0.86    48048\n",
      "6        macro avg       0.88    0.83      0.85    48048\n",
      "7     weighted avg       0.88    0.84      0.86    48048\n",
      "8      samples avg       0.89    0.85      0.86    48048\n",
      "-------------------------------------------------\n",
      "Fold 2 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.99      0.96    60539\n",
      "1  washing machine       0.62    0.69      0.66    49848\n",
      "2      dish washer       0.51    0.76      0.61    31498\n",
      "3        microwave       0.62    0.95      0.75    45078\n",
      "4           kettle       0.83    0.74      0.79    53030\n",
      "5        micro avg       0.71    0.83      0.77   239993\n",
      "6        macro avg       0.70    0.83      0.75   239993\n",
      "7     weighted avg       0.73    0.83      0.77   239993\n",
      "8      samples avg       0.69    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 3 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.85    0.92      0.88    11755\n",
      "1  washing machine       0.91    0.74      0.82     8482\n",
      "2      dish washer       0.82    0.71      0.76     8145\n",
      "3        microwave       0.88    0.73      0.80     9633\n",
      "4           kettle       0.95    0.90      0.92     9989\n",
      "5        micro avg       0.88    0.81      0.84    48004\n",
      "6        macro avg       0.88    0.80      0.84    48004\n",
      "7     weighted avg       0.88    0.81      0.84    48004\n",
      "8      samples avg       0.89    0.82      0.84    48004\n",
      "-------------------------------------------------\n",
      "Fold 3 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.98      0.94    60539\n",
      "1  washing machine       0.61    0.72      0.66    49848\n",
      "2      dish washer       0.62    0.68      0.65    31498\n",
      "3        microwave       0.66    0.85      0.74    45078\n",
      "4           kettle       0.77    0.76      0.77    53030\n",
      "5        micro avg       0.72    0.82      0.77   239993\n",
      "6        macro avg       0.71    0.80      0.75   239993\n",
      "7     weighted avg       0.73    0.82      0.77   239993\n",
      "8      samples avg       0.69    0.80      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 4 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.88    0.90      0.89    11880\n",
      "1  washing machine       0.90    0.75      0.82     8396\n",
      "2      dish washer       0.85    0.68      0.75     8215\n",
      "3        microwave       0.88    0.73      0.80     9566\n",
      "4           kettle       0.95    0.90      0.92    10018\n",
      "5        micro avg       0.89    0.80      0.85    48075\n",
      "6        macro avg       0.89    0.79      0.84    48075\n",
      "7     weighted avg       0.89    0.80      0.84    48075\n",
      "8      samples avg       0.90    0.82      0.84    48075\n",
      "-------------------------------------------------\n",
      "Fold 4 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.99      0.96    60539\n",
      "1  washing machine       0.59    0.75      0.66    49848\n",
      "2      dish washer       0.75    0.62      0.68    31498\n",
      "3        microwave       0.59    0.92      0.72    45078\n",
      "4           kettle       0.91    0.71      0.80    53030\n",
      "5        micro avg       0.74    0.82      0.78   239993\n",
      "6        macro avg       0.76    0.80      0.76   239993\n",
      "7     weighted avg       0.77    0.82      0.78   239993\n",
      "8      samples avg       0.72    0.81      0.74   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 5 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.88    0.90      0.89    11798\n",
      "1  washing machine       0.91    0.73      0.81     8396\n",
      "2      dish washer       0.84    0.69      0.75     8174\n",
      "3        microwave       0.85    0.79      0.82     9484\n",
      "4           kettle       0.96    0.87      0.91    10001\n",
      "5        micro avg       0.89    0.81      0.84    47853\n",
      "6        macro avg       0.89    0.79      0.84    47853\n",
      "7     weighted avg       0.89    0.81      0.84    47853\n",
      "8      samples avg       0.89    0.82      0.84    47853\n",
      "-------------------------------------------------\n",
      "Fold 5 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.98      0.96    60539\n",
      "1  washing machine       0.62    0.68      0.65    49848\n",
      "2      dish washer       0.70    0.64      0.67    31498\n",
      "3        microwave       0.57    0.96      0.72    45078\n",
      "4           kettle       0.85    0.72      0.78    53030\n",
      "5        micro avg       0.73    0.81      0.77   239993\n",
      "6        macro avg       0.74    0.80      0.75   239993\n",
      "7     weighted avg       0.75    0.81      0.77   239993\n",
      "8      samples avg       0.70    0.80      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 6 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.91      0.92    11828\n",
      "1  washing machine       0.91    0.82      0.86     8389\n",
      "2      dish washer       0.89    0.80      0.85     8207\n",
      "3        microwave       0.92    0.85      0.89     9542\n",
      "4           kettle       0.96    0.93      0.95     9968\n",
      "5        micro avg       0.93    0.87      0.90    47934\n",
      "6        macro avg       0.93    0.86      0.89    47934\n",
      "7     weighted avg       0.93    0.87      0.90    47934\n",
      "8      samples avg       0.93    0.88      0.90    47934\n",
      "-------------------------------------------------\n",
      "Fold 6 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.95    0.92      0.94    60539\n",
      "1  washing machine       0.60    0.70      0.65    49848\n",
      "2      dish washer       0.57    0.70      0.62    31498\n",
      "3        microwave       0.69    0.92      0.79    45078\n",
      "4           kettle       0.77    0.73      0.75    53030\n",
      "5        micro avg       0.72    0.80      0.76   239993\n",
      "6        macro avg       0.71    0.79      0.75   239993\n",
      "7     weighted avg       0.74    0.80      0.77   239993\n",
      "8      samples avg       0.69    0.78      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 7 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.91      0.91    11670\n",
      "1  washing machine       0.90    0.82      0.86     8394\n",
      "2      dish washer       0.87    0.78      0.82     8254\n",
      "3        microwave       0.89    0.85      0.87     9554\n",
      "4           kettle       0.96    0.92      0.94     9928\n",
      "5        micro avg       0.91    0.86      0.88    47800\n",
      "6        macro avg       0.91    0.86      0.88    47800\n",
      "7     weighted avg       0.91    0.86      0.88    47800\n",
      "8      samples avg       0.92    0.88      0.89    47800\n",
      "-------------------------------------------------\n",
      "Fold 7 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.98      0.96    60539\n",
      "1  washing machine       0.56    0.83      0.67    49848\n",
      "2      dish washer       0.71    0.65      0.67    31498\n",
      "3        microwave       0.63    0.90      0.74    45078\n",
      "4           kettle       0.80    0.73      0.76    53030\n",
      "5        micro avg       0.72    0.84      0.77   239993\n",
      "6        macro avg       0.73    0.82      0.76   239993\n",
      "7     weighted avg       0.74    0.84      0.78   239993\n",
      "8      samples avg       0.68    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 8 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.84      0.89    11782\n",
      "1  washing machine       0.63    0.91      0.74     8527\n",
      "2      dish washer       0.93    0.60      0.73     8269\n",
      "3        microwave       0.87    0.80      0.83     9595\n",
      "4           kettle       0.94    0.89      0.92     9911\n",
      "5        micro avg       0.84    0.81      0.83    48084\n",
      "6        macro avg       0.86    0.81      0.82    48084\n",
      "7     weighted avg       0.87    0.81      0.83    48084\n",
      "8      samples avg       0.84    0.83      0.82    48084\n",
      "-------------------------------------------------\n",
      "Fold 8 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.96    0.98      0.97    60539\n",
      "1  washing machine       0.57    0.85      0.68    49848\n",
      "2      dish washer       0.90    0.57      0.70    31498\n",
      "3        microwave       0.62    0.91      0.74    45078\n",
      "4           kettle       0.78    0.78      0.78    53030\n",
      "5        micro avg       0.73    0.84      0.78   239993\n",
      "6        macro avg       0.77    0.82      0.77   239993\n",
      "7     weighted avg       0.77    0.84      0.79   239993\n",
      "8      samples avg       0.72    0.84      0.75   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 9 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.93      0.92    11834\n",
      "1  washing machine       0.91    0.80      0.85     8478\n",
      "2      dish washer       0.85    0.79      0.82     8188\n",
      "3        microwave       0.93    0.83      0.87     9619\n",
      "4           kettle       0.96    0.93      0.94    10086\n",
      "5        micro avg       0.91    0.86      0.89    48205\n",
      "6        macro avg       0.91    0.85      0.88    48205\n",
      "7     weighted avg       0.91    0.86      0.89    48205\n",
      "8      samples avg       0.92    0.88      0.89    48205\n",
      "-------------------------------------------------\n",
      "Fold 9 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.89      0.90    60539\n",
      "1  washing machine       0.57    0.81      0.67    49848\n",
      "2      dish washer       0.58    0.71      0.64    31498\n",
      "3        microwave       0.67    0.85      0.75    45078\n",
      "4           kettle       0.86    0.72      0.78    53030\n",
      "5        micro avg       0.72    0.81      0.76   239993\n",
      "6        macro avg       0.72    0.80      0.75   239993\n",
      "7     weighted avg       0.74    0.81      0.76   239993\n",
      "8      samples avg       0.69    0.78      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 10 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.93      0.92    11928\n",
      "1  washing machine       0.90    0.81      0.85     8376\n",
      "2      dish washer       0.87    0.79      0.82     8204\n",
      "3        microwave       0.88    0.86      0.87     9506\n",
      "4           kettle       0.95    0.92      0.94     9963\n",
      "5        micro avg       0.91    0.87      0.89    47977\n",
      "6        macro avg       0.90    0.86      0.88    47977\n",
      "7     weighted avg       0.91    0.87      0.89    47977\n",
      "8      samples avg       0.92    0.88      0.89    47977\n",
      "-------------------------------------------------\n",
      "Fold 10 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.99      0.95    60539\n",
      "1  washing machine       0.58    0.80      0.67    49848\n",
      "2      dish washer       0.67    0.65      0.66    31498\n",
      "3        microwave       0.65    0.91      0.76    45078\n",
      "4           kettle       0.78    0.77      0.78    53030\n",
      "5        micro avg       0.72    0.84      0.78   239993\n",
      "6        macro avg       0.72    0.82      0.76   239993\n",
      "7     weighted avg       0.74    0.84      0.78   239993\n",
      "8      samples avg       0.70    0.82      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 11 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.91      0.92    11776\n",
      "1  washing machine       0.92    0.82      0.87     8517\n",
      "2      dish washer       0.86    0.82      0.84     8190\n",
      "3        microwave       0.89    0.87      0.88     9613\n",
      "4           kettle       0.97    0.92      0.95     9969\n",
      "5        micro avg       0.92    0.88      0.90    48065\n",
      "6        macro avg       0.91    0.87      0.89    48065\n",
      "7     weighted avg       0.92    0.88      0.90    48065\n",
      "8      samples avg       0.93    0.89      0.90    48065\n",
      "-------------------------------------------------\n",
      "Fold 11 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.94      0.94    60539\n",
      "1  washing machine       0.57    0.81      0.67    49848\n",
      "2      dish washer       0.62    0.68      0.64    31498\n",
      "3        microwave       0.67    0.90      0.77    45078\n",
      "4           kettle       0.81    0.70      0.75    53030\n",
      "5        micro avg       0.72    0.82      0.76   239993\n",
      "6        macro avg       0.72    0.80      0.75   239993\n",
      "7     weighted avg       0.74    0.82      0.77   239993\n",
      "8      samples avg       0.68    0.79      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 12 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.93      0.93    11825\n",
      "1  washing machine       0.92    0.83      0.87     8448\n",
      "2      dish washer       0.89    0.81      0.85     8210\n",
      "3        microwave       0.91    0.88      0.89     9562\n",
      "4           kettle       0.96    0.94      0.95     9927\n",
      "5        micro avg       0.92    0.88      0.90    47972\n",
      "6        macro avg       0.92    0.88      0.90    47972\n",
      "7     weighted avg       0.92    0.88      0.90    47972\n",
      "8      samples avg       0.93    0.90      0.91    47972\n",
      "-------------------------------------------------\n",
      "Fold 12 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.98      0.96    60539\n",
      "1  washing machine       0.58    0.82      0.68    49848\n",
      "2      dish washer       0.75    0.60      0.66    31498\n",
      "3        microwave       0.64    0.91      0.75    45078\n",
      "4           kettle       0.79    0.75      0.77    53030\n",
      "5        micro avg       0.73    0.83      0.78   239993\n",
      "6        macro avg       0.74    0.81      0.76   239993\n",
      "7     weighted avg       0.75    0.83      0.78   239993\n",
      "8      samples avg       0.71    0.82      0.74   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 13 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.94      0.92    11762\n",
      "1  washing machine       0.89    0.85      0.87     8396\n",
      "2      dish washer       0.83    0.86      0.84     8248\n",
      "3        microwave       0.91    0.86      0.88     9477\n",
      "4           kettle       0.94    0.94      0.94    10024\n",
      "5        micro avg       0.90    0.89      0.89    47907\n",
      "6        macro avg       0.89    0.89      0.89    47907\n",
      "7     weighted avg       0.90    0.89      0.89    47907\n",
      "8      samples avg       0.91    0.91      0.90    47907\n",
      "-------------------------------------------------\n",
      "Fold 13 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.88    0.96      0.92    60539\n",
      "1  washing machine       0.57    0.85      0.68    49848\n",
      "2      dish washer       0.61    0.70      0.65    31498\n",
      "3        microwave       0.65    0.88      0.74    45078\n",
      "4           kettle       0.66    0.83      0.74    53030\n",
      "5        micro avg       0.68    0.86      0.76   239993\n",
      "6        macro avg       0.67    0.84      0.75   239993\n",
      "7     weighted avg       0.69    0.86      0.76   239993\n",
      "8      samples avg       0.65    0.84      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 14 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.93      0.93    11786\n",
      "1  washing machine       0.93    0.82      0.87     8379\n",
      "2      dish washer       0.86    0.85      0.86     8269\n",
      "3        microwave       0.91    0.86      0.89     9574\n",
      "4           kettle       0.98    0.92      0.95     9978\n",
      "5        micro avg       0.92    0.88      0.90    47986\n",
      "6        macro avg       0.92    0.87      0.90    47986\n",
      "7     weighted avg       0.92    0.88      0.90    47986\n",
      "8      samples avg       0.93    0.90      0.90    47986\n",
      "-------------------------------------------------\n",
      "Fold 14 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.99      0.96    60539\n",
      "1  washing machine       0.57    0.78      0.66    49848\n",
      "2      dish washer       0.59    0.70      0.64    31498\n",
      "3        microwave       0.66    0.90      0.76    45078\n",
      "4           kettle       0.85    0.67      0.75    53030\n",
      "5        micro avg       0.72    0.82      0.77   239993\n",
      "6        macro avg       0.72    0.81      0.75   239993\n",
      "7     weighted avg       0.74    0.82      0.77   239993\n",
      "8      samples avg       0.69    0.80      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 15 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.92      0.93    11893\n",
      "1  washing machine       0.91    0.84      0.88     8424\n",
      "2      dish washer       0.86    0.86      0.86     8205\n",
      "3        microwave       0.90    0.88      0.89     9590\n",
      "4           kettle       0.97    0.93      0.95     9958\n",
      "5        micro avg       0.92    0.89      0.90    48070\n",
      "6        macro avg       0.91    0.89      0.90    48070\n",
      "7     weighted avg       0.92    0.89      0.90    48070\n",
      "8      samples avg       0.93    0.91      0.91    48070\n",
      "-------------------------------------------------\n",
      "Fold 15 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.99      0.96    60539\n",
      "1  washing machine       0.59    0.80      0.68    49848\n",
      "2      dish washer       0.60    0.71      0.65    31498\n",
      "3        microwave       0.63    0.93      0.75    45078\n",
      "4           kettle       0.85    0.69      0.76    53030\n",
      "5        micro avg       0.72    0.84      0.77   239993\n",
      "6        macro avg       0.72    0.82      0.76   239993\n",
      "7     weighted avg       0.74    0.84      0.78   239993\n",
      "8      samples avg       0.69    0.82      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 16 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.92      0.92    11865\n",
      "1  washing machine       0.92    0.84      0.88     8506\n",
      "2      dish washer       0.90    0.80      0.85     8222\n",
      "3        microwave       0.91    0.87      0.89     9541\n",
      "4           kettle       0.96    0.94      0.95     9954\n",
      "5        micro avg       0.93    0.88      0.90    48088\n",
      "6        macro avg       0.92    0.88      0.90    48088\n",
      "7     weighted avg       0.92    0.88      0.90    48088\n",
      "8      samples avg       0.93    0.90      0.91    48088\n",
      "-------------------------------------------------\n",
      "Fold 16 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.96      0.94    60539\n",
      "1  washing machine       0.57    0.81      0.67    49848\n",
      "2      dish washer       0.67    0.67      0.67    31498\n",
      "3        microwave       0.66    0.90      0.76    45078\n",
      "4           kettle       0.86    0.71      0.78    53030\n",
      "5        micro avg       0.73    0.82      0.77   239993\n",
      "6        macro avg       0.74    0.81      0.76   239993\n",
      "7     weighted avg       0.75    0.82      0.78   239993\n",
      "8      samples avg       0.70    0.80      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 17 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.76      0.84    11794\n",
      "1  washing machine       0.54    0.89      0.67     8394\n",
      "2      dish washer       0.85    0.57      0.68     8120\n",
      "3        microwave       0.86    0.60      0.71     9589\n",
      "4           kettle       0.95    0.82      0.88     9895\n",
      "5        micro avg       0.79    0.73      0.76    47792\n",
      "6        macro avg       0.83    0.73      0.76    47792\n",
      "7     weighted avg       0.84    0.73      0.77    47792\n",
      "8      samples avg       0.77    0.73      0.72    47792\n",
      "-------------------------------------------------\n",
      "Fold 17 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.96    0.96      0.96    60539\n",
      "1  washing machine       0.61    0.76      0.68    49848\n",
      "2      dish washer       0.62    0.65      0.63    31498\n",
      "3        microwave       0.56    0.95      0.70    45078\n",
      "4           kettle       0.88    0.70      0.78    53030\n",
      "5        micro avg       0.72    0.82      0.76   239993\n",
      "6        macro avg       0.73    0.80      0.75   239993\n",
      "7     weighted avg       0.75    0.82      0.77   239993\n",
      "8      samples avg       0.72    0.82      0.74   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 18 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.84      0.87    11818\n",
      "1  washing machine       0.52    0.92      0.67     8432\n",
      "2      dish washer       0.86    0.58      0.69     8328\n",
      "3        microwave       0.91    0.54      0.68     9480\n",
      "4           kettle       0.96    0.84      0.90     9933\n",
      "5        micro avg       0.79    0.75      0.77    47991\n",
      "6        macro avg       0.83    0.74      0.76    47991\n",
      "7     weighted avg       0.84    0.75      0.77    47991\n",
      "8      samples avg       0.77    0.75      0.73    47991\n",
      "-------------------------------------------------\n",
      "Fold 18 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.99      0.95    60539\n",
      "1  washing machine       0.64    0.79      0.71    49848\n",
      "2      dish washer       0.60    0.68      0.64    31498\n",
      "3        microwave       0.69    0.83      0.75    45078\n",
      "4           kettle       0.84    0.71      0.77    53030\n",
      "5        micro avg       0.75    0.82      0.78   239993\n",
      "6        macro avg       0.74    0.80      0.76   239993\n",
      "7     weighted avg       0.76    0.82      0.78   239993\n",
      "8      samples avg       0.75    0.82      0.76   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 19 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.92      0.93    11787\n",
      "1  washing machine       0.90    0.86      0.88     8464\n",
      "2      dish washer       0.88    0.82      0.85     8235\n",
      "3        microwave       0.92    0.86      0.89     9610\n",
      "4           kettle       0.97    0.93      0.95     9992\n",
      "5        micro avg       0.92    0.88      0.90    48088\n",
      "6        macro avg       0.92    0.88      0.90    48088\n",
      "7     weighted avg       0.92    0.88      0.90    48088\n",
      "8      samples avg       0.93    0.90      0.91    48088\n",
      "-------------------------------------------------\n",
      "Fold 19 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.96      0.95    60539\n",
      "1  washing machine       0.57    0.84      0.68    49848\n",
      "2      dish washer       0.53    0.73      0.61    31498\n",
      "3        microwave       0.68    0.83      0.75    45078\n",
      "4           kettle       0.73    0.76      0.74    53030\n",
      "5        micro avg       0.69    0.84      0.76   239993\n",
      "6        macro avg       0.69    0.82      0.75   239993\n",
      "7     weighted avg       0.71    0.84      0.77   239993\n",
      "8      samples avg       0.67    0.82      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 20 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.92      0.93    11778\n",
      "1  washing machine       0.91    0.84      0.87     8368\n",
      "2      dish washer       0.85    0.84      0.85     8217\n",
      "3        microwave       0.91    0.87      0.89     9596\n",
      "4           kettle       0.95    0.93      0.94    10082\n",
      "5        micro avg       0.91    0.89      0.90    48041\n",
      "6        macro avg       0.91    0.88      0.90    48041\n",
      "7     weighted avg       0.91    0.89      0.90    48041\n",
      "8      samples avg       0.93    0.90      0.90    48041\n",
      "-------------------------------------------------\n",
      "Fold 20 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.97      0.95    60539\n",
      "1  washing machine       0.57    0.82      0.67    49848\n",
      "2      dish washer       0.55    0.72      0.62    31498\n",
      "3        microwave       0.65    0.86      0.74    45078\n",
      "4           kettle       0.76    0.77      0.77    53030\n",
      "5        micro avg       0.70    0.84      0.76   239993\n",
      "6        macro avg       0.69    0.83      0.75   239993\n",
      "7     weighted avg       0.71    0.84      0.77   239993\n",
      "8      samples avg       0.67    0.82      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 21 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.86    0.90      0.88    11890\n",
      "1  washing machine       0.90    0.72      0.80     8479\n",
      "2      dish washer       0.88    0.58      0.70     8116\n",
      "3        microwave       0.55    0.93      0.69     9604\n",
      "4           kettle       0.96    0.77      0.85    10055\n",
      "5        micro avg       0.78    0.79      0.79    48144\n",
      "6        macro avg       0.83    0.78      0.78    48144\n",
      "7     weighted avg       0.83    0.79      0.79    48144\n",
      "8      samples avg       0.77    0.80      0.76    48144\n",
      "-------------------------------------------------\n",
      "Fold 21 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.99      0.95    60539\n",
      "1  washing machine       0.71    0.61      0.66    49848\n",
      "2      dish washer       0.57    0.70      0.63    31498\n",
      "3        microwave       0.58    0.91      0.71    45078\n",
      "4           kettle       0.94    0.53      0.68    53030\n",
      "5        micro avg       0.73    0.76      0.75   239993\n",
      "6        macro avg       0.74    0.75      0.72   239993\n",
      "7     weighted avg       0.77    0.76      0.74   239993\n",
      "8      samples avg       0.73    0.75      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 22 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.92      0.93    11862\n",
      "1  washing machine       0.88    0.89      0.89     8406\n",
      "2      dish washer       0.89    0.83      0.86     8269\n",
      "3        microwave       0.93    0.86      0.89     9586\n",
      "4           kettle       0.96    0.94      0.95     9876\n",
      "5        micro avg       0.92    0.89      0.91    47999\n",
      "6        macro avg       0.92    0.89      0.90    47999\n",
      "7     weighted avg       0.92    0.89      0.91    47999\n",
      "8      samples avg       0.93    0.91      0.91    47999\n",
      "-------------------------------------------------\n",
      "Fold 22 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.98      0.95    60539\n",
      "1  washing machine       0.57    0.87      0.68    49848\n",
      "2      dish washer       0.63    0.67      0.65    31498\n",
      "3        microwave       0.67    0.85      0.75    45078\n",
      "4           kettle       0.80    0.72      0.76    53030\n",
      "5        micro avg       0.72    0.84      0.77   239993\n",
      "6        macro avg       0.72    0.82      0.76   239993\n",
      "7     weighted avg       0.73    0.84      0.78   239993\n",
      "8      samples avg       0.69    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 23 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.91      0.93    11732\n",
      "1  washing machine       0.91    0.85      0.88     8519\n",
      "2      dish washer       0.90    0.84      0.87     8304\n",
      "3        microwave       0.91    0.87      0.89     9582\n",
      "4           kettle       0.95    0.94      0.95     9995\n",
      "5        micro avg       0.92    0.89      0.91    48132\n",
      "6        macro avg       0.92    0.88      0.90    48132\n",
      "7     weighted avg       0.92    0.89      0.91    48132\n",
      "8      samples avg       0.94    0.90      0.91    48132\n",
      "-------------------------------------------------\n",
      "Fold 23 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.98      0.96    60539\n",
      "1  washing machine       0.57    0.83      0.67    49848\n",
      "2      dish washer       0.76    0.62      0.68    31498\n",
      "3        microwave       0.64    0.92      0.75    45078\n",
      "4           kettle       0.75    0.78      0.76    53030\n",
      "5        micro avg       0.72    0.85      0.78   239993\n",
      "6        macro avg       0.73    0.82      0.77   239993\n",
      "7     weighted avg       0.74    0.85      0.78   239993\n",
      "8      samples avg       0.69    0.83      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 24 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.86      0.89    11836\n",
      "1  washing machine       0.78    0.85      0.81     8450\n",
      "2      dish washer       0.88    0.62      0.73     8204\n",
      "3        microwave       0.92    0.72      0.80     9561\n",
      "4           kettle       0.97    0.87      0.92     9908\n",
      "5        micro avg       0.90    0.79      0.84    47959\n",
      "6        macro avg       0.89    0.78      0.83    47959\n",
      "7     weighted avg       0.90    0.79      0.84    47959\n",
      "8      samples avg       0.89    0.80      0.83    47959\n",
      "-------------------------------------------------\n",
      "Fold 24 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.99      0.96    60539\n",
      "1  washing machine       0.60    0.82      0.69    49848\n",
      "2      dish washer       0.67    0.65      0.66    31498\n",
      "3        microwave       0.59    0.95      0.73    45078\n",
      "4           kettle       0.95    0.65      0.77    53030\n",
      "5        micro avg       0.73    0.83      0.77   239993\n",
      "6        macro avg       0.75    0.81      0.76   239993\n",
      "7     weighted avg       0.77    0.83      0.78   239993\n",
      "8      samples avg       0.72    0.82      0.74   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 25 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.93      0.92    11722\n",
      "1  washing machine       0.90    0.85      0.88     8310\n",
      "2      dish washer       0.86    0.87      0.86     8229\n",
      "3        microwave       0.92    0.86      0.89     9483\n",
      "4           kettle       0.97    0.93      0.95    10022\n",
      "5        micro avg       0.92    0.89      0.90    47766\n",
      "6        macro avg       0.91    0.89      0.90    47766\n",
      "7     weighted avg       0.92    0.89      0.90    47766\n",
      "8      samples avg       0.93    0.91      0.91    47766\n",
      "-------------------------------------------------\n",
      "Fold 25 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.98      0.94    60539\n",
      "1  washing machine       0.57    0.83      0.68    49848\n",
      "2      dish washer       0.60    0.70      0.64    31498\n",
      "3        microwave       0.64    0.91      0.75    45078\n",
      "4           kettle       0.85    0.70      0.77    53030\n",
      "5        micro avg       0.71    0.84      0.77   239993\n",
      "6        macro avg       0.71    0.82      0.76   239993\n",
      "7     weighted avg       0.73    0.84      0.77   239993\n",
      "8      samples avg       0.68    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Using koef 1.1\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 69s 97ms/step - loss: inf - F1Score: 0.6254 - WeightedF1: 0.6679 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.7423 - WeightedF1: 0.7727 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.8199 - WeightedF1: 0.8383 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.8676 - WeightedF1: 0.8830 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.8891 - WeightedF1: 0.9019 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.9033 - WeightedF1: 0.9148 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.9096 - WeightedF1: 0.9201 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.9166 - WeightedF1: 0.9264 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.9212 - WeightedF1: 0.9301 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.9257 - WeightedF1: 0.9344 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.9299 - WeightedF1: 0.9382 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.9329 - WeightedF1: 0.9409 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.9360 - WeightedF1: 0.9437 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.9406 - WeightedF1: 0.9474 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.9445 - WeightedF1: 0.9508 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.9469 - WeightedF1: 0.9529 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.9500 - WeightedF1: 0.9558 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.9520 - WeightedF1: 0.9577 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.9552 - WeightedF1: 0.9605 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.9581 - WeightedF1: 0.9631 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 6s 8ms/step\n",
      "3000/3000 [==============================] - 23s 8ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 52s 83ms/step - loss: inf - F1Score: 0.6363 - WeightedF1: 0.6759 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 49s 81ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 49s 81ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 49s 81ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 49s 81ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 49s 81ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 49s 81ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 49s 81ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 49s 81ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 49s 81ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 49s 81ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 49s 81ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 49s 81ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 49s 81ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 49s 81ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 49s 81ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.1036e-04\n",
      "600/600 [==============================] - 5s 8ms/step\n",
      "3000/3000 [==============================] - 23s 8ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 56s 83ms/step - loss: inf - F1Score: 0.6399 - WeightedF1: 0.6787 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.7145 - WeightedF1: 0.7475 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.7520 - WeightedF1: 0.7781 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.8013 - WeightedF1: 0.8192 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.8365 - WeightedF1: 0.8527 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.8634 - WeightedF1: 0.8774 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.8811 - WeightedF1: 0.8938 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.8942 - WeightedF1: 0.9053 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.9027 - WeightedF1: 0.9134 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.9085 - WeightedF1: 0.9189 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.9143 - WeightedF1: 0.9243 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.9200 - WeightedF1: 0.9296 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.9228 - WeightedF1: 0.9323 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.9271 - WeightedF1: 0.9361 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.9308 - WeightedF1: 0.9394 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.9336 - WeightedF1: 0.9418 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.9366 - WeightedF1: 0.9445 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.9393 - WeightedF1: 0.9470 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.9427 - WeightedF1: 0.9501 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.9442 - WeightedF1: 0.9514 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 5s 8ms/step\n",
      "3000/3000 [==============================] - 23s 8ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 61s 97ms/step - loss: inf - F1Score: 0.6274 - WeightedF1: 0.6673 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.7317 - WeightedF1: 0.7607 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.7786 - WeightedF1: 0.7974 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.8274 - WeightedF1: 0.8429 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.8628 - WeightedF1: 0.8769 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.8828 - WeightedF1: 0.8956 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.8943 - WeightedF1: 0.9061 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.9029 - WeightedF1: 0.9140 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.9081 - WeightedF1: 0.9187 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.9129 - WeightedF1: 0.9230 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.9109 - WeightedF1: 0.9221 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.9150 - WeightedF1: 0.9256 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.9263 - WeightedF1: 0.9354 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.9303 - WeightedF1: 0.9390 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.9337 - WeightedF1: 0.9419 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.9368 - WeightedF1: 0.9447 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.9399 - WeightedF1: 0.9474 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.9430 - WeightedF1: 0.9501 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 50s 84ms/step - loss: inf - F1Score: 0.9470 - WeightedF1: 0.9534 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.9501 - WeightedF1: 0.9561 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 6s 9ms/step\n",
      "3000/3000 [==============================] - 24s 8ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 52s 82ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 49s 81ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 49s 81ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 49s 81ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 49s 81ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 49s 81ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 49s 81ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 49s 81ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 49s 81ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 49s 81ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 48s 81ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 49s 81ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 48s 81ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 48s 81ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 49s 81ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 49s 81ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 49s 81ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 49s 81ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 48s 81ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.1036e-04\n",
      "600/600 [==============================] - 5s 8ms/step\n",
      "3000/3000 [==============================] - 23s 8ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 52s 82ms/step - loss: inf - F1Score: 0.6061 - WeightedF1: 0.6224 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.7250 - WeightedF1: 0.7361 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.7708 - WeightedF1: 0.7796 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.8046 - WeightedF1: 0.8121 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.8250 - WeightedF1: 0.8319 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.8388 - WeightedF1: 0.8451 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.8539 - WeightedF1: 0.8594 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.8653 - WeightedF1: 0.8704 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.8744 - WeightedF1: 0.8791 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.8827 - WeightedF1: 0.8870 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.8931 - WeightedF1: 0.8970 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.9009 - WeightedF1: 0.9044 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.9076 - WeightedF1: 0.9107 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.9151 - WeightedF1: 0.9178 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.9222 - WeightedF1: 0.9246 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.9287 - WeightedF1: 0.9308 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.9352 - WeightedF1: 0.9369 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.9417 - WeightedF1: 0.9433 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.9474 - WeightedF1: 0.9487 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.9535 - WeightedF1: 0.9545 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 5s 8ms/step\n",
      "3000/3000 [==============================] - 24s 8ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 51s 81ms/step - loss: inf - F1Score: 0.6224 - WeightedF1: 0.6375 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 49s 81ms/step - loss: inf - F1Score: 0.7624 - WeightedF1: 0.7711 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 49s 81ms/step - loss: inf - F1Score: 0.7988 - WeightedF1: 0.8061 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.8230 - WeightedF1: 0.8298 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.8408 - WeightedF1: 0.8468 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.8526 - WeightedF1: 0.8581 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.8622 - WeightedF1: 0.8673 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.8706 - WeightedF1: 0.8754 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.8783 - WeightedF1: 0.8827 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.8858 - WeightedF1: 0.8898 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.8932 - WeightedF1: 0.8969 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 49s 81ms/step - loss: inf - F1Score: 0.9025 - WeightedF1: 0.9058 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 49s 81ms/step - loss: inf - F1Score: 0.9082 - WeightedF1: 0.9113 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 49s 81ms/step - loss: inf - F1Score: 0.9168 - WeightedF1: 0.9194 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 49s 81ms/step - loss: inf - F1Score: 0.9237 - WeightedF1: 0.9260 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.9308 - WeightedF1: 0.9328 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 49s 81ms/step - loss: inf - F1Score: 0.9375 - WeightedF1: 0.9393 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.9432 - WeightedF1: 0.9448 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 49s 81ms/step - loss: inf - F1Score: 0.9492 - WeightedF1: 0.9505 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 49s 81ms/step - loss: inf - F1Score: 0.9556 - WeightedF1: 0.9566 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 5s 7ms/step\n",
      "3000/3000 [==============================] - 24s 8ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 51s 82ms/step - loss: inf - F1Score: 0.6053 - WeightedF1: 0.6218 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.7252 - WeightedF1: 0.7361 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.7709 - WeightedF1: 0.7790 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.7948 - WeightedF1: 0.8024 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.8141 - WeightedF1: 0.8211 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.8314 - WeightedF1: 0.8378 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.8456 - WeightedF1: 0.8515 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.8554 - WeightedF1: 0.8609 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.8642 - WeightedF1: 0.8694 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.8716 - WeightedF1: 0.8764 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.8812 - WeightedF1: 0.8855 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.8911 - WeightedF1: 0.8950 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.8990 - WeightedF1: 0.9025 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.9070 - WeightedF1: 0.9101 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.9138 - WeightedF1: 0.9166 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.9218 - WeightedF1: 0.9243 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.9283 - WeightedF1: 0.9304 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.9362 - WeightedF1: 0.9380 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.9416 - WeightedF1: 0.9432 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 49s 81ms/step - loss: inf - F1Score: 0.9482 - WeightedF1: 0.9495 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 5s 8ms/step\n",
      "3000/3000 [==============================] - 24s 8ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 51s 82ms/step - loss: inf - F1Score: 0.6068 - WeightedF1: 0.6240 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.7249 - WeightedF1: 0.7360 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.7708 - WeightedF1: 0.7795 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.8019 - WeightedF1: 0.8093 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.8249 - WeightedF1: 0.8316 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.8428 - WeightedF1: 0.8488 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.8543 - WeightedF1: 0.8598 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.8645 - WeightedF1: 0.8695 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.8728 - WeightedF1: 0.8774 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.8804 - WeightedF1: 0.8846 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.8881 - WeightedF1: 0.8920 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.8965 - WeightedF1: 0.9000 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.9039 - WeightedF1: 0.9071 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.9110 - WeightedF1: 0.9140 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 49s 81ms/step - loss: inf - F1Score: 0.9183 - WeightedF1: 0.9209 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 49s 81ms/step - loss: inf - F1Score: 0.9250 - WeightedF1: 0.9273 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.9318 - WeightedF1: 0.9338 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.9382 - WeightedF1: 0.9398 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.9442 - WeightedF1: 0.9457 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.9500 - WeightedF1: 0.9513 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 5s 8ms/step\n",
      "3000/3000 [==============================] - 24s 8ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 53s 83ms/step - loss: inf - F1Score: 0.5962 - WeightedF1: 0.6136 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.7149 - WeightedF1: 0.7266 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.7535 - WeightedF1: 0.7625 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.7820 - WeightedF1: 0.7900 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.8068 - WeightedF1: 0.8142 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.8271 - WeightedF1: 0.8338 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 50s 83ms/step - loss: inf - F1Score: 0.8430 - WeightedF1: 0.8492 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.8536 - WeightedF1: 0.8593 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.8642 - WeightedF1: 0.8694 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.8702 - WeightedF1: 0.8751 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.8806 - WeightedF1: 0.8850 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.8900 - WeightedF1: 0.8940 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.8974 - WeightedF1: 0.9011 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.9044 - WeightedF1: 0.9078 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.9109 - WeightedF1: 0.9139 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.9181 - WeightedF1: 0.9209 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.9239 - WeightedF1: 0.9264 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.9292 - WeightedF1: 0.9315 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.9360 - WeightedF1: 0.9380 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 49s 82ms/step - loss: inf - F1Score: 0.9413 - WeightedF1: 0.9431 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 5s 8ms/step\n",
      "3000/3000 [==============================] - 24s 8ms/step\n",
      "Fold 1 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.87    0.92      0.89    11706\n",
      "1  washing machine       0.90    0.75      0.82     8507\n",
      "2      dish washer       0.83    0.73      0.78     8309\n",
      "3        microwave       0.88    0.82      0.85     9549\n",
      "4           kettle       0.96    0.89      0.92     9949\n",
      "5        micro avg       0.89    0.83      0.86    48020\n",
      "6        macro avg       0.89    0.82      0.85    48020\n",
      "7     weighted avg       0.89    0.83      0.86    48020\n",
      "8      samples avg       0.89    0.84      0.85    48020\n",
      "-------------------------------------------------\n",
      "Fold 1 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.99      0.96    60539\n",
      "1  washing machine       0.74    0.55      0.63    49848\n",
      "2      dish washer       0.55    0.73      0.63    31498\n",
      "3        microwave       0.63    0.93      0.75    45078\n",
      "4           kettle       0.73    0.82      0.77    53030\n",
      "5        micro avg       0.72    0.82      0.77   239993\n",
      "6        macro avg       0.71    0.81      0.75   239993\n",
      "7     weighted avg       0.74    0.82      0.77   239993\n",
      "8      samples avg       0.71    0.80      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 2 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.89    0.90      0.90    11903\n",
      "1  washing machine       0.88    0.76      0.82     8383\n",
      "2      dish washer       0.81    0.77      0.79     8279\n",
      "3        microwave       0.86    0.82      0.84     9584\n",
      "4           kettle       0.95    0.91      0.93     9899\n",
      "5        micro avg       0.88    0.84      0.86    48048\n",
      "6        macro avg       0.88    0.83      0.85    48048\n",
      "7     weighted avg       0.88    0.84      0.86    48048\n",
      "8      samples avg       0.89    0.85      0.86    48048\n",
      "-------------------------------------------------\n",
      "Fold 2 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.99      0.96    60539\n",
      "1  washing machine       0.62    0.69      0.66    49848\n",
      "2      dish washer       0.51    0.76      0.61    31498\n",
      "3        microwave       0.62    0.95      0.75    45078\n",
      "4           kettle       0.83    0.74      0.79    53030\n",
      "5        micro avg       0.71    0.83      0.77   239993\n",
      "6        macro avg       0.70    0.83      0.75   239993\n",
      "7     weighted avg       0.73    0.83      0.77   239993\n",
      "8      samples avg       0.69    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 3 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.85    0.92      0.88    11755\n",
      "1  washing machine       0.91    0.74      0.82     8482\n",
      "2      dish washer       0.82    0.71      0.76     8145\n",
      "3        microwave       0.88    0.73      0.80     9633\n",
      "4           kettle       0.95    0.90      0.92     9989\n",
      "5        micro avg       0.88    0.81      0.84    48004\n",
      "6        macro avg       0.88    0.80      0.84    48004\n",
      "7     weighted avg       0.88    0.81      0.84    48004\n",
      "8      samples avg       0.89    0.82      0.84    48004\n",
      "-------------------------------------------------\n",
      "Fold 3 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.98      0.94    60539\n",
      "1  washing machine       0.61    0.72      0.66    49848\n",
      "2      dish washer       0.62    0.68      0.65    31498\n",
      "3        microwave       0.66    0.85      0.74    45078\n",
      "4           kettle       0.77    0.76      0.77    53030\n",
      "5        micro avg       0.72    0.82      0.77   239993\n",
      "6        macro avg       0.71    0.80      0.75   239993\n",
      "7     weighted avg       0.73    0.82      0.77   239993\n",
      "8      samples avg       0.69    0.80      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 4 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.88    0.90      0.89    11880\n",
      "1  washing machine       0.90    0.75      0.82     8396\n",
      "2      dish washer       0.85    0.68      0.75     8215\n",
      "3        microwave       0.88    0.73      0.80     9566\n",
      "4           kettle       0.95    0.90      0.92    10018\n",
      "5        micro avg       0.89    0.80      0.85    48075\n",
      "6        macro avg       0.89    0.79      0.84    48075\n",
      "7     weighted avg       0.89    0.80      0.84    48075\n",
      "8      samples avg       0.90    0.82      0.84    48075\n",
      "-------------------------------------------------\n",
      "Fold 4 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.99      0.96    60539\n",
      "1  washing machine       0.59    0.75      0.66    49848\n",
      "2      dish washer       0.75    0.62      0.68    31498\n",
      "3        microwave       0.59    0.92      0.72    45078\n",
      "4           kettle       0.91    0.71      0.80    53030\n",
      "5        micro avg       0.74    0.82      0.78   239993\n",
      "6        macro avg       0.76    0.80      0.76   239993\n",
      "7     weighted avg       0.77    0.82      0.78   239993\n",
      "8      samples avg       0.72    0.81      0.74   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 5 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.88    0.90      0.89    11798\n",
      "1  washing machine       0.91    0.73      0.81     8396\n",
      "2      dish washer       0.84    0.69      0.75     8174\n",
      "3        microwave       0.85    0.79      0.82     9484\n",
      "4           kettle       0.96    0.87      0.91    10001\n",
      "5        micro avg       0.89    0.81      0.84    47853\n",
      "6        macro avg       0.89    0.79      0.84    47853\n",
      "7     weighted avg       0.89    0.81      0.84    47853\n",
      "8      samples avg       0.89    0.82      0.84    47853\n",
      "-------------------------------------------------\n",
      "Fold 5 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.98      0.96    60539\n",
      "1  washing machine       0.62    0.68      0.65    49848\n",
      "2      dish washer       0.70    0.64      0.67    31498\n",
      "3        microwave       0.57    0.96      0.72    45078\n",
      "4           kettle       0.85    0.72      0.78    53030\n",
      "5        micro avg       0.73    0.81      0.77   239993\n",
      "6        macro avg       0.74    0.80      0.75   239993\n",
      "7     weighted avg       0.75    0.81      0.77   239993\n",
      "8      samples avg       0.70    0.80      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 6 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.91      0.92    11828\n",
      "1  washing machine       0.91    0.82      0.86     8389\n",
      "2      dish washer       0.89    0.80      0.85     8207\n",
      "3        microwave       0.92    0.85      0.89     9542\n",
      "4           kettle       0.96    0.93      0.95     9968\n",
      "5        micro avg       0.93    0.87      0.90    47934\n",
      "6        macro avg       0.93    0.86      0.89    47934\n",
      "7     weighted avg       0.93    0.87      0.90    47934\n",
      "8      samples avg       0.93    0.88      0.90    47934\n",
      "-------------------------------------------------\n",
      "Fold 6 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.95    0.92      0.94    60539\n",
      "1  washing machine       0.60    0.70      0.65    49848\n",
      "2      dish washer       0.57    0.70      0.62    31498\n",
      "3        microwave       0.69    0.92      0.79    45078\n",
      "4           kettle       0.77    0.73      0.75    53030\n",
      "5        micro avg       0.72    0.80      0.76   239993\n",
      "6        macro avg       0.71    0.79      0.75   239993\n",
      "7     weighted avg       0.74    0.80      0.77   239993\n",
      "8      samples avg       0.69    0.78      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 7 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.91      0.91    11670\n",
      "1  washing machine       0.90    0.82      0.86     8394\n",
      "2      dish washer       0.87    0.78      0.82     8254\n",
      "3        microwave       0.89    0.85      0.87     9554\n",
      "4           kettle       0.96    0.92      0.94     9928\n",
      "5        micro avg       0.91    0.86      0.88    47800\n",
      "6        macro avg       0.91    0.86      0.88    47800\n",
      "7     weighted avg       0.91    0.86      0.88    47800\n",
      "8      samples avg       0.92    0.88      0.89    47800\n",
      "-------------------------------------------------\n",
      "Fold 7 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.98      0.96    60539\n",
      "1  washing machine       0.56    0.83      0.67    49848\n",
      "2      dish washer       0.71    0.65      0.67    31498\n",
      "3        microwave       0.63    0.90      0.74    45078\n",
      "4           kettle       0.80    0.73      0.76    53030\n",
      "5        micro avg       0.72    0.84      0.77   239993\n",
      "6        macro avg       0.73    0.82      0.76   239993\n",
      "7     weighted avg       0.74    0.84      0.78   239993\n",
      "8      samples avg       0.68    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 8 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.84      0.89    11782\n",
      "1  washing machine       0.63    0.91      0.74     8527\n",
      "2      dish washer       0.93    0.60      0.73     8269\n",
      "3        microwave       0.87    0.80      0.83     9595\n",
      "4           kettle       0.94    0.89      0.92     9911\n",
      "5        micro avg       0.84    0.81      0.83    48084\n",
      "6        macro avg       0.86    0.81      0.82    48084\n",
      "7     weighted avg       0.87    0.81      0.83    48084\n",
      "8      samples avg       0.84    0.83      0.82    48084\n",
      "-------------------------------------------------\n",
      "Fold 8 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.96    0.98      0.97    60539\n",
      "1  washing machine       0.57    0.85      0.68    49848\n",
      "2      dish washer       0.90    0.57      0.70    31498\n",
      "3        microwave       0.62    0.91      0.74    45078\n",
      "4           kettle       0.78    0.78      0.78    53030\n",
      "5        micro avg       0.73    0.84      0.78   239993\n",
      "6        macro avg       0.77    0.82      0.77   239993\n",
      "7     weighted avg       0.77    0.84      0.79   239993\n",
      "8      samples avg       0.72    0.84      0.75   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 9 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.93      0.92    11834\n",
      "1  washing machine       0.91    0.80      0.85     8478\n",
      "2      dish washer       0.85    0.79      0.82     8188\n",
      "3        microwave       0.93    0.83      0.87     9619\n",
      "4           kettle       0.96    0.93      0.94    10086\n",
      "5        micro avg       0.91    0.86      0.89    48205\n",
      "6        macro avg       0.91    0.85      0.88    48205\n",
      "7     weighted avg       0.91    0.86      0.89    48205\n",
      "8      samples avg       0.92    0.88      0.89    48205\n",
      "-------------------------------------------------\n",
      "Fold 9 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.89      0.90    60539\n",
      "1  washing machine       0.57    0.81      0.67    49848\n",
      "2      dish washer       0.58    0.71      0.64    31498\n",
      "3        microwave       0.67    0.85      0.75    45078\n",
      "4           kettle       0.86    0.72      0.78    53030\n",
      "5        micro avg       0.72    0.81      0.76   239993\n",
      "6        macro avg       0.72    0.80      0.75   239993\n",
      "7     weighted avg       0.74    0.81      0.76   239993\n",
      "8      samples avg       0.69    0.78      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 10 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.93      0.92    11928\n",
      "1  washing machine       0.90    0.81      0.85     8376\n",
      "2      dish washer       0.87    0.79      0.82     8204\n",
      "3        microwave       0.88    0.86      0.87     9506\n",
      "4           kettle       0.95    0.92      0.94     9963\n",
      "5        micro avg       0.91    0.87      0.89    47977\n",
      "6        macro avg       0.90    0.86      0.88    47977\n",
      "7     weighted avg       0.91    0.87      0.89    47977\n",
      "8      samples avg       0.92    0.88      0.89    47977\n",
      "-------------------------------------------------\n",
      "Fold 10 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.99      0.95    60539\n",
      "1  washing machine       0.58    0.80      0.67    49848\n",
      "2      dish washer       0.67    0.65      0.66    31498\n",
      "3        microwave       0.65    0.91      0.76    45078\n",
      "4           kettle       0.78    0.77      0.78    53030\n",
      "5        micro avg       0.72    0.84      0.78   239993\n",
      "6        macro avg       0.72    0.82      0.76   239993\n",
      "7     weighted avg       0.74    0.84      0.78   239993\n",
      "8      samples avg       0.70    0.82      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 11 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.91      0.92    11776\n",
      "1  washing machine       0.92    0.82      0.87     8517\n",
      "2      dish washer       0.86    0.82      0.84     8190\n",
      "3        microwave       0.89    0.87      0.88     9613\n",
      "4           kettle       0.97    0.92      0.95     9969\n",
      "5        micro avg       0.92    0.88      0.90    48065\n",
      "6        macro avg       0.91    0.87      0.89    48065\n",
      "7     weighted avg       0.92    0.88      0.90    48065\n",
      "8      samples avg       0.93    0.89      0.90    48065\n",
      "-------------------------------------------------\n",
      "Fold 11 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.94      0.94    60539\n",
      "1  washing machine       0.57    0.81      0.67    49848\n",
      "2      dish washer       0.62    0.68      0.64    31498\n",
      "3        microwave       0.67    0.90      0.77    45078\n",
      "4           kettle       0.81    0.70      0.75    53030\n",
      "5        micro avg       0.72    0.82      0.76   239993\n",
      "6        macro avg       0.72    0.80      0.75   239993\n",
      "7     weighted avg       0.74    0.82      0.77   239993\n",
      "8      samples avg       0.68    0.79      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 12 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.93      0.93    11825\n",
      "1  washing machine       0.92    0.83      0.87     8448\n",
      "2      dish washer       0.89    0.81      0.85     8210\n",
      "3        microwave       0.91    0.88      0.89     9562\n",
      "4           kettle       0.96    0.94      0.95     9927\n",
      "5        micro avg       0.92    0.88      0.90    47972\n",
      "6        macro avg       0.92    0.88      0.90    47972\n",
      "7     weighted avg       0.92    0.88      0.90    47972\n",
      "8      samples avg       0.93    0.90      0.91    47972\n",
      "-------------------------------------------------\n",
      "Fold 12 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.98      0.96    60539\n",
      "1  washing machine       0.58    0.82      0.68    49848\n",
      "2      dish washer       0.75    0.60      0.66    31498\n",
      "3        microwave       0.64    0.91      0.75    45078\n",
      "4           kettle       0.79    0.75      0.77    53030\n",
      "5        micro avg       0.73    0.83      0.78   239993\n",
      "6        macro avg       0.74    0.81      0.76   239993\n",
      "7     weighted avg       0.75    0.83      0.78   239993\n",
      "8      samples avg       0.71    0.82      0.74   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 13 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.94      0.92    11762\n",
      "1  washing machine       0.89    0.85      0.87     8396\n",
      "2      dish washer       0.83    0.86      0.84     8248\n",
      "3        microwave       0.91    0.86      0.88     9477\n",
      "4           kettle       0.94    0.94      0.94    10024\n",
      "5        micro avg       0.90    0.89      0.89    47907\n",
      "6        macro avg       0.89    0.89      0.89    47907\n",
      "7     weighted avg       0.90    0.89      0.89    47907\n",
      "8      samples avg       0.91    0.91      0.90    47907\n",
      "-------------------------------------------------\n",
      "Fold 13 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.88    0.96      0.92    60539\n",
      "1  washing machine       0.57    0.85      0.68    49848\n",
      "2      dish washer       0.61    0.70      0.65    31498\n",
      "3        microwave       0.65    0.88      0.74    45078\n",
      "4           kettle       0.66    0.83      0.74    53030\n",
      "5        micro avg       0.68    0.86      0.76   239993\n",
      "6        macro avg       0.67    0.84      0.75   239993\n",
      "7     weighted avg       0.69    0.86      0.76   239993\n",
      "8      samples avg       0.65    0.84      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 14 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.93      0.93    11786\n",
      "1  washing machine       0.93    0.82      0.87     8379\n",
      "2      dish washer       0.86    0.85      0.86     8269\n",
      "3        microwave       0.91    0.86      0.89     9574\n",
      "4           kettle       0.98    0.92      0.95     9978\n",
      "5        micro avg       0.92    0.88      0.90    47986\n",
      "6        macro avg       0.92    0.87      0.90    47986\n",
      "7     weighted avg       0.92    0.88      0.90    47986\n",
      "8      samples avg       0.93    0.90      0.90    47986\n",
      "-------------------------------------------------\n",
      "Fold 14 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.99      0.96    60539\n",
      "1  washing machine       0.57    0.78      0.66    49848\n",
      "2      dish washer       0.59    0.70      0.64    31498\n",
      "3        microwave       0.66    0.90      0.76    45078\n",
      "4           kettle       0.85    0.67      0.75    53030\n",
      "5        micro avg       0.72    0.82      0.77   239993\n",
      "6        macro avg       0.72    0.81      0.75   239993\n",
      "7     weighted avg       0.74    0.82      0.77   239993\n",
      "8      samples avg       0.69    0.80      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 15 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.92      0.93    11893\n",
      "1  washing machine       0.91    0.84      0.88     8424\n",
      "2      dish washer       0.86    0.86      0.86     8205\n",
      "3        microwave       0.90    0.88      0.89     9590\n",
      "4           kettle       0.97    0.93      0.95     9958\n",
      "5        micro avg       0.92    0.89      0.90    48070\n",
      "6        macro avg       0.91    0.89      0.90    48070\n",
      "7     weighted avg       0.92    0.89      0.90    48070\n",
      "8      samples avg       0.93    0.91      0.91    48070\n",
      "-------------------------------------------------\n",
      "Fold 15 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.99      0.96    60539\n",
      "1  washing machine       0.59    0.80      0.68    49848\n",
      "2      dish washer       0.60    0.71      0.65    31498\n",
      "3        microwave       0.63    0.93      0.75    45078\n",
      "4           kettle       0.85    0.69      0.76    53030\n",
      "5        micro avg       0.72    0.84      0.77   239993\n",
      "6        macro avg       0.72    0.82      0.76   239993\n",
      "7     weighted avg       0.74    0.84      0.78   239993\n",
      "8      samples avg       0.69    0.82      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 16 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.92      0.92    11865\n",
      "1  washing machine       0.92    0.84      0.88     8506\n",
      "2      dish washer       0.90    0.80      0.85     8222\n",
      "3        microwave       0.91    0.87      0.89     9541\n",
      "4           kettle       0.96    0.94      0.95     9954\n",
      "5        micro avg       0.93    0.88      0.90    48088\n",
      "6        macro avg       0.92    0.88      0.90    48088\n",
      "7     weighted avg       0.92    0.88      0.90    48088\n",
      "8      samples avg       0.93    0.90      0.91    48088\n",
      "-------------------------------------------------\n",
      "Fold 16 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.96      0.94    60539\n",
      "1  washing machine       0.57    0.81      0.67    49848\n",
      "2      dish washer       0.67    0.67      0.67    31498\n",
      "3        microwave       0.66    0.90      0.76    45078\n",
      "4           kettle       0.86    0.71      0.78    53030\n",
      "5        micro avg       0.73    0.82      0.77   239993\n",
      "6        macro avg       0.74    0.81      0.76   239993\n",
      "7     weighted avg       0.75    0.82      0.78   239993\n",
      "8      samples avg       0.70    0.80      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 17 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.76      0.84    11794\n",
      "1  washing machine       0.54    0.89      0.67     8394\n",
      "2      dish washer       0.85    0.57      0.68     8120\n",
      "3        microwave       0.86    0.60      0.71     9589\n",
      "4           kettle       0.95    0.82      0.88     9895\n",
      "5        micro avg       0.79    0.73      0.76    47792\n",
      "6        macro avg       0.83    0.73      0.76    47792\n",
      "7     weighted avg       0.84    0.73      0.77    47792\n",
      "8      samples avg       0.77    0.73      0.72    47792\n",
      "-------------------------------------------------\n",
      "Fold 17 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.96    0.96      0.96    60539\n",
      "1  washing machine       0.61    0.76      0.68    49848\n",
      "2      dish washer       0.62    0.65      0.63    31498\n",
      "3        microwave       0.56    0.95      0.70    45078\n",
      "4           kettle       0.88    0.70      0.78    53030\n",
      "5        micro avg       0.72    0.82      0.76   239993\n",
      "6        macro avg       0.73    0.80      0.75   239993\n",
      "7     weighted avg       0.75    0.82      0.77   239993\n",
      "8      samples avg       0.72    0.82      0.74   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 18 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.84      0.87    11818\n",
      "1  washing machine       0.52    0.92      0.67     8432\n",
      "2      dish washer       0.86    0.58      0.69     8328\n",
      "3        microwave       0.91    0.54      0.68     9480\n",
      "4           kettle       0.96    0.84      0.90     9933\n",
      "5        micro avg       0.79    0.75      0.77    47991\n",
      "6        macro avg       0.83    0.74      0.76    47991\n",
      "7     weighted avg       0.84    0.75      0.77    47991\n",
      "8      samples avg       0.77    0.75      0.73    47991\n",
      "-------------------------------------------------\n",
      "Fold 18 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.99      0.95    60539\n",
      "1  washing machine       0.64    0.79      0.71    49848\n",
      "2      dish washer       0.60    0.68      0.64    31498\n",
      "3        microwave       0.69    0.83      0.75    45078\n",
      "4           kettle       0.84    0.71      0.77    53030\n",
      "5        micro avg       0.75    0.82      0.78   239993\n",
      "6        macro avg       0.74    0.80      0.76   239993\n",
      "7     weighted avg       0.76    0.82      0.78   239993\n",
      "8      samples avg       0.75    0.82      0.76   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 19 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.92      0.93    11787\n",
      "1  washing machine       0.90    0.86      0.88     8464\n",
      "2      dish washer       0.88    0.82      0.85     8235\n",
      "3        microwave       0.92    0.86      0.89     9610\n",
      "4           kettle       0.97    0.93      0.95     9992\n",
      "5        micro avg       0.92    0.88      0.90    48088\n",
      "6        macro avg       0.92    0.88      0.90    48088\n",
      "7     weighted avg       0.92    0.88      0.90    48088\n",
      "8      samples avg       0.93    0.90      0.91    48088\n",
      "-------------------------------------------------\n",
      "Fold 19 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.96      0.95    60539\n",
      "1  washing machine       0.57    0.84      0.68    49848\n",
      "2      dish washer       0.53    0.73      0.61    31498\n",
      "3        microwave       0.68    0.83      0.75    45078\n",
      "4           kettle       0.73    0.76      0.74    53030\n",
      "5        micro avg       0.69    0.84      0.76   239993\n",
      "6        macro avg       0.69    0.82      0.75   239993\n",
      "7     weighted avg       0.71    0.84      0.77   239993\n",
      "8      samples avg       0.67    0.82      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 20 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.92      0.93    11778\n",
      "1  washing machine       0.91    0.84      0.87     8368\n",
      "2      dish washer       0.85    0.84      0.85     8217\n",
      "3        microwave       0.91    0.87      0.89     9596\n",
      "4           kettle       0.95    0.93      0.94    10082\n",
      "5        micro avg       0.91    0.89      0.90    48041\n",
      "6        macro avg       0.91    0.88      0.90    48041\n",
      "7     weighted avg       0.91    0.89      0.90    48041\n",
      "8      samples avg       0.93    0.90      0.90    48041\n",
      "-------------------------------------------------\n",
      "Fold 20 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.97      0.95    60539\n",
      "1  washing machine       0.57    0.82      0.67    49848\n",
      "2      dish washer       0.55    0.72      0.62    31498\n",
      "3        microwave       0.65    0.86      0.74    45078\n",
      "4           kettle       0.76    0.77      0.77    53030\n",
      "5        micro avg       0.70    0.84      0.76   239993\n",
      "6        macro avg       0.69    0.83      0.75   239993\n",
      "7     weighted avg       0.71    0.84      0.77   239993\n",
      "8      samples avg       0.67    0.82      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 21 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.86    0.90      0.88    11890\n",
      "1  washing machine       0.90    0.72      0.80     8479\n",
      "2      dish washer       0.88    0.58      0.70     8116\n",
      "3        microwave       0.55    0.93      0.69     9604\n",
      "4           kettle       0.96    0.77      0.85    10055\n",
      "5        micro avg       0.78    0.79      0.79    48144\n",
      "6        macro avg       0.83    0.78      0.78    48144\n",
      "7     weighted avg       0.83    0.79      0.79    48144\n",
      "8      samples avg       0.77    0.80      0.76    48144\n",
      "-------------------------------------------------\n",
      "Fold 21 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.99      0.95    60539\n",
      "1  washing machine       0.71    0.61      0.66    49848\n",
      "2      dish washer       0.57    0.70      0.63    31498\n",
      "3        microwave       0.58    0.91      0.71    45078\n",
      "4           kettle       0.94    0.53      0.68    53030\n",
      "5        micro avg       0.73    0.76      0.75   239993\n",
      "6        macro avg       0.74    0.75      0.72   239993\n",
      "7     weighted avg       0.77    0.76      0.74   239993\n",
      "8      samples avg       0.73    0.75      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 22 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.92      0.93    11862\n",
      "1  washing machine       0.88    0.89      0.89     8406\n",
      "2      dish washer       0.89    0.83      0.86     8269\n",
      "3        microwave       0.93    0.86      0.89     9586\n",
      "4           kettle       0.96    0.94      0.95     9876\n",
      "5        micro avg       0.92    0.89      0.91    47999\n",
      "6        macro avg       0.92    0.89      0.90    47999\n",
      "7     weighted avg       0.92    0.89      0.91    47999\n",
      "8      samples avg       0.93    0.91      0.91    47999\n",
      "-------------------------------------------------\n",
      "Fold 22 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.98      0.95    60539\n",
      "1  washing machine       0.57    0.87      0.68    49848\n",
      "2      dish washer       0.63    0.67      0.65    31498\n",
      "3        microwave       0.67    0.85      0.75    45078\n",
      "4           kettle       0.80    0.72      0.76    53030\n",
      "5        micro avg       0.72    0.84      0.77   239993\n",
      "6        macro avg       0.72    0.82      0.76   239993\n",
      "7     weighted avg       0.73    0.84      0.78   239993\n",
      "8      samples avg       0.69    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 23 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.91      0.93    11732\n",
      "1  washing machine       0.91    0.85      0.88     8519\n",
      "2      dish washer       0.90    0.84      0.87     8304\n",
      "3        microwave       0.91    0.87      0.89     9582\n",
      "4           kettle       0.95    0.94      0.95     9995\n",
      "5        micro avg       0.92    0.89      0.91    48132\n",
      "6        macro avg       0.92    0.88      0.90    48132\n",
      "7     weighted avg       0.92    0.89      0.91    48132\n",
      "8      samples avg       0.94    0.90      0.91    48132\n",
      "-------------------------------------------------\n",
      "Fold 23 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.98      0.96    60539\n",
      "1  washing machine       0.57    0.83      0.67    49848\n",
      "2      dish washer       0.76    0.62      0.68    31498\n",
      "3        microwave       0.64    0.92      0.75    45078\n",
      "4           kettle       0.75    0.78      0.76    53030\n",
      "5        micro avg       0.72    0.85      0.78   239993\n",
      "6        macro avg       0.73    0.82      0.77   239993\n",
      "7     weighted avg       0.74    0.85      0.78   239993\n",
      "8      samples avg       0.69    0.83      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 24 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.86      0.89    11836\n",
      "1  washing machine       0.78    0.85      0.81     8450\n",
      "2      dish washer       0.88    0.62      0.73     8204\n",
      "3        microwave       0.92    0.72      0.80     9561\n",
      "4           kettle       0.97    0.87      0.92     9908\n",
      "5        micro avg       0.90    0.79      0.84    47959\n",
      "6        macro avg       0.89    0.78      0.83    47959\n",
      "7     weighted avg       0.90    0.79      0.84    47959\n",
      "8      samples avg       0.89    0.80      0.83    47959\n",
      "-------------------------------------------------\n",
      "Fold 24 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.99      0.96    60539\n",
      "1  washing machine       0.60    0.82      0.69    49848\n",
      "2      dish washer       0.67    0.65      0.66    31498\n",
      "3        microwave       0.59    0.95      0.73    45078\n",
      "4           kettle       0.95    0.65      0.77    53030\n",
      "5        micro avg       0.73    0.83      0.77   239993\n",
      "6        macro avg       0.75    0.81      0.76   239993\n",
      "7     weighted avg       0.77    0.83      0.78   239993\n",
      "8      samples avg       0.72    0.82      0.74   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 25 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.93      0.92    11722\n",
      "1  washing machine       0.90    0.85      0.88     8310\n",
      "2      dish washer       0.86    0.87      0.86     8229\n",
      "3        microwave       0.92    0.86      0.89     9483\n",
      "4           kettle       0.97    0.93      0.95    10022\n",
      "5        micro avg       0.92    0.89      0.90    47766\n",
      "6        macro avg       0.91    0.89      0.90    47766\n",
      "7     weighted avg       0.92    0.89      0.90    47766\n",
      "8      samples avg       0.93    0.91      0.91    47766\n",
      "-------------------------------------------------\n",
      "Fold 25 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.98      0.94    60539\n",
      "1  washing machine       0.57    0.83      0.68    49848\n",
      "2      dish washer       0.60    0.70      0.64    31498\n",
      "3        microwave       0.64    0.91      0.75    45078\n",
      "4           kettle       0.85    0.70      0.77    53030\n",
      "5        micro avg       0.71    0.84      0.77   239993\n",
      "6        macro avg       0.71    0.82      0.76   239993\n",
      "7     weighted avg       0.73    0.84      0.77   239993\n",
      "8      samples avg       0.68    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 26 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.92      0.93    11834\n",
      "1  washing machine       0.89    0.88      0.89     8486\n",
      "2      dish washer       0.86    0.87      0.86     8217\n",
      "3        microwave       0.94    0.86      0.90     9608\n",
      "4           kettle       0.96    0.94      0.95     9991\n",
      "5        micro avg       0.92    0.90      0.91    48136\n",
      "6        macro avg       0.92    0.89      0.90    48136\n",
      "7     weighted avg       0.92    0.90      0.91    48136\n",
      "8      samples avg       0.93    0.91      0.91    48136\n",
      "-------------------------------------------------\n",
      "Fold 26 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.97      0.94    60539\n",
      "1  washing machine       0.57    0.82      0.67    49848\n",
      "2      dish washer       0.54    0.74      0.62    31498\n",
      "3        microwave       0.67    0.89      0.77    45078\n",
      "4           kettle       0.78    0.74      0.76    53030\n",
      "5        micro avg       0.70    0.84      0.76   239993\n",
      "6        macro avg       0.70    0.83      0.75   239993\n",
      "7     weighted avg       0.72    0.84      0.77   239993\n",
      "8      samples avg       0.67    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 27 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.92      0.93    11760\n",
      "1  washing machine       0.88    0.88      0.88     8511\n",
      "2      dish washer       0.88    0.85      0.86     8235\n",
      "3        microwave       0.90    0.87      0.89     9475\n",
      "4           kettle       0.98    0.92      0.95     9937\n",
      "5        micro avg       0.92    0.89      0.91    47918\n",
      "6        macro avg       0.92    0.89      0.90    47918\n",
      "7     weighted avg       0.92    0.89      0.91    47918\n",
      "8      samples avg       0.93    0.91      0.91    47918\n",
      "-------------------------------------------------\n",
      "Fold 27 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.98      0.94    60539\n",
      "1  washing machine       0.57    0.86      0.69    49848\n",
      "2      dish washer       0.57    0.69      0.63    31498\n",
      "3        microwave       0.66    0.90      0.76    45078\n",
      "4           kettle       0.83    0.65      0.73    53030\n",
      "5        micro avg       0.71    0.83      0.76   239993\n",
      "6        macro avg       0.71    0.82      0.75   239993\n",
      "7     weighted avg       0.73    0.83      0.77   239993\n",
      "8      samples avg       0.68    0.81      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 28 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.93      0.92    11821\n",
      "1  washing machine       0.91    0.85      0.88     8312\n",
      "2      dish washer       0.88    0.83      0.85     8213\n",
      "3        microwave       0.91    0.87      0.89     9643\n",
      "4           kettle       0.97    0.93      0.95     9999\n",
      "5        micro avg       0.92    0.89      0.90    47988\n",
      "6        macro avg       0.92    0.88      0.90    47988\n",
      "7     weighted avg       0.92    0.89      0.90    47988\n",
      "8      samples avg       0.93    0.90      0.91    47988\n",
      "-------------------------------------------------\n",
      "Fold 28 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.99      0.95    60539\n",
      "1  washing machine       0.57    0.80      0.67    49848\n",
      "2      dish washer       0.61    0.68      0.64    31498\n",
      "3        microwave       0.64    0.92      0.76    45078\n",
      "4           kettle       0.81    0.64      0.71    53030\n",
      "5        micro avg       0.71    0.82      0.76   239993\n",
      "6        macro avg       0.71    0.80      0.74   239993\n",
      "7     weighted avg       0.73    0.82      0.76   239993\n",
      "8      samples avg       0.67    0.79      0.70   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 29 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.92      0.93    11744\n",
      "1  washing machine       0.89    0.87      0.88     8430\n",
      "2      dish washer       0.89    0.83      0.86     8249\n",
      "3        microwave       0.90    0.88      0.89     9546\n",
      "4           kettle       0.96    0.94      0.95     9980\n",
      "5        micro avg       0.92    0.89      0.90    47949\n",
      "6        macro avg       0.91    0.89      0.90    47949\n",
      "7     weighted avg       0.92    0.89      0.90    47949\n",
      "8      samples avg       0.93    0.91      0.91    47949\n",
      "-------------------------------------------------\n",
      "Fold 29 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.98      0.95    60539\n",
      "1  washing machine       0.57    0.84      0.68    49848\n",
      "2      dish washer       0.68    0.64      0.66    31498\n",
      "3        microwave       0.63    0.90      0.74    45078\n",
      "4           kettle       0.79    0.73      0.76    53030\n",
      "5        micro avg       0.71    0.84      0.77   239993\n",
      "6        macro avg       0.72    0.82      0.76   239993\n",
      "7     weighted avg       0.73    0.84      0.77   239993\n",
      "8      samples avg       0.69    0.82      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 30 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.91      0.93    11883\n",
      "1  washing machine       0.90    0.86      0.88     8425\n",
      "2      dish washer       0.88    0.82      0.85     8208\n",
      "3        microwave       0.92    0.85      0.89     9544\n",
      "4           kettle       0.96    0.93      0.95     9949\n",
      "5        micro avg       0.92    0.88      0.90    48009\n",
      "6        macro avg       0.92    0.88      0.90    48009\n",
      "7     weighted avg       0.92    0.88      0.90    48009\n",
      "8      samples avg       0.94    0.90      0.91    48009\n",
      "-------------------------------------------------\n",
      "Fold 30 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.98      0.96    60539\n",
      "1  washing machine       0.57    0.85      0.68    49848\n",
      "2      dish washer       0.70    0.64      0.67    31498\n",
      "3        microwave       0.70    0.89      0.78    45078\n",
      "4           kettle       0.89    0.68      0.77    53030\n",
      "5        micro avg       0.75    0.83      0.78   239993\n",
      "6        macro avg       0.76    0.81      0.77   239993\n",
      "7     weighted avg       0.77    0.83      0.79   239993\n",
      "8      samples avg       0.72    0.81      0.74   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Using koef 1.3\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 86s 118ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 57s 96ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 57s 96ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 57s 95ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 57s 95ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 57s 96ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 57s 96ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 57s 96ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 57s 96ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 57s 96ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 57s 96ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 57s 95ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 57s 95ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 57s 96ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 57s 96ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 57s 96ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 57s 95ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 57s 96ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 57s 96ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.1036e-04\n",
      "600/600 [==============================] - 6s 9ms/step\n",
      "3000/3000 [==============================] - 27s 9ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 61s 97ms/step - loss: inf - F1Score: 0.6174 - WeightedF1: 0.6576 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 58s 97ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 57s 96ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 57s 96ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 57s 96ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 57s 96ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 57s 96ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 57s 95ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 57s 95ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 57s 96ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 57s 96ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 57s 95ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 57s 96ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 57s 96ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 57s 96ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 57s 96ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 57s 95ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.1036e-04\n",
      "600/600 [==============================] - 6s 9ms/step\n",
      "3000/3000 [==============================] - 27s 9ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 60s 96ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 57s 95ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 57s 95ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 57s 95ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 57s 95ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 57s 96ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 57s 96ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 57s 96ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 57s 96ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 57s 96ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 57s 95ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 57s 96ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 57s 95ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 57s 96ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 57s 95ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 57s 96ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 57s 95ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 57s 95ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.1036e-04\n",
      "600/600 [==============================] - 6s 9ms/step\n",
      "3000/3000 [==============================] - 27s 9ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 74s 118ms/step - loss: inf - F1Score: 0.6247 - WeightedF1: 0.6658 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 59s 98ms/step - loss: inf - F1Score: 0.7106 - WeightedF1: 0.7434 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 58s 97ms/step - loss: inf - F1Score: 0.7381 - WeightedF1: 0.7660 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 58s 97ms/step - loss: inf - F1Score: 0.7585 - WeightedF1: 0.7831 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 59s 98ms/step - loss: inf - F1Score: 0.7962 - WeightedF1: 0.8143 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 59s 98ms/step - loss: inf - F1Score: 0.8345 - WeightedF1: 0.8505 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 59s 98ms/step - loss: inf - F1Score: 0.8636 - WeightedF1: 0.8782 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 59s 98ms/step - loss: inf - F1Score: 0.8780 - WeightedF1: 0.8917 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 59s 98ms/step - loss: inf - F1Score: 0.8891 - WeightedF1: 0.9017 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 59s 98ms/step - loss: inf - F1Score: 0.9007 - WeightedF1: 0.9118 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 59s 98ms/step - loss: inf - F1Score: 0.9084 - WeightedF1: 0.9188 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 58s 97ms/step - loss: inf - F1Score: 0.9139 - WeightedF1: 0.9237 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 59s 98ms/step - loss: inf - F1Score: 0.9197 - WeightedF1: 0.9289 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 58s 97ms/step - loss: inf - F1Score: 0.9239 - WeightedF1: 0.9327 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 59s 98ms/step - loss: inf - F1Score: 0.9276 - WeightedF1: 0.9360 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 59s 98ms/step - loss: inf - F1Score: 0.9316 - WeightedF1: 0.9396 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 58s 97ms/step - loss: inf - F1Score: 0.9344 - WeightedF1: 0.9423 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 58s 97ms/step - loss: inf - F1Score: 0.9369 - WeightedF1: 0.9445 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 58s 97ms/step - loss: inf - F1Score: 0.9400 - WeightedF1: 0.9474 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 58s 97ms/step - loss: inf - F1Score: 0.9429 - WeightedF1: 0.9500 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 7s 10ms/step\n",
      "3000/3000 [==============================] - 27s 9ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 61s 97ms/step - loss: inf - F1Score: 0.6337 - WeightedF1: 0.6727 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 58s 97ms/step - loss: inf - F1Score: 0.7457 - WeightedF1: 0.7719 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 58s 97ms/step - loss: inf - F1Score: 0.7634 - WeightedF1: 0.7822 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.7411 - WeightedF1: 0.7611 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.7410 - WeightedF1: 0.7611 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.7410 - WeightedF1: 0.7610 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.7412 - WeightedF1: 0.7612 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 57s 96ms/step - loss: inf - F1Score: 0.7411 - WeightedF1: 0.7611 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.7412 - WeightedF1: 0.7612 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.7412 - WeightedF1: 0.7612 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.7411 - WeightedF1: 0.7611 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.7412 - WeightedF1: 0.7612 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 57s 96ms/step - loss: inf - F1Score: 0.7412 - WeightedF1: 0.7612 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 57s 96ms/step - loss: inf - F1Score: 0.7409 - WeightedF1: 0.7610 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 57s 96ms/step - loss: inf - F1Score: 0.7411 - WeightedF1: 0.7611 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 57s 96ms/step - loss: inf - F1Score: 0.7412 - WeightedF1: 0.7612 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 57s 96ms/step - loss: inf - F1Score: 0.7412 - WeightedF1: 0.7612 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.7412 - WeightedF1: 0.7612 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 57s 95ms/step - loss: inf - F1Score: 0.7415 - WeightedF1: 0.7614 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 57s 96ms/step - loss: inf - F1Score: 0.7412 - WeightedF1: 0.7612 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 6s 9ms/step\n",
      "3000/3000 [==============================] - 27s 9ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 61s 96ms/step - loss: inf - F1Score: 0.6095 - WeightedF1: 0.6258 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.7187 - WeightedF1: 0.7297 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.7773 - WeightedF1: 0.7854 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.8049 - WeightedF1: 0.8123 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.8239 - WeightedF1: 0.8308 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 57s 96ms/step - loss: inf - F1Score: 0.8406 - WeightedF1: 0.8470 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.8550 - WeightedF1: 0.8606 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.8642 - WeightedF1: 0.8693 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.8725 - WeightedF1: 0.8773 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 57s 96ms/step - loss: inf - F1Score: 0.8813 - WeightedF1: 0.8855 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.8918 - WeightedF1: 0.8955 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 57s 96ms/step - loss: inf - F1Score: 0.8991 - WeightedF1: 0.9024 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.9072 - WeightedF1: 0.9102 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.9142 - WeightedF1: 0.9169 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.9217 - WeightedF1: 0.9240 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.9279 - WeightedF1: 0.9301 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 57s 96ms/step - loss: inf - F1Score: 0.9345 - WeightedF1: 0.9364 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.9408 - WeightedF1: 0.9423 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.9468 - WeightedF1: 0.9482 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.9532 - WeightedF1: 0.9544 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 6s 9ms/step\n",
      "3000/3000 [==============================] - 29s 9ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 60s 96ms/step - loss: inf - F1Score: 0.6086 - WeightedF1: 0.6247 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.7363 - WeightedF1: 0.7466 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.7826 - WeightedF1: 0.7907 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.8156 - WeightedF1: 0.8228 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.8355 - WeightedF1: 0.8419 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 58s 97ms/step - loss: inf - F1Score: 0.8483 - WeightedF1: 0.8542 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.8599 - WeightedF1: 0.8653 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.8681 - WeightedF1: 0.8732 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 58s 97ms/step - loss: inf - F1Score: 0.8762 - WeightedF1: 0.8808 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.8847 - WeightedF1: 0.8888 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 58s 97ms/step - loss: inf - F1Score: 0.8941 - WeightedF1: 0.8978 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 58s 97ms/step - loss: inf - F1Score: 0.9019 - WeightedF1: 0.9053 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.9093 - WeightedF1: 0.9124 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 58s 97ms/step - loss: inf - F1Score: 0.9165 - WeightedF1: 0.9192 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 58s 97ms/step - loss: inf - F1Score: 0.9237 - WeightedF1: 0.9261 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.9303 - WeightedF1: 0.9324 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 58s 97ms/step - loss: inf - F1Score: 0.9368 - WeightedF1: 0.9386 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 58s 97ms/step - loss: inf - F1Score: 0.9427 - WeightedF1: 0.9443 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 58s 97ms/step - loss: inf - F1Score: 0.9491 - WeightedF1: 0.9504 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 58s 97ms/step - loss: inf - F1Score: 0.9558 - WeightedF1: 0.9568 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 6s 9ms/step\n",
      "3000/3000 [==============================] - 28s 9ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 60s 96ms/step - loss: inf - F1Score: 0.6123 - WeightedF1: 0.6283 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 58s 97ms/step - loss: inf - F1Score: 0.7270 - WeightedF1: 0.7380 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 58s 97ms/step - loss: inf - F1Score: 0.7620 - WeightedF1: 0.7711 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.7960 - WeightedF1: 0.8042 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 58s 97ms/step - loss: inf - F1Score: 0.8207 - WeightedF1: 0.8278 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.8369 - WeightedF1: 0.8434 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 58s 97ms/step - loss: inf - F1Score: 0.8524 - WeightedF1: 0.8583 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.8637 - WeightedF1: 0.8690 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 58s 97ms/step - loss: inf - F1Score: 0.8742 - WeightedF1: 0.8790 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.8829 - WeightedF1: 0.8873 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.8925 - WeightedF1: 0.8963 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.9009 - WeightedF1: 0.9044 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.9094 - WeightedF1: 0.9125 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.9166 - WeightedF1: 0.9194 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 58s 97ms/step - loss: inf - F1Score: 0.9242 - WeightedF1: 0.9267 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 58s 97ms/step - loss: inf - F1Score: 0.9312 - WeightedF1: 0.9333 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.9377 - WeightedF1: 0.9395 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 58s 97ms/step - loss: inf - F1Score: 0.9438 - WeightedF1: 0.9454 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 58s 97ms/step - loss: inf - F1Score: 0.9504 - WeightedF1: 0.9517 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 58s 97ms/step - loss: inf - F1Score: 0.9557 - WeightedF1: 0.9569 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 6s 9ms/step\n",
      "3000/3000 [==============================] - 28s 9ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 59s 95ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.6566 - WeightedF1: 0.6715 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.7284 - WeightedF1: 0.7393 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.7754 - WeightedF1: 0.7836 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.7998 - WeightedF1: 0.8074 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.8189 - WeightedF1: 0.8258 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 57s 96ms/step - loss: inf - F1Score: 0.8326 - WeightedF1: 0.8390 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 57s 96ms/step - loss: inf - F1Score: 0.8449 - WeightedF1: 0.8507 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.8549 - WeightedF1: 0.8604 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 57s 96ms/step - loss: inf - F1Score: 0.8624 - WeightedF1: 0.8676 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.8712 - WeightedF1: 0.8760 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.8800 - WeightedF1: 0.8843 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.8868 - WeightedF1: 0.8908 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.8945 - WeightedF1: 0.8981 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.9013 - WeightedF1: 0.9047 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.9081 - WeightedF1: 0.9111 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 57s 96ms/step - loss: inf - F1Score: 0.9141 - WeightedF1: 0.9169 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.9198 - WeightedF1: 0.9224 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.9260 - WeightedF1: 0.9283 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.9317 - WeightedF1: 0.9338 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 6s 9ms/step\n",
      "3000/3000 [==============================] - 28s 9ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 60s 96ms/step - loss: inf - F1Score: 0.5978 - WeightedF1: 0.6146 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.7165 - WeightedF1: 0.7284 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.7679 - WeightedF1: 0.7766 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.8018 - WeightedF1: 0.8093 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.8251 - WeightedF1: 0.8321 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.8418 - WeightedF1: 0.8481 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.8524 - WeightedF1: 0.8582 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.8619 - WeightedF1: 0.8672 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.8711 - WeightedF1: 0.8760 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.8784 - WeightedF1: 0.8829 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.8878 - WeightedF1: 0.8919 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.8956 - WeightedF1: 0.8994 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.9030 - WeightedF1: 0.9064 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.9112 - WeightedF1: 0.9143 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.9182 - WeightedF1: 0.9210 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.9247 - WeightedF1: 0.9272 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.9311 - WeightedF1: 0.9333 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.9386 - WeightedF1: 0.9404 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.9449 - WeightedF1: 0.9464 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 58s 96ms/step - loss: inf - F1Score: 0.9510 - WeightedF1: 0.9525 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 6s 9ms/step\n",
      "3000/3000 [==============================] - 28s 9ms/step\n",
      "Fold 1 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.87    0.92      0.89    11706\n",
      "1  washing machine       0.90    0.75      0.82     8507\n",
      "2      dish washer       0.83    0.73      0.78     8309\n",
      "3        microwave       0.88    0.82      0.85     9549\n",
      "4           kettle       0.96    0.89      0.92     9949\n",
      "5        micro avg       0.89    0.83      0.86    48020\n",
      "6        macro avg       0.89    0.82      0.85    48020\n",
      "7     weighted avg       0.89    0.83      0.86    48020\n",
      "8      samples avg       0.89    0.84      0.85    48020\n",
      "-------------------------------------------------\n",
      "Fold 1 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.99      0.96    60539\n",
      "1  washing machine       0.74    0.55      0.63    49848\n",
      "2      dish washer       0.55    0.73      0.63    31498\n",
      "3        microwave       0.63    0.93      0.75    45078\n",
      "4           kettle       0.73    0.82      0.77    53030\n",
      "5        micro avg       0.72    0.82      0.77   239993\n",
      "6        macro avg       0.71    0.81      0.75   239993\n",
      "7     weighted avg       0.74    0.82      0.77   239993\n",
      "8      samples avg       0.71    0.80      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 2 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.89    0.90      0.90    11903\n",
      "1  washing machine       0.88    0.76      0.82     8383\n",
      "2      dish washer       0.81    0.77      0.79     8279\n",
      "3        microwave       0.86    0.82      0.84     9584\n",
      "4           kettle       0.95    0.91      0.93     9899\n",
      "5        micro avg       0.88    0.84      0.86    48048\n",
      "6        macro avg       0.88    0.83      0.85    48048\n",
      "7     weighted avg       0.88    0.84      0.86    48048\n",
      "8      samples avg       0.89    0.85      0.86    48048\n",
      "-------------------------------------------------\n",
      "Fold 2 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.99      0.96    60539\n",
      "1  washing machine       0.62    0.69      0.66    49848\n",
      "2      dish washer       0.51    0.76      0.61    31498\n",
      "3        microwave       0.62    0.95      0.75    45078\n",
      "4           kettle       0.83    0.74      0.79    53030\n",
      "5        micro avg       0.71    0.83      0.77   239993\n",
      "6        macro avg       0.70    0.83      0.75   239993\n",
      "7     weighted avg       0.73    0.83      0.77   239993\n",
      "8      samples avg       0.69    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 3 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.85    0.92      0.88    11755\n",
      "1  washing machine       0.91    0.74      0.82     8482\n",
      "2      dish washer       0.82    0.71      0.76     8145\n",
      "3        microwave       0.88    0.73      0.80     9633\n",
      "4           kettle       0.95    0.90      0.92     9989\n",
      "5        micro avg       0.88    0.81      0.84    48004\n",
      "6        macro avg       0.88    0.80      0.84    48004\n",
      "7     weighted avg       0.88    0.81      0.84    48004\n",
      "8      samples avg       0.89    0.82      0.84    48004\n",
      "-------------------------------------------------\n",
      "Fold 3 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.98      0.94    60539\n",
      "1  washing machine       0.61    0.72      0.66    49848\n",
      "2      dish washer       0.62    0.68      0.65    31498\n",
      "3        microwave       0.66    0.85      0.74    45078\n",
      "4           kettle       0.77    0.76      0.77    53030\n",
      "5        micro avg       0.72    0.82      0.77   239993\n",
      "6        macro avg       0.71    0.80      0.75   239993\n",
      "7     weighted avg       0.73    0.82      0.77   239993\n",
      "8      samples avg       0.69    0.80      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 4 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.88    0.90      0.89    11880\n",
      "1  washing machine       0.90    0.75      0.82     8396\n",
      "2      dish washer       0.85    0.68      0.75     8215\n",
      "3        microwave       0.88    0.73      0.80     9566\n",
      "4           kettle       0.95    0.90      0.92    10018\n",
      "5        micro avg       0.89    0.80      0.85    48075\n",
      "6        macro avg       0.89    0.79      0.84    48075\n",
      "7     weighted avg       0.89    0.80      0.84    48075\n",
      "8      samples avg       0.90    0.82      0.84    48075\n",
      "-------------------------------------------------\n",
      "Fold 4 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.99      0.96    60539\n",
      "1  washing machine       0.59    0.75      0.66    49848\n",
      "2      dish washer       0.75    0.62      0.68    31498\n",
      "3        microwave       0.59    0.92      0.72    45078\n",
      "4           kettle       0.91    0.71      0.80    53030\n",
      "5        micro avg       0.74    0.82      0.78   239993\n",
      "6        macro avg       0.76    0.80      0.76   239993\n",
      "7     weighted avg       0.77    0.82      0.78   239993\n",
      "8      samples avg       0.72    0.81      0.74   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 5 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.88    0.90      0.89    11798\n",
      "1  washing machine       0.91    0.73      0.81     8396\n",
      "2      dish washer       0.84    0.69      0.75     8174\n",
      "3        microwave       0.85    0.79      0.82     9484\n",
      "4           kettle       0.96    0.87      0.91    10001\n",
      "5        micro avg       0.89    0.81      0.84    47853\n",
      "6        macro avg       0.89    0.79      0.84    47853\n",
      "7     weighted avg       0.89    0.81      0.84    47853\n",
      "8      samples avg       0.89    0.82      0.84    47853\n",
      "-------------------------------------------------\n",
      "Fold 5 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.98      0.96    60539\n",
      "1  washing machine       0.62    0.68      0.65    49848\n",
      "2      dish washer       0.70    0.64      0.67    31498\n",
      "3        microwave       0.57    0.96      0.72    45078\n",
      "4           kettle       0.85    0.72      0.78    53030\n",
      "5        micro avg       0.73    0.81      0.77   239993\n",
      "6        macro avg       0.74    0.80      0.75   239993\n",
      "7     weighted avg       0.75    0.81      0.77   239993\n",
      "8      samples avg       0.70    0.80      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 6 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.91      0.92    11828\n",
      "1  washing machine       0.91    0.82      0.86     8389\n",
      "2      dish washer       0.89    0.80      0.85     8207\n",
      "3        microwave       0.92    0.85      0.89     9542\n",
      "4           kettle       0.96    0.93      0.95     9968\n",
      "5        micro avg       0.93    0.87      0.90    47934\n",
      "6        macro avg       0.93    0.86      0.89    47934\n",
      "7     weighted avg       0.93    0.87      0.90    47934\n",
      "8      samples avg       0.93    0.88      0.90    47934\n",
      "-------------------------------------------------\n",
      "Fold 6 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.95    0.92      0.94    60539\n",
      "1  washing machine       0.60    0.70      0.65    49848\n",
      "2      dish washer       0.57    0.70      0.62    31498\n",
      "3        microwave       0.69    0.92      0.79    45078\n",
      "4           kettle       0.77    0.73      0.75    53030\n",
      "5        micro avg       0.72    0.80      0.76   239993\n",
      "6        macro avg       0.71    0.79      0.75   239993\n",
      "7     weighted avg       0.74    0.80      0.77   239993\n",
      "8      samples avg       0.69    0.78      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 7 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.91      0.91    11670\n",
      "1  washing machine       0.90    0.82      0.86     8394\n",
      "2      dish washer       0.87    0.78      0.82     8254\n",
      "3        microwave       0.89    0.85      0.87     9554\n",
      "4           kettle       0.96    0.92      0.94     9928\n",
      "5        micro avg       0.91    0.86      0.88    47800\n",
      "6        macro avg       0.91    0.86      0.88    47800\n",
      "7     weighted avg       0.91    0.86      0.88    47800\n",
      "8      samples avg       0.92    0.88      0.89    47800\n",
      "-------------------------------------------------\n",
      "Fold 7 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.98      0.96    60539\n",
      "1  washing machine       0.56    0.83      0.67    49848\n",
      "2      dish washer       0.71    0.65      0.67    31498\n",
      "3        microwave       0.63    0.90      0.74    45078\n",
      "4           kettle       0.80    0.73      0.76    53030\n",
      "5        micro avg       0.72    0.84      0.77   239993\n",
      "6        macro avg       0.73    0.82      0.76   239993\n",
      "7     weighted avg       0.74    0.84      0.78   239993\n",
      "8      samples avg       0.68    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 8 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.84      0.89    11782\n",
      "1  washing machine       0.63    0.91      0.74     8527\n",
      "2      dish washer       0.93    0.60      0.73     8269\n",
      "3        microwave       0.87    0.80      0.83     9595\n",
      "4           kettle       0.94    0.89      0.92     9911\n",
      "5        micro avg       0.84    0.81      0.83    48084\n",
      "6        macro avg       0.86    0.81      0.82    48084\n",
      "7     weighted avg       0.87    0.81      0.83    48084\n",
      "8      samples avg       0.84    0.83      0.82    48084\n",
      "-------------------------------------------------\n",
      "Fold 8 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.96    0.98      0.97    60539\n",
      "1  washing machine       0.57    0.85      0.68    49848\n",
      "2      dish washer       0.90    0.57      0.70    31498\n",
      "3        microwave       0.62    0.91      0.74    45078\n",
      "4           kettle       0.78    0.78      0.78    53030\n",
      "5        micro avg       0.73    0.84      0.78   239993\n",
      "6        macro avg       0.77    0.82      0.77   239993\n",
      "7     weighted avg       0.77    0.84      0.79   239993\n",
      "8      samples avg       0.72    0.84      0.75   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 9 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.93      0.92    11834\n",
      "1  washing machine       0.91    0.80      0.85     8478\n",
      "2      dish washer       0.85    0.79      0.82     8188\n",
      "3        microwave       0.93    0.83      0.87     9619\n",
      "4           kettle       0.96    0.93      0.94    10086\n",
      "5        micro avg       0.91    0.86      0.89    48205\n",
      "6        macro avg       0.91    0.85      0.88    48205\n",
      "7     weighted avg       0.91    0.86      0.89    48205\n",
      "8      samples avg       0.92    0.88      0.89    48205\n",
      "-------------------------------------------------\n",
      "Fold 9 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.89      0.90    60539\n",
      "1  washing machine       0.57    0.81      0.67    49848\n",
      "2      dish washer       0.58    0.71      0.64    31498\n",
      "3        microwave       0.67    0.85      0.75    45078\n",
      "4           kettle       0.86    0.72      0.78    53030\n",
      "5        micro avg       0.72    0.81      0.76   239993\n",
      "6        macro avg       0.72    0.80      0.75   239993\n",
      "7     weighted avg       0.74    0.81      0.76   239993\n",
      "8      samples avg       0.69    0.78      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 10 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.93      0.92    11928\n",
      "1  washing machine       0.90    0.81      0.85     8376\n",
      "2      dish washer       0.87    0.79      0.82     8204\n",
      "3        microwave       0.88    0.86      0.87     9506\n",
      "4           kettle       0.95    0.92      0.94     9963\n",
      "5        micro avg       0.91    0.87      0.89    47977\n",
      "6        macro avg       0.90    0.86      0.88    47977\n",
      "7     weighted avg       0.91    0.87      0.89    47977\n",
      "8      samples avg       0.92    0.88      0.89    47977\n",
      "-------------------------------------------------\n",
      "Fold 10 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.99      0.95    60539\n",
      "1  washing machine       0.58    0.80      0.67    49848\n",
      "2      dish washer       0.67    0.65      0.66    31498\n",
      "3        microwave       0.65    0.91      0.76    45078\n",
      "4           kettle       0.78    0.77      0.78    53030\n",
      "5        micro avg       0.72    0.84      0.78   239993\n",
      "6        macro avg       0.72    0.82      0.76   239993\n",
      "7     weighted avg       0.74    0.84      0.78   239993\n",
      "8      samples avg       0.70    0.82      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 11 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.91      0.92    11776\n",
      "1  washing machine       0.92    0.82      0.87     8517\n",
      "2      dish washer       0.86    0.82      0.84     8190\n",
      "3        microwave       0.89    0.87      0.88     9613\n",
      "4           kettle       0.97    0.92      0.95     9969\n",
      "5        micro avg       0.92    0.88      0.90    48065\n",
      "6        macro avg       0.91    0.87      0.89    48065\n",
      "7     weighted avg       0.92    0.88      0.90    48065\n",
      "8      samples avg       0.93    0.89      0.90    48065\n",
      "-------------------------------------------------\n",
      "Fold 11 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.94      0.94    60539\n",
      "1  washing machine       0.57    0.81      0.67    49848\n",
      "2      dish washer       0.62    0.68      0.64    31498\n",
      "3        microwave       0.67    0.90      0.77    45078\n",
      "4           kettle       0.81    0.70      0.75    53030\n",
      "5        micro avg       0.72    0.82      0.76   239993\n",
      "6        macro avg       0.72    0.80      0.75   239993\n",
      "7     weighted avg       0.74    0.82      0.77   239993\n",
      "8      samples avg       0.68    0.79      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 12 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.93      0.93    11825\n",
      "1  washing machine       0.92    0.83      0.87     8448\n",
      "2      dish washer       0.89    0.81      0.85     8210\n",
      "3        microwave       0.91    0.88      0.89     9562\n",
      "4           kettle       0.96    0.94      0.95     9927\n",
      "5        micro avg       0.92    0.88      0.90    47972\n",
      "6        macro avg       0.92    0.88      0.90    47972\n",
      "7     weighted avg       0.92    0.88      0.90    47972\n",
      "8      samples avg       0.93    0.90      0.91    47972\n",
      "-------------------------------------------------\n",
      "Fold 12 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.98      0.96    60539\n",
      "1  washing machine       0.58    0.82      0.68    49848\n",
      "2      dish washer       0.75    0.60      0.66    31498\n",
      "3        microwave       0.64    0.91      0.75    45078\n",
      "4           kettle       0.79    0.75      0.77    53030\n",
      "5        micro avg       0.73    0.83      0.78   239993\n",
      "6        macro avg       0.74    0.81      0.76   239993\n",
      "7     weighted avg       0.75    0.83      0.78   239993\n",
      "8      samples avg       0.71    0.82      0.74   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 13 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.94      0.92    11762\n",
      "1  washing machine       0.89    0.85      0.87     8396\n",
      "2      dish washer       0.83    0.86      0.84     8248\n",
      "3        microwave       0.91    0.86      0.88     9477\n",
      "4           kettle       0.94    0.94      0.94    10024\n",
      "5        micro avg       0.90    0.89      0.89    47907\n",
      "6        macro avg       0.89    0.89      0.89    47907\n",
      "7     weighted avg       0.90    0.89      0.89    47907\n",
      "8      samples avg       0.91    0.91      0.90    47907\n",
      "-------------------------------------------------\n",
      "Fold 13 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.88    0.96      0.92    60539\n",
      "1  washing machine       0.57    0.85      0.68    49848\n",
      "2      dish washer       0.61    0.70      0.65    31498\n",
      "3        microwave       0.65    0.88      0.74    45078\n",
      "4           kettle       0.66    0.83      0.74    53030\n",
      "5        micro avg       0.68    0.86      0.76   239993\n",
      "6        macro avg       0.67    0.84      0.75   239993\n",
      "7     weighted avg       0.69    0.86      0.76   239993\n",
      "8      samples avg       0.65    0.84      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 14 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.93      0.93    11786\n",
      "1  washing machine       0.93    0.82      0.87     8379\n",
      "2      dish washer       0.86    0.85      0.86     8269\n",
      "3        microwave       0.91    0.86      0.89     9574\n",
      "4           kettle       0.98    0.92      0.95     9978\n",
      "5        micro avg       0.92    0.88      0.90    47986\n",
      "6        macro avg       0.92    0.87      0.90    47986\n",
      "7     weighted avg       0.92    0.88      0.90    47986\n",
      "8      samples avg       0.93    0.90      0.90    47986\n",
      "-------------------------------------------------\n",
      "Fold 14 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.99      0.96    60539\n",
      "1  washing machine       0.57    0.78      0.66    49848\n",
      "2      dish washer       0.59    0.70      0.64    31498\n",
      "3        microwave       0.66    0.90      0.76    45078\n",
      "4           kettle       0.85    0.67      0.75    53030\n",
      "5        micro avg       0.72    0.82      0.77   239993\n",
      "6        macro avg       0.72    0.81      0.75   239993\n",
      "7     weighted avg       0.74    0.82      0.77   239993\n",
      "8      samples avg       0.69    0.80      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 15 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.92      0.93    11893\n",
      "1  washing machine       0.91    0.84      0.88     8424\n",
      "2      dish washer       0.86    0.86      0.86     8205\n",
      "3        microwave       0.90    0.88      0.89     9590\n",
      "4           kettle       0.97    0.93      0.95     9958\n",
      "5        micro avg       0.92    0.89      0.90    48070\n",
      "6        macro avg       0.91    0.89      0.90    48070\n",
      "7     weighted avg       0.92    0.89      0.90    48070\n",
      "8      samples avg       0.93    0.91      0.91    48070\n",
      "-------------------------------------------------\n",
      "Fold 15 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.99      0.96    60539\n",
      "1  washing machine       0.59    0.80      0.68    49848\n",
      "2      dish washer       0.60    0.71      0.65    31498\n",
      "3        microwave       0.63    0.93      0.75    45078\n",
      "4           kettle       0.85    0.69      0.76    53030\n",
      "5        micro avg       0.72    0.84      0.77   239993\n",
      "6        macro avg       0.72    0.82      0.76   239993\n",
      "7     weighted avg       0.74    0.84      0.78   239993\n",
      "8      samples avg       0.69    0.82      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 16 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.92      0.92    11865\n",
      "1  washing machine       0.92    0.84      0.88     8506\n",
      "2      dish washer       0.90    0.80      0.85     8222\n",
      "3        microwave       0.91    0.87      0.89     9541\n",
      "4           kettle       0.96    0.94      0.95     9954\n",
      "5        micro avg       0.93    0.88      0.90    48088\n",
      "6        macro avg       0.92    0.88      0.90    48088\n",
      "7     weighted avg       0.92    0.88      0.90    48088\n",
      "8      samples avg       0.93    0.90      0.91    48088\n",
      "-------------------------------------------------\n",
      "Fold 16 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.96      0.94    60539\n",
      "1  washing machine       0.57    0.81      0.67    49848\n",
      "2      dish washer       0.67    0.67      0.67    31498\n",
      "3        microwave       0.66    0.90      0.76    45078\n",
      "4           kettle       0.86    0.71      0.78    53030\n",
      "5        micro avg       0.73    0.82      0.77   239993\n",
      "6        macro avg       0.74    0.81      0.76   239993\n",
      "7     weighted avg       0.75    0.82      0.78   239993\n",
      "8      samples avg       0.70    0.80      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 17 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.76      0.84    11794\n",
      "1  washing machine       0.54    0.89      0.67     8394\n",
      "2      dish washer       0.85    0.57      0.68     8120\n",
      "3        microwave       0.86    0.60      0.71     9589\n",
      "4           kettle       0.95    0.82      0.88     9895\n",
      "5        micro avg       0.79    0.73      0.76    47792\n",
      "6        macro avg       0.83    0.73      0.76    47792\n",
      "7     weighted avg       0.84    0.73      0.77    47792\n",
      "8      samples avg       0.77    0.73      0.72    47792\n",
      "-------------------------------------------------\n",
      "Fold 17 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.96    0.96      0.96    60539\n",
      "1  washing machine       0.61    0.76      0.68    49848\n",
      "2      dish washer       0.62    0.65      0.63    31498\n",
      "3        microwave       0.56    0.95      0.70    45078\n",
      "4           kettle       0.88    0.70      0.78    53030\n",
      "5        micro avg       0.72    0.82      0.76   239993\n",
      "6        macro avg       0.73    0.80      0.75   239993\n",
      "7     weighted avg       0.75    0.82      0.77   239993\n",
      "8      samples avg       0.72    0.82      0.74   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 18 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.84      0.87    11818\n",
      "1  washing machine       0.52    0.92      0.67     8432\n",
      "2      dish washer       0.86    0.58      0.69     8328\n",
      "3        microwave       0.91    0.54      0.68     9480\n",
      "4           kettle       0.96    0.84      0.90     9933\n",
      "5        micro avg       0.79    0.75      0.77    47991\n",
      "6        macro avg       0.83    0.74      0.76    47991\n",
      "7     weighted avg       0.84    0.75      0.77    47991\n",
      "8      samples avg       0.77    0.75      0.73    47991\n",
      "-------------------------------------------------\n",
      "Fold 18 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.99      0.95    60539\n",
      "1  washing machine       0.64    0.79      0.71    49848\n",
      "2      dish washer       0.60    0.68      0.64    31498\n",
      "3        microwave       0.69    0.83      0.75    45078\n",
      "4           kettle       0.84    0.71      0.77    53030\n",
      "5        micro avg       0.75    0.82      0.78   239993\n",
      "6        macro avg       0.74    0.80      0.76   239993\n",
      "7     weighted avg       0.76    0.82      0.78   239993\n",
      "8      samples avg       0.75    0.82      0.76   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 19 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.92      0.93    11787\n",
      "1  washing machine       0.90    0.86      0.88     8464\n",
      "2      dish washer       0.88    0.82      0.85     8235\n",
      "3        microwave       0.92    0.86      0.89     9610\n",
      "4           kettle       0.97    0.93      0.95     9992\n",
      "5        micro avg       0.92    0.88      0.90    48088\n",
      "6        macro avg       0.92    0.88      0.90    48088\n",
      "7     weighted avg       0.92    0.88      0.90    48088\n",
      "8      samples avg       0.93    0.90      0.91    48088\n",
      "-------------------------------------------------\n",
      "Fold 19 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.96      0.95    60539\n",
      "1  washing machine       0.57    0.84      0.68    49848\n",
      "2      dish washer       0.53    0.73      0.61    31498\n",
      "3        microwave       0.68    0.83      0.75    45078\n",
      "4           kettle       0.73    0.76      0.74    53030\n",
      "5        micro avg       0.69    0.84      0.76   239993\n",
      "6        macro avg       0.69    0.82      0.75   239993\n",
      "7     weighted avg       0.71    0.84      0.77   239993\n",
      "8      samples avg       0.67    0.82      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 20 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.92      0.93    11778\n",
      "1  washing machine       0.91    0.84      0.87     8368\n",
      "2      dish washer       0.85    0.84      0.85     8217\n",
      "3        microwave       0.91    0.87      0.89     9596\n",
      "4           kettle       0.95    0.93      0.94    10082\n",
      "5        micro avg       0.91    0.89      0.90    48041\n",
      "6        macro avg       0.91    0.88      0.90    48041\n",
      "7     weighted avg       0.91    0.89      0.90    48041\n",
      "8      samples avg       0.93    0.90      0.90    48041\n",
      "-------------------------------------------------\n",
      "Fold 20 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.97      0.95    60539\n",
      "1  washing machine       0.57    0.82      0.67    49848\n",
      "2      dish washer       0.55    0.72      0.62    31498\n",
      "3        microwave       0.65    0.86      0.74    45078\n",
      "4           kettle       0.76    0.77      0.77    53030\n",
      "5        micro avg       0.70    0.84      0.76   239993\n",
      "6        macro avg       0.69    0.83      0.75   239993\n",
      "7     weighted avg       0.71    0.84      0.77   239993\n",
      "8      samples avg       0.67    0.82      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 21 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.86    0.90      0.88    11890\n",
      "1  washing machine       0.90    0.72      0.80     8479\n",
      "2      dish washer       0.88    0.58      0.70     8116\n",
      "3        microwave       0.55    0.93      0.69     9604\n",
      "4           kettle       0.96    0.77      0.85    10055\n",
      "5        micro avg       0.78    0.79      0.79    48144\n",
      "6        macro avg       0.83    0.78      0.78    48144\n",
      "7     weighted avg       0.83    0.79      0.79    48144\n",
      "8      samples avg       0.77    0.80      0.76    48144\n",
      "-------------------------------------------------\n",
      "Fold 21 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.99      0.95    60539\n",
      "1  washing machine       0.71    0.61      0.66    49848\n",
      "2      dish washer       0.57    0.70      0.63    31498\n",
      "3        microwave       0.58    0.91      0.71    45078\n",
      "4           kettle       0.94    0.53      0.68    53030\n",
      "5        micro avg       0.73    0.76      0.75   239993\n",
      "6        macro avg       0.74    0.75      0.72   239993\n",
      "7     weighted avg       0.77    0.76      0.74   239993\n",
      "8      samples avg       0.73    0.75      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 22 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.92      0.93    11862\n",
      "1  washing machine       0.88    0.89      0.89     8406\n",
      "2      dish washer       0.89    0.83      0.86     8269\n",
      "3        microwave       0.93    0.86      0.89     9586\n",
      "4           kettle       0.96    0.94      0.95     9876\n",
      "5        micro avg       0.92    0.89      0.91    47999\n",
      "6        macro avg       0.92    0.89      0.90    47999\n",
      "7     weighted avg       0.92    0.89      0.91    47999\n",
      "8      samples avg       0.93    0.91      0.91    47999\n",
      "-------------------------------------------------\n",
      "Fold 22 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.98      0.95    60539\n",
      "1  washing machine       0.57    0.87      0.68    49848\n",
      "2      dish washer       0.63    0.67      0.65    31498\n",
      "3        microwave       0.67    0.85      0.75    45078\n",
      "4           kettle       0.80    0.72      0.76    53030\n",
      "5        micro avg       0.72    0.84      0.77   239993\n",
      "6        macro avg       0.72    0.82      0.76   239993\n",
      "7     weighted avg       0.73    0.84      0.78   239993\n",
      "8      samples avg       0.69    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 23 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.91      0.93    11732\n",
      "1  washing machine       0.91    0.85      0.88     8519\n",
      "2      dish washer       0.90    0.84      0.87     8304\n",
      "3        microwave       0.91    0.87      0.89     9582\n",
      "4           kettle       0.95    0.94      0.95     9995\n",
      "5        micro avg       0.92    0.89      0.91    48132\n",
      "6        macro avg       0.92    0.88      0.90    48132\n",
      "7     weighted avg       0.92    0.89      0.91    48132\n",
      "8      samples avg       0.94    0.90      0.91    48132\n",
      "-------------------------------------------------\n",
      "Fold 23 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.98      0.96    60539\n",
      "1  washing machine       0.57    0.83      0.67    49848\n",
      "2      dish washer       0.76    0.62      0.68    31498\n",
      "3        microwave       0.64    0.92      0.75    45078\n",
      "4           kettle       0.75    0.78      0.76    53030\n",
      "5        micro avg       0.72    0.85      0.78   239993\n",
      "6        macro avg       0.73    0.82      0.77   239993\n",
      "7     weighted avg       0.74    0.85      0.78   239993\n",
      "8      samples avg       0.69    0.83      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 24 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.86      0.89    11836\n",
      "1  washing machine       0.78    0.85      0.81     8450\n",
      "2      dish washer       0.88    0.62      0.73     8204\n",
      "3        microwave       0.92    0.72      0.80     9561\n",
      "4           kettle       0.97    0.87      0.92     9908\n",
      "5        micro avg       0.90    0.79      0.84    47959\n",
      "6        macro avg       0.89    0.78      0.83    47959\n",
      "7     weighted avg       0.90    0.79      0.84    47959\n",
      "8      samples avg       0.89    0.80      0.83    47959\n",
      "-------------------------------------------------\n",
      "Fold 24 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.99      0.96    60539\n",
      "1  washing machine       0.60    0.82      0.69    49848\n",
      "2      dish washer       0.67    0.65      0.66    31498\n",
      "3        microwave       0.59    0.95      0.73    45078\n",
      "4           kettle       0.95    0.65      0.77    53030\n",
      "5        micro avg       0.73    0.83      0.77   239993\n",
      "6        macro avg       0.75    0.81      0.76   239993\n",
      "7     weighted avg       0.77    0.83      0.78   239993\n",
      "8      samples avg       0.72    0.82      0.74   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 25 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.93      0.92    11722\n",
      "1  washing machine       0.90    0.85      0.88     8310\n",
      "2      dish washer       0.86    0.87      0.86     8229\n",
      "3        microwave       0.92    0.86      0.89     9483\n",
      "4           kettle       0.97    0.93      0.95    10022\n",
      "5        micro avg       0.92    0.89      0.90    47766\n",
      "6        macro avg       0.91    0.89      0.90    47766\n",
      "7     weighted avg       0.92    0.89      0.90    47766\n",
      "8      samples avg       0.93    0.91      0.91    47766\n",
      "-------------------------------------------------\n",
      "Fold 25 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.98      0.94    60539\n",
      "1  washing machine       0.57    0.83      0.68    49848\n",
      "2      dish washer       0.60    0.70      0.64    31498\n",
      "3        microwave       0.64    0.91      0.75    45078\n",
      "4           kettle       0.85    0.70      0.77    53030\n",
      "5        micro avg       0.71    0.84      0.77   239993\n",
      "6        macro avg       0.71    0.82      0.76   239993\n",
      "7     weighted avg       0.73    0.84      0.77   239993\n",
      "8      samples avg       0.68    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 26 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.92      0.93    11834\n",
      "1  washing machine       0.89    0.88      0.89     8486\n",
      "2      dish washer       0.86    0.87      0.86     8217\n",
      "3        microwave       0.94    0.86      0.90     9608\n",
      "4           kettle       0.96    0.94      0.95     9991\n",
      "5        micro avg       0.92    0.90      0.91    48136\n",
      "6        macro avg       0.92    0.89      0.90    48136\n",
      "7     weighted avg       0.92    0.90      0.91    48136\n",
      "8      samples avg       0.93    0.91      0.91    48136\n",
      "-------------------------------------------------\n",
      "Fold 26 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.97      0.94    60539\n",
      "1  washing machine       0.57    0.82      0.67    49848\n",
      "2      dish washer       0.54    0.74      0.62    31498\n",
      "3        microwave       0.67    0.89      0.77    45078\n",
      "4           kettle       0.78    0.74      0.76    53030\n",
      "5        micro avg       0.70    0.84      0.76   239993\n",
      "6        macro avg       0.70    0.83      0.75   239993\n",
      "7     weighted avg       0.72    0.84      0.77   239993\n",
      "8      samples avg       0.67    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 27 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.92      0.93    11760\n",
      "1  washing machine       0.88    0.88      0.88     8511\n",
      "2      dish washer       0.88    0.85      0.86     8235\n",
      "3        microwave       0.90    0.87      0.89     9475\n",
      "4           kettle       0.98    0.92      0.95     9937\n",
      "5        micro avg       0.92    0.89      0.91    47918\n",
      "6        macro avg       0.92    0.89      0.90    47918\n",
      "7     weighted avg       0.92    0.89      0.91    47918\n",
      "8      samples avg       0.93    0.91      0.91    47918\n",
      "-------------------------------------------------\n",
      "Fold 27 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.98      0.94    60539\n",
      "1  washing machine       0.57    0.86      0.69    49848\n",
      "2      dish washer       0.57    0.69      0.63    31498\n",
      "3        microwave       0.66    0.90      0.76    45078\n",
      "4           kettle       0.83    0.65      0.73    53030\n",
      "5        micro avg       0.71    0.83      0.76   239993\n",
      "6        macro avg       0.71    0.82      0.75   239993\n",
      "7     weighted avg       0.73    0.83      0.77   239993\n",
      "8      samples avg       0.68    0.81      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 28 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.93      0.92    11821\n",
      "1  washing machine       0.91    0.85      0.88     8312\n",
      "2      dish washer       0.88    0.83      0.85     8213\n",
      "3        microwave       0.91    0.87      0.89     9643\n",
      "4           kettle       0.97    0.93      0.95     9999\n",
      "5        micro avg       0.92    0.89      0.90    47988\n",
      "6        macro avg       0.92    0.88      0.90    47988\n",
      "7     weighted avg       0.92    0.89      0.90    47988\n",
      "8      samples avg       0.93    0.90      0.91    47988\n",
      "-------------------------------------------------\n",
      "Fold 28 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.99      0.95    60539\n",
      "1  washing machine       0.57    0.80      0.67    49848\n",
      "2      dish washer       0.61    0.68      0.64    31498\n",
      "3        microwave       0.64    0.92      0.76    45078\n",
      "4           kettle       0.81    0.64      0.71    53030\n",
      "5        micro avg       0.71    0.82      0.76   239993\n",
      "6        macro avg       0.71    0.80      0.74   239993\n",
      "7     weighted avg       0.73    0.82      0.76   239993\n",
      "8      samples avg       0.67    0.79      0.70   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 29 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.92      0.93    11744\n",
      "1  washing machine       0.89    0.87      0.88     8430\n",
      "2      dish washer       0.89    0.83      0.86     8249\n",
      "3        microwave       0.90    0.88      0.89     9546\n",
      "4           kettle       0.96    0.94      0.95     9980\n",
      "5        micro avg       0.92    0.89      0.90    47949\n",
      "6        macro avg       0.91    0.89      0.90    47949\n",
      "7     weighted avg       0.92    0.89      0.90    47949\n",
      "8      samples avg       0.93    0.91      0.91    47949\n",
      "-------------------------------------------------\n",
      "Fold 29 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.98      0.95    60539\n",
      "1  washing machine       0.57    0.84      0.68    49848\n",
      "2      dish washer       0.68    0.64      0.66    31498\n",
      "3        microwave       0.63    0.90      0.74    45078\n",
      "4           kettle       0.79    0.73      0.76    53030\n",
      "5        micro avg       0.71    0.84      0.77   239993\n",
      "6        macro avg       0.72    0.82      0.76   239993\n",
      "7     weighted avg       0.73    0.84      0.77   239993\n",
      "8      samples avg       0.69    0.82      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 30 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.91      0.93    11883\n",
      "1  washing machine       0.90    0.86      0.88     8425\n",
      "2      dish washer       0.88    0.82      0.85     8208\n",
      "3        microwave       0.92    0.85      0.89     9544\n",
      "4           kettle       0.96    0.93      0.95     9949\n",
      "5        micro avg       0.92    0.88      0.90    48009\n",
      "6        macro avg       0.92    0.88      0.90    48009\n",
      "7     weighted avg       0.92    0.88      0.90    48009\n",
      "8      samples avg       0.94    0.90      0.91    48009\n",
      "-------------------------------------------------\n",
      "Fold 30 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.98      0.96    60539\n",
      "1  washing machine       0.57    0.85      0.68    49848\n",
      "2      dish washer       0.70    0.64      0.67    31498\n",
      "3        microwave       0.70    0.89      0.78    45078\n",
      "4           kettle       0.89    0.68      0.77    53030\n",
      "5        micro avg       0.75    0.83      0.78   239993\n",
      "6        macro avg       0.76    0.81      0.77   239993\n",
      "7     weighted avg       0.77    0.83      0.79   239993\n",
      "8      samples avg       0.72    0.81      0.74   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 31 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.92      0.93    11875\n",
      "1  washing machine       0.92    0.85      0.89     8512\n",
      "2      dish washer       0.86    0.86      0.86     8137\n",
      "3        microwave       0.89    0.88      0.89     9475\n",
      "4           kettle       0.97    0.92      0.95     9969\n",
      "5        micro avg       0.92    0.89      0.90    47968\n",
      "6        macro avg       0.92    0.89      0.90    47968\n",
      "7     weighted avg       0.92    0.89      0.90    47968\n",
      "8      samples avg       0.93    0.91      0.91    47968\n",
      "-------------------------------------------------\n",
      "Fold 31 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.96      0.94    60539\n",
      "1  washing machine       0.58    0.81      0.67    49848\n",
      "2      dish washer       0.52    0.75      0.61    31498\n",
      "3        microwave       0.64    0.92      0.76    45078\n",
      "4           kettle       0.78    0.66      0.71    53030\n",
      "5        micro avg       0.69    0.83      0.75   239993\n",
      "6        macro avg       0.69    0.82      0.74   239993\n",
      "7     weighted avg       0.71    0.83      0.76   239993\n",
      "8      samples avg       0.66    0.80      0.70   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 32 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.92      0.93    11766\n",
      "1  washing machine       0.90    0.88      0.89     8431\n",
      "2      dish washer       0.89    0.84      0.86     8239\n",
      "3        microwave       0.92    0.88      0.89     9563\n",
      "4           kettle       0.97    0.94      0.95     9968\n",
      "5        micro avg       0.92    0.89      0.91    47967\n",
      "6        macro avg       0.92    0.89      0.91    47967\n",
      "7     weighted avg       0.92    0.89      0.91    47967\n",
      "8      samples avg       0.94    0.91      0.92    47967\n",
      "-------------------------------------------------\n",
      "Fold 32 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.97      0.95    60539\n",
      "1  washing machine       0.57    0.85      0.68    49848\n",
      "2      dish washer       0.59    0.67      0.63    31498\n",
      "3        microwave       0.65    0.90      0.75    45078\n",
      "4           kettle       0.83    0.70      0.76    53030\n",
      "5        micro avg       0.71    0.83      0.77   239993\n",
      "6        macro avg       0.71    0.82      0.75   239993\n",
      "7     weighted avg       0.73    0.83      0.77   239993\n",
      "8      samples avg       0.69    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 33 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.95    0.91      0.93    11780\n",
      "1  washing machine       0.90    0.87      0.88     8358\n",
      "2      dish washer       0.89    0.85      0.87     8275\n",
      "3        microwave       0.90    0.89      0.89     9670\n",
      "4           kettle       0.96    0.94      0.95     9962\n",
      "5        micro avg       0.92    0.89      0.91    48045\n",
      "6        macro avg       0.92    0.89      0.90    48045\n",
      "7     weighted avg       0.92    0.89      0.91    48045\n",
      "8      samples avg       0.93    0.91      0.91    48045\n",
      "-------------------------------------------------\n",
      "Fold 33 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.97      0.94    60539\n",
      "1  washing machine       0.57    0.83      0.68    49848\n",
      "2      dish washer       0.66    0.64      0.65    31498\n",
      "3        microwave       0.60    0.91      0.72    45078\n",
      "4           kettle       0.79    0.75      0.77    53030\n",
      "5        micro avg       0.70    0.84      0.76   239993\n",
      "6        macro avg       0.71    0.82      0.75   239993\n",
      "7     weighted avg       0.72    0.84      0.77   239993\n",
      "8      samples avg       0.67    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 34 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.93      0.92    11846\n",
      "1  washing machine       0.89    0.85      0.87     8455\n",
      "2      dish washer       0.87    0.81      0.84     8185\n",
      "3        microwave       0.91    0.85      0.87     9533\n",
      "4           kettle       0.95    0.94      0.95     9982\n",
      "5        micro avg       0.91    0.88      0.89    48001\n",
      "6        macro avg       0.91    0.87      0.89    48001\n",
      "7     weighted avg       0.91    0.88      0.89    48001\n",
      "8      samples avg       0.92    0.90      0.90    48001\n",
      "-------------------------------------------------\n",
      "Fold 34 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.99      0.95    60539\n",
      "1  washing machine       0.57    0.85      0.68    49848\n",
      "2      dish washer       0.71    0.63      0.67    31498\n",
      "3        microwave       0.62    0.93      0.74    45078\n",
      "4           kettle       0.78    0.75      0.77    53030\n",
      "5        micro avg       0.71    0.85      0.77   239993\n",
      "6        macro avg       0.72    0.83      0.76   239993\n",
      "7     weighted avg       0.73    0.85      0.78   239993\n",
      "8      samples avg       0.68    0.83      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 35 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.93      0.93    11775\n",
      "1  washing machine       0.89    0.87      0.88     8408\n",
      "2      dish washer       0.90    0.81      0.86     8286\n",
      "3        microwave       0.92    0.86      0.89     9575\n",
      "4           kettle       0.97    0.92      0.94     9975\n",
      "5        micro avg       0.92    0.88      0.90    48019\n",
      "6        macro avg       0.92    0.88      0.90    48019\n",
      "7     weighted avg       0.92    0.88      0.90    48019\n",
      "8      samples avg       0.93    0.90      0.91    48019\n",
      "-------------------------------------------------\n",
      "Fold 35 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.99      0.94    60539\n",
      "1  washing machine       0.57    0.84      0.68    49848\n",
      "2      dish washer       0.63    0.66      0.64    31498\n",
      "3        microwave       0.68    0.88      0.77    45078\n",
      "4           kettle       0.89    0.61      0.73    53030\n",
      "5        micro avg       0.73    0.81      0.77   239993\n",
      "6        macro avg       0.73    0.80      0.75   239993\n",
      "7     weighted avg       0.75    0.81      0.77   239993\n",
      "8      samples avg       0.69    0.79      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Using koef 1.5\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 92s 113ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 46s 76ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 46s 76ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 46s 76ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 46s 76ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 46s 77ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 46s 76ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 46s 76ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 45s 76ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 45s 76ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 46s 76ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 46s 77ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 46s 77ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 46s 76ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 46s 76ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 46s 76ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 46s 76ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 46s 76ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 46s 76ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 46s 76ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.1036e-04\n",
      "600/600 [==============================] - 6s 7ms/step\n",
      "3000/3000 [==============================] - 22s 7ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 49s 77ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 46s 76ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 46s 76ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 46s 77ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 46s 77ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 46s 76ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 46s 76ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 46s 76ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 45s 76ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 46s 76ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 46s 76ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 46s 76ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 46s 76ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 46s 76ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 46s 76ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 45s 76ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 46s 76ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 46s 76ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 46s 76ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 46s 76ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.1036e-04\n",
      "600/600 [==============================] - 5s 7ms/step\n",
      "3000/3000 [==============================] - 22s 7ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 48s 76ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 46s 76ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 46s 76ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 46s 76ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 46s 76ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 46s 76ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 45s 76ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 45s 76ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 46s 76ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 46s 76ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 45s 76ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 46s 76ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 46s 76ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 46s 76ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 46s 76ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 46s 76ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 45s 76ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 46s 76ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 46s 76ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 46s 76ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.1036e-04\n",
      "600/600 [==============================] - 5s 7ms/step\n",
      "600/600 [==============================] - 45s 75ms/step - loss: inf - F1Score: 0.7937 - WeightedF1: 0.8011 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 45s 75ms/step - loss: inf - F1Score: 0.7936 - WeightedF1: 0.8010 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 45s 75ms/step - loss: inf - F1Score: 0.7938 - WeightedF1: 0.8012 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 45s 75ms/step - loss: inf - F1Score: 0.7938 - WeightedF1: 0.8012 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 45s 75ms/step - loss: inf - F1Score: 0.7938 - WeightedF1: 0.8012 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 45s 75ms/step - loss: inf - F1Score: 0.7937 - WeightedF1: 0.8011 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 45s 75ms/step - loss: inf - F1Score: 0.7939 - WeightedF1: 0.8013 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 5s 7ms/step\n",
      "3000/3000 [==============================] - 23s 7ms/step\n",
      "Fold 1 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.87    0.92      0.89    11706\n",
      "1  washing machine       0.90    0.75      0.82     8507\n",
      "2      dish washer       0.83    0.73      0.78     8309\n",
      "3        microwave       0.88    0.82      0.85     9549\n",
      "4           kettle       0.96    0.89      0.92     9949\n",
      "5        micro avg       0.89    0.83      0.86    48020\n",
      "6        macro avg       0.89    0.82      0.85    48020\n",
      "7     weighted avg       0.89    0.83      0.86    48020\n",
      "8      samples avg       0.89    0.84      0.85    48020\n",
      "-------------------------------------------------\n",
      "Fold 1 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.99      0.96    60539\n",
      "1  washing machine       0.74    0.55      0.63    49848\n",
      "2      dish washer       0.55    0.73      0.63    31498\n",
      "3        microwave       0.63    0.93      0.75    45078\n",
      "4           kettle       0.73    0.82      0.77    53030\n",
      "5        micro avg       0.72    0.82      0.77   239993\n",
      "6        macro avg       0.71    0.81      0.75   239993\n",
      "7     weighted avg       0.74    0.82      0.77   239993\n",
      "8      samples avg       0.71    0.80      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 2 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.89    0.90      0.90    11903\n",
      "1  washing machine       0.88    0.76      0.82     8383\n",
      "2      dish washer       0.81    0.77      0.79     8279\n",
      "3        microwave       0.86    0.82      0.84     9584\n",
      "4           kettle       0.95    0.91      0.93     9899\n",
      "5        micro avg       0.88    0.84      0.86    48048\n",
      "6        macro avg       0.88    0.83      0.85    48048\n",
      "7     weighted avg       0.88    0.84      0.86    48048\n",
      "8      samples avg       0.89    0.85      0.86    48048\n",
      "-------------------------------------------------\n",
      "Fold 2 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.99      0.96    60539\n",
      "1  washing machine       0.62    0.69      0.66    49848\n",
      "2      dish washer       0.51    0.76      0.61    31498\n",
      "3        microwave       0.62    0.95      0.75    45078\n",
      "4           kettle       0.83    0.74      0.79    53030\n",
      "5        micro avg       0.71    0.83      0.77   239993\n",
      "6        macro avg       0.70    0.83      0.75   239993\n",
      "7     weighted avg       0.73    0.83      0.77   239993\n",
      "8      samples avg       0.69    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 3 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.85    0.92      0.88    11755\n",
      "1  washing machine       0.91    0.74      0.82     8482\n",
      "2      dish washer       0.82    0.71      0.76     8145\n",
      "3        microwave       0.88    0.73      0.80     9633\n",
      "4           kettle       0.95    0.90      0.92     9989\n",
      "5        micro avg       0.88    0.81      0.84    48004\n",
      "6        macro avg       0.88    0.80      0.84    48004\n",
      "7     weighted avg       0.88    0.81      0.84    48004\n",
      "8      samples avg       0.89    0.82      0.84    48004\n",
      "-------------------------------------------------\n",
      "Fold 3 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.98      0.94    60539\n",
      "1  washing machine       0.61    0.72      0.66    49848\n",
      "2      dish washer       0.62    0.68      0.65    31498\n",
      "3        microwave       0.66    0.85      0.74    45078\n",
      "4           kettle       0.77    0.76      0.77    53030\n",
      "5        micro avg       0.72    0.82      0.77   239993\n",
      "6        macro avg       0.71    0.80      0.75   239993\n",
      "7     weighted avg       0.73    0.82      0.77   239993\n",
      "8      samples avg       0.69    0.80      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 4 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.88    0.90      0.89    11880\n",
      "1  washing machine       0.90    0.75      0.82     8396\n",
      "2      dish washer       0.85    0.68      0.75     8215\n",
      "3        microwave       0.88    0.73      0.80     9566\n",
      "4           kettle       0.95    0.90      0.92    10018\n",
      "5        micro avg       0.89    0.80      0.85    48075\n",
      "6        macro avg       0.89    0.79      0.84    48075\n",
      "7     weighted avg       0.89    0.80      0.84    48075\n",
      "8      samples avg       0.90    0.82      0.84    48075\n",
      "-------------------------------------------------\n",
      "Fold 4 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.99      0.96    60539\n",
      "1  washing machine       0.59    0.75      0.66    49848\n",
      "2      dish washer       0.75    0.62      0.68    31498\n",
      "3        microwave       0.59    0.92      0.72    45078\n",
      "4           kettle       0.91    0.71      0.80    53030\n",
      "5        micro avg       0.74    0.82      0.78   239993\n",
      "6        macro avg       0.76    0.80      0.76   239993\n",
      "7     weighted avg       0.77    0.82      0.78   239993\n",
      "8      samples avg       0.72    0.81      0.74   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 5 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.88    0.90      0.89    11798\n",
      "1  washing machine       0.91    0.73      0.81     8396\n",
      "2      dish washer       0.84    0.69      0.75     8174\n",
      "3        microwave       0.85    0.79      0.82     9484\n",
      "4           kettle       0.96    0.87      0.91    10001\n",
      "5        micro avg       0.89    0.81      0.84    47853\n",
      "6        macro avg       0.89    0.79      0.84    47853\n",
      "7     weighted avg       0.89    0.81      0.84    47853\n",
      "8      samples avg       0.89    0.82      0.84    47853\n",
      "-------------------------------------------------\n",
      "Fold 5 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.98      0.96    60539\n",
      "1  washing machine       0.62    0.68      0.65    49848\n",
      "2      dish washer       0.70    0.64      0.67    31498\n",
      "3        microwave       0.57    0.96      0.72    45078\n",
      "4           kettle       0.85    0.72      0.78    53030\n",
      "5        micro avg       0.73    0.81      0.77   239993\n",
      "6        macro avg       0.74    0.80      0.75   239993\n",
      "7     weighted avg       0.75    0.81      0.77   239993\n",
      "8      samples avg       0.70    0.80      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 6 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.91      0.92    11828\n",
      "1  washing machine       0.91    0.82      0.86     8389\n",
      "2      dish washer       0.89    0.80      0.85     8207\n",
      "3        microwave       0.92    0.85      0.89     9542\n",
      "4           kettle       0.96    0.93      0.95     9968\n",
      "5        micro avg       0.93    0.87      0.90    47934\n",
      "6        macro avg       0.93    0.86      0.89    47934\n",
      "7     weighted avg       0.93    0.87      0.90    47934\n",
      "8      samples avg       0.93    0.88      0.90    47934\n",
      "-------------------------------------------------\n",
      "Fold 6 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.95    0.92      0.94    60539\n",
      "1  washing machine       0.60    0.70      0.65    49848\n",
      "2      dish washer       0.57    0.70      0.62    31498\n",
      "3        microwave       0.69    0.92      0.79    45078\n",
      "4           kettle       0.77    0.73      0.75    53030\n",
      "5        micro avg       0.72    0.80      0.76   239993\n",
      "6        macro avg       0.71    0.79      0.75   239993\n",
      "7     weighted avg       0.74    0.80      0.77   239993\n",
      "8      samples avg       0.69    0.78      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 7 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.91      0.91    11670\n",
      "1  washing machine       0.90    0.82      0.86     8394\n",
      "2      dish washer       0.87    0.78      0.82     8254\n",
      "3        microwave       0.89    0.85      0.87     9554\n",
      "4           kettle       0.96    0.92      0.94     9928\n",
      "5        micro avg       0.91    0.86      0.88    47800\n",
      "6        macro avg       0.91    0.86      0.88    47800\n",
      "7     weighted avg       0.91    0.86      0.88    47800\n",
      "8      samples avg       0.92    0.88      0.89    47800\n",
      "-------------------------------------------------\n",
      "Fold 7 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.98      0.96    60539\n",
      "1  washing machine       0.56    0.83      0.67    49848\n",
      "2      dish washer       0.71    0.65      0.67    31498\n",
      "3        microwave       0.63    0.90      0.74    45078\n",
      "4           kettle       0.80    0.73      0.76    53030\n",
      "5        micro avg       0.72    0.84      0.77   239993\n",
      "6        macro avg       0.73    0.82      0.76   239993\n",
      "7     weighted avg       0.74    0.84      0.78   239993\n",
      "8      samples avg       0.68    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 8 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.84      0.89    11782\n",
      "1  washing machine       0.63    0.91      0.74     8527\n",
      "2      dish washer       0.93    0.60      0.73     8269\n",
      "3        microwave       0.87    0.80      0.83     9595\n",
      "4           kettle       0.94    0.89      0.92     9911\n",
      "5        micro avg       0.84    0.81      0.83    48084\n",
      "6        macro avg       0.86    0.81      0.82    48084\n",
      "7     weighted avg       0.87    0.81      0.83    48084\n",
      "8      samples avg       0.84    0.83      0.82    48084\n",
      "-------------------------------------------------\n",
      "Fold 8 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.96    0.98      0.97    60539\n",
      "1  washing machine       0.57    0.85      0.68    49848\n",
      "2      dish washer       0.90    0.57      0.70    31498\n",
      "3        microwave       0.62    0.91      0.74    45078\n",
      "4           kettle       0.78    0.78      0.78    53030\n",
      "5        micro avg       0.73    0.84      0.78   239993\n",
      "6        macro avg       0.77    0.82      0.77   239993\n",
      "7     weighted avg       0.77    0.84      0.79   239993\n",
      "8      samples avg       0.72    0.84      0.75   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 9 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.93      0.92    11834\n",
      "1  washing machine       0.91    0.80      0.85     8478\n",
      "2      dish washer       0.85    0.79      0.82     8188\n",
      "3        microwave       0.93    0.83      0.87     9619\n",
      "4           kettle       0.96    0.93      0.94    10086\n",
      "5        micro avg       0.91    0.86      0.89    48205\n",
      "6        macro avg       0.91    0.85      0.88    48205\n",
      "7     weighted avg       0.91    0.86      0.89    48205\n",
      "8      samples avg       0.92    0.88      0.89    48205\n",
      "-------------------------------------------------\n",
      "Fold 9 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.89      0.90    60539\n",
      "1  washing machine       0.57    0.81      0.67    49848\n",
      "2      dish washer       0.58    0.71      0.64    31498\n",
      "3        microwave       0.67    0.85      0.75    45078\n",
      "4           kettle       0.86    0.72      0.78    53030\n",
      "5        micro avg       0.72    0.81      0.76   239993\n",
      "6        macro avg       0.72    0.80      0.75   239993\n",
      "7     weighted avg       0.74    0.81      0.76   239993\n",
      "8      samples avg       0.69    0.78      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 10 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.93      0.92    11928\n",
      "1  washing machine       0.90    0.81      0.85     8376\n",
      "2      dish washer       0.87    0.79      0.82     8204\n",
      "3        microwave       0.88    0.86      0.87     9506\n",
      "4           kettle       0.95    0.92      0.94     9963\n",
      "5        micro avg       0.91    0.87      0.89    47977\n",
      "6        macro avg       0.90    0.86      0.88    47977\n",
      "7     weighted avg       0.91    0.87      0.89    47977\n",
      "8      samples avg       0.92    0.88      0.89    47977\n",
      "-------------------------------------------------\n",
      "Fold 10 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.99      0.95    60539\n",
      "1  washing machine       0.58    0.80      0.67    49848\n",
      "2      dish washer       0.67    0.65      0.66    31498\n",
      "3        microwave       0.65    0.91      0.76    45078\n",
      "4           kettle       0.78    0.77      0.78    53030\n",
      "5        micro avg       0.72    0.84      0.78   239993\n",
      "6        macro avg       0.72    0.82      0.76   239993\n",
      "7     weighted avg       0.74    0.84      0.78   239993\n",
      "8      samples avg       0.70    0.82      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 11 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.91      0.92    11776\n",
      "1  washing machine       0.92    0.82      0.87     8517\n",
      "2      dish washer       0.86    0.82      0.84     8190\n",
      "3        microwave       0.89    0.87      0.88     9613\n",
      "4           kettle       0.97    0.92      0.95     9969\n",
      "5        micro avg       0.92    0.88      0.90    48065\n",
      "6        macro avg       0.91    0.87      0.89    48065\n",
      "7     weighted avg       0.92    0.88      0.90    48065\n",
      "8      samples avg       0.93    0.89      0.90    48065\n",
      "-------------------------------------------------\n",
      "Fold 11 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.94      0.94    60539\n",
      "1  washing machine       0.57    0.81      0.67    49848\n",
      "2      dish washer       0.62    0.68      0.64    31498\n",
      "3        microwave       0.67    0.90      0.77    45078\n",
      "4           kettle       0.81    0.70      0.75    53030\n",
      "5        micro avg       0.72    0.82      0.76   239993\n",
      "6        macro avg       0.72    0.80      0.75   239993\n",
      "7     weighted avg       0.74    0.82      0.77   239993\n",
      "8      samples avg       0.68    0.79      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 12 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.93      0.93    11825\n",
      "1  washing machine       0.92    0.83      0.87     8448\n",
      "2      dish washer       0.89    0.81      0.85     8210\n",
      "3        microwave       0.91    0.88      0.89     9562\n",
      "4           kettle       0.96    0.94      0.95     9927\n",
      "5        micro avg       0.92    0.88      0.90    47972\n",
      "6        macro avg       0.92    0.88      0.90    47972\n",
      "7     weighted avg       0.92    0.88      0.90    47972\n",
      "8      samples avg       0.93    0.90      0.91    47972\n",
      "-------------------------------------------------\n",
      "Fold 12 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.98      0.96    60539\n",
      "1  washing machine       0.58    0.82      0.68    49848\n",
      "2      dish washer       0.75    0.60      0.66    31498\n",
      "3        microwave       0.64    0.91      0.75    45078\n",
      "4           kettle       0.79    0.75      0.77    53030\n",
      "5        micro avg       0.73    0.83      0.78   239993\n",
      "6        macro avg       0.74    0.81      0.76   239993\n",
      "7     weighted avg       0.75    0.83      0.78   239993\n",
      "8      samples avg       0.71    0.82      0.74   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 13 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.94      0.92    11762\n",
      "1  washing machine       0.89    0.85      0.87     8396\n",
      "2      dish washer       0.83    0.86      0.84     8248\n",
      "3        microwave       0.91    0.86      0.88     9477\n",
      "4           kettle       0.94    0.94      0.94    10024\n",
      "5        micro avg       0.90    0.89      0.89    47907\n",
      "6        macro avg       0.89    0.89      0.89    47907\n",
      "7     weighted avg       0.90    0.89      0.89    47907\n",
      "8      samples avg       0.91    0.91      0.90    47907\n",
      "-------------------------------------------------\n",
      "Fold 13 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.88    0.96      0.92    60539\n",
      "1  washing machine       0.57    0.85      0.68    49848\n",
      "2      dish washer       0.61    0.70      0.65    31498\n",
      "3        microwave       0.65    0.88      0.74    45078\n",
      "4           kettle       0.66    0.83      0.74    53030\n",
      "5        micro avg       0.68    0.86      0.76   239993\n",
      "6        macro avg       0.67    0.84      0.75   239993\n",
      "7     weighted avg       0.69    0.86      0.76   239993\n",
      "8      samples avg       0.65    0.84      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 14 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.93      0.93    11786\n",
      "1  washing machine       0.93    0.82      0.87     8379\n",
      "2      dish washer       0.86    0.85      0.86     8269\n",
      "3        microwave       0.91    0.86      0.89     9574\n",
      "4           kettle       0.98    0.92      0.95     9978\n",
      "5        micro avg       0.92    0.88      0.90    47986\n",
      "6        macro avg       0.92    0.87      0.90    47986\n",
      "7     weighted avg       0.92    0.88      0.90    47986\n",
      "8      samples avg       0.93    0.90      0.90    47986\n",
      "-------------------------------------------------\n",
      "Fold 14 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.99      0.96    60539\n",
      "1  washing machine       0.57    0.78      0.66    49848\n",
      "2      dish washer       0.59    0.70      0.64    31498\n",
      "3        microwave       0.66    0.90      0.76    45078\n",
      "4           kettle       0.85    0.67      0.75    53030\n",
      "5        micro avg       0.72    0.82      0.77   239993\n",
      "6        macro avg       0.72    0.81      0.75   239993\n",
      "7     weighted avg       0.74    0.82      0.77   239993\n",
      "8      samples avg       0.69    0.80      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 15 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.92      0.93    11893\n",
      "1  washing machine       0.91    0.84      0.88     8424\n",
      "2      dish washer       0.86    0.86      0.86     8205\n",
      "3        microwave       0.90    0.88      0.89     9590\n",
      "4           kettle       0.97    0.93      0.95     9958\n",
      "5        micro avg       0.92    0.89      0.90    48070\n",
      "6        macro avg       0.91    0.89      0.90    48070\n",
      "7     weighted avg       0.92    0.89      0.90    48070\n",
      "8      samples avg       0.93    0.91      0.91    48070\n",
      "-------------------------------------------------\n",
      "Fold 15 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.99      0.96    60539\n",
      "1  washing machine       0.59    0.80      0.68    49848\n",
      "2      dish washer       0.60    0.71      0.65    31498\n",
      "3        microwave       0.63    0.93      0.75    45078\n",
      "4           kettle       0.85    0.69      0.76    53030\n",
      "5        micro avg       0.72    0.84      0.77   239993\n",
      "6        macro avg       0.72    0.82      0.76   239993\n",
      "7     weighted avg       0.74    0.84      0.78   239993\n",
      "8      samples avg       0.69    0.82      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 16 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.92      0.92    11865\n",
      "1  washing machine       0.92    0.84      0.88     8506\n",
      "2      dish washer       0.90    0.80      0.85     8222\n",
      "3        microwave       0.91    0.87      0.89     9541\n",
      "4           kettle       0.96    0.94      0.95     9954\n",
      "5        micro avg       0.93    0.88      0.90    48088\n",
      "6        macro avg       0.92    0.88      0.90    48088\n",
      "7     weighted avg       0.92    0.88      0.90    48088\n",
      "8      samples avg       0.93    0.90      0.91    48088\n",
      "-------------------------------------------------\n",
      "Fold 16 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.96      0.94    60539\n",
      "1  washing machine       0.57    0.81      0.67    49848\n",
      "2      dish washer       0.67    0.67      0.67    31498\n",
      "3        microwave       0.66    0.90      0.76    45078\n",
      "4           kettle       0.86    0.71      0.78    53030\n",
      "5        micro avg       0.73    0.82      0.77   239993\n",
      "6        macro avg       0.74    0.81      0.76   239993\n",
      "7     weighted avg       0.75    0.82      0.78   239993\n",
      "8      samples avg       0.70    0.80      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 17 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.76      0.84    11794\n",
      "1  washing machine       0.54    0.89      0.67     8394\n",
      "2      dish washer       0.85    0.57      0.68     8120\n",
      "3        microwave       0.86    0.60      0.71     9589\n",
      "4           kettle       0.95    0.82      0.88     9895\n",
      "5        micro avg       0.79    0.73      0.76    47792\n",
      "6        macro avg       0.83    0.73      0.76    47792\n",
      "7     weighted avg       0.84    0.73      0.77    47792\n",
      "8      samples avg       0.77    0.73      0.72    47792\n",
      "-------------------------------------------------\n",
      "Fold 17 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.96    0.96      0.96    60539\n",
      "1  washing machine       0.61    0.76      0.68    49848\n",
      "2      dish washer       0.62    0.65      0.63    31498\n",
      "3        microwave       0.56    0.95      0.70    45078\n",
      "4           kettle       0.88    0.70      0.78    53030\n",
      "5        micro avg       0.72    0.82      0.76   239993\n",
      "6        macro avg       0.73    0.80      0.75   239993\n",
      "7     weighted avg       0.75    0.82      0.77   239993\n",
      "8      samples avg       0.72    0.82      0.74   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 18 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.84      0.87    11818\n",
      "1  washing machine       0.52    0.92      0.67     8432\n",
      "2      dish washer       0.86    0.58      0.69     8328\n",
      "3        microwave       0.91    0.54      0.68     9480\n",
      "4           kettle       0.96    0.84      0.90     9933\n",
      "5        micro avg       0.79    0.75      0.77    47991\n",
      "6        macro avg       0.83    0.74      0.76    47991\n",
      "7     weighted avg       0.84    0.75      0.77    47991\n",
      "8      samples avg       0.77    0.75      0.73    47991\n",
      "-------------------------------------------------\n",
      "Fold 18 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.99      0.95    60539\n",
      "1  washing machine       0.64    0.79      0.71    49848\n",
      "2      dish washer       0.60    0.68      0.64    31498\n",
      "3        microwave       0.69    0.83      0.75    45078\n",
      "4           kettle       0.84    0.71      0.77    53030\n",
      "5        micro avg       0.75    0.82      0.78   239993\n",
      "6        macro avg       0.74    0.80      0.76   239993\n",
      "7     weighted avg       0.76    0.82      0.78   239993\n",
      "8      samples avg       0.75    0.82      0.76   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 19 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.92      0.93    11787\n",
      "1  washing machine       0.90    0.86      0.88     8464\n",
      "2      dish washer       0.88    0.82      0.85     8235\n",
      "3        microwave       0.92    0.86      0.89     9610\n",
      "4           kettle       0.97    0.93      0.95     9992\n",
      "5        micro avg       0.92    0.88      0.90    48088\n",
      "6        macro avg       0.92    0.88      0.90    48088\n",
      "7     weighted avg       0.92    0.88      0.90    48088\n",
      "8      samples avg       0.93    0.90      0.91    48088\n",
      "-------------------------------------------------\n",
      "Fold 19 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.96      0.95    60539\n",
      "1  washing machine       0.57    0.84      0.68    49848\n",
      "2      dish washer       0.53    0.73      0.61    31498\n",
      "3        microwave       0.68    0.83      0.75    45078\n",
      "4           kettle       0.73    0.76      0.74    53030\n",
      "5        micro avg       0.69    0.84      0.76   239993\n",
      "6        macro avg       0.69    0.82      0.75   239993\n",
      "7     weighted avg       0.71    0.84      0.77   239993\n",
      "8      samples avg       0.67    0.82      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 20 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.92      0.93    11778\n",
      "1  washing machine       0.91    0.84      0.87     8368\n",
      "2      dish washer       0.85    0.84      0.85     8217\n",
      "3        microwave       0.91    0.87      0.89     9596\n",
      "4           kettle       0.95    0.93      0.94    10082\n",
      "5        micro avg       0.91    0.89      0.90    48041\n",
      "6        macro avg       0.91    0.88      0.90    48041\n",
      "7     weighted avg       0.91    0.89      0.90    48041\n",
      "8      samples avg       0.93    0.90      0.90    48041\n",
      "-------------------------------------------------\n",
      "Fold 20 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.97      0.95    60539\n",
      "1  washing machine       0.57    0.82      0.67    49848\n",
      "2      dish washer       0.55    0.72      0.62    31498\n",
      "3        microwave       0.65    0.86      0.74    45078\n",
      "4           kettle       0.76    0.77      0.77    53030\n",
      "5        micro avg       0.70    0.84      0.76   239993\n",
      "6        macro avg       0.69    0.83      0.75   239993\n",
      "7     weighted avg       0.71    0.84      0.77   239993\n",
      "8      samples avg       0.67    0.82      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 21 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.86    0.90      0.88    11890\n",
      "1  washing machine       0.90    0.72      0.80     8479\n",
      "2      dish washer       0.88    0.58      0.70     8116\n",
      "3        microwave       0.55    0.93      0.69     9604\n",
      "4           kettle       0.96    0.77      0.85    10055\n",
      "5        micro avg       0.78    0.79      0.79    48144\n",
      "6        macro avg       0.83    0.78      0.78    48144\n",
      "7     weighted avg       0.83    0.79      0.79    48144\n",
      "8      samples avg       0.77    0.80      0.76    48144\n",
      "-------------------------------------------------\n",
      "Fold 21 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.99      0.95    60539\n",
      "1  washing machine       0.71    0.61      0.66    49848\n",
      "2      dish washer       0.57    0.70      0.63    31498\n",
      "3        microwave       0.58    0.91      0.71    45078\n",
      "4           kettle       0.94    0.53      0.68    53030\n",
      "5        micro avg       0.73    0.76      0.75   239993\n",
      "6        macro avg       0.74    0.75      0.72   239993\n",
      "7     weighted avg       0.77    0.76      0.74   239993\n",
      "8      samples avg       0.73    0.75      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 22 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.92      0.93    11862\n",
      "1  washing machine       0.88    0.89      0.89     8406\n",
      "2      dish washer       0.89    0.83      0.86     8269\n",
      "3        microwave       0.93    0.86      0.89     9586\n",
      "4           kettle       0.96    0.94      0.95     9876\n",
      "5        micro avg       0.92    0.89      0.91    47999\n",
      "6        macro avg       0.92    0.89      0.90    47999\n",
      "7     weighted avg       0.92    0.89      0.91    47999\n",
      "8      samples avg       0.93    0.91      0.91    47999\n",
      "-------------------------------------------------\n",
      "Fold 22 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.98      0.95    60539\n",
      "1  washing machine       0.57    0.87      0.68    49848\n",
      "2      dish washer       0.63    0.67      0.65    31498\n",
      "3        microwave       0.67    0.85      0.75    45078\n",
      "4           kettle       0.80    0.72      0.76    53030\n",
      "5        micro avg       0.72    0.84      0.77   239993\n",
      "6        macro avg       0.72    0.82      0.76   239993\n",
      "7     weighted avg       0.73    0.84      0.78   239993\n",
      "8      samples avg       0.69    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 23 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.91      0.93    11732\n",
      "1  washing machine       0.91    0.85      0.88     8519\n",
      "2      dish washer       0.90    0.84      0.87     8304\n",
      "3        microwave       0.91    0.87      0.89     9582\n",
      "4           kettle       0.95    0.94      0.95     9995\n",
      "5        micro avg       0.92    0.89      0.91    48132\n",
      "6        macro avg       0.92    0.88      0.90    48132\n",
      "7     weighted avg       0.92    0.89      0.91    48132\n",
      "8      samples avg       0.94    0.90      0.91    48132\n",
      "-------------------------------------------------\n",
      "Fold 23 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.98      0.96    60539\n",
      "1  washing machine       0.57    0.83      0.67    49848\n",
      "2      dish washer       0.76    0.62      0.68    31498\n",
      "3        microwave       0.64    0.92      0.75    45078\n",
      "4           kettle       0.75    0.78      0.76    53030\n",
      "5        micro avg       0.72    0.85      0.78   239993\n",
      "6        macro avg       0.73    0.82      0.77   239993\n",
      "7     weighted avg       0.74    0.85      0.78   239993\n",
      "8      samples avg       0.69    0.83      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 24 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.86      0.89    11836\n",
      "1  washing machine       0.78    0.85      0.81     8450\n",
      "2      dish washer       0.88    0.62      0.73     8204\n",
      "3        microwave       0.92    0.72      0.80     9561\n",
      "4           kettle       0.97    0.87      0.92     9908\n",
      "5        micro avg       0.90    0.79      0.84    47959\n",
      "6        macro avg       0.89    0.78      0.83    47959\n",
      "7     weighted avg       0.90    0.79      0.84    47959\n",
      "8      samples avg       0.89    0.80      0.83    47959\n",
      "-------------------------------------------------\n",
      "Fold 24 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.99      0.96    60539\n",
      "1  washing machine       0.60    0.82      0.69    49848\n",
      "2      dish washer       0.67    0.65      0.66    31498\n",
      "3        microwave       0.59    0.95      0.73    45078\n",
      "4           kettle       0.95    0.65      0.77    53030\n",
      "5        micro avg       0.73    0.83      0.77   239993\n",
      "6        macro avg       0.75    0.81      0.76   239993\n",
      "7     weighted avg       0.77    0.83      0.78   239993\n",
      "8      samples avg       0.72    0.82      0.74   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 25 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.93      0.92    11722\n",
      "1  washing machine       0.90    0.85      0.88     8310\n",
      "2      dish washer       0.86    0.87      0.86     8229\n",
      "3        microwave       0.92    0.86      0.89     9483\n",
      "4           kettle       0.97    0.93      0.95    10022\n",
      "5        micro avg       0.92    0.89      0.90    47766\n",
      "6        macro avg       0.91    0.89      0.90    47766\n",
      "7     weighted avg       0.92    0.89      0.90    47766\n",
      "8      samples avg       0.93    0.91      0.91    47766\n",
      "-------------------------------------------------\n",
      "Fold 25 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.98      0.94    60539\n",
      "1  washing machine       0.57    0.83      0.68    49848\n",
      "2      dish washer       0.60    0.70      0.64    31498\n",
      "3        microwave       0.64    0.91      0.75    45078\n",
      "4           kettle       0.85    0.70      0.77    53030\n",
      "5        micro avg       0.71    0.84      0.77   239993\n",
      "6        macro avg       0.71    0.82      0.76   239993\n",
      "7     weighted avg       0.73    0.84      0.77   239993\n",
      "8      samples avg       0.68    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 26 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.92      0.93    11834\n",
      "1  washing machine       0.89    0.88      0.89     8486\n",
      "2      dish washer       0.86    0.87      0.86     8217\n",
      "3        microwave       0.94    0.86      0.90     9608\n",
      "4           kettle       0.96    0.94      0.95     9991\n",
      "5        micro avg       0.92    0.90      0.91    48136\n",
      "6        macro avg       0.92    0.89      0.90    48136\n",
      "7     weighted avg       0.92    0.90      0.91    48136\n",
      "8      samples avg       0.93    0.91      0.91    48136\n",
      "-------------------------------------------------\n",
      "Fold 26 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.97      0.94    60539\n",
      "1  washing machine       0.57    0.82      0.67    49848\n",
      "2      dish washer       0.54    0.74      0.62    31498\n",
      "3        microwave       0.67    0.89      0.77    45078\n",
      "4           kettle       0.78    0.74      0.76    53030\n",
      "5        micro avg       0.70    0.84      0.76   239993\n",
      "6        macro avg       0.70    0.83      0.75   239993\n",
      "7     weighted avg       0.72    0.84      0.77   239993\n",
      "8      samples avg       0.67    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 27 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.92      0.93    11760\n",
      "1  washing machine       0.88    0.88      0.88     8511\n",
      "2      dish washer       0.88    0.85      0.86     8235\n",
      "3        microwave       0.90    0.87      0.89     9475\n",
      "4           kettle       0.98    0.92      0.95     9937\n",
      "5        micro avg       0.92    0.89      0.91    47918\n",
      "6        macro avg       0.92    0.89      0.90    47918\n",
      "7     weighted avg       0.92    0.89      0.91    47918\n",
      "8      samples avg       0.93    0.91      0.91    47918\n",
      "-------------------------------------------------\n",
      "Fold 27 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.98      0.94    60539\n",
      "1  washing machine       0.57    0.86      0.69    49848\n",
      "2      dish washer       0.57    0.69      0.63    31498\n",
      "3        microwave       0.66    0.90      0.76    45078\n",
      "4           kettle       0.83    0.65      0.73    53030\n",
      "5        micro avg       0.71    0.83      0.76   239993\n",
      "6        macro avg       0.71    0.82      0.75   239993\n",
      "7     weighted avg       0.73    0.83      0.77   239993\n",
      "8      samples avg       0.68    0.81      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 28 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.93      0.92    11821\n",
      "1  washing machine       0.91    0.85      0.88     8312\n",
      "2      dish washer       0.88    0.83      0.85     8213\n",
      "3        microwave       0.91    0.87      0.89     9643\n",
      "4           kettle       0.97    0.93      0.95     9999\n",
      "5        micro avg       0.92    0.89      0.90    47988\n",
      "6        macro avg       0.92    0.88      0.90    47988\n",
      "7     weighted avg       0.92    0.89      0.90    47988\n",
      "8      samples avg       0.93    0.90      0.91    47988\n",
      "-------------------------------------------------\n",
      "Fold 28 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.99      0.95    60539\n",
      "1  washing machine       0.57    0.80      0.67    49848\n",
      "2      dish washer       0.61    0.68      0.64    31498\n",
      "3        microwave       0.64    0.92      0.76    45078\n",
      "4           kettle       0.81    0.64      0.71    53030\n",
      "5        micro avg       0.71    0.82      0.76   239993\n",
      "6        macro avg       0.71    0.80      0.74   239993\n",
      "7     weighted avg       0.73    0.82      0.76   239993\n",
      "8      samples avg       0.67    0.79      0.70   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 29 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.92      0.93    11744\n",
      "1  washing machine       0.89    0.87      0.88     8430\n",
      "2      dish washer       0.89    0.83      0.86     8249\n",
      "3        microwave       0.90    0.88      0.89     9546\n",
      "4           kettle       0.96    0.94      0.95     9980\n",
      "5        micro avg       0.92    0.89      0.90    47949\n",
      "6        macro avg       0.91    0.89      0.90    47949\n",
      "7     weighted avg       0.92    0.89      0.90    47949\n",
      "8      samples avg       0.93    0.91      0.91    47949\n",
      "-------------------------------------------------\n",
      "Fold 29 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.98      0.95    60539\n",
      "1  washing machine       0.57    0.84      0.68    49848\n",
      "2      dish washer       0.68    0.64      0.66    31498\n",
      "3        microwave       0.63    0.90      0.74    45078\n",
      "4           kettle       0.79    0.73      0.76    53030\n",
      "5        micro avg       0.71    0.84      0.77   239993\n",
      "6        macro avg       0.72    0.82      0.76   239993\n",
      "7     weighted avg       0.73    0.84      0.77   239993\n",
      "8      samples avg       0.69    0.82      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 30 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.91      0.93    11883\n",
      "1  washing machine       0.90    0.86      0.88     8425\n",
      "2      dish washer       0.88    0.82      0.85     8208\n",
      "3        microwave       0.92    0.85      0.89     9544\n",
      "4           kettle       0.96    0.93      0.95     9949\n",
      "5        micro avg       0.92    0.88      0.90    48009\n",
      "6        macro avg       0.92    0.88      0.90    48009\n",
      "7     weighted avg       0.92    0.88      0.90    48009\n",
      "8      samples avg       0.94    0.90      0.91    48009\n",
      "-------------------------------------------------\n",
      "Fold 30 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.98      0.96    60539\n",
      "1  washing machine       0.57    0.85      0.68    49848\n",
      "2      dish washer       0.70    0.64      0.67    31498\n",
      "3        microwave       0.70    0.89      0.78    45078\n",
      "4           kettle       0.89    0.68      0.77    53030\n",
      "5        micro avg       0.75    0.83      0.78   239993\n",
      "6        macro avg       0.76    0.81      0.77   239993\n",
      "7     weighted avg       0.77    0.83      0.79   239993\n",
      "8      samples avg       0.72    0.81      0.74   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 31 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.92      0.93    11875\n",
      "1  washing machine       0.92    0.85      0.89     8512\n",
      "2      dish washer       0.86    0.86      0.86     8137\n",
      "3        microwave       0.89    0.88      0.89     9475\n",
      "4           kettle       0.97    0.92      0.95     9969\n",
      "5        micro avg       0.92    0.89      0.90    47968\n",
      "6        macro avg       0.92    0.89      0.90    47968\n",
      "7     weighted avg       0.92    0.89      0.90    47968\n",
      "8      samples avg       0.93    0.91      0.91    47968\n",
      "-------------------------------------------------\n",
      "Fold 31 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.96      0.94    60539\n",
      "1  washing machine       0.58    0.81      0.67    49848\n",
      "2      dish washer       0.52    0.75      0.61    31498\n",
      "3        microwave       0.64    0.92      0.76    45078\n",
      "4           kettle       0.78    0.66      0.71    53030\n",
      "5        micro avg       0.69    0.83      0.75   239993\n",
      "6        macro avg       0.69    0.82      0.74   239993\n",
      "7     weighted avg       0.71    0.83      0.76   239993\n",
      "8      samples avg       0.66    0.80      0.70   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 32 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.92      0.93    11766\n",
      "1  washing machine       0.90    0.88      0.89     8431\n",
      "2      dish washer       0.89    0.84      0.86     8239\n",
      "3        microwave       0.92    0.88      0.89     9563\n",
      "4           kettle       0.97    0.94      0.95     9968\n",
      "5        micro avg       0.92    0.89      0.91    47967\n",
      "6        macro avg       0.92    0.89      0.91    47967\n",
      "7     weighted avg       0.92    0.89      0.91    47967\n",
      "8      samples avg       0.94    0.91      0.92    47967\n",
      "-------------------------------------------------\n",
      "Fold 32 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.97      0.95    60539\n",
      "1  washing machine       0.57    0.85      0.68    49848\n",
      "2      dish washer       0.59    0.67      0.63    31498\n",
      "3        microwave       0.65    0.90      0.75    45078\n",
      "4           kettle       0.83    0.70      0.76    53030\n",
      "5        micro avg       0.71    0.83      0.77   239993\n",
      "6        macro avg       0.71    0.82      0.75   239993\n",
      "7     weighted avg       0.73    0.83      0.77   239993\n",
      "8      samples avg       0.69    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 33 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.95    0.91      0.93    11780\n",
      "1  washing machine       0.90    0.87      0.88     8358\n",
      "2      dish washer       0.89    0.85      0.87     8275\n",
      "3        microwave       0.90    0.89      0.89     9670\n",
      "4           kettle       0.96    0.94      0.95     9962\n",
      "5        micro avg       0.92    0.89      0.91    48045\n",
      "6        macro avg       0.92    0.89      0.90    48045\n",
      "7     weighted avg       0.92    0.89      0.91    48045\n",
      "8      samples avg       0.93    0.91      0.91    48045\n",
      "-------------------------------------------------\n",
      "Fold 33 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.97      0.94    60539\n",
      "1  washing machine       0.57    0.83      0.68    49848\n",
      "2      dish washer       0.66    0.64      0.65    31498\n",
      "3        microwave       0.60    0.91      0.72    45078\n",
      "4           kettle       0.79    0.75      0.77    53030\n",
      "5        micro avg       0.70    0.84      0.76   239993\n",
      "6        macro avg       0.71    0.82      0.75   239993\n",
      "7     weighted avg       0.72    0.84      0.77   239993\n",
      "8      samples avg       0.67    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 34 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.93      0.92    11846\n",
      "1  washing machine       0.89    0.85      0.87     8455\n",
      "2      dish washer       0.87    0.81      0.84     8185\n",
      "3        microwave       0.91    0.85      0.87     9533\n",
      "4           kettle       0.95    0.94      0.95     9982\n",
      "5        micro avg       0.91    0.88      0.89    48001\n",
      "6        macro avg       0.91    0.87      0.89    48001\n",
      "7     weighted avg       0.91    0.88      0.89    48001\n",
      "8      samples avg       0.92    0.90      0.90    48001\n",
      "-------------------------------------------------\n",
      "Fold 34 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.99      0.95    60539\n",
      "1  washing machine       0.57    0.85      0.68    49848\n",
      "2      dish washer       0.71    0.63      0.67    31498\n",
      "3        microwave       0.62    0.93      0.74    45078\n",
      "4           kettle       0.78    0.75      0.77    53030\n",
      "5        micro avg       0.71    0.85      0.77   239993\n",
      "6        macro avg       0.72    0.83      0.76   239993\n",
      "7     weighted avg       0.73    0.85      0.78   239993\n",
      "8      samples avg       0.68    0.83      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 35 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.93      0.93    11775\n",
      "1  washing machine       0.89    0.87      0.88     8408\n",
      "2      dish washer       0.90    0.81      0.86     8286\n",
      "3        microwave       0.92    0.86      0.89     9575\n",
      "4           kettle       0.97    0.92      0.94     9975\n",
      "5        micro avg       0.92    0.88      0.90    48019\n",
      "6        macro avg       0.92    0.88      0.90    48019\n",
      "7     weighted avg       0.92    0.88      0.90    48019\n",
      "8      samples avg       0.93    0.90      0.91    48019\n",
      "-------------------------------------------------\n",
      "Fold 35 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.99      0.94    60539\n",
      "1  washing machine       0.57    0.84      0.68    49848\n",
      "2      dish washer       0.63    0.66      0.64    31498\n",
      "3        microwave       0.68    0.88      0.77    45078\n",
      "4           kettle       0.89    0.61      0.73    53030\n",
      "5        micro avg       0.73    0.81      0.77   239993\n",
      "6        macro avg       0.73    0.80      0.75   239993\n",
      "7     weighted avg       0.75    0.81      0.77   239993\n",
      "8      samples avg       0.69    0.79      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 36 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.73    0.70      0.71    11874\n",
      "1  washing machine       0.58    0.12      0.19     8429\n",
      "2      dish washer       0.59    0.12      0.19     8174\n",
      "3        microwave       0.71    0.30      0.42     9533\n",
      "4           kettle       0.59    0.29      0.39     9925\n",
      "5        micro avg       0.67    0.34      0.45    47935\n",
      "6        macro avg       0.64    0.31      0.38    47935\n",
      "7     weighted avg       0.64    0.34      0.41    47935\n",
      "8      samples avg       0.49    0.35      0.38    47935\n",
      "-------------------------------------------------\n",
      "Fold 36 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.79    0.75      0.77    60539\n",
      "1  washing machine       0.52    0.38      0.44    49848\n",
      "2      dish washer       0.35    0.29      0.32    31498\n",
      "3        microwave       0.52    0.63      0.57    45078\n",
      "4           kettle       0.63    0.41      0.50    53030\n",
      "5        micro avg       0.59    0.51      0.55   239993\n",
      "6        macro avg       0.56    0.49      0.52   239993\n",
      "7     weighted avg       0.59    0.51      0.54   239993\n",
      "8      samples avg       0.47    0.48      0.43   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 37 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.92      0.93    11808\n",
      "1  washing machine       0.89    0.88      0.88     8450\n",
      "2      dish washer       0.90    0.83      0.86     8240\n",
      "3        microwave       0.93    0.85      0.89     9680\n",
      "4           kettle       0.96    0.94      0.95     9961\n",
      "5        micro avg       0.92    0.89      0.90    48139\n",
      "6        macro avg       0.92    0.88      0.90    48139\n",
      "7     weighted avg       0.92    0.89      0.90    48139\n",
      "8      samples avg       0.93    0.90      0.91    48139\n",
      "-------------------------------------------------\n",
      "Fold 37 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.99      0.95    60539\n",
      "1  washing machine       0.57    0.84      0.68    49848\n",
      "2      dish washer       0.58    0.70      0.63    31498\n",
      "3        microwave       0.66    0.85      0.75    45078\n",
      "4           kettle       0.89    0.68      0.77    53030\n",
      "5        micro avg       0.72    0.83      0.77   239993\n",
      "6        macro avg       0.72    0.81      0.76   239993\n",
      "7     weighted avg       0.75    0.83      0.78   239993\n",
      "8      samples avg       0.69    0.81      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 38 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.86    0.85      0.86    11775\n",
      "1  washing machine       0.81    0.74      0.77     8381\n",
      "2      dish washer       0.90    0.49      0.63     8220\n",
      "3        microwave       0.51    0.97      0.67     9499\n",
      "4           kettle       0.97    0.78      0.87     9992\n",
      "5        micro avg       0.75    0.78      0.76    47867\n",
      "6        macro avg       0.81    0.77      0.76    47867\n",
      "7     weighted avg       0.81    0.78      0.77    47867\n",
      "8      samples avg       0.72    0.78      0.72    47867\n",
      "-------------------------------------------------\n",
      "Fold 38 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.99      0.95    60539\n",
      "1  washing machine       0.63    0.71      0.67    49848\n",
      "2      dish washer       0.74    0.59      0.65    31498\n",
      "3        microwave       0.47    1.00      0.64    45078\n",
      "4           kettle       0.96    0.61      0.75    53030\n",
      "5        micro avg       0.69    0.79      0.74   239993\n",
      "6        macro avg       0.74    0.78      0.73   239993\n",
      "7     weighted avg       0.76    0.79      0.75   239993\n",
      "8      samples avg       0.66    0.78      0.69   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 39 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.92      0.92    11747\n",
      "1  washing machine       0.91    0.87      0.89     8522\n",
      "2      dish washer       0.89    0.81      0.85     8233\n",
      "3        microwave       0.92    0.85      0.89     9541\n",
      "4           kettle       0.96    0.93      0.95    10000\n",
      "5        micro avg       0.92    0.88      0.90    48043\n",
      "6        macro avg       0.92    0.88      0.90    48043\n",
      "7     weighted avg       0.92    0.88      0.90    48043\n",
      "8      samples avg       0.94    0.90      0.91    48043\n",
      "-------------------------------------------------\n",
      "Fold 39 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.99      0.95    60539\n",
      "1  washing machine       0.57    0.82      0.67    49848\n",
      "2      dish washer       0.68    0.63      0.66    31498\n",
      "3        microwave       0.63    0.91      0.74    45078\n",
      "4           kettle       0.82    0.71      0.76    53030\n",
      "5        micro avg       0.72    0.83      0.77   239993\n",
      "6        macro avg       0.72    0.81      0.76   239993\n",
      "7     weighted avg       0.74    0.83      0.77   239993\n",
      "8      samples avg       0.69    0.81      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 40 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.85      0.88    11838\n",
      "1  washing machine       0.90    0.67      0.77     8382\n",
      "2      dish washer       0.88    0.58      0.70     8255\n",
      "3        microwave       0.59    0.94      0.72     9563\n",
      "4           kettle       0.94    0.85      0.90     9978\n",
      "5        micro avg       0.81    0.79      0.80    48016\n",
      "6        macro avg       0.84    0.78      0.79    48016\n",
      "7     weighted avg       0.84    0.79      0.80    48016\n",
      "8      samples avg       0.79    0.79      0.77    48016\n",
      "-------------------------------------------------\n",
      "Fold 40 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.96    0.97      0.96    60539\n",
      "1  washing machine       0.75    0.45      0.56    49848\n",
      "2      dish washer       0.72    0.63      0.67    31498\n",
      "3        microwave       0.51    0.98      0.67    45078\n",
      "4           kettle       0.83    0.71      0.77    53030\n",
      "5        micro avg       0.73    0.76      0.75   239993\n",
      "6        macro avg       0.75    0.75      0.73   239993\n",
      "7     weighted avg       0.77    0.76      0.74   239993\n",
      "8      samples avg       0.69    0.75      0.70   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Using koef 1.7\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 127s 170ms/step - loss: inf - F1Score: 0.6287 - WeightedF1: 0.6688 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 80s 133ms/step - loss: inf - F1Score: 0.7603 - WeightedF1: 0.7866 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 80s 133ms/step - loss: inf - F1Score: 0.8175 - WeightedF1: 0.8335 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 80s 133ms/step - loss: inf - F1Score: 0.8610 - WeightedF1: 0.8743 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 80s 133ms/step - loss: inf - F1Score: 0.8834 - WeightedF1: 0.8957 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 80s 133ms/step - loss: inf - F1Score: 0.8930 - WeightedF1: 0.9046 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 80s 133ms/step - loss: inf - F1Score: 0.9027 - WeightedF1: 0.9136 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 80s 133ms/step - loss: inf - F1Score: 0.9097 - WeightedF1: 0.9203 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 80s 133ms/step - loss: inf - F1Score: 0.9135 - WeightedF1: 0.9237 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 80s 133ms/step - loss: inf - F1Score: 0.9179 - WeightedF1: 0.9277 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 79s 132ms/step - loss: inf - F1Score: 0.9228 - WeightedF1: 0.9321 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 79s 132ms/step - loss: inf - F1Score: 0.9264 - WeightedF1: 0.9354 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 79s 132ms/step - loss: inf - F1Score: 0.9300 - WeightedF1: 0.9386 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 80s 133ms/step - loss: inf - F1Score: 0.9336 - WeightedF1: 0.9418 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 80s 133ms/step - loss: inf - F1Score: 0.9366 - WeightedF1: 0.9445 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 80s 133ms/step - loss: inf - F1Score: 0.9397 - WeightedF1: 0.9471 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 80s 133ms/step - loss: inf - F1Score: 0.9447 - WeightedF1: 0.9513 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 79s 132ms/step - loss: inf - F1Score: 0.9476 - WeightedF1: 0.9537 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 80s 133ms/step - loss: inf - F1Score: 0.9508 - WeightedF1: 0.9566 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 79s 132ms/step - loss: inf - F1Score: 0.9542 - WeightedF1: 0.9596 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 9s 13ms/step\n",
      "3000/3000 [==============================] - 38s 13ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 82s 133ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 80s 133ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 80s 133ms/step - loss: inf - F1Score: 0.7528 - WeightedF1: 0.7796 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 80s 133ms/step - loss: inf - F1Score: 0.8089 - WeightedF1: 0.8254 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 79s 132ms/step - loss: inf - F1Score: 0.8213 - WeightedF1: 0.8333 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 79s 132ms/step - loss: inf - F1Score: 0.8234 - WeightedF1: 0.8349 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 80s 133ms/step - loss: inf - F1Score: 0.8687 - WeightedF1: 0.8815 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 80s 133ms/step - loss: inf - F1Score: 0.8868 - WeightedF1: 0.8985 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 79s 132ms/step - loss: inf - F1Score: 0.8986 - WeightedF1: 0.9095 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 80s 133ms/step - loss: inf - F1Score: 0.9066 - WeightedF1: 0.9169 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 80s 133ms/step - loss: inf - F1Score: 0.9127 - WeightedF1: 0.9225 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 80s 133ms/step - loss: inf - F1Score: 0.9189 - WeightedF1: 0.9284 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 80s 133ms/step - loss: inf - F1Score: 0.9222 - WeightedF1: 0.9314 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 80s 133ms/step - loss: inf - F1Score: 0.9274 - WeightedF1: 0.9362 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 80s 133ms/step - loss: inf - F1Score: 0.9301 - WeightedF1: 0.9387 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 80s 133ms/step - loss: inf - F1Score: 0.9335 - WeightedF1: 0.9417 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 80s 134ms/step - loss: inf - F1Score: 0.9369 - WeightedF1: 0.9447 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 80s 134ms/step - loss: inf - F1Score: 0.9396 - WeightedF1: 0.9472 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 80s 133ms/step - loss: inf - F1Score: 0.9429 - WeightedF1: 0.9502 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 80s 133ms/step - loss: inf - F1Score: 0.9463 - WeightedF1: 0.9533 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 8s 13ms/step\n",
      "3000/3000 [==============================] - 38s 13ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 81s 131ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 79s 131ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 79s 131ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 79s 132ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 79s 131ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 79s 131ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 79s 131ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 78s 131ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 78s 131ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 79s 131ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 79s 131ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 79s 131ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 78s 131ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 78s 131ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 78s 131ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 78s 131ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 79s 131ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 79s 131ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 78s 131ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 78s 130ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.1036e-04\n",
      "600/600 [==============================] - 8s 12ms/step\n",
      "3000/3000 [==============================] - 38s 13ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 106s 171ms/step - loss: inf - F1Score: 0.6330 - WeightedF1: 0.6773 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 80s 133ms/step - loss: inf - F1Score: 0.7510 - WeightedF1: 0.7799 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 80s 134ms/step - loss: inf - F1Score: 0.8065 - WeightedF1: 0.8234 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 80s 133ms/step - loss: inf - F1Score: 0.8515 - WeightedF1: 0.8667 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 80s 134ms/step - loss: inf - F1Score: 0.8817 - WeightedF1: 0.8942 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 80s 134ms/step - loss: inf - F1Score: 0.8947 - WeightedF1: 0.9062 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 80s 133ms/step - loss: inf - F1Score: 0.9086 - WeightedF1: 0.9192 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 80s 134ms/step - loss: inf - F1Score: 0.9151 - WeightedF1: 0.9250 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 80s 134ms/step - loss: inf - F1Score: 0.9186 - WeightedF1: 0.9281 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 80s 134ms/step - loss: inf - F1Score: 0.9236 - WeightedF1: 0.9324 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 80s 134ms/step - loss: inf - F1Score: 0.9284 - WeightedF1: 0.9368 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 80s 134ms/step - loss: inf - F1Score: 0.9326 - WeightedF1: 0.9407 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 80s 133ms/step - loss: inf - F1Score: 0.9350 - WeightedF1: 0.9428 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 80s 134ms/step - loss: inf - F1Score: 0.9391 - WeightedF1: 0.9466 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 80s 133ms/step - loss: inf - F1Score: 0.9429 - WeightedF1: 0.9497 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 80s 133ms/step - loss: inf - F1Score: 0.9469 - WeightedF1: 0.9530 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 80s 133ms/step - loss: inf - F1Score: 0.9513 - WeightedF1: 0.9570 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 80s 133ms/step - loss: inf - F1Score: 0.9539 - WeightedF1: 0.9594 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 80s 133ms/step - loss: inf - F1Score: 0.9575 - WeightedF1: 0.9626 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 80s 133ms/step - loss: inf - F1Score: 0.9607 - WeightedF1: 0.9656 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 9s 15ms/step\n",
      "3000/3000 [==============================] - 39s 13ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 82s 132ms/step - loss: inf - F1Score: 0.6178 - WeightedF1: 0.6599 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 79s 132ms/step - loss: inf - F1Score: 0.7253 - WeightedF1: 0.7562 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 80s 133ms/step - loss: inf - F1Score: 0.8036 - WeightedF1: 0.8193 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 79s 132ms/step - loss: inf - F1Score: 0.8612 - WeightedF1: 0.8743 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 79s 132ms/step - loss: inf - F1Score: 0.8829 - WeightedF1: 0.8943 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 79s 131ms/step - loss: inf - F1Score: 0.8796 - WeightedF1: 0.8907 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 79s 131ms/step - loss: inf - F1Score: 0.8795 - WeightedF1: 0.8906 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 79s 131ms/step - loss: inf - F1Score: 0.8796 - WeightedF1: 0.8907 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 79s 131ms/step - loss: inf - F1Score: 0.8795 - WeightedF1: 0.8906 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 79s 131ms/step - loss: inf - F1Score: 0.8796 - WeightedF1: 0.8907 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 78s 131ms/step - loss: inf - F1Score: 0.8796 - WeightedF1: 0.8907 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 79s 131ms/step - loss: inf - F1Score: 0.8795 - WeightedF1: 0.8906 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 79s 131ms/step - loss: inf - F1Score: 0.8795 - WeightedF1: 0.8906 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 78s 131ms/step - loss: inf - F1Score: 0.8794 - WeightedF1: 0.8906 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 78s 131ms/step - loss: inf - F1Score: 0.8795 - WeightedF1: 0.8906 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 79s 131ms/step - loss: inf - F1Score: 0.8796 - WeightedF1: 0.8906 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 79s 131ms/step - loss: inf - F1Score: 0.8796 - WeightedF1: 0.8907 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 79s 131ms/step - loss: inf - F1Score: 0.8794 - WeightedF1: 0.8905 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 78s 131ms/step - loss: inf - F1Score: 0.8797 - WeightedF1: 0.8907 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 78s 131ms/step - loss: inf - F1Score: 0.8796 - WeightedF1: 0.8906 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 8s 13ms/step\n",
      "3000/3000 [==============================] - 39s 13ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 81s 131ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 78s 130ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 78s 130ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 78s 131ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 78s 130ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 78s 130ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 78s 130ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 78s 130ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 78s 131ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 78s 130ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 78s 130ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 78s 130ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 78s 130ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 78s 130ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 78s 131ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 78s 130ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 78s 130ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 78s 130ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 78s 130ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 78s 130ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.1036e-04\n",
      "600/600 [==============================] - 8s 13ms/step\n",
      "600/600 [==============================] - 78s 130ms/step - loss: inf - F1Score: 0.7904 - WeightedF1: 0.7969 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 78s 131ms/step - loss: inf - F1Score: 0.8005 - WeightedF1: 0.8071 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 79s 132ms/step - loss: inf - F1Score: 0.8316 - WeightedF1: 0.8382 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 79s 132ms/step - loss: inf - F1Score: 0.8484 - WeightedF1: 0.8543 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 79s 132ms/step - loss: inf - F1Score: 0.8621 - WeightedF1: 0.8674 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 79s 131ms/step - loss: inf - F1Score: 0.8744 - WeightedF1: 0.8790 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 79s 132ms/step - loss: inf - F1Score: 0.8827 - WeightedF1: 0.8870 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 79s 132ms/step - loss: inf - F1Score: 0.8919 - WeightedF1: 0.8957 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 79s 132ms/step - loss: inf - F1Score: 0.9003 - WeightedF1: 0.9037 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 79s 132ms/step - loss: inf - F1Score: 0.9081 - WeightedF1: 0.9111 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 79s 132ms/step - loss: inf - F1Score: 0.9142 - WeightedF1: 0.9170 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 8s 13ms/step\n",
      "3000/3000 [==============================] - 38s 13ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 81s 131ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 78s 131ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 78s 130ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 78s 130ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 78s 130ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 78s 130ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 78s 130ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 78s 130ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 78s 130ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 78s 130ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 78s 130ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 78s 130ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 78s 130ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 78s 130ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 78s 130ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 78s 130ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 78s 131ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 78s 130ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 78s 130ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 78s 130ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.1036e-04\n",
      "600/600 [==============================] - 8s 13ms/step\n",
      "3000/3000 [==============================] - 41s 13ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 81s 130ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 78s 131ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 78s 130ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 78s 131ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 78s 130ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 78s 131ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 78s 130ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 78s 130ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 78s 130ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 78s 130ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 78s 131ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 78s 131ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 78s 130ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 78s 130ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 78s 130ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 78s 130ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 78s 130ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 78s 130ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 78s 130ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 78s 130ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.1036e-04\n",
      "600/600 [==============================] - 8s 13ms/step\n",
      "3000/3000 [==============================] - 39s 13ms/step\n",
      "Fold 1 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.87    0.92      0.89    11706\n",
      "1  washing machine       0.90    0.75      0.82     8507\n",
      "2      dish washer       0.83    0.73      0.78     8309\n",
      "3        microwave       0.88    0.82      0.85     9549\n",
      "4           kettle       0.96    0.89      0.92     9949\n",
      "5        micro avg       0.89    0.83      0.86    48020\n",
      "6        macro avg       0.89    0.82      0.85    48020\n",
      "7     weighted avg       0.89    0.83      0.86    48020\n",
      "8      samples avg       0.89    0.84      0.85    48020\n",
      "-------------------------------------------------\n",
      "Fold 1 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.99      0.96    60539\n",
      "1  washing machine       0.74    0.55      0.63    49848\n",
      "2      dish washer       0.55    0.73      0.63    31498\n",
      "3        microwave       0.63    0.93      0.75    45078\n",
      "4           kettle       0.73    0.82      0.77    53030\n",
      "5        micro avg       0.72    0.82      0.77   239993\n",
      "6        macro avg       0.71    0.81      0.75   239993\n",
      "7     weighted avg       0.74    0.82      0.77   239993\n",
      "8      samples avg       0.71    0.80      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 2 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.89    0.90      0.90    11903\n",
      "1  washing machine       0.88    0.76      0.82     8383\n",
      "2      dish washer       0.81    0.77      0.79     8279\n",
      "3        microwave       0.86    0.82      0.84     9584\n",
      "4           kettle       0.95    0.91      0.93     9899\n",
      "5        micro avg       0.88    0.84      0.86    48048\n",
      "6        macro avg       0.88    0.83      0.85    48048\n",
      "7     weighted avg       0.88    0.84      0.86    48048\n",
      "8      samples avg       0.89    0.85      0.86    48048\n",
      "-------------------------------------------------\n",
      "Fold 2 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.99      0.96    60539\n",
      "1  washing machine       0.62    0.69      0.66    49848\n",
      "2      dish washer       0.51    0.76      0.61    31498\n",
      "3        microwave       0.62    0.95      0.75    45078\n",
      "4           kettle       0.83    0.74      0.79    53030\n",
      "5        micro avg       0.71    0.83      0.77   239993\n",
      "6        macro avg       0.70    0.83      0.75   239993\n",
      "7     weighted avg       0.73    0.83      0.77   239993\n",
      "8      samples avg       0.69    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 3 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.85    0.92      0.88    11755\n",
      "1  washing machine       0.91    0.74      0.82     8482\n",
      "2      dish washer       0.82    0.71      0.76     8145\n",
      "3        microwave       0.88    0.73      0.80     9633\n",
      "4           kettle       0.95    0.90      0.92     9989\n",
      "5        micro avg       0.88    0.81      0.84    48004\n",
      "6        macro avg       0.88    0.80      0.84    48004\n",
      "7     weighted avg       0.88    0.81      0.84    48004\n",
      "8      samples avg       0.89    0.82      0.84    48004\n",
      "-------------------------------------------------\n",
      "Fold 3 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.98      0.94    60539\n",
      "1  washing machine       0.61    0.72      0.66    49848\n",
      "2      dish washer       0.62    0.68      0.65    31498\n",
      "3        microwave       0.66    0.85      0.74    45078\n",
      "4           kettle       0.77    0.76      0.77    53030\n",
      "5        micro avg       0.72    0.82      0.77   239993\n",
      "6        macro avg       0.71    0.80      0.75   239993\n",
      "7     weighted avg       0.73    0.82      0.77   239993\n",
      "8      samples avg       0.69    0.80      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 4 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.88    0.90      0.89    11880\n",
      "1  washing machine       0.90    0.75      0.82     8396\n",
      "2      dish washer       0.85    0.68      0.75     8215\n",
      "3        microwave       0.88    0.73      0.80     9566\n",
      "4           kettle       0.95    0.90      0.92    10018\n",
      "5        micro avg       0.89    0.80      0.85    48075\n",
      "6        macro avg       0.89    0.79      0.84    48075\n",
      "7     weighted avg       0.89    0.80      0.84    48075\n",
      "8      samples avg       0.90    0.82      0.84    48075\n",
      "-------------------------------------------------\n",
      "Fold 4 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.99      0.96    60539\n",
      "1  washing machine       0.59    0.75      0.66    49848\n",
      "2      dish washer       0.75    0.62      0.68    31498\n",
      "3        microwave       0.59    0.92      0.72    45078\n",
      "4           kettle       0.91    0.71      0.80    53030\n",
      "5        micro avg       0.74    0.82      0.78   239993\n",
      "6        macro avg       0.76    0.80      0.76   239993\n",
      "7     weighted avg       0.77    0.82      0.78   239993\n",
      "8      samples avg       0.72    0.81      0.74   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 5 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.88    0.90      0.89    11798\n",
      "1  washing machine       0.91    0.73      0.81     8396\n",
      "2      dish washer       0.84    0.69      0.75     8174\n",
      "3        microwave       0.85    0.79      0.82     9484\n",
      "4           kettle       0.96    0.87      0.91    10001\n",
      "5        micro avg       0.89    0.81      0.84    47853\n",
      "6        macro avg       0.89    0.79      0.84    47853\n",
      "7     weighted avg       0.89    0.81      0.84    47853\n",
      "8      samples avg       0.89    0.82      0.84    47853\n",
      "-------------------------------------------------\n",
      "Fold 5 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.98      0.96    60539\n",
      "1  washing machine       0.62    0.68      0.65    49848\n",
      "2      dish washer       0.70    0.64      0.67    31498\n",
      "3        microwave       0.57    0.96      0.72    45078\n",
      "4           kettle       0.85    0.72      0.78    53030\n",
      "5        micro avg       0.73    0.81      0.77   239993\n",
      "6        macro avg       0.74    0.80      0.75   239993\n",
      "7     weighted avg       0.75    0.81      0.77   239993\n",
      "8      samples avg       0.70    0.80      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 6 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.91      0.92    11828\n",
      "1  washing machine       0.91    0.82      0.86     8389\n",
      "2      dish washer       0.89    0.80      0.85     8207\n",
      "3        microwave       0.92    0.85      0.89     9542\n",
      "4           kettle       0.96    0.93      0.95     9968\n",
      "5        micro avg       0.93    0.87      0.90    47934\n",
      "6        macro avg       0.93    0.86      0.89    47934\n",
      "7     weighted avg       0.93    0.87      0.90    47934\n",
      "8      samples avg       0.93    0.88      0.90    47934\n",
      "-------------------------------------------------\n",
      "Fold 6 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.95    0.92      0.94    60539\n",
      "1  washing machine       0.60    0.70      0.65    49848\n",
      "2      dish washer       0.57    0.70      0.62    31498\n",
      "3        microwave       0.69    0.92      0.79    45078\n",
      "4           kettle       0.77    0.73      0.75    53030\n",
      "5        micro avg       0.72    0.80      0.76   239993\n",
      "6        macro avg       0.71    0.79      0.75   239993\n",
      "7     weighted avg       0.74    0.80      0.77   239993\n",
      "8      samples avg       0.69    0.78      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 7 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.91      0.91    11670\n",
      "1  washing machine       0.90    0.82      0.86     8394\n",
      "2      dish washer       0.87    0.78      0.82     8254\n",
      "3        microwave       0.89    0.85      0.87     9554\n",
      "4           kettle       0.96    0.92      0.94     9928\n",
      "5        micro avg       0.91    0.86      0.88    47800\n",
      "6        macro avg       0.91    0.86      0.88    47800\n",
      "7     weighted avg       0.91    0.86      0.88    47800\n",
      "8      samples avg       0.92    0.88      0.89    47800\n",
      "-------------------------------------------------\n",
      "Fold 7 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.98      0.96    60539\n",
      "1  washing machine       0.56    0.83      0.67    49848\n",
      "2      dish washer       0.71    0.65      0.67    31498\n",
      "3        microwave       0.63    0.90      0.74    45078\n",
      "4           kettle       0.80    0.73      0.76    53030\n",
      "5        micro avg       0.72    0.84      0.77   239993\n",
      "6        macro avg       0.73    0.82      0.76   239993\n",
      "7     weighted avg       0.74    0.84      0.78   239993\n",
      "8      samples avg       0.68    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 8 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.84      0.89    11782\n",
      "1  washing machine       0.63    0.91      0.74     8527\n",
      "2      dish washer       0.93    0.60      0.73     8269\n",
      "3        microwave       0.87    0.80      0.83     9595\n",
      "4           kettle       0.94    0.89      0.92     9911\n",
      "5        micro avg       0.84    0.81      0.83    48084\n",
      "6        macro avg       0.86    0.81      0.82    48084\n",
      "7     weighted avg       0.87    0.81      0.83    48084\n",
      "8      samples avg       0.84    0.83      0.82    48084\n",
      "-------------------------------------------------\n",
      "Fold 8 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.96    0.98      0.97    60539\n",
      "1  washing machine       0.57    0.85      0.68    49848\n",
      "2      dish washer       0.90    0.57      0.70    31498\n",
      "3        microwave       0.62    0.91      0.74    45078\n",
      "4           kettle       0.78    0.78      0.78    53030\n",
      "5        micro avg       0.73    0.84      0.78   239993\n",
      "6        macro avg       0.77    0.82      0.77   239993\n",
      "7     weighted avg       0.77    0.84      0.79   239993\n",
      "8      samples avg       0.72    0.84      0.75   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 9 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.93      0.92    11834\n",
      "1  washing machine       0.91    0.80      0.85     8478\n",
      "2      dish washer       0.85    0.79      0.82     8188\n",
      "3        microwave       0.93    0.83      0.87     9619\n",
      "4           kettle       0.96    0.93      0.94    10086\n",
      "5        micro avg       0.91    0.86      0.89    48205\n",
      "6        macro avg       0.91    0.85      0.88    48205\n",
      "7     weighted avg       0.91    0.86      0.89    48205\n",
      "8      samples avg       0.92    0.88      0.89    48205\n",
      "-------------------------------------------------\n",
      "Fold 9 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.89      0.90    60539\n",
      "1  washing machine       0.57    0.81      0.67    49848\n",
      "2      dish washer       0.58    0.71      0.64    31498\n",
      "3        microwave       0.67    0.85      0.75    45078\n",
      "4           kettle       0.86    0.72      0.78    53030\n",
      "5        micro avg       0.72    0.81      0.76   239993\n",
      "6        macro avg       0.72    0.80      0.75   239993\n",
      "7     weighted avg       0.74    0.81      0.76   239993\n",
      "8      samples avg       0.69    0.78      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 10 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.93      0.92    11928\n",
      "1  washing machine       0.90    0.81      0.85     8376\n",
      "2      dish washer       0.87    0.79      0.82     8204\n",
      "3        microwave       0.88    0.86      0.87     9506\n",
      "4           kettle       0.95    0.92      0.94     9963\n",
      "5        micro avg       0.91    0.87      0.89    47977\n",
      "6        macro avg       0.90    0.86      0.88    47977\n",
      "7     weighted avg       0.91    0.87      0.89    47977\n",
      "8      samples avg       0.92    0.88      0.89    47977\n",
      "-------------------------------------------------\n",
      "Fold 10 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.99      0.95    60539\n",
      "1  washing machine       0.58    0.80      0.67    49848\n",
      "2      dish washer       0.67    0.65      0.66    31498\n",
      "3        microwave       0.65    0.91      0.76    45078\n",
      "4           kettle       0.78    0.77      0.78    53030\n",
      "5        micro avg       0.72    0.84      0.78   239993\n",
      "6        macro avg       0.72    0.82      0.76   239993\n",
      "7     weighted avg       0.74    0.84      0.78   239993\n",
      "8      samples avg       0.70    0.82      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 11 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.91      0.92    11776\n",
      "1  washing machine       0.92    0.82      0.87     8517\n",
      "2      dish washer       0.86    0.82      0.84     8190\n",
      "3        microwave       0.89    0.87      0.88     9613\n",
      "4           kettle       0.97    0.92      0.95     9969\n",
      "5        micro avg       0.92    0.88      0.90    48065\n",
      "6        macro avg       0.91    0.87      0.89    48065\n",
      "7     weighted avg       0.92    0.88      0.90    48065\n",
      "8      samples avg       0.93    0.89      0.90    48065\n",
      "-------------------------------------------------\n",
      "Fold 11 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.94      0.94    60539\n",
      "1  washing machine       0.57    0.81      0.67    49848\n",
      "2      dish washer       0.62    0.68      0.64    31498\n",
      "3        microwave       0.67    0.90      0.77    45078\n",
      "4           kettle       0.81    0.70      0.75    53030\n",
      "5        micro avg       0.72    0.82      0.76   239993\n",
      "6        macro avg       0.72    0.80      0.75   239993\n",
      "7     weighted avg       0.74    0.82      0.77   239993\n",
      "8      samples avg       0.68    0.79      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 12 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.93      0.93    11825\n",
      "1  washing machine       0.92    0.83      0.87     8448\n",
      "2      dish washer       0.89    0.81      0.85     8210\n",
      "3        microwave       0.91    0.88      0.89     9562\n",
      "4           kettle       0.96    0.94      0.95     9927\n",
      "5        micro avg       0.92    0.88      0.90    47972\n",
      "6        macro avg       0.92    0.88      0.90    47972\n",
      "7     weighted avg       0.92    0.88      0.90    47972\n",
      "8      samples avg       0.93    0.90      0.91    47972\n",
      "-------------------------------------------------\n",
      "Fold 12 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.98      0.96    60539\n",
      "1  washing machine       0.58    0.82      0.68    49848\n",
      "2      dish washer       0.75    0.60      0.66    31498\n",
      "3        microwave       0.64    0.91      0.75    45078\n",
      "4           kettle       0.79    0.75      0.77    53030\n",
      "5        micro avg       0.73    0.83      0.78   239993\n",
      "6        macro avg       0.74    0.81      0.76   239993\n",
      "7     weighted avg       0.75    0.83      0.78   239993\n",
      "8      samples avg       0.71    0.82      0.74   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 13 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.94      0.92    11762\n",
      "1  washing machine       0.89    0.85      0.87     8396\n",
      "2      dish washer       0.83    0.86      0.84     8248\n",
      "3        microwave       0.91    0.86      0.88     9477\n",
      "4           kettle       0.94    0.94      0.94    10024\n",
      "5        micro avg       0.90    0.89      0.89    47907\n",
      "6        macro avg       0.89    0.89      0.89    47907\n",
      "7     weighted avg       0.90    0.89      0.89    47907\n",
      "8      samples avg       0.91    0.91      0.90    47907\n",
      "-------------------------------------------------\n",
      "Fold 13 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.88    0.96      0.92    60539\n",
      "1  washing machine       0.57    0.85      0.68    49848\n",
      "2      dish washer       0.61    0.70      0.65    31498\n",
      "3        microwave       0.65    0.88      0.74    45078\n",
      "4           kettle       0.66    0.83      0.74    53030\n",
      "5        micro avg       0.68    0.86      0.76   239993\n",
      "6        macro avg       0.67    0.84      0.75   239993\n",
      "7     weighted avg       0.69    0.86      0.76   239993\n",
      "8      samples avg       0.65    0.84      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 14 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.93      0.93    11786\n",
      "1  washing machine       0.93    0.82      0.87     8379\n",
      "2      dish washer       0.86    0.85      0.86     8269\n",
      "3        microwave       0.91    0.86      0.89     9574\n",
      "4           kettle       0.98    0.92      0.95     9978\n",
      "5        micro avg       0.92    0.88      0.90    47986\n",
      "6        macro avg       0.92    0.87      0.90    47986\n",
      "7     weighted avg       0.92    0.88      0.90    47986\n",
      "8      samples avg       0.93    0.90      0.90    47986\n",
      "-------------------------------------------------\n",
      "Fold 14 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.99      0.96    60539\n",
      "1  washing machine       0.57    0.78      0.66    49848\n",
      "2      dish washer       0.59    0.70      0.64    31498\n",
      "3        microwave       0.66    0.90      0.76    45078\n",
      "4           kettle       0.85    0.67      0.75    53030\n",
      "5        micro avg       0.72    0.82      0.77   239993\n",
      "6        macro avg       0.72    0.81      0.75   239993\n",
      "7     weighted avg       0.74    0.82      0.77   239993\n",
      "8      samples avg       0.69    0.80      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 15 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.92      0.93    11893\n",
      "1  washing machine       0.91    0.84      0.88     8424\n",
      "2      dish washer       0.86    0.86      0.86     8205\n",
      "3        microwave       0.90    0.88      0.89     9590\n",
      "4           kettle       0.97    0.93      0.95     9958\n",
      "5        micro avg       0.92    0.89      0.90    48070\n",
      "6        macro avg       0.91    0.89      0.90    48070\n",
      "7     weighted avg       0.92    0.89      0.90    48070\n",
      "8      samples avg       0.93    0.91      0.91    48070\n",
      "-------------------------------------------------\n",
      "Fold 15 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.99      0.96    60539\n",
      "1  washing machine       0.59    0.80      0.68    49848\n",
      "2      dish washer       0.60    0.71      0.65    31498\n",
      "3        microwave       0.63    0.93      0.75    45078\n",
      "4           kettle       0.85    0.69      0.76    53030\n",
      "5        micro avg       0.72    0.84      0.77   239993\n",
      "6        macro avg       0.72    0.82      0.76   239993\n",
      "7     weighted avg       0.74    0.84      0.78   239993\n",
      "8      samples avg       0.69    0.82      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 16 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.92      0.92    11865\n",
      "1  washing machine       0.92    0.84      0.88     8506\n",
      "2      dish washer       0.90    0.80      0.85     8222\n",
      "3        microwave       0.91    0.87      0.89     9541\n",
      "4           kettle       0.96    0.94      0.95     9954\n",
      "5        micro avg       0.93    0.88      0.90    48088\n",
      "6        macro avg       0.92    0.88      0.90    48088\n",
      "7     weighted avg       0.92    0.88      0.90    48088\n",
      "8      samples avg       0.93    0.90      0.91    48088\n",
      "-------------------------------------------------\n",
      "Fold 16 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.96      0.94    60539\n",
      "1  washing machine       0.57    0.81      0.67    49848\n",
      "2      dish washer       0.67    0.67      0.67    31498\n",
      "3        microwave       0.66    0.90      0.76    45078\n",
      "4           kettle       0.86    0.71      0.78    53030\n",
      "5        micro avg       0.73    0.82      0.77   239993\n",
      "6        macro avg       0.74    0.81      0.76   239993\n",
      "7     weighted avg       0.75    0.82      0.78   239993\n",
      "8      samples avg       0.70    0.80      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 17 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.76      0.84    11794\n",
      "1  washing machine       0.54    0.89      0.67     8394\n",
      "2      dish washer       0.85    0.57      0.68     8120\n",
      "3        microwave       0.86    0.60      0.71     9589\n",
      "4           kettle       0.95    0.82      0.88     9895\n",
      "5        micro avg       0.79    0.73      0.76    47792\n",
      "6        macro avg       0.83    0.73      0.76    47792\n",
      "7     weighted avg       0.84    0.73      0.77    47792\n",
      "8      samples avg       0.77    0.73      0.72    47792\n",
      "-------------------------------------------------\n",
      "Fold 17 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.96    0.96      0.96    60539\n",
      "1  washing machine       0.61    0.76      0.68    49848\n",
      "2      dish washer       0.62    0.65      0.63    31498\n",
      "3        microwave       0.56    0.95      0.70    45078\n",
      "4           kettle       0.88    0.70      0.78    53030\n",
      "5        micro avg       0.72    0.82      0.76   239993\n",
      "6        macro avg       0.73    0.80      0.75   239993\n",
      "7     weighted avg       0.75    0.82      0.77   239993\n",
      "8      samples avg       0.72    0.82      0.74   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 18 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.84      0.87    11818\n",
      "1  washing machine       0.52    0.92      0.67     8432\n",
      "2      dish washer       0.86    0.58      0.69     8328\n",
      "3        microwave       0.91    0.54      0.68     9480\n",
      "4           kettle       0.96    0.84      0.90     9933\n",
      "5        micro avg       0.79    0.75      0.77    47991\n",
      "6        macro avg       0.83    0.74      0.76    47991\n",
      "7     weighted avg       0.84    0.75      0.77    47991\n",
      "8      samples avg       0.77    0.75      0.73    47991\n",
      "-------------------------------------------------\n",
      "Fold 18 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.99      0.95    60539\n",
      "1  washing machine       0.64    0.79      0.71    49848\n",
      "2      dish washer       0.60    0.68      0.64    31498\n",
      "3        microwave       0.69    0.83      0.75    45078\n",
      "4           kettle       0.84    0.71      0.77    53030\n",
      "5        micro avg       0.75    0.82      0.78   239993\n",
      "6        macro avg       0.74    0.80      0.76   239993\n",
      "7     weighted avg       0.76    0.82      0.78   239993\n",
      "8      samples avg       0.75    0.82      0.76   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 19 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.92      0.93    11787\n",
      "1  washing machine       0.90    0.86      0.88     8464\n",
      "2      dish washer       0.88    0.82      0.85     8235\n",
      "3        microwave       0.92    0.86      0.89     9610\n",
      "4           kettle       0.97    0.93      0.95     9992\n",
      "5        micro avg       0.92    0.88      0.90    48088\n",
      "6        macro avg       0.92    0.88      0.90    48088\n",
      "7     weighted avg       0.92    0.88      0.90    48088\n",
      "8      samples avg       0.93    0.90      0.91    48088\n",
      "-------------------------------------------------\n",
      "Fold 19 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.96      0.95    60539\n",
      "1  washing machine       0.57    0.84      0.68    49848\n",
      "2      dish washer       0.53    0.73      0.61    31498\n",
      "3        microwave       0.68    0.83      0.75    45078\n",
      "4           kettle       0.73    0.76      0.74    53030\n",
      "5        micro avg       0.69    0.84      0.76   239993\n",
      "6        macro avg       0.69    0.82      0.75   239993\n",
      "7     weighted avg       0.71    0.84      0.77   239993\n",
      "8      samples avg       0.67    0.82      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 20 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.92      0.93    11778\n",
      "1  washing machine       0.91    0.84      0.87     8368\n",
      "2      dish washer       0.85    0.84      0.85     8217\n",
      "3        microwave       0.91    0.87      0.89     9596\n",
      "4           kettle       0.95    0.93      0.94    10082\n",
      "5        micro avg       0.91    0.89      0.90    48041\n",
      "6        macro avg       0.91    0.88      0.90    48041\n",
      "7     weighted avg       0.91    0.89      0.90    48041\n",
      "8      samples avg       0.93    0.90      0.90    48041\n",
      "-------------------------------------------------\n",
      "Fold 20 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.97      0.95    60539\n",
      "1  washing machine       0.57    0.82      0.67    49848\n",
      "2      dish washer       0.55    0.72      0.62    31498\n",
      "3        microwave       0.65    0.86      0.74    45078\n",
      "4           kettle       0.76    0.77      0.77    53030\n",
      "5        micro avg       0.70    0.84      0.76   239993\n",
      "6        macro avg       0.69    0.83      0.75   239993\n",
      "7     weighted avg       0.71    0.84      0.77   239993\n",
      "8      samples avg       0.67    0.82      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 21 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.86    0.90      0.88    11890\n",
      "1  washing machine       0.90    0.72      0.80     8479\n",
      "2      dish washer       0.88    0.58      0.70     8116\n",
      "3        microwave       0.55    0.93      0.69     9604\n",
      "4           kettle       0.96    0.77      0.85    10055\n",
      "5        micro avg       0.78    0.79      0.79    48144\n",
      "6        macro avg       0.83    0.78      0.78    48144\n",
      "7     weighted avg       0.83    0.79      0.79    48144\n",
      "8      samples avg       0.77    0.80      0.76    48144\n",
      "-------------------------------------------------\n",
      "Fold 21 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.99      0.95    60539\n",
      "1  washing machine       0.71    0.61      0.66    49848\n",
      "2      dish washer       0.57    0.70      0.63    31498\n",
      "3        microwave       0.58    0.91      0.71    45078\n",
      "4           kettle       0.94    0.53      0.68    53030\n",
      "5        micro avg       0.73    0.76      0.75   239993\n",
      "6        macro avg       0.74    0.75      0.72   239993\n",
      "7     weighted avg       0.77    0.76      0.74   239993\n",
      "8      samples avg       0.73    0.75      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 22 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.92      0.93    11862\n",
      "1  washing machine       0.88    0.89      0.89     8406\n",
      "2      dish washer       0.89    0.83      0.86     8269\n",
      "3        microwave       0.93    0.86      0.89     9586\n",
      "4           kettle       0.96    0.94      0.95     9876\n",
      "5        micro avg       0.92    0.89      0.91    47999\n",
      "6        macro avg       0.92    0.89      0.90    47999\n",
      "7     weighted avg       0.92    0.89      0.91    47999\n",
      "8      samples avg       0.93    0.91      0.91    47999\n",
      "-------------------------------------------------\n",
      "Fold 22 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.98      0.95    60539\n",
      "1  washing machine       0.57    0.87      0.68    49848\n",
      "2      dish washer       0.63    0.67      0.65    31498\n",
      "3        microwave       0.67    0.85      0.75    45078\n",
      "4           kettle       0.80    0.72      0.76    53030\n",
      "5        micro avg       0.72    0.84      0.77   239993\n",
      "6        macro avg       0.72    0.82      0.76   239993\n",
      "7     weighted avg       0.73    0.84      0.78   239993\n",
      "8      samples avg       0.69    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 23 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.91      0.93    11732\n",
      "1  washing machine       0.91    0.85      0.88     8519\n",
      "2      dish washer       0.90    0.84      0.87     8304\n",
      "3        microwave       0.91    0.87      0.89     9582\n",
      "4           kettle       0.95    0.94      0.95     9995\n",
      "5        micro avg       0.92    0.89      0.91    48132\n",
      "6        macro avg       0.92    0.88      0.90    48132\n",
      "7     weighted avg       0.92    0.89      0.91    48132\n",
      "8      samples avg       0.94    0.90      0.91    48132\n",
      "-------------------------------------------------\n",
      "Fold 23 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.98      0.96    60539\n",
      "1  washing machine       0.57    0.83      0.67    49848\n",
      "2      dish washer       0.76    0.62      0.68    31498\n",
      "3        microwave       0.64    0.92      0.75    45078\n",
      "4           kettle       0.75    0.78      0.76    53030\n",
      "5        micro avg       0.72    0.85      0.78   239993\n",
      "6        macro avg       0.73    0.82      0.77   239993\n",
      "7     weighted avg       0.74    0.85      0.78   239993\n",
      "8      samples avg       0.69    0.83      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 24 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.86      0.89    11836\n",
      "1  washing machine       0.78    0.85      0.81     8450\n",
      "2      dish washer       0.88    0.62      0.73     8204\n",
      "3        microwave       0.92    0.72      0.80     9561\n",
      "4           kettle       0.97    0.87      0.92     9908\n",
      "5        micro avg       0.90    0.79      0.84    47959\n",
      "6        macro avg       0.89    0.78      0.83    47959\n",
      "7     weighted avg       0.90    0.79      0.84    47959\n",
      "8      samples avg       0.89    0.80      0.83    47959\n",
      "-------------------------------------------------\n",
      "Fold 24 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.99      0.96    60539\n",
      "1  washing machine       0.60    0.82      0.69    49848\n",
      "2      dish washer       0.67    0.65      0.66    31498\n",
      "3        microwave       0.59    0.95      0.73    45078\n",
      "4           kettle       0.95    0.65      0.77    53030\n",
      "5        micro avg       0.73    0.83      0.77   239993\n",
      "6        macro avg       0.75    0.81      0.76   239993\n",
      "7     weighted avg       0.77    0.83      0.78   239993\n",
      "8      samples avg       0.72    0.82      0.74   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 25 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.93      0.92    11722\n",
      "1  washing machine       0.90    0.85      0.88     8310\n",
      "2      dish washer       0.86    0.87      0.86     8229\n",
      "3        microwave       0.92    0.86      0.89     9483\n",
      "4           kettle       0.97    0.93      0.95    10022\n",
      "5        micro avg       0.92    0.89      0.90    47766\n",
      "6        macro avg       0.91    0.89      0.90    47766\n",
      "7     weighted avg       0.92    0.89      0.90    47766\n",
      "8      samples avg       0.93    0.91      0.91    47766\n",
      "-------------------------------------------------\n",
      "Fold 25 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.98      0.94    60539\n",
      "1  washing machine       0.57    0.83      0.68    49848\n",
      "2      dish washer       0.60    0.70      0.64    31498\n",
      "3        microwave       0.64    0.91      0.75    45078\n",
      "4           kettle       0.85    0.70      0.77    53030\n",
      "5        micro avg       0.71    0.84      0.77   239993\n",
      "6        macro avg       0.71    0.82      0.76   239993\n",
      "7     weighted avg       0.73    0.84      0.77   239993\n",
      "8      samples avg       0.68    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 26 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.92      0.93    11834\n",
      "1  washing machine       0.89    0.88      0.89     8486\n",
      "2      dish washer       0.86    0.87      0.86     8217\n",
      "3        microwave       0.94    0.86      0.90     9608\n",
      "4           kettle       0.96    0.94      0.95     9991\n",
      "5        micro avg       0.92    0.90      0.91    48136\n",
      "6        macro avg       0.92    0.89      0.90    48136\n",
      "7     weighted avg       0.92    0.90      0.91    48136\n",
      "8      samples avg       0.93    0.91      0.91    48136\n",
      "-------------------------------------------------\n",
      "Fold 26 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.97      0.94    60539\n",
      "1  washing machine       0.57    0.82      0.67    49848\n",
      "2      dish washer       0.54    0.74      0.62    31498\n",
      "3        microwave       0.67    0.89      0.77    45078\n",
      "4           kettle       0.78    0.74      0.76    53030\n",
      "5        micro avg       0.70    0.84      0.76   239993\n",
      "6        macro avg       0.70    0.83      0.75   239993\n",
      "7     weighted avg       0.72    0.84      0.77   239993\n",
      "8      samples avg       0.67    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 27 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.92      0.93    11760\n",
      "1  washing machine       0.88    0.88      0.88     8511\n",
      "2      dish washer       0.88    0.85      0.86     8235\n",
      "3        microwave       0.90    0.87      0.89     9475\n",
      "4           kettle       0.98    0.92      0.95     9937\n",
      "5        micro avg       0.92    0.89      0.91    47918\n",
      "6        macro avg       0.92    0.89      0.90    47918\n",
      "7     weighted avg       0.92    0.89      0.91    47918\n",
      "8      samples avg       0.93    0.91      0.91    47918\n",
      "-------------------------------------------------\n",
      "Fold 27 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.98      0.94    60539\n",
      "1  washing machine       0.57    0.86      0.69    49848\n",
      "2      dish washer       0.57    0.69      0.63    31498\n",
      "3        microwave       0.66    0.90      0.76    45078\n",
      "4           kettle       0.83    0.65      0.73    53030\n",
      "5        micro avg       0.71    0.83      0.76   239993\n",
      "6        macro avg       0.71    0.82      0.75   239993\n",
      "7     weighted avg       0.73    0.83      0.77   239993\n",
      "8      samples avg       0.68    0.81      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 28 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.93      0.92    11821\n",
      "1  washing machine       0.91    0.85      0.88     8312\n",
      "2      dish washer       0.88    0.83      0.85     8213\n",
      "3        microwave       0.91    0.87      0.89     9643\n",
      "4           kettle       0.97    0.93      0.95     9999\n",
      "5        micro avg       0.92    0.89      0.90    47988\n",
      "6        macro avg       0.92    0.88      0.90    47988\n",
      "7     weighted avg       0.92    0.89      0.90    47988\n",
      "8      samples avg       0.93    0.90      0.91    47988\n",
      "-------------------------------------------------\n",
      "Fold 28 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.99      0.95    60539\n",
      "1  washing machine       0.57    0.80      0.67    49848\n",
      "2      dish washer       0.61    0.68      0.64    31498\n",
      "3        microwave       0.64    0.92      0.76    45078\n",
      "4           kettle       0.81    0.64      0.71    53030\n",
      "5        micro avg       0.71    0.82      0.76   239993\n",
      "6        macro avg       0.71    0.80      0.74   239993\n",
      "7     weighted avg       0.73    0.82      0.76   239993\n",
      "8      samples avg       0.67    0.79      0.70   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 29 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.92      0.93    11744\n",
      "1  washing machine       0.89    0.87      0.88     8430\n",
      "2      dish washer       0.89    0.83      0.86     8249\n",
      "3        microwave       0.90    0.88      0.89     9546\n",
      "4           kettle       0.96    0.94      0.95     9980\n",
      "5        micro avg       0.92    0.89      0.90    47949\n",
      "6        macro avg       0.91    0.89      0.90    47949\n",
      "7     weighted avg       0.92    0.89      0.90    47949\n",
      "8      samples avg       0.93    0.91      0.91    47949\n",
      "-------------------------------------------------\n",
      "Fold 29 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.98      0.95    60539\n",
      "1  washing machine       0.57    0.84      0.68    49848\n",
      "2      dish washer       0.68    0.64      0.66    31498\n",
      "3        microwave       0.63    0.90      0.74    45078\n",
      "4           kettle       0.79    0.73      0.76    53030\n",
      "5        micro avg       0.71    0.84      0.77   239993\n",
      "6        macro avg       0.72    0.82      0.76   239993\n",
      "7     weighted avg       0.73    0.84      0.77   239993\n",
      "8      samples avg       0.69    0.82      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 30 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.91      0.93    11883\n",
      "1  washing machine       0.90    0.86      0.88     8425\n",
      "2      dish washer       0.88    0.82      0.85     8208\n",
      "3        microwave       0.92    0.85      0.89     9544\n",
      "4           kettle       0.96    0.93      0.95     9949\n",
      "5        micro avg       0.92    0.88      0.90    48009\n",
      "6        macro avg       0.92    0.88      0.90    48009\n",
      "7     weighted avg       0.92    0.88      0.90    48009\n",
      "8      samples avg       0.94    0.90      0.91    48009\n",
      "-------------------------------------------------\n",
      "Fold 30 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.98      0.96    60539\n",
      "1  washing machine       0.57    0.85      0.68    49848\n",
      "2      dish washer       0.70    0.64      0.67    31498\n",
      "3        microwave       0.70    0.89      0.78    45078\n",
      "4           kettle       0.89    0.68      0.77    53030\n",
      "5        micro avg       0.75    0.83      0.78   239993\n",
      "6        macro avg       0.76    0.81      0.77   239993\n",
      "7     weighted avg       0.77    0.83      0.79   239993\n",
      "8      samples avg       0.72    0.81      0.74   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 31 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.92      0.93    11875\n",
      "1  washing machine       0.92    0.85      0.89     8512\n",
      "2      dish washer       0.86    0.86      0.86     8137\n",
      "3        microwave       0.89    0.88      0.89     9475\n",
      "4           kettle       0.97    0.92      0.95     9969\n",
      "5        micro avg       0.92    0.89      0.90    47968\n",
      "6        macro avg       0.92    0.89      0.90    47968\n",
      "7     weighted avg       0.92    0.89      0.90    47968\n",
      "8      samples avg       0.93    0.91      0.91    47968\n",
      "-------------------------------------------------\n",
      "Fold 31 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.96      0.94    60539\n",
      "1  washing machine       0.58    0.81      0.67    49848\n",
      "2      dish washer       0.52    0.75      0.61    31498\n",
      "3        microwave       0.64    0.92      0.76    45078\n",
      "4           kettle       0.78    0.66      0.71    53030\n",
      "5        micro avg       0.69    0.83      0.75   239993\n",
      "6        macro avg       0.69    0.82      0.74   239993\n",
      "7     weighted avg       0.71    0.83      0.76   239993\n",
      "8      samples avg       0.66    0.80      0.70   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 32 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.92      0.93    11766\n",
      "1  washing machine       0.90    0.88      0.89     8431\n",
      "2      dish washer       0.89    0.84      0.86     8239\n",
      "3        microwave       0.92    0.88      0.89     9563\n",
      "4           kettle       0.97    0.94      0.95     9968\n",
      "5        micro avg       0.92    0.89      0.91    47967\n",
      "6        macro avg       0.92    0.89      0.91    47967\n",
      "7     weighted avg       0.92    0.89      0.91    47967\n",
      "8      samples avg       0.94    0.91      0.92    47967\n",
      "-------------------------------------------------\n",
      "Fold 32 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.97      0.95    60539\n",
      "1  washing machine       0.57    0.85      0.68    49848\n",
      "2      dish washer       0.59    0.67      0.63    31498\n",
      "3        microwave       0.65    0.90      0.75    45078\n",
      "4           kettle       0.83    0.70      0.76    53030\n",
      "5        micro avg       0.71    0.83      0.77   239993\n",
      "6        macro avg       0.71    0.82      0.75   239993\n",
      "7     weighted avg       0.73    0.83      0.77   239993\n",
      "8      samples avg       0.69    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 33 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.95    0.91      0.93    11780\n",
      "1  washing machine       0.90    0.87      0.88     8358\n",
      "2      dish washer       0.89    0.85      0.87     8275\n",
      "3        microwave       0.90    0.89      0.89     9670\n",
      "4           kettle       0.96    0.94      0.95     9962\n",
      "5        micro avg       0.92    0.89      0.91    48045\n",
      "6        macro avg       0.92    0.89      0.90    48045\n",
      "7     weighted avg       0.92    0.89      0.91    48045\n",
      "8      samples avg       0.93    0.91      0.91    48045\n",
      "-------------------------------------------------\n",
      "Fold 33 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.97      0.94    60539\n",
      "1  washing machine       0.57    0.83      0.68    49848\n",
      "2      dish washer       0.66    0.64      0.65    31498\n",
      "3        microwave       0.60    0.91      0.72    45078\n",
      "4           kettle       0.79    0.75      0.77    53030\n",
      "5        micro avg       0.70    0.84      0.76   239993\n",
      "6        macro avg       0.71    0.82      0.75   239993\n",
      "7     weighted avg       0.72    0.84      0.77   239993\n",
      "8      samples avg       0.67    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 34 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.93      0.92    11846\n",
      "1  washing machine       0.89    0.85      0.87     8455\n",
      "2      dish washer       0.87    0.81      0.84     8185\n",
      "3        microwave       0.91    0.85      0.87     9533\n",
      "4           kettle       0.95    0.94      0.95     9982\n",
      "5        micro avg       0.91    0.88      0.89    48001\n",
      "6        macro avg       0.91    0.87      0.89    48001\n",
      "7     weighted avg       0.91    0.88      0.89    48001\n",
      "8      samples avg       0.92    0.90      0.90    48001\n",
      "-------------------------------------------------\n",
      "Fold 34 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.99      0.95    60539\n",
      "1  washing machine       0.57    0.85      0.68    49848\n",
      "2      dish washer       0.71    0.63      0.67    31498\n",
      "3        microwave       0.62    0.93      0.74    45078\n",
      "4           kettle       0.78    0.75      0.77    53030\n",
      "5        micro avg       0.71    0.85      0.77   239993\n",
      "6        macro avg       0.72    0.83      0.76   239993\n",
      "7     weighted avg       0.73    0.85      0.78   239993\n",
      "8      samples avg       0.68    0.83      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 35 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.93      0.93    11775\n",
      "1  washing machine       0.89    0.87      0.88     8408\n",
      "2      dish washer       0.90    0.81      0.86     8286\n",
      "3        microwave       0.92    0.86      0.89     9575\n",
      "4           kettle       0.97    0.92      0.94     9975\n",
      "5        micro avg       0.92    0.88      0.90    48019\n",
      "6        macro avg       0.92    0.88      0.90    48019\n",
      "7     weighted avg       0.92    0.88      0.90    48019\n",
      "8      samples avg       0.93    0.90      0.91    48019\n",
      "-------------------------------------------------\n",
      "Fold 35 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.99      0.94    60539\n",
      "1  washing machine       0.57    0.84      0.68    49848\n",
      "2      dish washer       0.63    0.66      0.64    31498\n",
      "3        microwave       0.68    0.88      0.77    45078\n",
      "4           kettle       0.89    0.61      0.73    53030\n",
      "5        micro avg       0.73    0.81      0.77   239993\n",
      "6        macro avg       0.73    0.80      0.75   239993\n",
      "7     weighted avg       0.75    0.81      0.77   239993\n",
      "8      samples avg       0.69    0.79      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 36 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.73    0.70      0.71    11874\n",
      "1  washing machine       0.58    0.12      0.19     8429\n",
      "2      dish washer       0.59    0.12      0.19     8174\n",
      "3        microwave       0.71    0.30      0.42     9533\n",
      "4           kettle       0.59    0.29      0.39     9925\n",
      "5        micro avg       0.67    0.34      0.45    47935\n",
      "6        macro avg       0.64    0.31      0.38    47935\n",
      "7     weighted avg       0.64    0.34      0.41    47935\n",
      "8      samples avg       0.49    0.35      0.38    47935\n",
      "-------------------------------------------------\n",
      "Fold 36 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.79    0.75      0.77    60539\n",
      "1  washing machine       0.52    0.38      0.44    49848\n",
      "2      dish washer       0.35    0.29      0.32    31498\n",
      "3        microwave       0.52    0.63      0.57    45078\n",
      "4           kettle       0.63    0.41      0.50    53030\n",
      "5        micro avg       0.59    0.51      0.55   239993\n",
      "6        macro avg       0.56    0.49      0.52   239993\n",
      "7     weighted avg       0.59    0.51      0.54   239993\n",
      "8      samples avg       0.47    0.48      0.43   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 37 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.92      0.93    11808\n",
      "1  washing machine       0.89    0.88      0.88     8450\n",
      "2      dish washer       0.90    0.83      0.86     8240\n",
      "3        microwave       0.93    0.85      0.89     9680\n",
      "4           kettle       0.96    0.94      0.95     9961\n",
      "5        micro avg       0.92    0.89      0.90    48139\n",
      "6        macro avg       0.92    0.88      0.90    48139\n",
      "7     weighted avg       0.92    0.89      0.90    48139\n",
      "8      samples avg       0.93    0.90      0.91    48139\n",
      "-------------------------------------------------\n",
      "Fold 37 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.99      0.95    60539\n",
      "1  washing machine       0.57    0.84      0.68    49848\n",
      "2      dish washer       0.58    0.70      0.63    31498\n",
      "3        microwave       0.66    0.85      0.75    45078\n",
      "4           kettle       0.89    0.68      0.77    53030\n",
      "5        micro avg       0.72    0.83      0.77   239993\n",
      "6        macro avg       0.72    0.81      0.76   239993\n",
      "7     weighted avg       0.75    0.83      0.78   239993\n",
      "8      samples avg       0.69    0.81      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 38 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.86    0.85      0.86    11775\n",
      "1  washing machine       0.81    0.74      0.77     8381\n",
      "2      dish washer       0.90    0.49      0.63     8220\n",
      "3        microwave       0.51    0.97      0.67     9499\n",
      "4           kettle       0.97    0.78      0.87     9992\n",
      "5        micro avg       0.75    0.78      0.76    47867\n",
      "6        macro avg       0.81    0.77      0.76    47867\n",
      "7     weighted avg       0.81    0.78      0.77    47867\n",
      "8      samples avg       0.72    0.78      0.72    47867\n",
      "-------------------------------------------------\n",
      "Fold 38 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.99      0.95    60539\n",
      "1  washing machine       0.63    0.71      0.67    49848\n",
      "2      dish washer       0.74    0.59      0.65    31498\n",
      "3        microwave       0.47    1.00      0.64    45078\n",
      "4           kettle       0.96    0.61      0.75    53030\n",
      "5        micro avg       0.69    0.79      0.74   239993\n",
      "6        macro avg       0.74    0.78      0.73   239993\n",
      "7     weighted avg       0.76    0.79      0.75   239993\n",
      "8      samples avg       0.66    0.78      0.69   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 39 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.92      0.92    11747\n",
      "1  washing machine       0.91    0.87      0.89     8522\n",
      "2      dish washer       0.89    0.81      0.85     8233\n",
      "3        microwave       0.92    0.85      0.89     9541\n",
      "4           kettle       0.96    0.93      0.95    10000\n",
      "5        micro avg       0.92    0.88      0.90    48043\n",
      "6        macro avg       0.92    0.88      0.90    48043\n",
      "7     weighted avg       0.92    0.88      0.90    48043\n",
      "8      samples avg       0.94    0.90      0.91    48043\n",
      "-------------------------------------------------\n",
      "Fold 39 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.99      0.95    60539\n",
      "1  washing machine       0.57    0.82      0.67    49848\n",
      "2      dish washer       0.68    0.63      0.66    31498\n",
      "3        microwave       0.63    0.91      0.74    45078\n",
      "4           kettle       0.82    0.71      0.76    53030\n",
      "5        micro avg       0.72    0.83      0.77   239993\n",
      "6        macro avg       0.72    0.81      0.76   239993\n",
      "7     weighted avg       0.74    0.83      0.77   239993\n",
      "8      samples avg       0.69    0.81      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 40 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.85      0.88    11838\n",
      "1  washing machine       0.90    0.67      0.77     8382\n",
      "2      dish washer       0.88    0.58      0.70     8255\n",
      "3        microwave       0.59    0.94      0.72     9563\n",
      "4           kettle       0.94    0.85      0.90     9978\n",
      "5        micro avg       0.81    0.79      0.80    48016\n",
      "6        macro avg       0.84    0.78      0.79    48016\n",
      "7     weighted avg       0.84    0.79      0.80    48016\n",
      "8      samples avg       0.79    0.79      0.77    48016\n",
      "-------------------------------------------------\n",
      "Fold 40 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.96    0.97      0.96    60539\n",
      "1  washing machine       0.75    0.45      0.56    49848\n",
      "2      dish washer       0.72    0.63      0.67    31498\n",
      "3        microwave       0.51    0.98      0.67    45078\n",
      "4           kettle       0.83    0.71      0.77    53030\n",
      "5        micro avg       0.73    0.76      0.75   239993\n",
      "6        macro avg       0.75    0.75      0.73   239993\n",
      "7     weighted avg       0.77    0.76      0.74   239993\n",
      "8      samples avg       0.69    0.75      0.70   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 41 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.71    0.77      0.74    11773\n",
      "1  washing machine       0.52    0.33      0.40     8500\n",
      "2      dish washer       0.61    0.16      0.25     8251\n",
      "3        microwave       0.75    0.40      0.52     9529\n",
      "4           kettle       0.70    0.36      0.48     9958\n",
      "5        micro avg       0.67    0.43      0.52    48011\n",
      "6        macro avg       0.66    0.40      0.48    48011\n",
      "7     weighted avg       0.66    0.43      0.50    48011\n",
      "8      samples avg       0.48    0.41      0.41    48011\n",
      "-------------------------------------------------\n",
      "Fold 41 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.69    0.94      0.80    60539\n",
      "1  washing machine       0.51    0.58      0.55    49848\n",
      "2      dish washer       0.36    0.54      0.43    31498\n",
      "3        microwave       0.56    0.93      0.70    45078\n",
      "4           kettle       0.63    0.50      0.56    53030\n",
      "5        micro avg       0.57    0.71      0.63   239993\n",
      "6        macro avg       0.55    0.70      0.61   239993\n",
      "7     weighted avg       0.57    0.71      0.63   239993\n",
      "8      samples avg       0.48    0.66      0.53   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 42 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.89    0.88      0.88    11841\n",
      "1  washing machine       0.51    0.91      0.66     8504\n",
      "2      dish washer       0.85    0.60      0.70     8182\n",
      "3        microwave       0.68    0.85      0.75     9501\n",
      "4           kettle       0.98    0.72      0.83     9986\n",
      "5        micro avg       0.74    0.80      0.77    48014\n",
      "6        macro avg       0.78    0.79      0.77    48014\n",
      "7     weighted avg       0.79    0.80      0.78    48014\n",
      "8      samples avg       0.73    0.79      0.73    48014\n",
      "-------------------------------------------------\n",
      "Fold 42 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.98      0.95    60539\n",
      "1  washing machine       0.67    0.62      0.64    49848\n",
      "2      dish washer       0.68    0.64      0.66    31498\n",
      "3        microwave       0.52    0.98      0.68    45078\n",
      "4           kettle       0.91    0.54      0.68    53030\n",
      "5        micro avg       0.71    0.77      0.74   239993\n",
      "6        macro avg       0.74    0.75      0.72   239993\n",
      "7     weighted avg       0.76    0.77      0.74   239993\n",
      "8      samples avg       0.70    0.77      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 43 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.91      0.92    11789\n",
      "1  washing machine       0.92    0.84      0.88     8414\n",
      "2      dish washer       0.92    0.76      0.83     8194\n",
      "3        microwave       0.93    0.85      0.88     9689\n",
      "4           kettle       0.96    0.93      0.95     9896\n",
      "5        micro avg       0.93    0.86      0.90    47982\n",
      "6        macro avg       0.93    0.86      0.89    47982\n",
      "7     weighted avg       0.93    0.86      0.90    47982\n",
      "8      samples avg       0.94    0.88      0.90    47982\n",
      "-------------------------------------------------\n",
      "Fold 43 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.99      0.96    60539\n",
      "1  washing machine       0.58    0.78      0.66    49848\n",
      "2      dish washer       0.76    0.61      0.68    31498\n",
      "3        microwave       0.69    0.88      0.77    45078\n",
      "4           kettle       0.78    0.74      0.76    53030\n",
      "5        micro avg       0.74    0.82      0.78   239993\n",
      "6        macro avg       0.75    0.80      0.77   239993\n",
      "7     weighted avg       0.76    0.82      0.78   239993\n",
      "8      samples avg       0.71    0.80      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 44 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.73    0.84      0.78    11844\n",
      "1  washing machine       0.50    0.59      0.54     8439\n",
      "2      dish washer       0.51    0.47      0.49     8252\n",
      "3        microwave       0.66    0.51      0.58     9532\n",
      "4           kettle       0.65    0.79      0.71     9977\n",
      "5        micro avg       0.62    0.66      0.64    48044\n",
      "6        macro avg       0.61    0.64      0.62    48044\n",
      "7     weighted avg       0.62    0.66      0.63    48044\n",
      "8      samples avg       0.55    0.61      0.53    48044\n",
      "-------------------------------------------------\n",
      "Fold 44 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.70    0.94      0.80    60539\n",
      "1  washing machine       0.52    0.80      0.63    49848\n",
      "2      dish washer       0.33    0.79      0.47    31498\n",
      "3        microwave       0.56    0.93      0.70    45078\n",
      "4           kettle       0.58    0.86      0.69    53030\n",
      "5        micro avg       0.54    0.87      0.67   239993\n",
      "6        macro avg       0.54    0.86      0.66   239993\n",
      "7     weighted avg       0.56    0.87      0.68   239993\n",
      "8      samples avg       0.47    0.82      0.57   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 45 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.62    0.64      0.63    11795\n",
      "1  washing machine       0.83    0.01      0.01     8307\n",
      "2      dish washer       0.53    0.13      0.20     8243\n",
      "3        microwave       0.62    0.36      0.45     9565\n",
      "4           kettle       0.38    0.22      0.28    10039\n",
      "5        micro avg       0.56    0.30      0.39    47949\n",
      "6        macro avg       0.59    0.27      0.32    47949\n",
      "7     weighted avg       0.59    0.30      0.34    47949\n",
      "8      samples avg       0.34    0.32      0.31    47949\n",
      "-------------------------------------------------\n",
      "Fold 45 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.64    0.69      0.66    60539\n",
      "1  washing machine       0.41    0.03      0.06    49848\n",
      "2      dish washer       0.31    0.29      0.30    31498\n",
      "3        microwave       0.57    0.64      0.61    45078\n",
      "4           kettle       0.41    0.31      0.35    53030\n",
      "5        micro avg       0.52    0.41      0.46   239993\n",
      "6        macro avg       0.47    0.39      0.40   239993\n",
      "7     weighted avg       0.49    0.41      0.41   239993\n",
      "8      samples avg       0.34    0.43      0.35   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Using koef 1.9\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 147s 195ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 89s 149ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 89s 149ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 89s 149ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 89s 149ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 89s 149ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 89s 148ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 89s 148ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 89s 148ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 89s 148ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 89s 148ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 89s 148ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 89s 148ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 89s 148ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 89s 149ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 89s 149ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 89s 149ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 89s 148ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 89s 148ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 89s 148ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.1036e-04\n",
      "600/600 [==============================] - 10s 14ms/step\n",
      "3000/3000 [==============================] - 43s 14ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 93s 150ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 89s 149ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 89s 149ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 89s 149ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 89s 149ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 89s 149ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 89s 149ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 89s 149ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 89s 149ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 89s 149ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 89s 149ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 89s 149ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 89s 148ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 89s 148ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 89s 149ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 89s 149ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 90s 150ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 89s 149ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 89s 149ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 89s 148ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.1036e-04\n",
      "600/600 [==============================] - 9s 14ms/step\n",
      "600/600 [==============================] - 90s 151ms/step - loss: inf - F1Score: 0.7440 - WeightedF1: 0.7737 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 91s 151ms/step - loss: inf - F1Score: 0.8044 - WeightedF1: 0.8230 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 90s 151ms/step - loss: inf - F1Score: 0.8566 - WeightedF1: 0.8712 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 90s 151ms/step - loss: inf - F1Score: 0.8811 - WeightedF1: 0.8943 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 90s 151ms/step - loss: inf - F1Score: 0.8948 - WeightedF1: 0.9064 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 90s 151ms/step - loss: inf - F1Score: 0.9031 - WeightedF1: 0.9138 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 91s 151ms/step - loss: inf - F1Score: 0.9088 - WeightedF1: 0.9189 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 91s 151ms/step - loss: inf - F1Score: 0.9138 - WeightedF1: 0.9236 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 90s 151ms/step - loss: inf - F1Score: 0.9161 - WeightedF1: 0.9258 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 90s 151ms/step - loss: inf - F1Score: 0.9223 - WeightedF1: 0.9312 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 90s 151ms/step - loss: inf - F1Score: 0.9261 - WeightedF1: 0.9348 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 90s 151ms/step - loss: inf - F1Score: 0.9294 - WeightedF1: 0.9378 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 91s 151ms/step - loss: inf - F1Score: 0.9320 - WeightedF1: 0.9403 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 90s 151ms/step - loss: inf - F1Score: 0.9353 - WeightedF1: 0.9432 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 90s 151ms/step - loss: inf - F1Score: 0.9387 - WeightedF1: 0.9463 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 90s 151ms/step - loss: inf - F1Score: 0.9415 - WeightedF1: 0.9489 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 90s 151ms/step - loss: inf - F1Score: 0.9443 - WeightedF1: 0.9514 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 90s 151ms/step - loss: inf - F1Score: 0.9476 - WeightedF1: 0.9544 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 90s 151ms/step - loss: inf - F1Score: 0.9506 - WeightedF1: 0.9571 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 10s 16ms/step\n",
      "3000/3000 [==============================] - 43s 14ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 92s 149ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 89s 148ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 89s 149ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 89s 148ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 89s 149ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 89s 148ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 89s 148ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 89s 148ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 89s 148ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 89s 148ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 89s 148ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 89s 149ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 89s 149ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 89s 148ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 89s 148ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 89s 148ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 89s 148ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 89s 148ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 89s 148ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 89s 148ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.1036e-04\n",
      "600/600 [==============================] - 9s 14ms/step\n",
      "3000/3000 [==============================] - 43s 14ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 96s 150ms/step - loss: inf - F1Score: 0.6149 - WeightedF1: 0.6304 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 90s 151ms/step - loss: inf - F1Score: 0.6949 - WeightedF1: 0.7077 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 91s 151ms/step - loss: inf - F1Score: 0.7477 - WeightedF1: 0.7569 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 90s 150ms/step - loss: inf - F1Score: 0.7866 - WeightedF1: 0.7946 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 89s 148ms/step - loss: inf - F1Score: 0.7745 - WeightedF1: 0.7828 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 89s 148ms/step - loss: inf - F1Score: 0.7744 - WeightedF1: 0.7827 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 89s 148ms/step - loss: inf - F1Score: 0.7744 - WeightedF1: 0.7827 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 89s 148ms/step - loss: inf - F1Score: 0.7745 - WeightedF1: 0.7828 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 89s 148ms/step - loss: inf - F1Score: 0.7743 - WeightedF1: 0.7826 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 89s 148ms/step - loss: inf - F1Score: 0.7744 - WeightedF1: 0.7827 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 89s 148ms/step - loss: inf - F1Score: 0.7744 - WeightedF1: 0.7828 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 89s 148ms/step - loss: inf - F1Score: 0.7744 - WeightedF1: 0.7827 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 89s 148ms/step - loss: inf - F1Score: 0.7743 - WeightedF1: 0.7826 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 89s 148ms/step - loss: inf - F1Score: 0.7745 - WeightedF1: 0.7828 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 89s 148ms/step - loss: inf - F1Score: 0.7743 - WeightedF1: 0.7826 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 89s 148ms/step - loss: inf - F1Score: 0.7743 - WeightedF1: 0.7826 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 89s 148ms/step - loss: inf - F1Score: 0.7744 - WeightedF1: 0.7827 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 89s 149ms/step - loss: inf - F1Score: 0.7744 - WeightedF1: 0.7827 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 89s 148ms/step - loss: inf - F1Score: 0.7745 - WeightedF1: 0.7828 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 89s 148ms/step - loss: inf - F1Score: 0.7744 - WeightedF1: 0.7828 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 9s 15ms/step\n",
      "3000/3000 [==============================] - 45s 15ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 93s 151ms/step - loss: inf - F1Score: 0.5974 - WeightedF1: 0.6152 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 91s 151ms/step - loss: inf - F1Score: 0.7188 - WeightedF1: 0.7305 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 91s 151ms/step - loss: inf - F1Score: 0.7588 - WeightedF1: 0.7678 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 90s 151ms/step - loss: inf - F1Score: 0.7871 - WeightedF1: 0.7950 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 90s 151ms/step - loss: inf - F1Score: 0.8103 - WeightedF1: 0.8175 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 90s 151ms/step - loss: inf - F1Score: 0.8277 - WeightedF1: 0.8342 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 90s 151ms/step - loss: inf - F1Score: 0.8420 - WeightedF1: 0.8479 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 90s 151ms/step - loss: inf - F1Score: 0.8521 - WeightedF1: 0.8577 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 90s 151ms/step - loss: inf - F1Score: 0.8620 - WeightedF1: 0.8671 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 91s 151ms/step - loss: inf - F1Score: 0.8718 - WeightedF1: 0.8765 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 90s 151ms/step - loss: inf - F1Score: 0.8819 - WeightedF1: 0.8862 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 90s 151ms/step - loss: inf - F1Score: 0.8906 - WeightedF1: 0.8944 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 90s 151ms/step - loss: inf - F1Score: 0.8976 - WeightedF1: 0.9010 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 90s 150ms/step - loss: inf - F1Score: 0.9048 - WeightedF1: 0.9078 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 90s 150ms/step - loss: inf - F1Score: 0.9117 - WeightedF1: 0.9146 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 90s 151ms/step - loss: inf - F1Score: 0.9183 - WeightedF1: 0.9208 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 90s 150ms/step - loss: inf - F1Score: 0.9251 - WeightedF1: 0.9274 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 90s 150ms/step - loss: inf - F1Score: 0.9312 - WeightedF1: 0.9332 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 90s 151ms/step - loss: inf - F1Score: 0.9372 - WeightedF1: 0.9389 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 90s 151ms/step - loss: inf - F1Score: 0.9436 - WeightedF1: 0.9450 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 9s 14ms/step\n",
      "600/600 [==============================] - 90s 150ms/step - loss: inf - F1Score: 0.7585 - WeightedF1: 0.7672 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 90s 150ms/step - loss: inf - F1Score: 0.7933 - WeightedF1: 0.8007 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 90s 150ms/step - loss: inf - F1Score: 0.8160 - WeightedF1: 0.8227 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 90s 150ms/step - loss: inf - F1Score: 0.8352 - WeightedF1: 0.8414 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 90s 150ms/step - loss: inf - F1Score: 0.8496 - WeightedF1: 0.8552 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 90s 149ms/step - loss: inf - F1Score: 0.8606 - WeightedF1: 0.8658 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 90s 150ms/step - loss: inf - F1Score: 0.8726 - WeightedF1: 0.8772 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 90s 150ms/step - loss: inf - F1Score: 0.8804 - WeightedF1: 0.8846 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 90s 150ms/step - loss: inf - F1Score: 0.8873 - WeightedF1: 0.8912 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 90s 150ms/step - loss: inf - F1Score: 0.8962 - WeightedF1: 0.8996 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 90s 150ms/step - loss: inf - F1Score: 0.9050 - WeightedF1: 0.9081 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 90s 150ms/step - loss: inf - F1Score: 0.9131 - WeightedF1: 0.9159 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 90s 150ms/step - loss: inf - F1Score: 0.9205 - WeightedF1: 0.9229 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 90s 149ms/step - loss: inf - F1Score: 0.9272 - WeightedF1: 0.9293 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 90s 150ms/step - loss: inf - F1Score: 0.9339 - WeightedF1: 0.9357 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 90s 149ms/step - loss: inf - F1Score: 0.9409 - WeightedF1: 0.9425 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 90s 149ms/step - loss: inf - F1Score: 0.9475 - WeightedF1: 0.9488 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 90s 149ms/step - loss: inf - F1Score: 0.9536 - WeightedF1: 0.9547 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 90s 150ms/step - loss: inf - F1Score: 0.9598 - WeightedF1: 0.9606 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 9s 15ms/step\n",
      "3000/3000 [==============================] - 43s 14ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 91s 148ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 88s 147ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 88s 147ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 88s 147ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 89s 148ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 89s 148ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 88s 147ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 88s 147ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 89s 148ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 89s 148ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 88s 147ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 88s 147ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 88s 147ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 88s 147ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 88s 147ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 88s 147ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 88s 147ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 88s 147ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 88s 147ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 88s 147ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.1036e-04\n",
      "600/600 [==============================] - 9s 14ms/step\n",
      "3000/3000 [==============================] - 43s 14ms/step\n",
      "Fold 1 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.87    0.92      0.89    11706\n",
      "1  washing machine       0.90    0.75      0.82     8507\n",
      "2      dish washer       0.83    0.73      0.78     8309\n",
      "3        microwave       0.88    0.82      0.85     9549\n",
      "4           kettle       0.96    0.89      0.92     9949\n",
      "5        micro avg       0.89    0.83      0.86    48020\n",
      "6        macro avg       0.89    0.82      0.85    48020\n",
      "7     weighted avg       0.89    0.83      0.86    48020\n",
      "8      samples avg       0.89    0.84      0.85    48020\n",
      "-------------------------------------------------\n",
      "Fold 1 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.99      0.96    60539\n",
      "1  washing machine       0.74    0.55      0.63    49848\n",
      "2      dish washer       0.55    0.73      0.63    31498\n",
      "3        microwave       0.63    0.93      0.75    45078\n",
      "4           kettle       0.73    0.82      0.77    53030\n",
      "5        micro avg       0.72    0.82      0.77   239993\n",
      "6        macro avg       0.71    0.81      0.75   239993\n",
      "7     weighted avg       0.74    0.82      0.77   239993\n",
      "8      samples avg       0.71    0.80      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 2 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.89    0.90      0.90    11903\n",
      "1  washing machine       0.88    0.76      0.82     8383\n",
      "2      dish washer       0.81    0.77      0.79     8279\n",
      "3        microwave       0.86    0.82      0.84     9584\n",
      "4           kettle       0.95    0.91      0.93     9899\n",
      "5        micro avg       0.88    0.84      0.86    48048\n",
      "6        macro avg       0.88    0.83      0.85    48048\n",
      "7     weighted avg       0.88    0.84      0.86    48048\n",
      "8      samples avg       0.89    0.85      0.86    48048\n",
      "-------------------------------------------------\n",
      "Fold 2 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.99      0.96    60539\n",
      "1  washing machine       0.62    0.69      0.66    49848\n",
      "2      dish washer       0.51    0.76      0.61    31498\n",
      "3        microwave       0.62    0.95      0.75    45078\n",
      "4           kettle       0.83    0.74      0.79    53030\n",
      "5        micro avg       0.71    0.83      0.77   239993\n",
      "6        macro avg       0.70    0.83      0.75   239993\n",
      "7     weighted avg       0.73    0.83      0.77   239993\n",
      "8      samples avg       0.69    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 3 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.85    0.92      0.88    11755\n",
      "1  washing machine       0.91    0.74      0.82     8482\n",
      "2      dish washer       0.82    0.71      0.76     8145\n",
      "3        microwave       0.88    0.73      0.80     9633\n",
      "4           kettle       0.95    0.90      0.92     9989\n",
      "5        micro avg       0.88    0.81      0.84    48004\n",
      "6        macro avg       0.88    0.80      0.84    48004\n",
      "7     weighted avg       0.88    0.81      0.84    48004\n",
      "8      samples avg       0.89    0.82      0.84    48004\n",
      "-------------------------------------------------\n",
      "Fold 3 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.98      0.94    60539\n",
      "1  washing machine       0.61    0.72      0.66    49848\n",
      "2      dish washer       0.62    0.68      0.65    31498\n",
      "3        microwave       0.66    0.85      0.74    45078\n",
      "4           kettle       0.77    0.76      0.77    53030\n",
      "5        micro avg       0.72    0.82      0.77   239993\n",
      "6        macro avg       0.71    0.80      0.75   239993\n",
      "7     weighted avg       0.73    0.82      0.77   239993\n",
      "8      samples avg       0.69    0.80      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 4 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.88    0.90      0.89    11880\n",
      "1  washing machine       0.90    0.75      0.82     8396\n",
      "2      dish washer       0.85    0.68      0.75     8215\n",
      "3        microwave       0.88    0.73      0.80     9566\n",
      "4           kettle       0.95    0.90      0.92    10018\n",
      "5        micro avg       0.89    0.80      0.85    48075\n",
      "6        macro avg       0.89    0.79      0.84    48075\n",
      "7     weighted avg       0.89    0.80      0.84    48075\n",
      "8      samples avg       0.90    0.82      0.84    48075\n",
      "-------------------------------------------------\n",
      "Fold 4 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.99      0.96    60539\n",
      "1  washing machine       0.59    0.75      0.66    49848\n",
      "2      dish washer       0.75    0.62      0.68    31498\n",
      "3        microwave       0.59    0.92      0.72    45078\n",
      "4           kettle       0.91    0.71      0.80    53030\n",
      "5        micro avg       0.74    0.82      0.78   239993\n",
      "6        macro avg       0.76    0.80      0.76   239993\n",
      "7     weighted avg       0.77    0.82      0.78   239993\n",
      "8      samples avg       0.72    0.81      0.74   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 5 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.88    0.90      0.89    11798\n",
      "1  washing machine       0.91    0.73      0.81     8396\n",
      "2      dish washer       0.84    0.69      0.75     8174\n",
      "3        microwave       0.85    0.79      0.82     9484\n",
      "4           kettle       0.96    0.87      0.91    10001\n",
      "5        micro avg       0.89    0.81      0.84    47853\n",
      "6        macro avg       0.89    0.79      0.84    47853\n",
      "7     weighted avg       0.89    0.81      0.84    47853\n",
      "8      samples avg       0.89    0.82      0.84    47853\n",
      "-------------------------------------------------\n",
      "Fold 5 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.98      0.96    60539\n",
      "1  washing machine       0.62    0.68      0.65    49848\n",
      "2      dish washer       0.70    0.64      0.67    31498\n",
      "3        microwave       0.57    0.96      0.72    45078\n",
      "4           kettle       0.85    0.72      0.78    53030\n",
      "5        micro avg       0.73    0.81      0.77   239993\n",
      "6        macro avg       0.74    0.80      0.75   239993\n",
      "7     weighted avg       0.75    0.81      0.77   239993\n",
      "8      samples avg       0.70    0.80      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 6 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.91      0.92    11828\n",
      "1  washing machine       0.91    0.82      0.86     8389\n",
      "2      dish washer       0.89    0.80      0.85     8207\n",
      "3        microwave       0.92    0.85      0.89     9542\n",
      "4           kettle       0.96    0.93      0.95     9968\n",
      "5        micro avg       0.93    0.87      0.90    47934\n",
      "6        macro avg       0.93    0.86      0.89    47934\n",
      "7     weighted avg       0.93    0.87      0.90    47934\n",
      "8      samples avg       0.93    0.88      0.90    47934\n",
      "-------------------------------------------------\n",
      "Fold 6 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.95    0.92      0.94    60539\n",
      "1  washing machine       0.60    0.70      0.65    49848\n",
      "2      dish washer       0.57    0.70      0.62    31498\n",
      "3        microwave       0.69    0.92      0.79    45078\n",
      "4           kettle       0.77    0.73      0.75    53030\n",
      "5        micro avg       0.72    0.80      0.76   239993\n",
      "6        macro avg       0.71    0.79      0.75   239993\n",
      "7     weighted avg       0.74    0.80      0.77   239993\n",
      "8      samples avg       0.69    0.78      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 7 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.91      0.91    11670\n",
      "1  washing machine       0.90    0.82      0.86     8394\n",
      "2      dish washer       0.87    0.78      0.82     8254\n",
      "3        microwave       0.89    0.85      0.87     9554\n",
      "4           kettle       0.96    0.92      0.94     9928\n",
      "5        micro avg       0.91    0.86      0.88    47800\n",
      "6        macro avg       0.91    0.86      0.88    47800\n",
      "7     weighted avg       0.91    0.86      0.88    47800\n",
      "8      samples avg       0.92    0.88      0.89    47800\n",
      "-------------------------------------------------\n",
      "Fold 7 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.98      0.96    60539\n",
      "1  washing machine       0.56    0.83      0.67    49848\n",
      "2      dish washer       0.71    0.65      0.67    31498\n",
      "3        microwave       0.63    0.90      0.74    45078\n",
      "4           kettle       0.80    0.73      0.76    53030\n",
      "5        micro avg       0.72    0.84      0.77   239993\n",
      "6        macro avg       0.73    0.82      0.76   239993\n",
      "7     weighted avg       0.74    0.84      0.78   239993\n",
      "8      samples avg       0.68    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 8 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.84      0.89    11782\n",
      "1  washing machine       0.63    0.91      0.74     8527\n",
      "2      dish washer       0.93    0.60      0.73     8269\n",
      "3        microwave       0.87    0.80      0.83     9595\n",
      "4           kettle       0.94    0.89      0.92     9911\n",
      "5        micro avg       0.84    0.81      0.83    48084\n",
      "6        macro avg       0.86    0.81      0.82    48084\n",
      "7     weighted avg       0.87    0.81      0.83    48084\n",
      "8      samples avg       0.84    0.83      0.82    48084\n",
      "-------------------------------------------------\n",
      "Fold 8 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.96    0.98      0.97    60539\n",
      "1  washing machine       0.57    0.85      0.68    49848\n",
      "2      dish washer       0.90    0.57      0.70    31498\n",
      "3        microwave       0.62    0.91      0.74    45078\n",
      "4           kettle       0.78    0.78      0.78    53030\n",
      "5        micro avg       0.73    0.84      0.78   239993\n",
      "6        macro avg       0.77    0.82      0.77   239993\n",
      "7     weighted avg       0.77    0.84      0.79   239993\n",
      "8      samples avg       0.72    0.84      0.75   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 9 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.93      0.92    11834\n",
      "1  washing machine       0.91    0.80      0.85     8478\n",
      "2      dish washer       0.85    0.79      0.82     8188\n",
      "3        microwave       0.93    0.83      0.87     9619\n",
      "4           kettle       0.96    0.93      0.94    10086\n",
      "5        micro avg       0.91    0.86      0.89    48205\n",
      "6        macro avg       0.91    0.85      0.88    48205\n",
      "7     weighted avg       0.91    0.86      0.89    48205\n",
      "8      samples avg       0.92    0.88      0.89    48205\n",
      "-------------------------------------------------\n",
      "Fold 9 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.89      0.90    60539\n",
      "1  washing machine       0.57    0.81      0.67    49848\n",
      "2      dish washer       0.58    0.71      0.64    31498\n",
      "3        microwave       0.67    0.85      0.75    45078\n",
      "4           kettle       0.86    0.72      0.78    53030\n",
      "5        micro avg       0.72    0.81      0.76   239993\n",
      "6        macro avg       0.72    0.80      0.75   239993\n",
      "7     weighted avg       0.74    0.81      0.76   239993\n",
      "8      samples avg       0.69    0.78      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 10 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.93      0.92    11928\n",
      "1  washing machine       0.90    0.81      0.85     8376\n",
      "2      dish washer       0.87    0.79      0.82     8204\n",
      "3        microwave       0.88    0.86      0.87     9506\n",
      "4           kettle       0.95    0.92      0.94     9963\n",
      "5        micro avg       0.91    0.87      0.89    47977\n",
      "6        macro avg       0.90    0.86      0.88    47977\n",
      "7     weighted avg       0.91    0.87      0.89    47977\n",
      "8      samples avg       0.92    0.88      0.89    47977\n",
      "-------------------------------------------------\n",
      "Fold 10 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.99      0.95    60539\n",
      "1  washing machine       0.58    0.80      0.67    49848\n",
      "2      dish washer       0.67    0.65      0.66    31498\n",
      "3        microwave       0.65    0.91      0.76    45078\n",
      "4           kettle       0.78    0.77      0.78    53030\n",
      "5        micro avg       0.72    0.84      0.78   239993\n",
      "6        macro avg       0.72    0.82      0.76   239993\n",
      "7     weighted avg       0.74    0.84      0.78   239993\n",
      "8      samples avg       0.70    0.82      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 11 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.91      0.92    11776\n",
      "1  washing machine       0.92    0.82      0.87     8517\n",
      "2      dish washer       0.86    0.82      0.84     8190\n",
      "3        microwave       0.89    0.87      0.88     9613\n",
      "4           kettle       0.97    0.92      0.95     9969\n",
      "5        micro avg       0.92    0.88      0.90    48065\n",
      "6        macro avg       0.91    0.87      0.89    48065\n",
      "7     weighted avg       0.92    0.88      0.90    48065\n",
      "8      samples avg       0.93    0.89      0.90    48065\n",
      "-------------------------------------------------\n",
      "Fold 11 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.94      0.94    60539\n",
      "1  washing machine       0.57    0.81      0.67    49848\n",
      "2      dish washer       0.62    0.68      0.64    31498\n",
      "3        microwave       0.67    0.90      0.77    45078\n",
      "4           kettle       0.81    0.70      0.75    53030\n",
      "5        micro avg       0.72    0.82      0.76   239993\n",
      "6        macro avg       0.72    0.80      0.75   239993\n",
      "7     weighted avg       0.74    0.82      0.77   239993\n",
      "8      samples avg       0.68    0.79      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 12 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.93      0.93    11825\n",
      "1  washing machine       0.92    0.83      0.87     8448\n",
      "2      dish washer       0.89    0.81      0.85     8210\n",
      "3        microwave       0.91    0.88      0.89     9562\n",
      "4           kettle       0.96    0.94      0.95     9927\n",
      "5        micro avg       0.92    0.88      0.90    47972\n",
      "6        macro avg       0.92    0.88      0.90    47972\n",
      "7     weighted avg       0.92    0.88      0.90    47972\n",
      "8      samples avg       0.93    0.90      0.91    47972\n",
      "-------------------------------------------------\n",
      "Fold 12 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.98      0.96    60539\n",
      "1  washing machine       0.58    0.82      0.68    49848\n",
      "2      dish washer       0.75    0.60      0.66    31498\n",
      "3        microwave       0.64    0.91      0.75    45078\n",
      "4           kettle       0.79    0.75      0.77    53030\n",
      "5        micro avg       0.73    0.83      0.78   239993\n",
      "6        macro avg       0.74    0.81      0.76   239993\n",
      "7     weighted avg       0.75    0.83      0.78   239993\n",
      "8      samples avg       0.71    0.82      0.74   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 13 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.94      0.92    11762\n",
      "1  washing machine       0.89    0.85      0.87     8396\n",
      "2      dish washer       0.83    0.86      0.84     8248\n",
      "3        microwave       0.91    0.86      0.88     9477\n",
      "4           kettle       0.94    0.94      0.94    10024\n",
      "5        micro avg       0.90    0.89      0.89    47907\n",
      "6        macro avg       0.89    0.89      0.89    47907\n",
      "7     weighted avg       0.90    0.89      0.89    47907\n",
      "8      samples avg       0.91    0.91      0.90    47907\n",
      "-------------------------------------------------\n",
      "Fold 13 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.88    0.96      0.92    60539\n",
      "1  washing machine       0.57    0.85      0.68    49848\n",
      "2      dish washer       0.61    0.70      0.65    31498\n",
      "3        microwave       0.65    0.88      0.74    45078\n",
      "4           kettle       0.66    0.83      0.74    53030\n",
      "5        micro avg       0.68    0.86      0.76   239993\n",
      "6        macro avg       0.67    0.84      0.75   239993\n",
      "7     weighted avg       0.69    0.86      0.76   239993\n",
      "8      samples avg       0.65    0.84      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 14 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.93      0.93    11786\n",
      "1  washing machine       0.93    0.82      0.87     8379\n",
      "2      dish washer       0.86    0.85      0.86     8269\n",
      "3        microwave       0.91    0.86      0.89     9574\n",
      "4           kettle       0.98    0.92      0.95     9978\n",
      "5        micro avg       0.92    0.88      0.90    47986\n",
      "6        macro avg       0.92    0.87      0.90    47986\n",
      "7     weighted avg       0.92    0.88      0.90    47986\n",
      "8      samples avg       0.93    0.90      0.90    47986\n",
      "-------------------------------------------------\n",
      "Fold 14 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.99      0.96    60539\n",
      "1  washing machine       0.57    0.78      0.66    49848\n",
      "2      dish washer       0.59    0.70      0.64    31498\n",
      "3        microwave       0.66    0.90      0.76    45078\n",
      "4           kettle       0.85    0.67      0.75    53030\n",
      "5        micro avg       0.72    0.82      0.77   239993\n",
      "6        macro avg       0.72    0.81      0.75   239993\n",
      "7     weighted avg       0.74    0.82      0.77   239993\n",
      "8      samples avg       0.69    0.80      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 15 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.92      0.93    11893\n",
      "1  washing machine       0.91    0.84      0.88     8424\n",
      "2      dish washer       0.86    0.86      0.86     8205\n",
      "3        microwave       0.90    0.88      0.89     9590\n",
      "4           kettle       0.97    0.93      0.95     9958\n",
      "5        micro avg       0.92    0.89      0.90    48070\n",
      "6        macro avg       0.91    0.89      0.90    48070\n",
      "7     weighted avg       0.92    0.89      0.90    48070\n",
      "8      samples avg       0.93    0.91      0.91    48070\n",
      "-------------------------------------------------\n",
      "Fold 15 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.99      0.96    60539\n",
      "1  washing machine       0.59    0.80      0.68    49848\n",
      "2      dish washer       0.60    0.71      0.65    31498\n",
      "3        microwave       0.63    0.93      0.75    45078\n",
      "4           kettle       0.85    0.69      0.76    53030\n",
      "5        micro avg       0.72    0.84      0.77   239993\n",
      "6        macro avg       0.72    0.82      0.76   239993\n",
      "7     weighted avg       0.74    0.84      0.78   239993\n",
      "8      samples avg       0.69    0.82      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 16 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.92      0.92    11865\n",
      "1  washing machine       0.92    0.84      0.88     8506\n",
      "2      dish washer       0.90    0.80      0.85     8222\n",
      "3        microwave       0.91    0.87      0.89     9541\n",
      "4           kettle       0.96    0.94      0.95     9954\n",
      "5        micro avg       0.93    0.88      0.90    48088\n",
      "6        macro avg       0.92    0.88      0.90    48088\n",
      "7     weighted avg       0.92    0.88      0.90    48088\n",
      "8      samples avg       0.93    0.90      0.91    48088\n",
      "-------------------------------------------------\n",
      "Fold 16 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.96      0.94    60539\n",
      "1  washing machine       0.57    0.81      0.67    49848\n",
      "2      dish washer       0.67    0.67      0.67    31498\n",
      "3        microwave       0.66    0.90      0.76    45078\n",
      "4           kettle       0.86    0.71      0.78    53030\n",
      "5        micro avg       0.73    0.82      0.77   239993\n",
      "6        macro avg       0.74    0.81      0.76   239993\n",
      "7     weighted avg       0.75    0.82      0.78   239993\n",
      "8      samples avg       0.70    0.80      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 17 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.76      0.84    11794\n",
      "1  washing machine       0.54    0.89      0.67     8394\n",
      "2      dish washer       0.85    0.57      0.68     8120\n",
      "3        microwave       0.86    0.60      0.71     9589\n",
      "4           kettle       0.95    0.82      0.88     9895\n",
      "5        micro avg       0.79    0.73      0.76    47792\n",
      "6        macro avg       0.83    0.73      0.76    47792\n",
      "7     weighted avg       0.84    0.73      0.77    47792\n",
      "8      samples avg       0.77    0.73      0.72    47792\n",
      "-------------------------------------------------\n",
      "Fold 17 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.96    0.96      0.96    60539\n",
      "1  washing machine       0.61    0.76      0.68    49848\n",
      "2      dish washer       0.62    0.65      0.63    31498\n",
      "3        microwave       0.56    0.95      0.70    45078\n",
      "4           kettle       0.88    0.70      0.78    53030\n",
      "5        micro avg       0.72    0.82      0.76   239993\n",
      "6        macro avg       0.73    0.80      0.75   239993\n",
      "7     weighted avg       0.75    0.82      0.77   239993\n",
      "8      samples avg       0.72    0.82      0.74   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 18 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.84      0.87    11818\n",
      "1  washing machine       0.52    0.92      0.67     8432\n",
      "2      dish washer       0.86    0.58      0.69     8328\n",
      "3        microwave       0.91    0.54      0.68     9480\n",
      "4           kettle       0.96    0.84      0.90     9933\n",
      "5        micro avg       0.79    0.75      0.77    47991\n",
      "6        macro avg       0.83    0.74      0.76    47991\n",
      "7     weighted avg       0.84    0.75      0.77    47991\n",
      "8      samples avg       0.77    0.75      0.73    47991\n",
      "-------------------------------------------------\n",
      "Fold 18 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.99      0.95    60539\n",
      "1  washing machine       0.64    0.79      0.71    49848\n",
      "2      dish washer       0.60    0.68      0.64    31498\n",
      "3        microwave       0.69    0.83      0.75    45078\n",
      "4           kettle       0.84    0.71      0.77    53030\n",
      "5        micro avg       0.75    0.82      0.78   239993\n",
      "6        macro avg       0.74    0.80      0.76   239993\n",
      "7     weighted avg       0.76    0.82      0.78   239993\n",
      "8      samples avg       0.75    0.82      0.76   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 19 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.92      0.93    11787\n",
      "1  washing machine       0.90    0.86      0.88     8464\n",
      "2      dish washer       0.88    0.82      0.85     8235\n",
      "3        microwave       0.92    0.86      0.89     9610\n",
      "4           kettle       0.97    0.93      0.95     9992\n",
      "5        micro avg       0.92    0.88      0.90    48088\n",
      "6        macro avg       0.92    0.88      0.90    48088\n",
      "7     weighted avg       0.92    0.88      0.90    48088\n",
      "8      samples avg       0.93    0.90      0.91    48088\n",
      "-------------------------------------------------\n",
      "Fold 19 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.96      0.95    60539\n",
      "1  washing machine       0.57    0.84      0.68    49848\n",
      "2      dish washer       0.53    0.73      0.61    31498\n",
      "3        microwave       0.68    0.83      0.75    45078\n",
      "4           kettle       0.73    0.76      0.74    53030\n",
      "5        micro avg       0.69    0.84      0.76   239993\n",
      "6        macro avg       0.69    0.82      0.75   239993\n",
      "7     weighted avg       0.71    0.84      0.77   239993\n",
      "8      samples avg       0.67    0.82      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 20 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.92      0.93    11778\n",
      "1  washing machine       0.91    0.84      0.87     8368\n",
      "2      dish washer       0.85    0.84      0.85     8217\n",
      "3        microwave       0.91    0.87      0.89     9596\n",
      "4           kettle       0.95    0.93      0.94    10082\n",
      "5        micro avg       0.91    0.89      0.90    48041\n",
      "6        macro avg       0.91    0.88      0.90    48041\n",
      "7     weighted avg       0.91    0.89      0.90    48041\n",
      "8      samples avg       0.93    0.90      0.90    48041\n",
      "-------------------------------------------------\n",
      "Fold 20 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.97      0.95    60539\n",
      "1  washing machine       0.57    0.82      0.67    49848\n",
      "2      dish washer       0.55    0.72      0.62    31498\n",
      "3        microwave       0.65    0.86      0.74    45078\n",
      "4           kettle       0.76    0.77      0.77    53030\n",
      "5        micro avg       0.70    0.84      0.76   239993\n",
      "6        macro avg       0.69    0.83      0.75   239993\n",
      "7     weighted avg       0.71    0.84      0.77   239993\n",
      "8      samples avg       0.67    0.82      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 21 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.86    0.90      0.88    11890\n",
      "1  washing machine       0.90    0.72      0.80     8479\n",
      "2      dish washer       0.88    0.58      0.70     8116\n",
      "3        microwave       0.55    0.93      0.69     9604\n",
      "4           kettle       0.96    0.77      0.85    10055\n",
      "5        micro avg       0.78    0.79      0.79    48144\n",
      "6        macro avg       0.83    0.78      0.78    48144\n",
      "7     weighted avg       0.83    0.79      0.79    48144\n",
      "8      samples avg       0.77    0.80      0.76    48144\n",
      "-------------------------------------------------\n",
      "Fold 21 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.99      0.95    60539\n",
      "1  washing machine       0.71    0.61      0.66    49848\n",
      "2      dish washer       0.57    0.70      0.63    31498\n",
      "3        microwave       0.58    0.91      0.71    45078\n",
      "4           kettle       0.94    0.53      0.68    53030\n",
      "5        micro avg       0.73    0.76      0.75   239993\n",
      "6        macro avg       0.74    0.75      0.72   239993\n",
      "7     weighted avg       0.77    0.76      0.74   239993\n",
      "8      samples avg       0.73    0.75      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 22 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.92      0.93    11862\n",
      "1  washing machine       0.88    0.89      0.89     8406\n",
      "2      dish washer       0.89    0.83      0.86     8269\n",
      "3        microwave       0.93    0.86      0.89     9586\n",
      "4           kettle       0.96    0.94      0.95     9876\n",
      "5        micro avg       0.92    0.89      0.91    47999\n",
      "6        macro avg       0.92    0.89      0.90    47999\n",
      "7     weighted avg       0.92    0.89      0.91    47999\n",
      "8      samples avg       0.93    0.91      0.91    47999\n",
      "-------------------------------------------------\n",
      "Fold 22 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.98      0.95    60539\n",
      "1  washing machine       0.57    0.87      0.68    49848\n",
      "2      dish washer       0.63    0.67      0.65    31498\n",
      "3        microwave       0.67    0.85      0.75    45078\n",
      "4           kettle       0.80    0.72      0.76    53030\n",
      "5        micro avg       0.72    0.84      0.77   239993\n",
      "6        macro avg       0.72    0.82      0.76   239993\n",
      "7     weighted avg       0.73    0.84      0.78   239993\n",
      "8      samples avg       0.69    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 23 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.91      0.93    11732\n",
      "1  washing machine       0.91    0.85      0.88     8519\n",
      "2      dish washer       0.90    0.84      0.87     8304\n",
      "3        microwave       0.91    0.87      0.89     9582\n",
      "4           kettle       0.95    0.94      0.95     9995\n",
      "5        micro avg       0.92    0.89      0.91    48132\n",
      "6        macro avg       0.92    0.88      0.90    48132\n",
      "7     weighted avg       0.92    0.89      0.91    48132\n",
      "8      samples avg       0.94    0.90      0.91    48132\n",
      "-------------------------------------------------\n",
      "Fold 23 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.98      0.96    60539\n",
      "1  washing machine       0.57    0.83      0.67    49848\n",
      "2      dish washer       0.76    0.62      0.68    31498\n",
      "3        microwave       0.64    0.92      0.75    45078\n",
      "4           kettle       0.75    0.78      0.76    53030\n",
      "5        micro avg       0.72    0.85      0.78   239993\n",
      "6        macro avg       0.73    0.82      0.77   239993\n",
      "7     weighted avg       0.74    0.85      0.78   239993\n",
      "8      samples avg       0.69    0.83      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 24 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.86      0.89    11836\n",
      "1  washing machine       0.78    0.85      0.81     8450\n",
      "2      dish washer       0.88    0.62      0.73     8204\n",
      "3        microwave       0.92    0.72      0.80     9561\n",
      "4           kettle       0.97    0.87      0.92     9908\n",
      "5        micro avg       0.90    0.79      0.84    47959\n",
      "6        macro avg       0.89    0.78      0.83    47959\n",
      "7     weighted avg       0.90    0.79      0.84    47959\n",
      "8      samples avg       0.89    0.80      0.83    47959\n",
      "-------------------------------------------------\n",
      "Fold 24 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.99      0.96    60539\n",
      "1  washing machine       0.60    0.82      0.69    49848\n",
      "2      dish washer       0.67    0.65      0.66    31498\n",
      "3        microwave       0.59    0.95      0.73    45078\n",
      "4           kettle       0.95    0.65      0.77    53030\n",
      "5        micro avg       0.73    0.83      0.77   239993\n",
      "6        macro avg       0.75    0.81      0.76   239993\n",
      "7     weighted avg       0.77    0.83      0.78   239993\n",
      "8      samples avg       0.72    0.82      0.74   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 25 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.93      0.92    11722\n",
      "1  washing machine       0.90    0.85      0.88     8310\n",
      "2      dish washer       0.86    0.87      0.86     8229\n",
      "3        microwave       0.92    0.86      0.89     9483\n",
      "4           kettle       0.97    0.93      0.95    10022\n",
      "5        micro avg       0.92    0.89      0.90    47766\n",
      "6        macro avg       0.91    0.89      0.90    47766\n",
      "7     weighted avg       0.92    0.89      0.90    47766\n",
      "8      samples avg       0.93    0.91      0.91    47766\n",
      "-------------------------------------------------\n",
      "Fold 25 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.98      0.94    60539\n",
      "1  washing machine       0.57    0.83      0.68    49848\n",
      "2      dish washer       0.60    0.70      0.64    31498\n",
      "3        microwave       0.64    0.91      0.75    45078\n",
      "4           kettle       0.85    0.70      0.77    53030\n",
      "5        micro avg       0.71    0.84      0.77   239993\n",
      "6        macro avg       0.71    0.82      0.76   239993\n",
      "7     weighted avg       0.73    0.84      0.77   239993\n",
      "8      samples avg       0.68    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 26 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.92      0.93    11834\n",
      "1  washing machine       0.89    0.88      0.89     8486\n",
      "2      dish washer       0.86    0.87      0.86     8217\n",
      "3        microwave       0.94    0.86      0.90     9608\n",
      "4           kettle       0.96    0.94      0.95     9991\n",
      "5        micro avg       0.92    0.90      0.91    48136\n",
      "6        macro avg       0.92    0.89      0.90    48136\n",
      "7     weighted avg       0.92    0.90      0.91    48136\n",
      "8      samples avg       0.93    0.91      0.91    48136\n",
      "-------------------------------------------------\n",
      "Fold 26 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.97      0.94    60539\n",
      "1  washing machine       0.57    0.82      0.67    49848\n",
      "2      dish washer       0.54    0.74      0.62    31498\n",
      "3        microwave       0.67    0.89      0.77    45078\n",
      "4           kettle       0.78    0.74      0.76    53030\n",
      "5        micro avg       0.70    0.84      0.76   239993\n",
      "6        macro avg       0.70    0.83      0.75   239993\n",
      "7     weighted avg       0.72    0.84      0.77   239993\n",
      "8      samples avg       0.67    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 27 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.92      0.93    11760\n",
      "1  washing machine       0.88    0.88      0.88     8511\n",
      "2      dish washer       0.88    0.85      0.86     8235\n",
      "3        microwave       0.90    0.87      0.89     9475\n",
      "4           kettle       0.98    0.92      0.95     9937\n",
      "5        micro avg       0.92    0.89      0.91    47918\n",
      "6        macro avg       0.92    0.89      0.90    47918\n",
      "7     weighted avg       0.92    0.89      0.91    47918\n",
      "8      samples avg       0.93    0.91      0.91    47918\n",
      "-------------------------------------------------\n",
      "Fold 27 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.98      0.94    60539\n",
      "1  washing machine       0.57    0.86      0.69    49848\n",
      "2      dish washer       0.57    0.69      0.63    31498\n",
      "3        microwave       0.66    0.90      0.76    45078\n",
      "4           kettle       0.83    0.65      0.73    53030\n",
      "5        micro avg       0.71    0.83      0.76   239993\n",
      "6        macro avg       0.71    0.82      0.75   239993\n",
      "7     weighted avg       0.73    0.83      0.77   239993\n",
      "8      samples avg       0.68    0.81      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 28 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.93      0.92    11821\n",
      "1  washing machine       0.91    0.85      0.88     8312\n",
      "2      dish washer       0.88    0.83      0.85     8213\n",
      "3        microwave       0.91    0.87      0.89     9643\n",
      "4           kettle       0.97    0.93      0.95     9999\n",
      "5        micro avg       0.92    0.89      0.90    47988\n",
      "6        macro avg       0.92    0.88      0.90    47988\n",
      "7     weighted avg       0.92    0.89      0.90    47988\n",
      "8      samples avg       0.93    0.90      0.91    47988\n",
      "-------------------------------------------------\n",
      "Fold 28 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.99      0.95    60539\n",
      "1  washing machine       0.57    0.80      0.67    49848\n",
      "2      dish washer       0.61    0.68      0.64    31498\n",
      "3        microwave       0.64    0.92      0.76    45078\n",
      "4           kettle       0.81    0.64      0.71    53030\n",
      "5        micro avg       0.71    0.82      0.76   239993\n",
      "6        macro avg       0.71    0.80      0.74   239993\n",
      "7     weighted avg       0.73    0.82      0.76   239993\n",
      "8      samples avg       0.67    0.79      0.70   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 29 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.92      0.93    11744\n",
      "1  washing machine       0.89    0.87      0.88     8430\n",
      "2      dish washer       0.89    0.83      0.86     8249\n",
      "3        microwave       0.90    0.88      0.89     9546\n",
      "4           kettle       0.96    0.94      0.95     9980\n",
      "5        micro avg       0.92    0.89      0.90    47949\n",
      "6        macro avg       0.91    0.89      0.90    47949\n",
      "7     weighted avg       0.92    0.89      0.90    47949\n",
      "8      samples avg       0.93    0.91      0.91    47949\n",
      "-------------------------------------------------\n",
      "Fold 29 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.98      0.95    60539\n",
      "1  washing machine       0.57    0.84      0.68    49848\n",
      "2      dish washer       0.68    0.64      0.66    31498\n",
      "3        microwave       0.63    0.90      0.74    45078\n",
      "4           kettle       0.79    0.73      0.76    53030\n",
      "5        micro avg       0.71    0.84      0.77   239993\n",
      "6        macro avg       0.72    0.82      0.76   239993\n",
      "7     weighted avg       0.73    0.84      0.77   239993\n",
      "8      samples avg       0.69    0.82      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 30 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.91      0.93    11883\n",
      "1  washing machine       0.90    0.86      0.88     8425\n",
      "2      dish washer       0.88    0.82      0.85     8208\n",
      "3        microwave       0.92    0.85      0.89     9544\n",
      "4           kettle       0.96    0.93      0.95     9949\n",
      "5        micro avg       0.92    0.88      0.90    48009\n",
      "6        macro avg       0.92    0.88      0.90    48009\n",
      "7     weighted avg       0.92    0.88      0.90    48009\n",
      "8      samples avg       0.94    0.90      0.91    48009\n",
      "-------------------------------------------------\n",
      "Fold 30 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.98      0.96    60539\n",
      "1  washing machine       0.57    0.85      0.68    49848\n",
      "2      dish washer       0.70    0.64      0.67    31498\n",
      "3        microwave       0.70    0.89      0.78    45078\n",
      "4           kettle       0.89    0.68      0.77    53030\n",
      "5        micro avg       0.75    0.83      0.78   239993\n",
      "6        macro avg       0.76    0.81      0.77   239993\n",
      "7     weighted avg       0.77    0.83      0.79   239993\n",
      "8      samples avg       0.72    0.81      0.74   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 31 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.92      0.93    11875\n",
      "1  washing machine       0.92    0.85      0.89     8512\n",
      "2      dish washer       0.86    0.86      0.86     8137\n",
      "3        microwave       0.89    0.88      0.89     9475\n",
      "4           kettle       0.97    0.92      0.95     9969\n",
      "5        micro avg       0.92    0.89      0.90    47968\n",
      "6        macro avg       0.92    0.89      0.90    47968\n",
      "7     weighted avg       0.92    0.89      0.90    47968\n",
      "8      samples avg       0.93    0.91      0.91    47968\n",
      "-------------------------------------------------\n",
      "Fold 31 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.96      0.94    60539\n",
      "1  washing machine       0.58    0.81      0.67    49848\n",
      "2      dish washer       0.52    0.75      0.61    31498\n",
      "3        microwave       0.64    0.92      0.76    45078\n",
      "4           kettle       0.78    0.66      0.71    53030\n",
      "5        micro avg       0.69    0.83      0.75   239993\n",
      "6        macro avg       0.69    0.82      0.74   239993\n",
      "7     weighted avg       0.71    0.83      0.76   239993\n",
      "8      samples avg       0.66    0.80      0.70   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 32 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.92      0.93    11766\n",
      "1  washing machine       0.90    0.88      0.89     8431\n",
      "2      dish washer       0.89    0.84      0.86     8239\n",
      "3        microwave       0.92    0.88      0.89     9563\n",
      "4           kettle       0.97    0.94      0.95     9968\n",
      "5        micro avg       0.92    0.89      0.91    47967\n",
      "6        macro avg       0.92    0.89      0.91    47967\n",
      "7     weighted avg       0.92    0.89      0.91    47967\n",
      "8      samples avg       0.94    0.91      0.92    47967\n",
      "-------------------------------------------------\n",
      "Fold 32 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.97      0.95    60539\n",
      "1  washing machine       0.57    0.85      0.68    49848\n",
      "2      dish washer       0.59    0.67      0.63    31498\n",
      "3        microwave       0.65    0.90      0.75    45078\n",
      "4           kettle       0.83    0.70      0.76    53030\n",
      "5        micro avg       0.71    0.83      0.77   239993\n",
      "6        macro avg       0.71    0.82      0.75   239993\n",
      "7     weighted avg       0.73    0.83      0.77   239993\n",
      "8      samples avg       0.69    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 33 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.95    0.91      0.93    11780\n",
      "1  washing machine       0.90    0.87      0.88     8358\n",
      "2      dish washer       0.89    0.85      0.87     8275\n",
      "3        microwave       0.90    0.89      0.89     9670\n",
      "4           kettle       0.96    0.94      0.95     9962\n",
      "5        micro avg       0.92    0.89      0.91    48045\n",
      "6        macro avg       0.92    0.89      0.90    48045\n",
      "7     weighted avg       0.92    0.89      0.91    48045\n",
      "8      samples avg       0.93    0.91      0.91    48045\n",
      "-------------------------------------------------\n",
      "Fold 33 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.97      0.94    60539\n",
      "1  washing machine       0.57    0.83      0.68    49848\n",
      "2      dish washer       0.66    0.64      0.65    31498\n",
      "3        microwave       0.60    0.91      0.72    45078\n",
      "4           kettle       0.79    0.75      0.77    53030\n",
      "5        micro avg       0.70    0.84      0.76   239993\n",
      "6        macro avg       0.71    0.82      0.75   239993\n",
      "7     weighted avg       0.72    0.84      0.77   239993\n",
      "8      samples avg       0.67    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 34 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.93      0.92    11846\n",
      "1  washing machine       0.89    0.85      0.87     8455\n",
      "2      dish washer       0.87    0.81      0.84     8185\n",
      "3        microwave       0.91    0.85      0.87     9533\n",
      "4           kettle       0.95    0.94      0.95     9982\n",
      "5        micro avg       0.91    0.88      0.89    48001\n",
      "6        macro avg       0.91    0.87      0.89    48001\n",
      "7     weighted avg       0.91    0.88      0.89    48001\n",
      "8      samples avg       0.92    0.90      0.90    48001\n",
      "-------------------------------------------------\n",
      "Fold 34 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.99      0.95    60539\n",
      "1  washing machine       0.57    0.85      0.68    49848\n",
      "2      dish washer       0.71    0.63      0.67    31498\n",
      "3        microwave       0.62    0.93      0.74    45078\n",
      "4           kettle       0.78    0.75      0.77    53030\n",
      "5        micro avg       0.71    0.85      0.77   239993\n",
      "6        macro avg       0.72    0.83      0.76   239993\n",
      "7     weighted avg       0.73    0.85      0.78   239993\n",
      "8      samples avg       0.68    0.83      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 35 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.93      0.93    11775\n",
      "1  washing machine       0.89    0.87      0.88     8408\n",
      "2      dish washer       0.90    0.81      0.86     8286\n",
      "3        microwave       0.92    0.86      0.89     9575\n",
      "4           kettle       0.97    0.92      0.94     9975\n",
      "5        micro avg       0.92    0.88      0.90    48019\n",
      "6        macro avg       0.92    0.88      0.90    48019\n",
      "7     weighted avg       0.92    0.88      0.90    48019\n",
      "8      samples avg       0.93    0.90      0.91    48019\n",
      "-------------------------------------------------\n",
      "Fold 35 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.99      0.94    60539\n",
      "1  washing machine       0.57    0.84      0.68    49848\n",
      "2      dish washer       0.63    0.66      0.64    31498\n",
      "3        microwave       0.68    0.88      0.77    45078\n",
      "4           kettle       0.89    0.61      0.73    53030\n",
      "5        micro avg       0.73    0.81      0.77   239993\n",
      "6        macro avg       0.73    0.80      0.75   239993\n",
      "7     weighted avg       0.75    0.81      0.77   239993\n",
      "8      samples avg       0.69    0.79      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 36 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.73    0.70      0.71    11874\n",
      "1  washing machine       0.58    0.12      0.19     8429\n",
      "2      dish washer       0.59    0.12      0.19     8174\n",
      "3        microwave       0.71    0.30      0.42     9533\n",
      "4           kettle       0.59    0.29      0.39     9925\n",
      "5        micro avg       0.67    0.34      0.45    47935\n",
      "6        macro avg       0.64    0.31      0.38    47935\n",
      "7     weighted avg       0.64    0.34      0.41    47935\n",
      "8      samples avg       0.49    0.35      0.38    47935\n",
      "-------------------------------------------------\n",
      "Fold 36 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.79    0.75      0.77    60539\n",
      "1  washing machine       0.52    0.38      0.44    49848\n",
      "2      dish washer       0.35    0.29      0.32    31498\n",
      "3        microwave       0.52    0.63      0.57    45078\n",
      "4           kettle       0.63    0.41      0.50    53030\n",
      "5        micro avg       0.59    0.51      0.55   239993\n",
      "6        macro avg       0.56    0.49      0.52   239993\n",
      "7     weighted avg       0.59    0.51      0.54   239993\n",
      "8      samples avg       0.47    0.48      0.43   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 37 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.92      0.93    11808\n",
      "1  washing machine       0.89    0.88      0.88     8450\n",
      "2      dish washer       0.90    0.83      0.86     8240\n",
      "3        microwave       0.93    0.85      0.89     9680\n",
      "4           kettle       0.96    0.94      0.95     9961\n",
      "5        micro avg       0.92    0.89      0.90    48139\n",
      "6        macro avg       0.92    0.88      0.90    48139\n",
      "7     weighted avg       0.92    0.89      0.90    48139\n",
      "8      samples avg       0.93    0.90      0.91    48139\n",
      "-------------------------------------------------\n",
      "Fold 37 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.99      0.95    60539\n",
      "1  washing machine       0.57    0.84      0.68    49848\n",
      "2      dish washer       0.58    0.70      0.63    31498\n",
      "3        microwave       0.66    0.85      0.75    45078\n",
      "4           kettle       0.89    0.68      0.77    53030\n",
      "5        micro avg       0.72    0.83      0.77   239993\n",
      "6        macro avg       0.72    0.81      0.76   239993\n",
      "7     weighted avg       0.75    0.83      0.78   239993\n",
      "8      samples avg       0.69    0.81      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 38 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.86    0.85      0.86    11775\n",
      "1  washing machine       0.81    0.74      0.77     8381\n",
      "2      dish washer       0.90    0.49      0.63     8220\n",
      "3        microwave       0.51    0.97      0.67     9499\n",
      "4           kettle       0.97    0.78      0.87     9992\n",
      "5        micro avg       0.75    0.78      0.76    47867\n",
      "6        macro avg       0.81    0.77      0.76    47867\n",
      "7     weighted avg       0.81    0.78      0.77    47867\n",
      "8      samples avg       0.72    0.78      0.72    47867\n",
      "-------------------------------------------------\n",
      "Fold 38 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.99      0.95    60539\n",
      "1  washing machine       0.63    0.71      0.67    49848\n",
      "2      dish washer       0.74    0.59      0.65    31498\n",
      "3        microwave       0.47    1.00      0.64    45078\n",
      "4           kettle       0.96    0.61      0.75    53030\n",
      "5        micro avg       0.69    0.79      0.74   239993\n",
      "6        macro avg       0.74    0.78      0.73   239993\n",
      "7     weighted avg       0.76    0.79      0.75   239993\n",
      "8      samples avg       0.66    0.78      0.69   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 39 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.92      0.92    11747\n",
      "1  washing machine       0.91    0.87      0.89     8522\n",
      "2      dish washer       0.89    0.81      0.85     8233\n",
      "3        microwave       0.92    0.85      0.89     9541\n",
      "4           kettle       0.96    0.93      0.95    10000\n",
      "5        micro avg       0.92    0.88      0.90    48043\n",
      "6        macro avg       0.92    0.88      0.90    48043\n",
      "7     weighted avg       0.92    0.88      0.90    48043\n",
      "8      samples avg       0.94    0.90      0.91    48043\n",
      "-------------------------------------------------\n",
      "Fold 39 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.99      0.95    60539\n",
      "1  washing machine       0.57    0.82      0.67    49848\n",
      "2      dish washer       0.68    0.63      0.66    31498\n",
      "3        microwave       0.63    0.91      0.74    45078\n",
      "4           kettle       0.82    0.71      0.76    53030\n",
      "5        micro avg       0.72    0.83      0.77   239993\n",
      "6        macro avg       0.72    0.81      0.76   239993\n",
      "7     weighted avg       0.74    0.83      0.77   239993\n",
      "8      samples avg       0.69    0.81      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 40 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.85      0.88    11838\n",
      "1  washing machine       0.90    0.67      0.77     8382\n",
      "2      dish washer       0.88    0.58      0.70     8255\n",
      "3        microwave       0.59    0.94      0.72     9563\n",
      "4           kettle       0.94    0.85      0.90     9978\n",
      "5        micro avg       0.81    0.79      0.80    48016\n",
      "6        macro avg       0.84    0.78      0.79    48016\n",
      "7     weighted avg       0.84    0.79      0.80    48016\n",
      "8      samples avg       0.79    0.79      0.77    48016\n",
      "-------------------------------------------------\n",
      "Fold 40 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.96    0.97      0.96    60539\n",
      "1  washing machine       0.75    0.45      0.56    49848\n",
      "2      dish washer       0.72    0.63      0.67    31498\n",
      "3        microwave       0.51    0.98      0.67    45078\n",
      "4           kettle       0.83    0.71      0.77    53030\n",
      "5        micro avg       0.73    0.76      0.75   239993\n",
      "6        macro avg       0.75    0.75      0.73   239993\n",
      "7     weighted avg       0.77    0.76      0.74   239993\n",
      "8      samples avg       0.69    0.75      0.70   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 41 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.71    0.77      0.74    11773\n",
      "1  washing machine       0.52    0.33      0.40     8500\n",
      "2      dish washer       0.61    0.16      0.25     8251\n",
      "3        microwave       0.75    0.40      0.52     9529\n",
      "4           kettle       0.70    0.36      0.48     9958\n",
      "5        micro avg       0.67    0.43      0.52    48011\n",
      "6        macro avg       0.66    0.40      0.48    48011\n",
      "7     weighted avg       0.66    0.43      0.50    48011\n",
      "8      samples avg       0.48    0.41      0.41    48011\n",
      "-------------------------------------------------\n",
      "Fold 41 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.69    0.94      0.80    60539\n",
      "1  washing machine       0.51    0.58      0.55    49848\n",
      "2      dish washer       0.36    0.54      0.43    31498\n",
      "3        microwave       0.56    0.93      0.70    45078\n",
      "4           kettle       0.63    0.50      0.56    53030\n",
      "5        micro avg       0.57    0.71      0.63   239993\n",
      "6        macro avg       0.55    0.70      0.61   239993\n",
      "7     weighted avg       0.57    0.71      0.63   239993\n",
      "8      samples avg       0.48    0.66      0.53   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 42 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.89    0.88      0.88    11841\n",
      "1  washing machine       0.51    0.91      0.66     8504\n",
      "2      dish washer       0.85    0.60      0.70     8182\n",
      "3        microwave       0.68    0.85      0.75     9501\n",
      "4           kettle       0.98    0.72      0.83     9986\n",
      "5        micro avg       0.74    0.80      0.77    48014\n",
      "6        macro avg       0.78    0.79      0.77    48014\n",
      "7     weighted avg       0.79    0.80      0.78    48014\n",
      "8      samples avg       0.73    0.79      0.73    48014\n",
      "-------------------------------------------------\n",
      "Fold 42 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.98      0.95    60539\n",
      "1  washing machine       0.67    0.62      0.64    49848\n",
      "2      dish washer       0.68    0.64      0.66    31498\n",
      "3        microwave       0.52    0.98      0.68    45078\n",
      "4           kettle       0.91    0.54      0.68    53030\n",
      "5        micro avg       0.71    0.77      0.74   239993\n",
      "6        macro avg       0.74    0.75      0.72   239993\n",
      "7     weighted avg       0.76    0.77      0.74   239993\n",
      "8      samples avg       0.70    0.77      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 43 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.91      0.92    11789\n",
      "1  washing machine       0.92    0.84      0.88     8414\n",
      "2      dish washer       0.92    0.76      0.83     8194\n",
      "3        microwave       0.93    0.85      0.88     9689\n",
      "4           kettle       0.96    0.93      0.95     9896\n",
      "5        micro avg       0.93    0.86      0.90    47982\n",
      "6        macro avg       0.93    0.86      0.89    47982\n",
      "7     weighted avg       0.93    0.86      0.90    47982\n",
      "8      samples avg       0.94    0.88      0.90    47982\n",
      "-------------------------------------------------\n",
      "Fold 43 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.99      0.96    60539\n",
      "1  washing machine       0.58    0.78      0.66    49848\n",
      "2      dish washer       0.76    0.61      0.68    31498\n",
      "3        microwave       0.69    0.88      0.77    45078\n",
      "4           kettle       0.78    0.74      0.76    53030\n",
      "5        micro avg       0.74    0.82      0.78   239993\n",
      "6        macro avg       0.75    0.80      0.77   239993\n",
      "7     weighted avg       0.76    0.82      0.78   239993\n",
      "8      samples avg       0.71    0.80      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 44 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.73    0.84      0.78    11844\n",
      "1  washing machine       0.50    0.59      0.54     8439\n",
      "2      dish washer       0.51    0.47      0.49     8252\n",
      "3        microwave       0.66    0.51      0.58     9532\n",
      "4           kettle       0.65    0.79      0.71     9977\n",
      "5        micro avg       0.62    0.66      0.64    48044\n",
      "6        macro avg       0.61    0.64      0.62    48044\n",
      "7     weighted avg       0.62    0.66      0.63    48044\n",
      "8      samples avg       0.55    0.61      0.53    48044\n",
      "-------------------------------------------------\n",
      "Fold 44 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.70    0.94      0.80    60539\n",
      "1  washing machine       0.52    0.80      0.63    49848\n",
      "2      dish washer       0.33    0.79      0.47    31498\n",
      "3        microwave       0.56    0.93      0.70    45078\n",
      "4           kettle       0.58    0.86      0.69    53030\n",
      "5        micro avg       0.54    0.87      0.67   239993\n",
      "6        macro avg       0.54    0.86      0.66   239993\n",
      "7     weighted avg       0.56    0.87      0.68   239993\n",
      "8      samples avg       0.47    0.82      0.57   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 45 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.62    0.64      0.63    11795\n",
      "1  washing machine       0.83    0.01      0.01     8307\n",
      "2      dish washer       0.53    0.13      0.20     8243\n",
      "3        microwave       0.62    0.36      0.45     9565\n",
      "4           kettle       0.38    0.22      0.28    10039\n",
      "5        micro avg       0.56    0.30      0.39    47949\n",
      "6        macro avg       0.59    0.27      0.32    47949\n",
      "7     weighted avg       0.59    0.30      0.34    47949\n",
      "8      samples avg       0.34    0.32      0.31    47949\n",
      "-------------------------------------------------\n",
      "Fold 45 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.64    0.69      0.66    60539\n",
      "1  washing machine       0.41    0.03      0.06    49848\n",
      "2      dish washer       0.31    0.29      0.30    31498\n",
      "3        microwave       0.57    0.64      0.61    45078\n",
      "4           kettle       0.41    0.31      0.35    53030\n",
      "5        micro avg       0.52    0.41      0.46   239993\n",
      "6        macro avg       0.47    0.39      0.40   239993\n",
      "7     weighted avg       0.49    0.41      0.41   239993\n",
      "8      samples avg       0.34    0.43      0.35   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 46 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.83    0.92      0.87    11715\n",
      "1  washing machine       0.88    0.69      0.78     8418\n",
      "2      dish washer       0.91    0.55      0.68     8208\n",
      "3        microwave       0.51    0.99      0.67     9610\n",
      "4           kettle       0.94    0.84      0.89     9968\n",
      "5        micro avg       0.75    0.81      0.78    47919\n",
      "6        macro avg       0.81    0.80      0.78    47919\n",
      "7     weighted avg       0.81    0.81      0.79    47919\n",
      "8      samples avg       0.73    0.82      0.75    47919\n",
      "-------------------------------------------------\n",
      "Fold 46 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.85    1.00      0.91    60539\n",
      "1  washing machine       0.60    0.68      0.64    49848\n",
      "2      dish washer       0.68    0.61      0.64    31498\n",
      "3        microwave       0.52    0.97      0.68    45078\n",
      "4           kettle       0.79    0.73      0.76    53030\n",
      "5        micro avg       0.68    0.82      0.74   239993\n",
      "6        macro avg       0.69    0.80      0.73   239993\n",
      "7     weighted avg       0.70    0.82      0.74   239993\n",
      "8      samples avg       0.65    0.79      0.69   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 47 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.94      0.92    11872\n",
      "1  washing machine       0.92    0.85      0.88     8496\n",
      "2      dish washer       0.90    0.83      0.86     8167\n",
      "3        microwave       0.91    0.87      0.89     9611\n",
      "4           kettle       0.97    0.93      0.95     9948\n",
      "5        micro avg       0.92    0.89      0.90    48094\n",
      "6        macro avg       0.92    0.88      0.90    48094\n",
      "7     weighted avg       0.92    0.89      0.90    48094\n",
      "8      samples avg       0.93    0.91      0.91    48094\n",
      "-------------------------------------------------\n",
      "Fold 47 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.99      0.94    60539\n",
      "1  washing machine       0.57    0.81      0.67    49848\n",
      "2      dish washer       0.73    0.62      0.67    31498\n",
      "3        microwave       0.62    0.95      0.75    45078\n",
      "4           kettle       0.84    0.67      0.75    53030\n",
      "5        micro avg       0.72    0.83      0.77   239993\n",
      "6        macro avg       0.73    0.81      0.76   239993\n",
      "7     weighted avg       0.75    0.83      0.77   239993\n",
      "8      samples avg       0.69    0.81      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 48 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.93      0.93    11869\n",
      "1  washing machine       0.89    0.88      0.88     8413\n",
      "2      dish washer       0.90    0.80      0.85     8172\n",
      "3        microwave       0.89    0.88      0.88     9614\n",
      "4           kettle       0.97    0.93      0.95     9961\n",
      "5        micro avg       0.91    0.89      0.90    48029\n",
      "6        macro avg       0.91    0.88      0.90    48029\n",
      "7     weighted avg       0.91    0.89      0.90    48029\n",
      "8      samples avg       0.93    0.91      0.91    48029\n",
      "-------------------------------------------------\n",
      "Fold 48 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.99      0.94    60539\n",
      "1  washing machine       0.57    0.84      0.68    49848\n",
      "2      dish washer       0.76    0.61      0.68    31498\n",
      "3        microwave       0.58    0.95      0.72    45078\n",
      "4           kettle       0.82    0.70      0.75    53030\n",
      "5        micro avg       0.71    0.84      0.77   239993\n",
      "6        macro avg       0.73    0.82      0.76   239993\n",
      "7     weighted avg       0.73    0.84      0.77   239993\n",
      "8      samples avg       0.68    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 49 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.93      0.93    11878\n",
      "1  washing machine       0.89    0.88      0.89     8373\n",
      "2      dish washer       0.90    0.82      0.86     8220\n",
      "3        microwave       0.93    0.85      0.89     9496\n",
      "4           kettle       0.97    0.93      0.95     9963\n",
      "5        micro avg       0.92    0.89      0.91    47930\n",
      "6        macro avg       0.92    0.88      0.90    47930\n",
      "7     weighted avg       0.92    0.89      0.91    47930\n",
      "8      samples avg       0.94    0.90      0.91    47930\n",
      "-------------------------------------------------\n",
      "Fold 49 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.89    0.99      0.94    60539\n",
      "1  washing machine       0.57    0.84      0.67    49848\n",
      "2      dish washer       0.69    0.62      0.65    31498\n",
      "3        microwave       0.67    0.89      0.76    45078\n",
      "4           kettle       0.81    0.68      0.74    53030\n",
      "5        micro avg       0.72    0.82      0.77   239993\n",
      "6        macro avg       0.72    0.80      0.75   239993\n",
      "7     weighted avg       0.74    0.82      0.77   239993\n",
      "8      samples avg       0.69    0.80      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 50 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.61    0.53      0.57    11708\n",
      "1  washing machine       0.40    0.13      0.19     8464\n",
      "2      dish washer       0.36    0.04      0.07     8355\n",
      "3        microwave       0.82    0.19      0.31     9485\n",
      "4           kettle       0.50    0.41      0.45    10016\n",
      "5        micro avg       0.56    0.28      0.37    48028\n",
      "6        macro avg       0.54    0.26      0.32    48028\n",
      "7     weighted avg       0.55    0.28      0.34    48028\n",
      "8      samples avg       0.29    0.33      0.29    48028\n",
      "-------------------------------------------------\n",
      "Fold 50 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.63    0.70      0.66    60539\n",
      "1  washing machine       0.46    0.47      0.46    49848\n",
      "2      dish washer       0.19    0.18      0.18    31498\n",
      "3        microwave       0.57    0.64      0.60    45078\n",
      "4           kettle       0.54    0.61      0.57    53030\n",
      "5        micro avg       0.51    0.55      0.53   239993\n",
      "6        macro avg       0.48    0.52      0.50   239993\n",
      "7     weighted avg       0.50    0.55      0.53   239993\n",
      "8      samples avg       0.34    0.57      0.40   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Using koef 2.1\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 177s 233ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 105s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 105s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 105s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 105s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 105s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 105s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 105s 175ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 105s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 105s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 105s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 105s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 105s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 106s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 105s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 105s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 105s 175ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 105s 175ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 105s 175ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 105s 175ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.1036e-04\n",
      "600/600 [==============================] - 12s 17ms/step\n",
      "3000/3000 [==============================] - 53s 18ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 110s 179ms/step - loss: inf - F1Score: 0.6165 - WeightedF1: 0.6574 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 106s 177ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 106s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 106s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 106s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 106s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 106s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 106s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 106s 177ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 106s 177ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 106s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 106s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 106s 177ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 106s 177ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 106s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 106s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 106s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 106s 177ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 106s 177ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 106s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.1036e-04\n",
      "600/600 [==============================] - 11s 17ms/step\n",
      "3000/3000 [==============================] - 51s 17ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 143s 234ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 106s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 106s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 106s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 105s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 106s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 105s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 105s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 105s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 105s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 105s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 105s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 105s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 105s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 105s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 105s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 105s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 105s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 105s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 105s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.1036e-04\n",
      "600/600 [==============================] - 12s 19ms/step\n",
      "3000/3000 [==============================] - 51s 17ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 106s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 106s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 106s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 106s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 106s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 106s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 106s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 106s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 106s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 106s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 106s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 106s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 106s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 106s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.1036e-04\n",
      "600/600 [==============================] - 11s 17ms/step\n",
      "600/600 [==============================] - 105s 175ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 105s 175ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 105s 175ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 105s 175ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 105s 175ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 105s 175ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 105s 175ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 105s 175ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 105s 175ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 105s 175ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 105s 175ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 105s 175ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 105s 175ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 105s 175ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 105s 175ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 105s 175ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.1036e-04\n",
      "600/600 [==============================] - 10s 17ms/step\n",
      "3000/3000 [==============================] - 53s 17ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 105s 175ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 105s 175ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 105s 175ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 105s 175ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 105s 175ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 105s 175ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 105s 175ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 105s 175ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 105s 175ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 105s 175ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 105s 175ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 105s 175ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 105s 175ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 105s 175ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 105s 175ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.1036e-04\n",
      "600/600 [==============================] - 11s 17ms/step\n",
      "600/600 [==============================] - 105s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 105s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 105s 175ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 105s 175ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 105s 175ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 105s 175ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 105s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 105s 176ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 105s 175ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 105s 175ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 105s 175ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 105s 175ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 105s 175ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 105s 175ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 105s 175ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 105s 175ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.1036e-04\n",
      "600/600 [==============================] - 11s 17ms/step\n",
      "3000/3000 [==============================] - 51s 17ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 107s 178ms/step - loss: inf - F1Score: 0.8560 - WeightedF1: 0.8615 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 107s 178ms/step - loss: inf - F1Score: 0.8656 - WeightedF1: 0.8708 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 107s 178ms/step - loss: inf - F1Score: 0.8706 - WeightedF1: 0.8756 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 107s 178ms/step - loss: inf - F1Score: 0.8796 - WeightedF1: 0.8840 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 107s 178ms/step - loss: inf - F1Score: 0.8873 - WeightedF1: 0.8913 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 107s 178ms/step - loss: inf - F1Score: 0.8957 - WeightedF1: 0.8994 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 107s 178ms/step - loss: inf - F1Score: 0.9041 - WeightedF1: 0.9075 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 107s 178ms/step - loss: inf - F1Score: 0.9118 - WeightedF1: 0.9147 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 107s 178ms/step - loss: inf - F1Score: 0.9193 - WeightedF1: 0.9219 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 106s 177ms/step - loss: inf - F1Score: 0.9269 - WeightedF1: 0.9292 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 107s 178ms/step - loss: inf - F1Score: 0.9334 - WeightedF1: 0.9354 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 106s 177ms/step - loss: inf - F1Score: 0.9412 - WeightedF1: 0.9427 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 106s 177ms/step - loss: inf - F1Score: 0.9477 - WeightedF1: 0.9491 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 107s 178ms/step - loss: inf - F1Score: 0.9545 - WeightedF1: 0.9555 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 11s 17ms/step\n",
      "3000/3000 [==============================] - 51s 17ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 105s 176ms/step - loss: inf - F1Score: 0.7015 - WeightedF1: 0.7154 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 105s 176ms/step - loss: inf - F1Score: 0.7017 - WeightedF1: 0.7156 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 105s 176ms/step - loss: inf - F1Score: 0.7015 - WeightedF1: 0.7154 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 105s 176ms/step - loss: inf - F1Score: 0.7015 - WeightedF1: 0.7154 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 105s 176ms/step - loss: inf - F1Score: 0.7015 - WeightedF1: 0.7154 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 105s 176ms/step - loss: inf - F1Score: 0.7016 - WeightedF1: 0.7155 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 105s 176ms/step - loss: inf - F1Score: 0.7014 - WeightedF1: 0.7153 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 105s 176ms/step - loss: inf - F1Score: 0.7015 - WeightedF1: 0.7154 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 105s 176ms/step - loss: inf - F1Score: 0.7014 - WeightedF1: 0.7154 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 105s 176ms/step - loss: inf - F1Score: 0.7016 - WeightedF1: 0.7155 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 105s 176ms/step - loss: inf - F1Score: 0.7015 - WeightedF1: 0.7154 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 105s 176ms/step - loss: inf - F1Score: 0.7017 - WeightedF1: 0.7156 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 105s 175ms/step - loss: inf - F1Score: 0.7017 - WeightedF1: 0.7156 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 105s 175ms/step - loss: inf - F1Score: 0.7015 - WeightedF1: 0.7154 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 105s 175ms/step - loss: inf - F1Score: 0.7014 - WeightedF1: 0.7154 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 10s 17ms/step\n",
      "3000/3000 [==============================] - 51s 17ms/step\n",
      "Fold 1 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.87    0.92      0.89    11706\n",
      "1  washing machine       0.90    0.75      0.82     8507\n",
      "2      dish washer       0.83    0.73      0.78     8309\n",
      "3        microwave       0.88    0.82      0.85     9549\n",
      "4           kettle       0.96    0.89      0.92     9949\n",
      "5        micro avg       0.89    0.83      0.86    48020\n",
      "6        macro avg       0.89    0.82      0.85    48020\n",
      "7     weighted avg       0.89    0.83      0.86    48020\n",
      "8      samples avg       0.89    0.84      0.85    48020\n",
      "-------------------------------------------------\n",
      "Fold 1 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.99      0.96    60539\n",
      "1  washing machine       0.74    0.55      0.63    49848\n",
      "2      dish washer       0.55    0.73      0.63    31498\n",
      "3        microwave       0.63    0.93      0.75    45078\n",
      "4           kettle       0.73    0.82      0.77    53030\n",
      "5        micro avg       0.72    0.82      0.77   239993\n",
      "6        macro avg       0.71    0.81      0.75   239993\n",
      "7     weighted avg       0.74    0.82      0.77   239993\n",
      "8      samples avg       0.71    0.80      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 2 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.89    0.90      0.90    11903\n",
      "1  washing machine       0.88    0.76      0.82     8383\n",
      "2      dish washer       0.81    0.77      0.79     8279\n",
      "3        microwave       0.86    0.82      0.84     9584\n",
      "4           kettle       0.95    0.91      0.93     9899\n",
      "5        micro avg       0.88    0.84      0.86    48048\n",
      "6        macro avg       0.88    0.83      0.85    48048\n",
      "7     weighted avg       0.88    0.84      0.86    48048\n",
      "8      samples avg       0.89    0.85      0.86    48048\n",
      "-------------------------------------------------\n",
      "Fold 2 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.99      0.96    60539\n",
      "1  washing machine       0.62    0.69      0.66    49848\n",
      "2      dish washer       0.51    0.76      0.61    31498\n",
      "3        microwave       0.62    0.95      0.75    45078\n",
      "4           kettle       0.83    0.74      0.79    53030\n",
      "5        micro avg       0.71    0.83      0.77   239993\n",
      "6        macro avg       0.70    0.83      0.75   239993\n",
      "7     weighted avg       0.73    0.83      0.77   239993\n",
      "8      samples avg       0.69    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 3 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.85    0.92      0.88    11755\n",
      "1  washing machine       0.91    0.74      0.82     8482\n",
      "2      dish washer       0.82    0.71      0.76     8145\n",
      "3        microwave       0.88    0.73      0.80     9633\n",
      "4           kettle       0.95    0.90      0.92     9989\n",
      "5        micro avg       0.88    0.81      0.84    48004\n",
      "6        macro avg       0.88    0.80      0.84    48004\n",
      "7     weighted avg       0.88    0.81      0.84    48004\n",
      "8      samples avg       0.89    0.82      0.84    48004\n",
      "-------------------------------------------------\n",
      "Fold 3 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.98      0.94    60539\n",
      "1  washing machine       0.61    0.72      0.66    49848\n",
      "2      dish washer       0.62    0.68      0.65    31498\n",
      "3        microwave       0.66    0.85      0.74    45078\n",
      "4           kettle       0.77    0.76      0.77    53030\n",
      "5        micro avg       0.72    0.82      0.77   239993\n",
      "6        macro avg       0.71    0.80      0.75   239993\n",
      "7     weighted avg       0.73    0.82      0.77   239993\n",
      "8      samples avg       0.69    0.80      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 4 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.88    0.90      0.89    11880\n",
      "1  washing machine       0.90    0.75      0.82     8396\n",
      "2      dish washer       0.85    0.68      0.75     8215\n",
      "3        microwave       0.88    0.73      0.80     9566\n",
      "4           kettle       0.95    0.90      0.92    10018\n",
      "5        micro avg       0.89    0.80      0.85    48075\n",
      "6        macro avg       0.89    0.79      0.84    48075\n",
      "7     weighted avg       0.89    0.80      0.84    48075\n",
      "8      samples avg       0.90    0.82      0.84    48075\n",
      "-------------------------------------------------\n",
      "Fold 4 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.99      0.96    60539\n",
      "1  washing machine       0.59    0.75      0.66    49848\n",
      "2      dish washer       0.75    0.62      0.68    31498\n",
      "3        microwave       0.59    0.92      0.72    45078\n",
      "4           kettle       0.91    0.71      0.80    53030\n",
      "5        micro avg       0.74    0.82      0.78   239993\n",
      "6        macro avg       0.76    0.80      0.76   239993\n",
      "7     weighted avg       0.77    0.82      0.78   239993\n",
      "8      samples avg       0.72    0.81      0.74   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 5 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.88    0.90      0.89    11798\n",
      "1  washing machine       0.91    0.73      0.81     8396\n",
      "2      dish washer       0.84    0.69      0.75     8174\n",
      "3        microwave       0.85    0.79      0.82     9484\n",
      "4           kettle       0.96    0.87      0.91    10001\n",
      "5        micro avg       0.89    0.81      0.84    47853\n",
      "6        macro avg       0.89    0.79      0.84    47853\n",
      "7     weighted avg       0.89    0.81      0.84    47853\n",
      "8      samples avg       0.89    0.82      0.84    47853\n",
      "-------------------------------------------------\n",
      "Fold 5 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.98      0.96    60539\n",
      "1  washing machine       0.62    0.68      0.65    49848\n",
      "2      dish washer       0.70    0.64      0.67    31498\n",
      "3        microwave       0.57    0.96      0.72    45078\n",
      "4           kettle       0.85    0.72      0.78    53030\n",
      "5        micro avg       0.73    0.81      0.77   239993\n",
      "6        macro avg       0.74    0.80      0.75   239993\n",
      "7     weighted avg       0.75    0.81      0.77   239993\n",
      "8      samples avg       0.70    0.80      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 6 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.91      0.92    11828\n",
      "1  washing machine       0.91    0.82      0.86     8389\n",
      "2      dish washer       0.89    0.80      0.85     8207\n",
      "3        microwave       0.92    0.85      0.89     9542\n",
      "4           kettle       0.96    0.93      0.95     9968\n",
      "5        micro avg       0.93    0.87      0.90    47934\n",
      "6        macro avg       0.93    0.86      0.89    47934\n",
      "7     weighted avg       0.93    0.87      0.90    47934\n",
      "8      samples avg       0.93    0.88      0.90    47934\n",
      "-------------------------------------------------\n",
      "Fold 6 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.95    0.92      0.94    60539\n",
      "1  washing machine       0.60    0.70      0.65    49848\n",
      "2      dish washer       0.57    0.70      0.62    31498\n",
      "3        microwave       0.69    0.92      0.79    45078\n",
      "4           kettle       0.77    0.73      0.75    53030\n",
      "5        micro avg       0.72    0.80      0.76   239993\n",
      "6        macro avg       0.71    0.79      0.75   239993\n",
      "7     weighted avg       0.74    0.80      0.77   239993\n",
      "8      samples avg       0.69    0.78      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 7 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.91      0.91    11670\n",
      "1  washing machine       0.90    0.82      0.86     8394\n",
      "2      dish washer       0.87    0.78      0.82     8254\n",
      "3        microwave       0.89    0.85      0.87     9554\n",
      "4           kettle       0.96    0.92      0.94     9928\n",
      "5        micro avg       0.91    0.86      0.88    47800\n",
      "6        macro avg       0.91    0.86      0.88    47800\n",
      "7     weighted avg       0.91    0.86      0.88    47800\n",
      "8      samples avg       0.92    0.88      0.89    47800\n",
      "-------------------------------------------------\n",
      "Fold 7 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.98      0.96    60539\n",
      "1  washing machine       0.56    0.83      0.67    49848\n",
      "2      dish washer       0.71    0.65      0.67    31498\n",
      "3        microwave       0.63    0.90      0.74    45078\n",
      "4           kettle       0.80    0.73      0.76    53030\n",
      "5        micro avg       0.72    0.84      0.77   239993\n",
      "6        macro avg       0.73    0.82      0.76   239993\n",
      "7     weighted avg       0.74    0.84      0.78   239993\n",
      "8      samples avg       0.68    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 8 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.84      0.89    11782\n",
      "1  washing machine       0.63    0.91      0.74     8527\n",
      "2      dish washer       0.93    0.60      0.73     8269\n",
      "3        microwave       0.87    0.80      0.83     9595\n",
      "4           kettle       0.94    0.89      0.92     9911\n",
      "5        micro avg       0.84    0.81      0.83    48084\n",
      "6        macro avg       0.86    0.81      0.82    48084\n",
      "7     weighted avg       0.87    0.81      0.83    48084\n",
      "8      samples avg       0.84    0.83      0.82    48084\n",
      "-------------------------------------------------\n",
      "Fold 8 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.96    0.98      0.97    60539\n",
      "1  washing machine       0.57    0.85      0.68    49848\n",
      "2      dish washer       0.90    0.57      0.70    31498\n",
      "3        microwave       0.62    0.91      0.74    45078\n",
      "4           kettle       0.78    0.78      0.78    53030\n",
      "5        micro avg       0.73    0.84      0.78   239993\n",
      "6        macro avg       0.77    0.82      0.77   239993\n",
      "7     weighted avg       0.77    0.84      0.79   239993\n",
      "8      samples avg       0.72    0.84      0.75   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 9 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.93      0.92    11834\n",
      "1  washing machine       0.91    0.80      0.85     8478\n",
      "2      dish washer       0.85    0.79      0.82     8188\n",
      "3        microwave       0.93    0.83      0.87     9619\n",
      "4           kettle       0.96    0.93      0.94    10086\n",
      "5        micro avg       0.91    0.86      0.89    48205\n",
      "6        macro avg       0.91    0.85      0.88    48205\n",
      "7     weighted avg       0.91    0.86      0.89    48205\n",
      "8      samples avg       0.92    0.88      0.89    48205\n",
      "-------------------------------------------------\n",
      "Fold 9 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.89      0.90    60539\n",
      "1  washing machine       0.57    0.81      0.67    49848\n",
      "2      dish washer       0.58    0.71      0.64    31498\n",
      "3        microwave       0.67    0.85      0.75    45078\n",
      "4           kettle       0.86    0.72      0.78    53030\n",
      "5        micro avg       0.72    0.81      0.76   239993\n",
      "6        macro avg       0.72    0.80      0.75   239993\n",
      "7     weighted avg       0.74    0.81      0.76   239993\n",
      "8      samples avg       0.69    0.78      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 10 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.93      0.92    11928\n",
      "1  washing machine       0.90    0.81      0.85     8376\n",
      "2      dish washer       0.87    0.79      0.82     8204\n",
      "3        microwave       0.88    0.86      0.87     9506\n",
      "4           kettle       0.95    0.92      0.94     9963\n",
      "5        micro avg       0.91    0.87      0.89    47977\n",
      "6        macro avg       0.90    0.86      0.88    47977\n",
      "7     weighted avg       0.91    0.87      0.89    47977\n",
      "8      samples avg       0.92    0.88      0.89    47977\n",
      "-------------------------------------------------\n",
      "Fold 10 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.99      0.95    60539\n",
      "1  washing machine       0.58    0.80      0.67    49848\n",
      "2      dish washer       0.67    0.65      0.66    31498\n",
      "3        microwave       0.65    0.91      0.76    45078\n",
      "4           kettle       0.78    0.77      0.78    53030\n",
      "5        micro avg       0.72    0.84      0.78   239993\n",
      "6        macro avg       0.72    0.82      0.76   239993\n",
      "7     weighted avg       0.74    0.84      0.78   239993\n",
      "8      samples avg       0.70    0.82      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 11 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.91      0.92    11776\n",
      "1  washing machine       0.92    0.82      0.87     8517\n",
      "2      dish washer       0.86    0.82      0.84     8190\n",
      "3        microwave       0.89    0.87      0.88     9613\n",
      "4           kettle       0.97    0.92      0.95     9969\n",
      "5        micro avg       0.92    0.88      0.90    48065\n",
      "6        macro avg       0.91    0.87      0.89    48065\n",
      "7     weighted avg       0.92    0.88      0.90    48065\n",
      "8      samples avg       0.93    0.89      0.90    48065\n",
      "-------------------------------------------------\n",
      "Fold 11 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.94      0.94    60539\n",
      "1  washing machine       0.57    0.81      0.67    49848\n",
      "2      dish washer       0.62    0.68      0.64    31498\n",
      "3        microwave       0.67    0.90      0.77    45078\n",
      "4           kettle       0.81    0.70      0.75    53030\n",
      "5        micro avg       0.72    0.82      0.76   239993\n",
      "6        macro avg       0.72    0.80      0.75   239993\n",
      "7     weighted avg       0.74    0.82      0.77   239993\n",
      "8      samples avg       0.68    0.79      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 12 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.93      0.93    11825\n",
      "1  washing machine       0.92    0.83      0.87     8448\n",
      "2      dish washer       0.89    0.81      0.85     8210\n",
      "3        microwave       0.91    0.88      0.89     9562\n",
      "4           kettle       0.96    0.94      0.95     9927\n",
      "5        micro avg       0.92    0.88      0.90    47972\n",
      "6        macro avg       0.92    0.88      0.90    47972\n",
      "7     weighted avg       0.92    0.88      0.90    47972\n",
      "8      samples avg       0.93    0.90      0.91    47972\n",
      "-------------------------------------------------\n",
      "Fold 12 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.98      0.96    60539\n",
      "1  washing machine       0.58    0.82      0.68    49848\n",
      "2      dish washer       0.75    0.60      0.66    31498\n",
      "3        microwave       0.64    0.91      0.75    45078\n",
      "4           kettle       0.79    0.75      0.77    53030\n",
      "5        micro avg       0.73    0.83      0.78   239993\n",
      "6        macro avg       0.74    0.81      0.76   239993\n",
      "7     weighted avg       0.75    0.83      0.78   239993\n",
      "8      samples avg       0.71    0.82      0.74   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 13 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.94      0.92    11762\n",
      "1  washing machine       0.89    0.85      0.87     8396\n",
      "2      dish washer       0.83    0.86      0.84     8248\n",
      "3        microwave       0.91    0.86      0.88     9477\n",
      "4           kettle       0.94    0.94      0.94    10024\n",
      "5        micro avg       0.90    0.89      0.89    47907\n",
      "6        macro avg       0.89    0.89      0.89    47907\n",
      "7     weighted avg       0.90    0.89      0.89    47907\n",
      "8      samples avg       0.91    0.91      0.90    47907\n",
      "-------------------------------------------------\n",
      "Fold 13 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.88    0.96      0.92    60539\n",
      "1  washing machine       0.57    0.85      0.68    49848\n",
      "2      dish washer       0.61    0.70      0.65    31498\n",
      "3        microwave       0.65    0.88      0.74    45078\n",
      "4           kettle       0.66    0.83      0.74    53030\n",
      "5        micro avg       0.68    0.86      0.76   239993\n",
      "6        macro avg       0.67    0.84      0.75   239993\n",
      "7     weighted avg       0.69    0.86      0.76   239993\n",
      "8      samples avg       0.65    0.84      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 14 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.93      0.93    11786\n",
      "1  washing machine       0.93    0.82      0.87     8379\n",
      "2      dish washer       0.86    0.85      0.86     8269\n",
      "3        microwave       0.91    0.86      0.89     9574\n",
      "4           kettle       0.98    0.92      0.95     9978\n",
      "5        micro avg       0.92    0.88      0.90    47986\n",
      "6        macro avg       0.92    0.87      0.90    47986\n",
      "7     weighted avg       0.92    0.88      0.90    47986\n",
      "8      samples avg       0.93    0.90      0.90    47986\n",
      "-------------------------------------------------\n",
      "Fold 14 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.99      0.96    60539\n",
      "1  washing machine       0.57    0.78      0.66    49848\n",
      "2      dish washer       0.59    0.70      0.64    31498\n",
      "3        microwave       0.66    0.90      0.76    45078\n",
      "4           kettle       0.85    0.67      0.75    53030\n",
      "5        micro avg       0.72    0.82      0.77   239993\n",
      "6        macro avg       0.72    0.81      0.75   239993\n",
      "7     weighted avg       0.74    0.82      0.77   239993\n",
      "8      samples avg       0.69    0.80      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 15 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.92      0.93    11893\n",
      "1  washing machine       0.91    0.84      0.88     8424\n",
      "2      dish washer       0.86    0.86      0.86     8205\n",
      "3        microwave       0.90    0.88      0.89     9590\n",
      "4           kettle       0.97    0.93      0.95     9958\n",
      "5        micro avg       0.92    0.89      0.90    48070\n",
      "6        macro avg       0.91    0.89      0.90    48070\n",
      "7     weighted avg       0.92    0.89      0.90    48070\n",
      "8      samples avg       0.93    0.91      0.91    48070\n",
      "-------------------------------------------------\n",
      "Fold 15 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.99      0.96    60539\n",
      "1  washing machine       0.59    0.80      0.68    49848\n",
      "2      dish washer       0.60    0.71      0.65    31498\n",
      "3        microwave       0.63    0.93      0.75    45078\n",
      "4           kettle       0.85    0.69      0.76    53030\n",
      "5        micro avg       0.72    0.84      0.77   239993\n",
      "6        macro avg       0.72    0.82      0.76   239993\n",
      "7     weighted avg       0.74    0.84      0.78   239993\n",
      "8      samples avg       0.69    0.82      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 16 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.92      0.92    11865\n",
      "1  washing machine       0.92    0.84      0.88     8506\n",
      "2      dish washer       0.90    0.80      0.85     8222\n",
      "3        microwave       0.91    0.87      0.89     9541\n",
      "4           kettle       0.96    0.94      0.95     9954\n",
      "5        micro avg       0.93    0.88      0.90    48088\n",
      "6        macro avg       0.92    0.88      0.90    48088\n",
      "7     weighted avg       0.92    0.88      0.90    48088\n",
      "8      samples avg       0.93    0.90      0.91    48088\n",
      "-------------------------------------------------\n",
      "Fold 16 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.96      0.94    60539\n",
      "1  washing machine       0.57    0.81      0.67    49848\n",
      "2      dish washer       0.67    0.67      0.67    31498\n",
      "3        microwave       0.66    0.90      0.76    45078\n",
      "4           kettle       0.86    0.71      0.78    53030\n",
      "5        micro avg       0.73    0.82      0.77   239993\n",
      "6        macro avg       0.74    0.81      0.76   239993\n",
      "7     weighted avg       0.75    0.82      0.78   239993\n",
      "8      samples avg       0.70    0.80      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 17 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.76      0.84    11794\n",
      "1  washing machine       0.54    0.89      0.67     8394\n",
      "2      dish washer       0.85    0.57      0.68     8120\n",
      "3        microwave       0.86    0.60      0.71     9589\n",
      "4           kettle       0.95    0.82      0.88     9895\n",
      "5        micro avg       0.79    0.73      0.76    47792\n",
      "6        macro avg       0.83    0.73      0.76    47792\n",
      "7     weighted avg       0.84    0.73      0.77    47792\n",
      "8      samples avg       0.77    0.73      0.72    47792\n",
      "-------------------------------------------------\n",
      "Fold 17 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.96    0.96      0.96    60539\n",
      "1  washing machine       0.61    0.76      0.68    49848\n",
      "2      dish washer       0.62    0.65      0.63    31498\n",
      "3        microwave       0.56    0.95      0.70    45078\n",
      "4           kettle       0.88    0.70      0.78    53030\n",
      "5        micro avg       0.72    0.82      0.76   239993\n",
      "6        macro avg       0.73    0.80      0.75   239993\n",
      "7     weighted avg       0.75    0.82      0.77   239993\n",
      "8      samples avg       0.72    0.82      0.74   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 18 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.84      0.87    11818\n",
      "1  washing machine       0.52    0.92      0.67     8432\n",
      "2      dish washer       0.86    0.58      0.69     8328\n",
      "3        microwave       0.91    0.54      0.68     9480\n",
      "4           kettle       0.96    0.84      0.90     9933\n",
      "5        micro avg       0.79    0.75      0.77    47991\n",
      "6        macro avg       0.83    0.74      0.76    47991\n",
      "7     weighted avg       0.84    0.75      0.77    47991\n",
      "8      samples avg       0.77    0.75      0.73    47991\n",
      "-------------------------------------------------\n",
      "Fold 18 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.99      0.95    60539\n",
      "1  washing machine       0.64    0.79      0.71    49848\n",
      "2      dish washer       0.60    0.68      0.64    31498\n",
      "3        microwave       0.69    0.83      0.75    45078\n",
      "4           kettle       0.84    0.71      0.77    53030\n",
      "5        micro avg       0.75    0.82      0.78   239993\n",
      "6        macro avg       0.74    0.80      0.76   239993\n",
      "7     weighted avg       0.76    0.82      0.78   239993\n",
      "8      samples avg       0.75    0.82      0.76   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 19 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.92      0.93    11787\n",
      "1  washing machine       0.90    0.86      0.88     8464\n",
      "2      dish washer       0.88    0.82      0.85     8235\n",
      "3        microwave       0.92    0.86      0.89     9610\n",
      "4           kettle       0.97    0.93      0.95     9992\n",
      "5        micro avg       0.92    0.88      0.90    48088\n",
      "6        macro avg       0.92    0.88      0.90    48088\n",
      "7     weighted avg       0.92    0.88      0.90    48088\n",
      "8      samples avg       0.93    0.90      0.91    48088\n",
      "-------------------------------------------------\n",
      "Fold 19 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.96      0.95    60539\n",
      "1  washing machine       0.57    0.84      0.68    49848\n",
      "2      dish washer       0.53    0.73      0.61    31498\n",
      "3        microwave       0.68    0.83      0.75    45078\n",
      "4           kettle       0.73    0.76      0.74    53030\n",
      "5        micro avg       0.69    0.84      0.76   239993\n",
      "6        macro avg       0.69    0.82      0.75   239993\n",
      "7     weighted avg       0.71    0.84      0.77   239993\n",
      "8      samples avg       0.67    0.82      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 20 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.92      0.93    11778\n",
      "1  washing machine       0.91    0.84      0.87     8368\n",
      "2      dish washer       0.85    0.84      0.85     8217\n",
      "3        microwave       0.91    0.87      0.89     9596\n",
      "4           kettle       0.95    0.93      0.94    10082\n",
      "5        micro avg       0.91    0.89      0.90    48041\n",
      "6        macro avg       0.91    0.88      0.90    48041\n",
      "7     weighted avg       0.91    0.89      0.90    48041\n",
      "8      samples avg       0.93    0.90      0.90    48041\n",
      "-------------------------------------------------\n",
      "Fold 20 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.97      0.95    60539\n",
      "1  washing machine       0.57    0.82      0.67    49848\n",
      "2      dish washer       0.55    0.72      0.62    31498\n",
      "3        microwave       0.65    0.86      0.74    45078\n",
      "4           kettle       0.76    0.77      0.77    53030\n",
      "5        micro avg       0.70    0.84      0.76   239993\n",
      "6        macro avg       0.69    0.83      0.75   239993\n",
      "7     weighted avg       0.71    0.84      0.77   239993\n",
      "8      samples avg       0.67    0.82      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 21 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.86    0.90      0.88    11890\n",
      "1  washing machine       0.90    0.72      0.80     8479\n",
      "2      dish washer       0.88    0.58      0.70     8116\n",
      "3        microwave       0.55    0.93      0.69     9604\n",
      "4           kettle       0.96    0.77      0.85    10055\n",
      "5        micro avg       0.78    0.79      0.79    48144\n",
      "6        macro avg       0.83    0.78      0.78    48144\n",
      "7     weighted avg       0.83    0.79      0.79    48144\n",
      "8      samples avg       0.77    0.80      0.76    48144\n",
      "-------------------------------------------------\n",
      "Fold 21 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.99      0.95    60539\n",
      "1  washing machine       0.71    0.61      0.66    49848\n",
      "2      dish washer       0.57    0.70      0.63    31498\n",
      "3        microwave       0.58    0.91      0.71    45078\n",
      "4           kettle       0.94    0.53      0.68    53030\n",
      "5        micro avg       0.73    0.76      0.75   239993\n",
      "6        macro avg       0.74    0.75      0.72   239993\n",
      "7     weighted avg       0.77    0.76      0.74   239993\n",
      "8      samples avg       0.73    0.75      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 22 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.92      0.93    11862\n",
      "1  washing machine       0.88    0.89      0.89     8406\n",
      "2      dish washer       0.89    0.83      0.86     8269\n",
      "3        microwave       0.93    0.86      0.89     9586\n",
      "4           kettle       0.96    0.94      0.95     9876\n",
      "5        micro avg       0.92    0.89      0.91    47999\n",
      "6        macro avg       0.92    0.89      0.90    47999\n",
      "7     weighted avg       0.92    0.89      0.91    47999\n",
      "8      samples avg       0.93    0.91      0.91    47999\n",
      "-------------------------------------------------\n",
      "Fold 22 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.98      0.95    60539\n",
      "1  washing machine       0.57    0.87      0.68    49848\n",
      "2      dish washer       0.63    0.67      0.65    31498\n",
      "3        microwave       0.67    0.85      0.75    45078\n",
      "4           kettle       0.80    0.72      0.76    53030\n",
      "5        micro avg       0.72    0.84      0.77   239993\n",
      "6        macro avg       0.72    0.82      0.76   239993\n",
      "7     weighted avg       0.73    0.84      0.78   239993\n",
      "8      samples avg       0.69    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 23 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.91      0.93    11732\n",
      "1  washing machine       0.91    0.85      0.88     8519\n",
      "2      dish washer       0.90    0.84      0.87     8304\n",
      "3        microwave       0.91    0.87      0.89     9582\n",
      "4           kettle       0.95    0.94      0.95     9995\n",
      "5        micro avg       0.92    0.89      0.91    48132\n",
      "6        macro avg       0.92    0.88      0.90    48132\n",
      "7     weighted avg       0.92    0.89      0.91    48132\n",
      "8      samples avg       0.94    0.90      0.91    48132\n",
      "-------------------------------------------------\n",
      "Fold 23 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.98      0.96    60539\n",
      "1  washing machine       0.57    0.83      0.67    49848\n",
      "2      dish washer       0.76    0.62      0.68    31498\n",
      "3        microwave       0.64    0.92      0.75    45078\n",
      "4           kettle       0.75    0.78      0.76    53030\n",
      "5        micro avg       0.72    0.85      0.78   239993\n",
      "6        macro avg       0.73    0.82      0.77   239993\n",
      "7     weighted avg       0.74    0.85      0.78   239993\n",
      "8      samples avg       0.69    0.83      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 24 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.86      0.89    11836\n",
      "1  washing machine       0.78    0.85      0.81     8450\n",
      "2      dish washer       0.88    0.62      0.73     8204\n",
      "3        microwave       0.92    0.72      0.80     9561\n",
      "4           kettle       0.97    0.87      0.92     9908\n",
      "5        micro avg       0.90    0.79      0.84    47959\n",
      "6        macro avg       0.89    0.78      0.83    47959\n",
      "7     weighted avg       0.90    0.79      0.84    47959\n",
      "8      samples avg       0.89    0.80      0.83    47959\n",
      "-------------------------------------------------\n",
      "Fold 24 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.99      0.96    60539\n",
      "1  washing machine       0.60    0.82      0.69    49848\n",
      "2      dish washer       0.67    0.65      0.66    31498\n",
      "3        microwave       0.59    0.95      0.73    45078\n",
      "4           kettle       0.95    0.65      0.77    53030\n",
      "5        micro avg       0.73    0.83      0.77   239993\n",
      "6        macro avg       0.75    0.81      0.76   239993\n",
      "7     weighted avg       0.77    0.83      0.78   239993\n",
      "8      samples avg       0.72    0.82      0.74   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 25 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.93      0.92    11722\n",
      "1  washing machine       0.90    0.85      0.88     8310\n",
      "2      dish washer       0.86    0.87      0.86     8229\n",
      "3        microwave       0.92    0.86      0.89     9483\n",
      "4           kettle       0.97    0.93      0.95    10022\n",
      "5        micro avg       0.92    0.89      0.90    47766\n",
      "6        macro avg       0.91    0.89      0.90    47766\n",
      "7     weighted avg       0.92    0.89      0.90    47766\n",
      "8      samples avg       0.93    0.91      0.91    47766\n",
      "-------------------------------------------------\n",
      "Fold 25 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.98      0.94    60539\n",
      "1  washing machine       0.57    0.83      0.68    49848\n",
      "2      dish washer       0.60    0.70      0.64    31498\n",
      "3        microwave       0.64    0.91      0.75    45078\n",
      "4           kettle       0.85    0.70      0.77    53030\n",
      "5        micro avg       0.71    0.84      0.77   239993\n",
      "6        macro avg       0.71    0.82      0.76   239993\n",
      "7     weighted avg       0.73    0.84      0.77   239993\n",
      "8      samples avg       0.68    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 26 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.92      0.93    11834\n",
      "1  washing machine       0.89    0.88      0.89     8486\n",
      "2      dish washer       0.86    0.87      0.86     8217\n",
      "3        microwave       0.94    0.86      0.90     9608\n",
      "4           kettle       0.96    0.94      0.95     9991\n",
      "5        micro avg       0.92    0.90      0.91    48136\n",
      "6        macro avg       0.92    0.89      0.90    48136\n",
      "7     weighted avg       0.92    0.90      0.91    48136\n",
      "8      samples avg       0.93    0.91      0.91    48136\n",
      "-------------------------------------------------\n",
      "Fold 26 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.97      0.94    60539\n",
      "1  washing machine       0.57    0.82      0.67    49848\n",
      "2      dish washer       0.54    0.74      0.62    31498\n",
      "3        microwave       0.67    0.89      0.77    45078\n",
      "4           kettle       0.78    0.74      0.76    53030\n",
      "5        micro avg       0.70    0.84      0.76   239993\n",
      "6        macro avg       0.70    0.83      0.75   239993\n",
      "7     weighted avg       0.72    0.84      0.77   239993\n",
      "8      samples avg       0.67    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 27 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.92      0.93    11760\n",
      "1  washing machine       0.88    0.88      0.88     8511\n",
      "2      dish washer       0.88    0.85      0.86     8235\n",
      "3        microwave       0.90    0.87      0.89     9475\n",
      "4           kettle       0.98    0.92      0.95     9937\n",
      "5        micro avg       0.92    0.89      0.91    47918\n",
      "6        macro avg       0.92    0.89      0.90    47918\n",
      "7     weighted avg       0.92    0.89      0.91    47918\n",
      "8      samples avg       0.93    0.91      0.91    47918\n",
      "-------------------------------------------------\n",
      "Fold 27 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.98      0.94    60539\n",
      "1  washing machine       0.57    0.86      0.69    49848\n",
      "2      dish washer       0.57    0.69      0.63    31498\n",
      "3        microwave       0.66    0.90      0.76    45078\n",
      "4           kettle       0.83    0.65      0.73    53030\n",
      "5        micro avg       0.71    0.83      0.76   239993\n",
      "6        macro avg       0.71    0.82      0.75   239993\n",
      "7     weighted avg       0.73    0.83      0.77   239993\n",
      "8      samples avg       0.68    0.81      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 28 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.93      0.92    11821\n",
      "1  washing machine       0.91    0.85      0.88     8312\n",
      "2      dish washer       0.88    0.83      0.85     8213\n",
      "3        microwave       0.91    0.87      0.89     9643\n",
      "4           kettle       0.97    0.93      0.95     9999\n",
      "5        micro avg       0.92    0.89      0.90    47988\n",
      "6        macro avg       0.92    0.88      0.90    47988\n",
      "7     weighted avg       0.92    0.89      0.90    47988\n",
      "8      samples avg       0.93    0.90      0.91    47988\n",
      "-------------------------------------------------\n",
      "Fold 28 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.99      0.95    60539\n",
      "1  washing machine       0.57    0.80      0.67    49848\n",
      "2      dish washer       0.61    0.68      0.64    31498\n",
      "3        microwave       0.64    0.92      0.76    45078\n",
      "4           kettle       0.81    0.64      0.71    53030\n",
      "5        micro avg       0.71    0.82      0.76   239993\n",
      "6        macro avg       0.71    0.80      0.74   239993\n",
      "7     weighted avg       0.73    0.82      0.76   239993\n",
      "8      samples avg       0.67    0.79      0.70   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 29 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.92      0.93    11744\n",
      "1  washing machine       0.89    0.87      0.88     8430\n",
      "2      dish washer       0.89    0.83      0.86     8249\n",
      "3        microwave       0.90    0.88      0.89     9546\n",
      "4           kettle       0.96    0.94      0.95     9980\n",
      "5        micro avg       0.92    0.89      0.90    47949\n",
      "6        macro avg       0.91    0.89      0.90    47949\n",
      "7     weighted avg       0.92    0.89      0.90    47949\n",
      "8      samples avg       0.93    0.91      0.91    47949\n",
      "-------------------------------------------------\n",
      "Fold 29 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.98      0.95    60539\n",
      "1  washing machine       0.57    0.84      0.68    49848\n",
      "2      dish washer       0.68    0.64      0.66    31498\n",
      "3        microwave       0.63    0.90      0.74    45078\n",
      "4           kettle       0.79    0.73      0.76    53030\n",
      "5        micro avg       0.71    0.84      0.77   239993\n",
      "6        macro avg       0.72    0.82      0.76   239993\n",
      "7     weighted avg       0.73    0.84      0.77   239993\n",
      "8      samples avg       0.69    0.82      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 30 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.91      0.93    11883\n",
      "1  washing machine       0.90    0.86      0.88     8425\n",
      "2      dish washer       0.88    0.82      0.85     8208\n",
      "3        microwave       0.92    0.85      0.89     9544\n",
      "4           kettle       0.96    0.93      0.95     9949\n",
      "5        micro avg       0.92    0.88      0.90    48009\n",
      "6        macro avg       0.92    0.88      0.90    48009\n",
      "7     weighted avg       0.92    0.88      0.90    48009\n",
      "8      samples avg       0.94    0.90      0.91    48009\n",
      "-------------------------------------------------\n",
      "Fold 30 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.98      0.96    60539\n",
      "1  washing machine       0.57    0.85      0.68    49848\n",
      "2      dish washer       0.70    0.64      0.67    31498\n",
      "3        microwave       0.70    0.89      0.78    45078\n",
      "4           kettle       0.89    0.68      0.77    53030\n",
      "5        micro avg       0.75    0.83      0.78   239993\n",
      "6        macro avg       0.76    0.81      0.77   239993\n",
      "7     weighted avg       0.77    0.83      0.79   239993\n",
      "8      samples avg       0.72    0.81      0.74   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 31 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.92      0.93    11875\n",
      "1  washing machine       0.92    0.85      0.89     8512\n",
      "2      dish washer       0.86    0.86      0.86     8137\n",
      "3        microwave       0.89    0.88      0.89     9475\n",
      "4           kettle       0.97    0.92      0.95     9969\n",
      "5        micro avg       0.92    0.89      0.90    47968\n",
      "6        macro avg       0.92    0.89      0.90    47968\n",
      "7     weighted avg       0.92    0.89      0.90    47968\n",
      "8      samples avg       0.93    0.91      0.91    47968\n",
      "-------------------------------------------------\n",
      "Fold 31 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.96      0.94    60539\n",
      "1  washing machine       0.58    0.81      0.67    49848\n",
      "2      dish washer       0.52    0.75      0.61    31498\n",
      "3        microwave       0.64    0.92      0.76    45078\n",
      "4           kettle       0.78    0.66      0.71    53030\n",
      "5        micro avg       0.69    0.83      0.75   239993\n",
      "6        macro avg       0.69    0.82      0.74   239993\n",
      "7     weighted avg       0.71    0.83      0.76   239993\n",
      "8      samples avg       0.66    0.80      0.70   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 32 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.92      0.93    11766\n",
      "1  washing machine       0.90    0.88      0.89     8431\n",
      "2      dish washer       0.89    0.84      0.86     8239\n",
      "3        microwave       0.92    0.88      0.89     9563\n",
      "4           kettle       0.97    0.94      0.95     9968\n",
      "5        micro avg       0.92    0.89      0.91    47967\n",
      "6        macro avg       0.92    0.89      0.91    47967\n",
      "7     weighted avg       0.92    0.89      0.91    47967\n",
      "8      samples avg       0.94    0.91      0.92    47967\n",
      "-------------------------------------------------\n",
      "Fold 32 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.97      0.95    60539\n",
      "1  washing machine       0.57    0.85      0.68    49848\n",
      "2      dish washer       0.59    0.67      0.63    31498\n",
      "3        microwave       0.65    0.90      0.75    45078\n",
      "4           kettle       0.83    0.70      0.76    53030\n",
      "5        micro avg       0.71    0.83      0.77   239993\n",
      "6        macro avg       0.71    0.82      0.75   239993\n",
      "7     weighted avg       0.73    0.83      0.77   239993\n",
      "8      samples avg       0.69    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 33 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.95    0.91      0.93    11780\n",
      "1  washing machine       0.90    0.87      0.88     8358\n",
      "2      dish washer       0.89    0.85      0.87     8275\n",
      "3        microwave       0.90    0.89      0.89     9670\n",
      "4           kettle       0.96    0.94      0.95     9962\n",
      "5        micro avg       0.92    0.89      0.91    48045\n",
      "6        macro avg       0.92    0.89      0.90    48045\n",
      "7     weighted avg       0.92    0.89      0.91    48045\n",
      "8      samples avg       0.93    0.91      0.91    48045\n",
      "-------------------------------------------------\n",
      "Fold 33 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.97      0.94    60539\n",
      "1  washing machine       0.57    0.83      0.68    49848\n",
      "2      dish washer       0.66    0.64      0.65    31498\n",
      "3        microwave       0.60    0.91      0.72    45078\n",
      "4           kettle       0.79    0.75      0.77    53030\n",
      "5        micro avg       0.70    0.84      0.76   239993\n",
      "6        macro avg       0.71    0.82      0.75   239993\n",
      "7     weighted avg       0.72    0.84      0.77   239993\n",
      "8      samples avg       0.67    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 34 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.93      0.92    11846\n",
      "1  washing machine       0.89    0.85      0.87     8455\n",
      "2      dish washer       0.87    0.81      0.84     8185\n",
      "3        microwave       0.91    0.85      0.87     9533\n",
      "4           kettle       0.95    0.94      0.95     9982\n",
      "5        micro avg       0.91    0.88      0.89    48001\n",
      "6        macro avg       0.91    0.87      0.89    48001\n",
      "7     weighted avg       0.91    0.88      0.89    48001\n",
      "8      samples avg       0.92    0.90      0.90    48001\n",
      "-------------------------------------------------\n",
      "Fold 34 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.99      0.95    60539\n",
      "1  washing machine       0.57    0.85      0.68    49848\n",
      "2      dish washer       0.71    0.63      0.67    31498\n",
      "3        microwave       0.62    0.93      0.74    45078\n",
      "4           kettle       0.78    0.75      0.77    53030\n",
      "5        micro avg       0.71    0.85      0.77   239993\n",
      "6        macro avg       0.72    0.83      0.76   239993\n",
      "7     weighted avg       0.73    0.85      0.78   239993\n",
      "8      samples avg       0.68    0.83      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 35 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.93      0.93    11775\n",
      "1  washing machine       0.89    0.87      0.88     8408\n",
      "2      dish washer       0.90    0.81      0.86     8286\n",
      "3        microwave       0.92    0.86      0.89     9575\n",
      "4           kettle       0.97    0.92      0.94     9975\n",
      "5        micro avg       0.92    0.88      0.90    48019\n",
      "6        macro avg       0.92    0.88      0.90    48019\n",
      "7     weighted avg       0.92    0.88      0.90    48019\n",
      "8      samples avg       0.93    0.90      0.91    48019\n",
      "-------------------------------------------------\n",
      "Fold 35 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.99      0.94    60539\n",
      "1  washing machine       0.57    0.84      0.68    49848\n",
      "2      dish washer       0.63    0.66      0.64    31498\n",
      "3        microwave       0.68    0.88      0.77    45078\n",
      "4           kettle       0.89    0.61      0.73    53030\n",
      "5        micro avg       0.73    0.81      0.77   239993\n",
      "6        macro avg       0.73    0.80      0.75   239993\n",
      "7     weighted avg       0.75    0.81      0.77   239993\n",
      "8      samples avg       0.69    0.79      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 36 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.73    0.70      0.71    11874\n",
      "1  washing machine       0.58    0.12      0.19     8429\n",
      "2      dish washer       0.59    0.12      0.19     8174\n",
      "3        microwave       0.71    0.30      0.42     9533\n",
      "4           kettle       0.59    0.29      0.39     9925\n",
      "5        micro avg       0.67    0.34      0.45    47935\n",
      "6        macro avg       0.64    0.31      0.38    47935\n",
      "7     weighted avg       0.64    0.34      0.41    47935\n",
      "8      samples avg       0.49    0.35      0.38    47935\n",
      "-------------------------------------------------\n",
      "Fold 36 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.79    0.75      0.77    60539\n",
      "1  washing machine       0.52    0.38      0.44    49848\n",
      "2      dish washer       0.35    0.29      0.32    31498\n",
      "3        microwave       0.52    0.63      0.57    45078\n",
      "4           kettle       0.63    0.41      0.50    53030\n",
      "5        micro avg       0.59    0.51      0.55   239993\n",
      "6        macro avg       0.56    0.49      0.52   239993\n",
      "7     weighted avg       0.59    0.51      0.54   239993\n",
      "8      samples avg       0.47    0.48      0.43   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 37 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.92      0.93    11808\n",
      "1  washing machine       0.89    0.88      0.88     8450\n",
      "2      dish washer       0.90    0.83      0.86     8240\n",
      "3        microwave       0.93    0.85      0.89     9680\n",
      "4           kettle       0.96    0.94      0.95     9961\n",
      "5        micro avg       0.92    0.89      0.90    48139\n",
      "6        macro avg       0.92    0.88      0.90    48139\n",
      "7     weighted avg       0.92    0.89      0.90    48139\n",
      "8      samples avg       0.93    0.90      0.91    48139\n",
      "-------------------------------------------------\n",
      "Fold 37 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.99      0.95    60539\n",
      "1  washing machine       0.57    0.84      0.68    49848\n",
      "2      dish washer       0.58    0.70      0.63    31498\n",
      "3        microwave       0.66    0.85      0.75    45078\n",
      "4           kettle       0.89    0.68      0.77    53030\n",
      "5        micro avg       0.72    0.83      0.77   239993\n",
      "6        macro avg       0.72    0.81      0.76   239993\n",
      "7     weighted avg       0.75    0.83      0.78   239993\n",
      "8      samples avg       0.69    0.81      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 38 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.86    0.85      0.86    11775\n",
      "1  washing machine       0.81    0.74      0.77     8381\n",
      "2      dish washer       0.90    0.49      0.63     8220\n",
      "3        microwave       0.51    0.97      0.67     9499\n",
      "4           kettle       0.97    0.78      0.87     9992\n",
      "5        micro avg       0.75    0.78      0.76    47867\n",
      "6        macro avg       0.81    0.77      0.76    47867\n",
      "7     weighted avg       0.81    0.78      0.77    47867\n",
      "8      samples avg       0.72    0.78      0.72    47867\n",
      "-------------------------------------------------\n",
      "Fold 38 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.99      0.95    60539\n",
      "1  washing machine       0.63    0.71      0.67    49848\n",
      "2      dish washer       0.74    0.59      0.65    31498\n",
      "3        microwave       0.47    1.00      0.64    45078\n",
      "4           kettle       0.96    0.61      0.75    53030\n",
      "5        micro avg       0.69    0.79      0.74   239993\n",
      "6        macro avg       0.74    0.78      0.73   239993\n",
      "7     weighted avg       0.76    0.79      0.75   239993\n",
      "8      samples avg       0.66    0.78      0.69   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 39 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.92      0.92    11747\n",
      "1  washing machine       0.91    0.87      0.89     8522\n",
      "2      dish washer       0.89    0.81      0.85     8233\n",
      "3        microwave       0.92    0.85      0.89     9541\n",
      "4           kettle       0.96    0.93      0.95    10000\n",
      "5        micro avg       0.92    0.88      0.90    48043\n",
      "6        macro avg       0.92    0.88      0.90    48043\n",
      "7     weighted avg       0.92    0.88      0.90    48043\n",
      "8      samples avg       0.94    0.90      0.91    48043\n",
      "-------------------------------------------------\n",
      "Fold 39 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.99      0.95    60539\n",
      "1  washing machine       0.57    0.82      0.67    49848\n",
      "2      dish washer       0.68    0.63      0.66    31498\n",
      "3        microwave       0.63    0.91      0.74    45078\n",
      "4           kettle       0.82    0.71      0.76    53030\n",
      "5        micro avg       0.72    0.83      0.77   239993\n",
      "6        macro avg       0.72    0.81      0.76   239993\n",
      "7     weighted avg       0.74    0.83      0.77   239993\n",
      "8      samples avg       0.69    0.81      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 40 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.85      0.88    11838\n",
      "1  washing machine       0.90    0.67      0.77     8382\n",
      "2      dish washer       0.88    0.58      0.70     8255\n",
      "3        microwave       0.59    0.94      0.72     9563\n",
      "4           kettle       0.94    0.85      0.90     9978\n",
      "5        micro avg       0.81    0.79      0.80    48016\n",
      "6        macro avg       0.84    0.78      0.79    48016\n",
      "7     weighted avg       0.84    0.79      0.80    48016\n",
      "8      samples avg       0.79    0.79      0.77    48016\n",
      "-------------------------------------------------\n",
      "Fold 40 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.96    0.97      0.96    60539\n",
      "1  washing machine       0.75    0.45      0.56    49848\n",
      "2      dish washer       0.72    0.63      0.67    31498\n",
      "3        microwave       0.51    0.98      0.67    45078\n",
      "4           kettle       0.83    0.71      0.77    53030\n",
      "5        micro avg       0.73    0.76      0.75   239993\n",
      "6        macro avg       0.75    0.75      0.73   239993\n",
      "7     weighted avg       0.77    0.76      0.74   239993\n",
      "8      samples avg       0.69    0.75      0.70   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 41 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.71    0.77      0.74    11773\n",
      "1  washing machine       0.52    0.33      0.40     8500\n",
      "2      dish washer       0.61    0.16      0.25     8251\n",
      "3        microwave       0.75    0.40      0.52     9529\n",
      "4           kettle       0.70    0.36      0.48     9958\n",
      "5        micro avg       0.67    0.43      0.52    48011\n",
      "6        macro avg       0.66    0.40      0.48    48011\n",
      "7     weighted avg       0.66    0.43      0.50    48011\n",
      "8      samples avg       0.48    0.41      0.41    48011\n",
      "-------------------------------------------------\n",
      "Fold 41 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.69    0.94      0.80    60539\n",
      "1  washing machine       0.51    0.58      0.55    49848\n",
      "2      dish washer       0.36    0.54      0.43    31498\n",
      "3        microwave       0.56    0.93      0.70    45078\n",
      "4           kettle       0.63    0.50      0.56    53030\n",
      "5        micro avg       0.57    0.71      0.63   239993\n",
      "6        macro avg       0.55    0.70      0.61   239993\n",
      "7     weighted avg       0.57    0.71      0.63   239993\n",
      "8      samples avg       0.48    0.66      0.53   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 42 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.89    0.88      0.88    11841\n",
      "1  washing machine       0.51    0.91      0.66     8504\n",
      "2      dish washer       0.85    0.60      0.70     8182\n",
      "3        microwave       0.68    0.85      0.75     9501\n",
      "4           kettle       0.98    0.72      0.83     9986\n",
      "5        micro avg       0.74    0.80      0.77    48014\n",
      "6        macro avg       0.78    0.79      0.77    48014\n",
      "7     weighted avg       0.79    0.80      0.78    48014\n",
      "8      samples avg       0.73    0.79      0.73    48014\n",
      "-------------------------------------------------\n",
      "Fold 42 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.98      0.95    60539\n",
      "1  washing machine       0.67    0.62      0.64    49848\n",
      "2      dish washer       0.68    0.64      0.66    31498\n",
      "3        microwave       0.52    0.98      0.68    45078\n",
      "4           kettle       0.91    0.54      0.68    53030\n",
      "5        micro avg       0.71    0.77      0.74   239993\n",
      "6        macro avg       0.74    0.75      0.72   239993\n",
      "7     weighted avg       0.76    0.77      0.74   239993\n",
      "8      samples avg       0.70    0.77      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 43 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.91      0.92    11789\n",
      "1  washing machine       0.92    0.84      0.88     8414\n",
      "2      dish washer       0.92    0.76      0.83     8194\n",
      "3        microwave       0.93    0.85      0.88     9689\n",
      "4           kettle       0.96    0.93      0.95     9896\n",
      "5        micro avg       0.93    0.86      0.90    47982\n",
      "6        macro avg       0.93    0.86      0.89    47982\n",
      "7     weighted avg       0.93    0.86      0.90    47982\n",
      "8      samples avg       0.94    0.88      0.90    47982\n",
      "-------------------------------------------------\n",
      "Fold 43 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.99      0.96    60539\n",
      "1  washing machine       0.58    0.78      0.66    49848\n",
      "2      dish washer       0.76    0.61      0.68    31498\n",
      "3        microwave       0.69    0.88      0.77    45078\n",
      "4           kettle       0.78    0.74      0.76    53030\n",
      "5        micro avg       0.74    0.82      0.78   239993\n",
      "6        macro avg       0.75    0.80      0.77   239993\n",
      "7     weighted avg       0.76    0.82      0.78   239993\n",
      "8      samples avg       0.71    0.80      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 44 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.73    0.84      0.78    11844\n",
      "1  washing machine       0.50    0.59      0.54     8439\n",
      "2      dish washer       0.51    0.47      0.49     8252\n",
      "3        microwave       0.66    0.51      0.58     9532\n",
      "4           kettle       0.65    0.79      0.71     9977\n",
      "5        micro avg       0.62    0.66      0.64    48044\n",
      "6        macro avg       0.61    0.64      0.62    48044\n",
      "7     weighted avg       0.62    0.66      0.63    48044\n",
      "8      samples avg       0.55    0.61      0.53    48044\n",
      "-------------------------------------------------\n",
      "Fold 44 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.70    0.94      0.80    60539\n",
      "1  washing machine       0.52    0.80      0.63    49848\n",
      "2      dish washer       0.33    0.79      0.47    31498\n",
      "3        microwave       0.56    0.93      0.70    45078\n",
      "4           kettle       0.58    0.86      0.69    53030\n",
      "5        micro avg       0.54    0.87      0.67   239993\n",
      "6        macro avg       0.54    0.86      0.66   239993\n",
      "7     weighted avg       0.56    0.87      0.68   239993\n",
      "8      samples avg       0.47    0.82      0.57   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 45 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.62    0.64      0.63    11795\n",
      "1  washing machine       0.83    0.01      0.01     8307\n",
      "2      dish washer       0.53    0.13      0.20     8243\n",
      "3        microwave       0.62    0.36      0.45     9565\n",
      "4           kettle       0.38    0.22      0.28    10039\n",
      "5        micro avg       0.56    0.30      0.39    47949\n",
      "6        macro avg       0.59    0.27      0.32    47949\n",
      "7     weighted avg       0.59    0.30      0.34    47949\n",
      "8      samples avg       0.34    0.32      0.31    47949\n",
      "-------------------------------------------------\n",
      "Fold 45 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.64    0.69      0.66    60539\n",
      "1  washing machine       0.41    0.03      0.06    49848\n",
      "2      dish washer       0.31    0.29      0.30    31498\n",
      "3        microwave       0.57    0.64      0.61    45078\n",
      "4           kettle       0.41    0.31      0.35    53030\n",
      "5        micro avg       0.52    0.41      0.46   239993\n",
      "6        macro avg       0.47    0.39      0.40   239993\n",
      "7     weighted avg       0.49    0.41      0.41   239993\n",
      "8      samples avg       0.34    0.43      0.35   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 46 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.83    0.92      0.87    11715\n",
      "1  washing machine       0.88    0.69      0.78     8418\n",
      "2      dish washer       0.91    0.55      0.68     8208\n",
      "3        microwave       0.51    0.99      0.67     9610\n",
      "4           kettle       0.94    0.84      0.89     9968\n",
      "5        micro avg       0.75    0.81      0.78    47919\n",
      "6        macro avg       0.81    0.80      0.78    47919\n",
      "7     weighted avg       0.81    0.81      0.79    47919\n",
      "8      samples avg       0.73    0.82      0.75    47919\n",
      "-------------------------------------------------\n",
      "Fold 46 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.85    1.00      0.91    60539\n",
      "1  washing machine       0.60    0.68      0.64    49848\n",
      "2      dish washer       0.68    0.61      0.64    31498\n",
      "3        microwave       0.52    0.97      0.68    45078\n",
      "4           kettle       0.79    0.73      0.76    53030\n",
      "5        micro avg       0.68    0.82      0.74   239993\n",
      "6        macro avg       0.69    0.80      0.73   239993\n",
      "7     weighted avg       0.70    0.82      0.74   239993\n",
      "8      samples avg       0.65    0.79      0.69   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 47 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.94      0.92    11872\n",
      "1  washing machine       0.92    0.85      0.88     8496\n",
      "2      dish washer       0.90    0.83      0.86     8167\n",
      "3        microwave       0.91    0.87      0.89     9611\n",
      "4           kettle       0.97    0.93      0.95     9948\n",
      "5        micro avg       0.92    0.89      0.90    48094\n",
      "6        macro avg       0.92    0.88      0.90    48094\n",
      "7     weighted avg       0.92    0.89      0.90    48094\n",
      "8      samples avg       0.93    0.91      0.91    48094\n",
      "-------------------------------------------------\n",
      "Fold 47 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.99      0.94    60539\n",
      "1  washing machine       0.57    0.81      0.67    49848\n",
      "2      dish washer       0.73    0.62      0.67    31498\n",
      "3        microwave       0.62    0.95      0.75    45078\n",
      "4           kettle       0.84    0.67      0.75    53030\n",
      "5        micro avg       0.72    0.83      0.77   239993\n",
      "6        macro avg       0.73    0.81      0.76   239993\n",
      "7     weighted avg       0.75    0.83      0.77   239993\n",
      "8      samples avg       0.69    0.81      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 48 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.93      0.93    11869\n",
      "1  washing machine       0.89    0.88      0.88     8413\n",
      "2      dish washer       0.90    0.80      0.85     8172\n",
      "3        microwave       0.89    0.88      0.88     9614\n",
      "4           kettle       0.97    0.93      0.95     9961\n",
      "5        micro avg       0.91    0.89      0.90    48029\n",
      "6        macro avg       0.91    0.88      0.90    48029\n",
      "7     weighted avg       0.91    0.89      0.90    48029\n",
      "8      samples avg       0.93    0.91      0.91    48029\n",
      "-------------------------------------------------\n",
      "Fold 48 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.99      0.94    60539\n",
      "1  washing machine       0.57    0.84      0.68    49848\n",
      "2      dish washer       0.76    0.61      0.68    31498\n",
      "3        microwave       0.58    0.95      0.72    45078\n",
      "4           kettle       0.82    0.70      0.75    53030\n",
      "5        micro avg       0.71    0.84      0.77   239993\n",
      "6        macro avg       0.73    0.82      0.76   239993\n",
      "7     weighted avg       0.73    0.84      0.77   239993\n",
      "8      samples avg       0.68    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 49 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.93      0.93    11878\n",
      "1  washing machine       0.89    0.88      0.89     8373\n",
      "2      dish washer       0.90    0.82      0.86     8220\n",
      "3        microwave       0.93    0.85      0.89     9496\n",
      "4           kettle       0.97    0.93      0.95     9963\n",
      "5        micro avg       0.92    0.89      0.91    47930\n",
      "6        macro avg       0.92    0.88      0.90    47930\n",
      "7     weighted avg       0.92    0.89      0.91    47930\n",
      "8      samples avg       0.94    0.90      0.91    47930\n",
      "-------------------------------------------------\n",
      "Fold 49 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.89    0.99      0.94    60539\n",
      "1  washing machine       0.57    0.84      0.67    49848\n",
      "2      dish washer       0.69    0.62      0.65    31498\n",
      "3        microwave       0.67    0.89      0.76    45078\n",
      "4           kettle       0.81    0.68      0.74    53030\n",
      "5        micro avg       0.72    0.82      0.77   239993\n",
      "6        macro avg       0.72    0.80      0.75   239993\n",
      "7     weighted avg       0.74    0.82      0.77   239993\n",
      "8      samples avg       0.69    0.80      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 50 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.61    0.53      0.57    11708\n",
      "1  washing machine       0.40    0.13      0.19     8464\n",
      "2      dish washer       0.36    0.04      0.07     8355\n",
      "3        microwave       0.82    0.19      0.31     9485\n",
      "4           kettle       0.50    0.41      0.45    10016\n",
      "5        micro avg       0.56    0.28      0.37    48028\n",
      "6        macro avg       0.54    0.26      0.32    48028\n",
      "7     weighted avg       0.55    0.28      0.34    48028\n",
      "8      samples avg       0.29    0.33      0.29    48028\n",
      "-------------------------------------------------\n",
      "Fold 50 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.63    0.70      0.66    60539\n",
      "1  washing machine       0.46    0.47      0.46    49848\n",
      "2      dish washer       0.19    0.18      0.18    31498\n",
      "3        microwave       0.57    0.64      0.60    45078\n",
      "4           kettle       0.54    0.61      0.57    53030\n",
      "5        micro avg       0.51    0.55      0.53   239993\n",
      "6        macro avg       0.48    0.52      0.50   239993\n",
      "7     weighted avg       0.50    0.55      0.53   239993\n",
      "8      samples avg       0.34    0.57      0.40   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 51 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.72    0.57      0.63    11778\n",
      "1  washing machine       0.00    0.00      0.00     8407\n",
      "2      dish washer       0.37    0.16      0.22     8234\n",
      "3        microwave       0.62    0.42      0.50     9616\n",
      "4           kettle       0.65    0.13      0.21     9945\n",
      "5        micro avg       0.62    0.28      0.38    47980\n",
      "6        macro avg       0.47    0.25      0.31    47980\n",
      "7     weighted avg       0.50    0.28      0.34    47980\n",
      "8      samples avg       0.30    0.28      0.27    47980\n",
      "-------------------------------------------------\n",
      "Fold 51 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.71    0.68      0.70    60539\n",
      "1  washing machine       0.00    0.00      0.00    49848\n",
      "2      dish washer       0.19    0.23      0.21    31498\n",
      "3        microwave       0.56    0.70      0.62    45078\n",
      "4           kettle       0.51    0.01      0.02    53030\n",
      "5        micro avg       0.53    0.34      0.41   239993\n",
      "6        macro avg       0.40    0.33      0.31   239993\n",
      "7     weighted avg       0.42    0.34      0.33   239993\n",
      "8      samples avg       0.33    0.35      0.32   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 52 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.60    0.57      0.59    11716\n",
      "1  washing machine       0.39    0.11      0.17     8502\n",
      "2      dish washer       0.29    0.04      0.07     8180\n",
      "3        microwave       0.64    0.30      0.41     9593\n",
      "4           kettle       0.50    0.24      0.33    10037\n",
      "5        micro avg       0.55    0.28      0.37    48028\n",
      "6        macro avg       0.48    0.25      0.31    48028\n",
      "7     weighted avg       0.50    0.28      0.33    48028\n",
      "8      samples avg       0.31    0.31      0.28    48028\n",
      "-------------------------------------------------\n",
      "Fold 52 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.63    0.65      0.64    60539\n",
      "1  washing machine       0.46    0.31      0.37    49848\n",
      "2      dish washer       0.20    0.13      0.16    31498\n",
      "3        microwave       0.55    0.59      0.57    45078\n",
      "4           kettle       0.56    0.45      0.50    53030\n",
      "5        micro avg       0.53    0.46      0.49   239993\n",
      "6        macro avg       0.48    0.43      0.45   239993\n",
      "7     weighted avg       0.51    0.46      0.48   239993\n",
      "8      samples avg       0.32    0.49      0.36   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 53 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.62    0.96      0.76    11969\n",
      "1  washing machine       0.53    0.16      0.24     8437\n",
      "2      dish washer       0.56    0.17      0.26     8227\n",
      "3        microwave       0.64    0.51      0.57     9470\n",
      "4           kettle       0.55    0.58      0.56    10024\n",
      "5        micro avg       0.60    0.51      0.55    48127\n",
      "6        macro avg       0.58    0.47      0.48    48127\n",
      "7     weighted avg       0.59    0.51      0.50    48127\n",
      "8      samples avg       0.55    0.50      0.48    48127\n",
      "-------------------------------------------------\n",
      "Fold 53 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.63    1.00      0.77    60539\n",
      "1  washing machine       0.53    0.50      0.52    49848\n",
      "2      dish washer       0.34    0.50      0.40    31498\n",
      "3        microwave       0.56    0.94      0.70    45078\n",
      "4           kettle       0.58    0.85      0.69    53030\n",
      "5        micro avg       0.55    0.79      0.65   239993\n",
      "6        macro avg       0.53    0.76      0.62   239993\n",
      "7     weighted avg       0.55    0.79      0.64   239993\n",
      "8      samples avg       0.51    0.74      0.56   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 54 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.92      0.92    11810\n",
      "1  washing machine       0.89    0.86      0.88     8419\n",
      "2      dish washer       0.87    0.84      0.85     8330\n",
      "3        microwave       0.89    0.86      0.88     9509\n",
      "4           kettle       0.96    0.93      0.95     9942\n",
      "5        micro avg       0.91    0.89      0.90    48010\n",
      "6        macro avg       0.91    0.88      0.89    48010\n",
      "7     weighted avg       0.91    0.89      0.90    48010\n",
      "8      samples avg       0.92    0.90      0.90    48010\n",
      "-------------------------------------------------\n",
      "Fold 54 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.99      0.95    60539\n",
      "1  washing machine       0.57    0.78      0.66    49848\n",
      "2      dish washer       0.64    0.67      0.65    31498\n",
      "3        microwave       0.61    0.93      0.74    45078\n",
      "4           kettle       0.86    0.68      0.76    53030\n",
      "5        micro avg       0.71    0.83      0.77   239993\n",
      "6        macro avg       0.72    0.81      0.75   239993\n",
      "7     weighted avg       0.74    0.83      0.77   239993\n",
      "8      samples avg       0.68    0.81      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 55 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.87    0.80      0.83    11769\n",
      "1  washing machine       0.70    0.46      0.55     8399\n",
      "2      dish washer       0.73    0.50      0.59     8151\n",
      "3        microwave       0.51    0.99      0.67     9628\n",
      "4           kettle       0.91    0.83      0.86     9908\n",
      "5        micro avg       0.70    0.73      0.72    47855\n",
      "6        macro avg       0.74    0.71      0.70    47855\n",
      "7     weighted avg       0.75    0.73      0.72    47855\n",
      "8      samples avg       0.68    0.72      0.67    47855\n",
      "-------------------------------------------------\n",
      "Fold 55 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.89    0.97      0.93    60539\n",
      "1  washing machine       0.70    0.41      0.51    49848\n",
      "2      dish washer       0.65    0.53      0.58    31498\n",
      "3        microwave       0.48    1.00      0.65    45078\n",
      "4           kettle       0.85    0.70      0.77    53030\n",
      "5        micro avg       0.69    0.74      0.72   239993\n",
      "6        macro avg       0.72    0.72      0.69   239993\n",
      "7     weighted avg       0.73    0.74      0.71   239993\n",
      "8      samples avg       0.67    0.73      0.67   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Using koef 2.3\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 116s 194ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 116s 194ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 116s 194ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 116s 194ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 116s 194ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 116s 194ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 116s 194ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.1036e-04\n",
      "600/600 [==============================] - 13s 19ms/step\n",
      "600/600 [==============================] - 116s 194ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 116s 194ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 116s 194ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 116s 194ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 116s 194ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 116s 194ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 116s 194ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 116s 194ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 116s 194ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.1036e-04\n",
      "600/600 [==============================] - 12s 19ms/step\n",
      "600/600 [==============================] - 116s 194ms/step - loss: inf - F1Score: 0.6653 - WeightedF1: 0.7008 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 116s 194ms/step - loss: inf - F1Score: 0.6653 - WeightedF1: 0.7008 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 116s 194ms/step - loss: inf - F1Score: 0.6669 - WeightedF1: 0.7038 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 117s 196ms/step - loss: inf - F1Score: 0.7130 - WeightedF1: 0.7444 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 118s 196ms/step - loss: inf - F1Score: 0.8063 - WeightedF1: 0.8228 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 116s 194ms/step - loss: inf - F1Score: 0.8277 - WeightedF1: 0.8429 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: inf - F1Score: 0.8275 - WeightedF1: 0.8428 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 117s 195ms/step - loss: inf - F1Score: 0.8460 - WeightedF1: 0.8600 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 118s 196ms/step - loss: inf - F1Score: 0.8696 - WeightedF1: 0.8821 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 118s 196ms/step - loss: inf - F1Score: 0.8883 - WeightedF1: 0.9008 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 118s 196ms/step - loss: inf - F1Score: 0.8997 - WeightedF1: 0.9116 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 117s 196ms/step - loss: inf - F1Score: 0.9093 - WeightedF1: 0.9201 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 117s 196ms/step - loss: inf - F1Score: 0.9155 - WeightedF1: 0.9253 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 118s 196ms/step - loss: inf - F1Score: 0.9204 - WeightedF1: 0.9298 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 12s 19ms/step\n",
      "3000/3000 [==============================] - 57s 19ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 116s 194ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 116s 194ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 117s 194ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 117s 194ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 116s 194ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 116s 194ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 117s 194ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 117s 194ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 116s 194ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 116s 194ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 116s 194ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 116s 194ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 116s 194ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 116s 194ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 116s 194ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 116s 194ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.1036e-04\n",
      "600/600 [==============================] - 14s 22ms/step\n",
      "3000/3000 [==============================] - 57s 19ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 116s 194ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 116s 194ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 116s 194ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 116s 194ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 116s 194ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 116s 194ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.1036e-04\n",
      "600/600 [==============================] - 12s 19ms/step\n",
      "3000/3000 [==============================] - 57s 19ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.1036e-04\n",
      "600/600 [==============================] - 12s 19ms/step\n",
      "3000/3000 [==============================] - 59s 19ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.1036e-04\n",
      "600/600 [==============================] - 12s 19ms/step\n",
      "3000/3000 [==============================] - 57s 19ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 116s 192ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.1036e-04\n",
      "600/600 [==============================] - 12s 19ms/step\n",
      "3000/3000 [==============================] - 57s 19ms/step\n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 116s 193ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.1036e-04\n",
      "600/600 [==============================] - 12s 19ms/step\n",
      "600/600 [==============================] - 118s 196ms/step - loss: inf - F1Score: 0.8349 - WeightedF1: 0.8410 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 118s 196ms/step - loss: inf - F1Score: 0.8451 - WeightedF1: 0.8509 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 117s 196ms/step - loss: inf - F1Score: 0.8527 - WeightedF1: 0.8582 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 117s 196ms/step - loss: inf - F1Score: 0.8589 - WeightedF1: 0.8641 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 118s 196ms/step - loss: inf - F1Score: 0.8653 - WeightedF1: 0.8703 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 118s 196ms/step - loss: inf - F1Score: 0.8740 - WeightedF1: 0.8786 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 118s 196ms/step - loss: inf - F1Score: 0.8813 - WeightedF1: 0.8856 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 117s 196ms/step - loss: inf - F1Score: 0.8888 - WeightedF1: 0.8928 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 117s 196ms/step - loss: inf - F1Score: 0.8961 - WeightedF1: 0.8998 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 117s 196ms/step - loss: inf - F1Score: 0.9030 - WeightedF1: 0.9064 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 117s 196ms/step - loss: inf - F1Score: 0.9102 - WeightedF1: 0.9133 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 118s 196ms/step - loss: inf - F1Score: 0.9172 - WeightedF1: 0.9201 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 118s 196ms/step - loss: inf - F1Score: 0.9242 - WeightedF1: 0.9267 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 118s 196ms/step - loss: inf - F1Score: 0.9313 - WeightedF1: 0.9336 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 117s 196ms/step - loss: inf - F1Score: 0.9390 - WeightedF1: 0.9409 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 12s 19ms/step\n",
      "3000/3000 [==============================] - 57s 19ms/step\n",
      "Fold 1 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.87    0.92      0.89    11706\n",
      "1  washing machine       0.90    0.75      0.82     8507\n",
      "2      dish washer       0.83    0.73      0.78     8309\n",
      "3        microwave       0.88    0.82      0.85     9549\n",
      "4           kettle       0.96    0.89      0.92     9949\n",
      "5        micro avg       0.89    0.83      0.86    48020\n",
      "6        macro avg       0.89    0.82      0.85    48020\n",
      "7     weighted avg       0.89    0.83      0.86    48020\n",
      "8      samples avg       0.89    0.84      0.85    48020\n",
      "-------------------------------------------------\n",
      "Fold 1 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.99      0.96    60539\n",
      "1  washing machine       0.74    0.55      0.63    49848\n",
      "2      dish washer       0.55    0.73      0.63    31498\n",
      "3        microwave       0.63    0.93      0.75    45078\n",
      "4           kettle       0.73    0.82      0.77    53030\n",
      "5        micro avg       0.72    0.82      0.77   239993\n",
      "6        macro avg       0.71    0.81      0.75   239993\n",
      "7     weighted avg       0.74    0.82      0.77   239993\n",
      "8      samples avg       0.71    0.80      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 2 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.89    0.90      0.90    11903\n",
      "1  washing machine       0.88    0.76      0.82     8383\n",
      "2      dish washer       0.81    0.77      0.79     8279\n",
      "3        microwave       0.86    0.82      0.84     9584\n",
      "4           kettle       0.95    0.91      0.93     9899\n",
      "5        micro avg       0.88    0.84      0.86    48048\n",
      "6        macro avg       0.88    0.83      0.85    48048\n",
      "7     weighted avg       0.88    0.84      0.86    48048\n",
      "8      samples avg       0.89    0.85      0.86    48048\n",
      "-------------------------------------------------\n",
      "Fold 2 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.99      0.96    60539\n",
      "1  washing machine       0.62    0.69      0.66    49848\n",
      "2      dish washer       0.51    0.76      0.61    31498\n",
      "3        microwave       0.62    0.95      0.75    45078\n",
      "4           kettle       0.83    0.74      0.79    53030\n",
      "5        micro avg       0.71    0.83      0.77   239993\n",
      "6        macro avg       0.70    0.83      0.75   239993\n",
      "7     weighted avg       0.73    0.83      0.77   239993\n",
      "8      samples avg       0.69    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 3 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.85    0.92      0.88    11755\n",
      "1  washing machine       0.91    0.74      0.82     8482\n",
      "2      dish washer       0.82    0.71      0.76     8145\n",
      "3        microwave       0.88    0.73      0.80     9633\n",
      "4           kettle       0.95    0.90      0.92     9989\n",
      "5        micro avg       0.88    0.81      0.84    48004\n",
      "6        macro avg       0.88    0.80      0.84    48004\n",
      "7     weighted avg       0.88    0.81      0.84    48004\n",
      "8      samples avg       0.89    0.82      0.84    48004\n",
      "-------------------------------------------------\n",
      "Fold 3 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.98      0.94    60539\n",
      "1  washing machine       0.61    0.72      0.66    49848\n",
      "2      dish washer       0.62    0.68      0.65    31498\n",
      "3        microwave       0.66    0.85      0.74    45078\n",
      "4           kettle       0.77    0.76      0.77    53030\n",
      "5        micro avg       0.72    0.82      0.77   239993\n",
      "6        macro avg       0.71    0.80      0.75   239993\n",
      "7     weighted avg       0.73    0.82      0.77   239993\n",
      "8      samples avg       0.69    0.80      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 4 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.88    0.90      0.89    11880\n",
      "1  washing machine       0.90    0.75      0.82     8396\n",
      "2      dish washer       0.85    0.68      0.75     8215\n",
      "3        microwave       0.88    0.73      0.80     9566\n",
      "4           kettle       0.95    0.90      0.92    10018\n",
      "5        micro avg       0.89    0.80      0.85    48075\n",
      "6        macro avg       0.89    0.79      0.84    48075\n",
      "7     weighted avg       0.89    0.80      0.84    48075\n",
      "8      samples avg       0.90    0.82      0.84    48075\n",
      "-------------------------------------------------\n",
      "Fold 4 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.99      0.96    60539\n",
      "1  washing machine       0.59    0.75      0.66    49848\n",
      "2      dish washer       0.75    0.62      0.68    31498\n",
      "3        microwave       0.59    0.92      0.72    45078\n",
      "4           kettle       0.91    0.71      0.80    53030\n",
      "5        micro avg       0.74    0.82      0.78   239993\n",
      "6        macro avg       0.76    0.80      0.76   239993\n",
      "7     weighted avg       0.77    0.82      0.78   239993\n",
      "8      samples avg       0.72    0.81      0.74   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 5 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.88    0.90      0.89    11798\n",
      "1  washing machine       0.91    0.73      0.81     8396\n",
      "2      dish washer       0.84    0.69      0.75     8174\n",
      "3        microwave       0.85    0.79      0.82     9484\n",
      "4           kettle       0.96    0.87      0.91    10001\n",
      "5        micro avg       0.89    0.81      0.84    47853\n",
      "6        macro avg       0.89    0.79      0.84    47853\n",
      "7     weighted avg       0.89    0.81      0.84    47853\n",
      "8      samples avg       0.89    0.82      0.84    47853\n",
      "-------------------------------------------------\n",
      "Fold 5 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.98      0.96    60539\n",
      "1  washing machine       0.62    0.68      0.65    49848\n",
      "2      dish washer       0.70    0.64      0.67    31498\n",
      "3        microwave       0.57    0.96      0.72    45078\n",
      "4           kettle       0.85    0.72      0.78    53030\n",
      "5        micro avg       0.73    0.81      0.77   239993\n",
      "6        macro avg       0.74    0.80      0.75   239993\n",
      "7     weighted avg       0.75    0.81      0.77   239993\n",
      "8      samples avg       0.70    0.80      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 6 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.91      0.92    11828\n",
      "1  washing machine       0.91    0.82      0.86     8389\n",
      "2      dish washer       0.89    0.80      0.85     8207\n",
      "3        microwave       0.92    0.85      0.89     9542\n",
      "4           kettle       0.96    0.93      0.95     9968\n",
      "5        micro avg       0.93    0.87      0.90    47934\n",
      "6        macro avg       0.93    0.86      0.89    47934\n",
      "7     weighted avg       0.93    0.87      0.90    47934\n",
      "8      samples avg       0.93    0.88      0.90    47934\n",
      "-------------------------------------------------\n",
      "Fold 6 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.95    0.92      0.94    60539\n",
      "1  washing machine       0.60    0.70      0.65    49848\n",
      "2      dish washer       0.57    0.70      0.62    31498\n",
      "3        microwave       0.69    0.92      0.79    45078\n",
      "4           kettle       0.77    0.73      0.75    53030\n",
      "5        micro avg       0.72    0.80      0.76   239993\n",
      "6        macro avg       0.71    0.79      0.75   239993\n",
      "7     weighted avg       0.74    0.80      0.77   239993\n",
      "8      samples avg       0.69    0.78      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 7 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.91      0.91    11670\n",
      "1  washing machine       0.90    0.82      0.86     8394\n",
      "2      dish washer       0.87    0.78      0.82     8254\n",
      "3        microwave       0.89    0.85      0.87     9554\n",
      "4           kettle       0.96    0.92      0.94     9928\n",
      "5        micro avg       0.91    0.86      0.88    47800\n",
      "6        macro avg       0.91    0.86      0.88    47800\n",
      "7     weighted avg       0.91    0.86      0.88    47800\n",
      "8      samples avg       0.92    0.88      0.89    47800\n",
      "-------------------------------------------------\n",
      "Fold 7 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.98      0.96    60539\n",
      "1  washing machine       0.56    0.83      0.67    49848\n",
      "2      dish washer       0.71    0.65      0.67    31498\n",
      "3        microwave       0.63    0.90      0.74    45078\n",
      "4           kettle       0.80    0.73      0.76    53030\n",
      "5        micro avg       0.72    0.84      0.77   239993\n",
      "6        macro avg       0.73    0.82      0.76   239993\n",
      "7     weighted avg       0.74    0.84      0.78   239993\n",
      "8      samples avg       0.68    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 8 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.84      0.89    11782\n",
      "1  washing machine       0.63    0.91      0.74     8527\n",
      "2      dish washer       0.93    0.60      0.73     8269\n",
      "3        microwave       0.87    0.80      0.83     9595\n",
      "4           kettle       0.94    0.89      0.92     9911\n",
      "5        micro avg       0.84    0.81      0.83    48084\n",
      "6        macro avg       0.86    0.81      0.82    48084\n",
      "7     weighted avg       0.87    0.81      0.83    48084\n",
      "8      samples avg       0.84    0.83      0.82    48084\n",
      "-------------------------------------------------\n",
      "Fold 8 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.96    0.98      0.97    60539\n",
      "1  washing machine       0.57    0.85      0.68    49848\n",
      "2      dish washer       0.90    0.57      0.70    31498\n",
      "3        microwave       0.62    0.91      0.74    45078\n",
      "4           kettle       0.78    0.78      0.78    53030\n",
      "5        micro avg       0.73    0.84      0.78   239993\n",
      "6        macro avg       0.77    0.82      0.77   239993\n",
      "7     weighted avg       0.77    0.84      0.79   239993\n",
      "8      samples avg       0.72    0.84      0.75   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 9 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.93      0.92    11834\n",
      "1  washing machine       0.91    0.80      0.85     8478\n",
      "2      dish washer       0.85    0.79      0.82     8188\n",
      "3        microwave       0.93    0.83      0.87     9619\n",
      "4           kettle       0.96    0.93      0.94    10086\n",
      "5        micro avg       0.91    0.86      0.89    48205\n",
      "6        macro avg       0.91    0.85      0.88    48205\n",
      "7     weighted avg       0.91    0.86      0.89    48205\n",
      "8      samples avg       0.92    0.88      0.89    48205\n",
      "-------------------------------------------------\n",
      "Fold 9 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.89      0.90    60539\n",
      "1  washing machine       0.57    0.81      0.67    49848\n",
      "2      dish washer       0.58    0.71      0.64    31498\n",
      "3        microwave       0.67    0.85      0.75    45078\n",
      "4           kettle       0.86    0.72      0.78    53030\n",
      "5        micro avg       0.72    0.81      0.76   239993\n",
      "6        macro avg       0.72    0.80      0.75   239993\n",
      "7     weighted avg       0.74    0.81      0.76   239993\n",
      "8      samples avg       0.69    0.78      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 10 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.93      0.92    11928\n",
      "1  washing machine       0.90    0.81      0.85     8376\n",
      "2      dish washer       0.87    0.79      0.82     8204\n",
      "3        microwave       0.88    0.86      0.87     9506\n",
      "4           kettle       0.95    0.92      0.94     9963\n",
      "5        micro avg       0.91    0.87      0.89    47977\n",
      "6        macro avg       0.90    0.86      0.88    47977\n",
      "7     weighted avg       0.91    0.87      0.89    47977\n",
      "8      samples avg       0.92    0.88      0.89    47977\n",
      "-------------------------------------------------\n",
      "Fold 10 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.99      0.95    60539\n",
      "1  washing machine       0.58    0.80      0.67    49848\n",
      "2      dish washer       0.67    0.65      0.66    31498\n",
      "3        microwave       0.65    0.91      0.76    45078\n",
      "4           kettle       0.78    0.77      0.78    53030\n",
      "5        micro avg       0.72    0.84      0.78   239993\n",
      "6        macro avg       0.72    0.82      0.76   239993\n",
      "7     weighted avg       0.74    0.84      0.78   239993\n",
      "8      samples avg       0.70    0.82      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 11 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.91      0.92    11776\n",
      "1  washing machine       0.92    0.82      0.87     8517\n",
      "2      dish washer       0.86    0.82      0.84     8190\n",
      "3        microwave       0.89    0.87      0.88     9613\n",
      "4           kettle       0.97    0.92      0.95     9969\n",
      "5        micro avg       0.92    0.88      0.90    48065\n",
      "6        macro avg       0.91    0.87      0.89    48065\n",
      "7     weighted avg       0.92    0.88      0.90    48065\n",
      "8      samples avg       0.93    0.89      0.90    48065\n",
      "-------------------------------------------------\n",
      "Fold 11 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.94      0.94    60539\n",
      "1  washing machine       0.57    0.81      0.67    49848\n",
      "2      dish washer       0.62    0.68      0.64    31498\n",
      "3        microwave       0.67    0.90      0.77    45078\n",
      "4           kettle       0.81    0.70      0.75    53030\n",
      "5        micro avg       0.72    0.82      0.76   239993\n",
      "6        macro avg       0.72    0.80      0.75   239993\n",
      "7     weighted avg       0.74    0.82      0.77   239993\n",
      "8      samples avg       0.68    0.79      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 12 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.93      0.93    11825\n",
      "1  washing machine       0.92    0.83      0.87     8448\n",
      "2      dish washer       0.89    0.81      0.85     8210\n",
      "3        microwave       0.91    0.88      0.89     9562\n",
      "4           kettle       0.96    0.94      0.95     9927\n",
      "5        micro avg       0.92    0.88      0.90    47972\n",
      "6        macro avg       0.92    0.88      0.90    47972\n",
      "7     weighted avg       0.92    0.88      0.90    47972\n",
      "8      samples avg       0.93    0.90      0.91    47972\n",
      "-------------------------------------------------\n",
      "Fold 12 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.98      0.96    60539\n",
      "1  washing machine       0.58    0.82      0.68    49848\n",
      "2      dish washer       0.75    0.60      0.66    31498\n",
      "3        microwave       0.64    0.91      0.75    45078\n",
      "4           kettle       0.79    0.75      0.77    53030\n",
      "5        micro avg       0.73    0.83      0.78   239993\n",
      "6        macro avg       0.74    0.81      0.76   239993\n",
      "7     weighted avg       0.75    0.83      0.78   239993\n",
      "8      samples avg       0.71    0.82      0.74   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 13 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.94      0.92    11762\n",
      "1  washing machine       0.89    0.85      0.87     8396\n",
      "2      dish washer       0.83    0.86      0.84     8248\n",
      "3        microwave       0.91    0.86      0.88     9477\n",
      "4           kettle       0.94    0.94      0.94    10024\n",
      "5        micro avg       0.90    0.89      0.89    47907\n",
      "6        macro avg       0.89    0.89      0.89    47907\n",
      "7     weighted avg       0.90    0.89      0.89    47907\n",
      "8      samples avg       0.91    0.91      0.90    47907\n",
      "-------------------------------------------------\n",
      "Fold 13 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.88    0.96      0.92    60539\n",
      "1  washing machine       0.57    0.85      0.68    49848\n",
      "2      dish washer       0.61    0.70      0.65    31498\n",
      "3        microwave       0.65    0.88      0.74    45078\n",
      "4           kettle       0.66    0.83      0.74    53030\n",
      "5        micro avg       0.68    0.86      0.76   239993\n",
      "6        macro avg       0.67    0.84      0.75   239993\n",
      "7     weighted avg       0.69    0.86      0.76   239993\n",
      "8      samples avg       0.65    0.84      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 14 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.93      0.93    11786\n",
      "1  washing machine       0.93    0.82      0.87     8379\n",
      "2      dish washer       0.86    0.85      0.86     8269\n",
      "3        microwave       0.91    0.86      0.89     9574\n",
      "4           kettle       0.98    0.92      0.95     9978\n",
      "5        micro avg       0.92    0.88      0.90    47986\n",
      "6        macro avg       0.92    0.87      0.90    47986\n",
      "7     weighted avg       0.92    0.88      0.90    47986\n",
      "8      samples avg       0.93    0.90      0.90    47986\n",
      "-------------------------------------------------\n",
      "Fold 14 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.99      0.96    60539\n",
      "1  washing machine       0.57    0.78      0.66    49848\n",
      "2      dish washer       0.59    0.70      0.64    31498\n",
      "3        microwave       0.66    0.90      0.76    45078\n",
      "4           kettle       0.85    0.67      0.75    53030\n",
      "5        micro avg       0.72    0.82      0.77   239993\n",
      "6        macro avg       0.72    0.81      0.75   239993\n",
      "7     weighted avg       0.74    0.82      0.77   239993\n",
      "8      samples avg       0.69    0.80      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 15 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.92      0.93    11893\n",
      "1  washing machine       0.91    0.84      0.88     8424\n",
      "2      dish washer       0.86    0.86      0.86     8205\n",
      "3        microwave       0.90    0.88      0.89     9590\n",
      "4           kettle       0.97    0.93      0.95     9958\n",
      "5        micro avg       0.92    0.89      0.90    48070\n",
      "6        macro avg       0.91    0.89      0.90    48070\n",
      "7     weighted avg       0.92    0.89      0.90    48070\n",
      "8      samples avg       0.93    0.91      0.91    48070\n",
      "-------------------------------------------------\n",
      "Fold 15 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.99      0.96    60539\n",
      "1  washing machine       0.59    0.80      0.68    49848\n",
      "2      dish washer       0.60    0.71      0.65    31498\n",
      "3        microwave       0.63    0.93      0.75    45078\n",
      "4           kettle       0.85    0.69      0.76    53030\n",
      "5        micro avg       0.72    0.84      0.77   239993\n",
      "6        macro avg       0.72    0.82      0.76   239993\n",
      "7     weighted avg       0.74    0.84      0.78   239993\n",
      "8      samples avg       0.69    0.82      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 16 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.92      0.92    11865\n",
      "1  washing machine       0.92    0.84      0.88     8506\n",
      "2      dish washer       0.90    0.80      0.85     8222\n",
      "3        microwave       0.91    0.87      0.89     9541\n",
      "4           kettle       0.96    0.94      0.95     9954\n",
      "5        micro avg       0.93    0.88      0.90    48088\n",
      "6        macro avg       0.92    0.88      0.90    48088\n",
      "7     weighted avg       0.92    0.88      0.90    48088\n",
      "8      samples avg       0.93    0.90      0.91    48088\n",
      "-------------------------------------------------\n",
      "Fold 16 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.96      0.94    60539\n",
      "1  washing machine       0.57    0.81      0.67    49848\n",
      "2      dish washer       0.67    0.67      0.67    31498\n",
      "3        microwave       0.66    0.90      0.76    45078\n",
      "4           kettle       0.86    0.71      0.78    53030\n",
      "5        micro avg       0.73    0.82      0.77   239993\n",
      "6        macro avg       0.74    0.81      0.76   239993\n",
      "7     weighted avg       0.75    0.82      0.78   239993\n",
      "8      samples avg       0.70    0.80      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 17 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.76      0.84    11794\n",
      "1  washing machine       0.54    0.89      0.67     8394\n",
      "2      dish washer       0.85    0.57      0.68     8120\n",
      "3        microwave       0.86    0.60      0.71     9589\n",
      "4           kettle       0.95    0.82      0.88     9895\n",
      "5        micro avg       0.79    0.73      0.76    47792\n",
      "6        macro avg       0.83    0.73      0.76    47792\n",
      "7     weighted avg       0.84    0.73      0.77    47792\n",
      "8      samples avg       0.77    0.73      0.72    47792\n",
      "-------------------------------------------------\n",
      "Fold 17 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.96    0.96      0.96    60539\n",
      "1  washing machine       0.61    0.76      0.68    49848\n",
      "2      dish washer       0.62    0.65      0.63    31498\n",
      "3        microwave       0.56    0.95      0.70    45078\n",
      "4           kettle       0.88    0.70      0.78    53030\n",
      "5        micro avg       0.72    0.82      0.76   239993\n",
      "6        macro avg       0.73    0.80      0.75   239993\n",
      "7     weighted avg       0.75    0.82      0.77   239993\n",
      "8      samples avg       0.72    0.82      0.74   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 18 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.84      0.87    11818\n",
      "1  washing machine       0.52    0.92      0.67     8432\n",
      "2      dish washer       0.86    0.58      0.69     8328\n",
      "3        microwave       0.91    0.54      0.68     9480\n",
      "4           kettle       0.96    0.84      0.90     9933\n",
      "5        micro avg       0.79    0.75      0.77    47991\n",
      "6        macro avg       0.83    0.74      0.76    47991\n",
      "7     weighted avg       0.84    0.75      0.77    47991\n",
      "8      samples avg       0.77    0.75      0.73    47991\n",
      "-------------------------------------------------\n",
      "Fold 18 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.99      0.95    60539\n",
      "1  washing machine       0.64    0.79      0.71    49848\n",
      "2      dish washer       0.60    0.68      0.64    31498\n",
      "3        microwave       0.69    0.83      0.75    45078\n",
      "4           kettle       0.84    0.71      0.77    53030\n",
      "5        micro avg       0.75    0.82      0.78   239993\n",
      "6        macro avg       0.74    0.80      0.76   239993\n",
      "7     weighted avg       0.76    0.82      0.78   239993\n",
      "8      samples avg       0.75    0.82      0.76   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 19 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.92      0.93    11787\n",
      "1  washing machine       0.90    0.86      0.88     8464\n",
      "2      dish washer       0.88    0.82      0.85     8235\n",
      "3        microwave       0.92    0.86      0.89     9610\n",
      "4           kettle       0.97    0.93      0.95     9992\n",
      "5        micro avg       0.92    0.88      0.90    48088\n",
      "6        macro avg       0.92    0.88      0.90    48088\n",
      "7     weighted avg       0.92    0.88      0.90    48088\n",
      "8      samples avg       0.93    0.90      0.91    48088\n",
      "-------------------------------------------------\n",
      "Fold 19 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.96      0.95    60539\n",
      "1  washing machine       0.57    0.84      0.68    49848\n",
      "2      dish washer       0.53    0.73      0.61    31498\n",
      "3        microwave       0.68    0.83      0.75    45078\n",
      "4           kettle       0.73    0.76      0.74    53030\n",
      "5        micro avg       0.69    0.84      0.76   239993\n",
      "6        macro avg       0.69    0.82      0.75   239993\n",
      "7     weighted avg       0.71    0.84      0.77   239993\n",
      "8      samples avg       0.67    0.82      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 20 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.92      0.93    11778\n",
      "1  washing machine       0.91    0.84      0.87     8368\n",
      "2      dish washer       0.85    0.84      0.85     8217\n",
      "3        microwave       0.91    0.87      0.89     9596\n",
      "4           kettle       0.95    0.93      0.94    10082\n",
      "5        micro avg       0.91    0.89      0.90    48041\n",
      "6        macro avg       0.91    0.88      0.90    48041\n",
      "7     weighted avg       0.91    0.89      0.90    48041\n",
      "8      samples avg       0.93    0.90      0.90    48041\n",
      "-------------------------------------------------\n",
      "Fold 20 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.97      0.95    60539\n",
      "1  washing machine       0.57    0.82      0.67    49848\n",
      "2      dish washer       0.55    0.72      0.62    31498\n",
      "3        microwave       0.65    0.86      0.74    45078\n",
      "4           kettle       0.76    0.77      0.77    53030\n",
      "5        micro avg       0.70    0.84      0.76   239993\n",
      "6        macro avg       0.69    0.83      0.75   239993\n",
      "7     weighted avg       0.71    0.84      0.77   239993\n",
      "8      samples avg       0.67    0.82      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 21 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.86    0.90      0.88    11890\n",
      "1  washing machine       0.90    0.72      0.80     8479\n",
      "2      dish washer       0.88    0.58      0.70     8116\n",
      "3        microwave       0.55    0.93      0.69     9604\n",
      "4           kettle       0.96    0.77      0.85    10055\n",
      "5        micro avg       0.78    0.79      0.79    48144\n",
      "6        macro avg       0.83    0.78      0.78    48144\n",
      "7     weighted avg       0.83    0.79      0.79    48144\n",
      "8      samples avg       0.77    0.80      0.76    48144\n",
      "-------------------------------------------------\n",
      "Fold 21 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.99      0.95    60539\n",
      "1  washing machine       0.71    0.61      0.66    49848\n",
      "2      dish washer       0.57    0.70      0.63    31498\n",
      "3        microwave       0.58    0.91      0.71    45078\n",
      "4           kettle       0.94    0.53      0.68    53030\n",
      "5        micro avg       0.73    0.76      0.75   239993\n",
      "6        macro avg       0.74    0.75      0.72   239993\n",
      "7     weighted avg       0.77    0.76      0.74   239993\n",
      "8      samples avg       0.73    0.75      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 22 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.92      0.93    11862\n",
      "1  washing machine       0.88    0.89      0.89     8406\n",
      "2      dish washer       0.89    0.83      0.86     8269\n",
      "3        microwave       0.93    0.86      0.89     9586\n",
      "4           kettle       0.96    0.94      0.95     9876\n",
      "5        micro avg       0.92    0.89      0.91    47999\n",
      "6        macro avg       0.92    0.89      0.90    47999\n",
      "7     weighted avg       0.92    0.89      0.91    47999\n",
      "8      samples avg       0.93    0.91      0.91    47999\n",
      "-------------------------------------------------\n",
      "Fold 22 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.98      0.95    60539\n",
      "1  washing machine       0.57    0.87      0.68    49848\n",
      "2      dish washer       0.63    0.67      0.65    31498\n",
      "3        microwave       0.67    0.85      0.75    45078\n",
      "4           kettle       0.80    0.72      0.76    53030\n",
      "5        micro avg       0.72    0.84      0.77   239993\n",
      "6        macro avg       0.72    0.82      0.76   239993\n",
      "7     weighted avg       0.73    0.84      0.78   239993\n",
      "8      samples avg       0.69    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 23 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.91      0.93    11732\n",
      "1  washing machine       0.91    0.85      0.88     8519\n",
      "2      dish washer       0.90    0.84      0.87     8304\n",
      "3        microwave       0.91    0.87      0.89     9582\n",
      "4           kettle       0.95    0.94      0.95     9995\n",
      "5        micro avg       0.92    0.89      0.91    48132\n",
      "6        macro avg       0.92    0.88      0.90    48132\n",
      "7     weighted avg       0.92    0.89      0.91    48132\n",
      "8      samples avg       0.94    0.90      0.91    48132\n",
      "-------------------------------------------------\n",
      "Fold 23 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.98      0.96    60539\n",
      "1  washing machine       0.57    0.83      0.67    49848\n",
      "2      dish washer       0.76    0.62      0.68    31498\n",
      "3        microwave       0.64    0.92      0.75    45078\n",
      "4           kettle       0.75    0.78      0.76    53030\n",
      "5        micro avg       0.72    0.85      0.78   239993\n",
      "6        macro avg       0.73    0.82      0.77   239993\n",
      "7     weighted avg       0.74    0.85      0.78   239993\n",
      "8      samples avg       0.69    0.83      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 24 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.86      0.89    11836\n",
      "1  washing machine       0.78    0.85      0.81     8450\n",
      "2      dish washer       0.88    0.62      0.73     8204\n",
      "3        microwave       0.92    0.72      0.80     9561\n",
      "4           kettle       0.97    0.87      0.92     9908\n",
      "5        micro avg       0.90    0.79      0.84    47959\n",
      "6        macro avg       0.89    0.78      0.83    47959\n",
      "7     weighted avg       0.90    0.79      0.84    47959\n",
      "8      samples avg       0.89    0.80      0.83    47959\n",
      "-------------------------------------------------\n",
      "Fold 24 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.99      0.96    60539\n",
      "1  washing machine       0.60    0.82      0.69    49848\n",
      "2      dish washer       0.67    0.65      0.66    31498\n",
      "3        microwave       0.59    0.95      0.73    45078\n",
      "4           kettle       0.95    0.65      0.77    53030\n",
      "5        micro avg       0.73    0.83      0.77   239993\n",
      "6        macro avg       0.75    0.81      0.76   239993\n",
      "7     weighted avg       0.77    0.83      0.78   239993\n",
      "8      samples avg       0.72    0.82      0.74   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 25 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.93      0.92    11722\n",
      "1  washing machine       0.90    0.85      0.88     8310\n",
      "2      dish washer       0.86    0.87      0.86     8229\n",
      "3        microwave       0.92    0.86      0.89     9483\n",
      "4           kettle       0.97    0.93      0.95    10022\n",
      "5        micro avg       0.92    0.89      0.90    47766\n",
      "6        macro avg       0.91    0.89      0.90    47766\n",
      "7     weighted avg       0.92    0.89      0.90    47766\n",
      "8      samples avg       0.93    0.91      0.91    47766\n",
      "-------------------------------------------------\n",
      "Fold 25 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.98      0.94    60539\n",
      "1  washing machine       0.57    0.83      0.68    49848\n",
      "2      dish washer       0.60    0.70      0.64    31498\n",
      "3        microwave       0.64    0.91      0.75    45078\n",
      "4           kettle       0.85    0.70      0.77    53030\n",
      "5        micro avg       0.71    0.84      0.77   239993\n",
      "6        macro avg       0.71    0.82      0.76   239993\n",
      "7     weighted avg       0.73    0.84      0.77   239993\n",
      "8      samples avg       0.68    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 26 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.92      0.93    11834\n",
      "1  washing machine       0.89    0.88      0.89     8486\n",
      "2      dish washer       0.86    0.87      0.86     8217\n",
      "3        microwave       0.94    0.86      0.90     9608\n",
      "4           kettle       0.96    0.94      0.95     9991\n",
      "5        micro avg       0.92    0.90      0.91    48136\n",
      "6        macro avg       0.92    0.89      0.90    48136\n",
      "7     weighted avg       0.92    0.90      0.91    48136\n",
      "8      samples avg       0.93    0.91      0.91    48136\n",
      "-------------------------------------------------\n",
      "Fold 26 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.97      0.94    60539\n",
      "1  washing machine       0.57    0.82      0.67    49848\n",
      "2      dish washer       0.54    0.74      0.62    31498\n",
      "3        microwave       0.67    0.89      0.77    45078\n",
      "4           kettle       0.78    0.74      0.76    53030\n",
      "5        micro avg       0.70    0.84      0.76   239993\n",
      "6        macro avg       0.70    0.83      0.75   239993\n",
      "7     weighted avg       0.72    0.84      0.77   239993\n",
      "8      samples avg       0.67    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 27 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.92      0.93    11760\n",
      "1  washing machine       0.88    0.88      0.88     8511\n",
      "2      dish washer       0.88    0.85      0.86     8235\n",
      "3        microwave       0.90    0.87      0.89     9475\n",
      "4           kettle       0.98    0.92      0.95     9937\n",
      "5        micro avg       0.92    0.89      0.91    47918\n",
      "6        macro avg       0.92    0.89      0.90    47918\n",
      "7     weighted avg       0.92    0.89      0.91    47918\n",
      "8      samples avg       0.93    0.91      0.91    47918\n",
      "-------------------------------------------------\n",
      "Fold 27 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.98      0.94    60539\n",
      "1  washing machine       0.57    0.86      0.69    49848\n",
      "2      dish washer       0.57    0.69      0.63    31498\n",
      "3        microwave       0.66    0.90      0.76    45078\n",
      "4           kettle       0.83    0.65      0.73    53030\n",
      "5        micro avg       0.71    0.83      0.76   239993\n",
      "6        macro avg       0.71    0.82      0.75   239993\n",
      "7     weighted avg       0.73    0.83      0.77   239993\n",
      "8      samples avg       0.68    0.81      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 28 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.93      0.92    11821\n",
      "1  washing machine       0.91    0.85      0.88     8312\n",
      "2      dish washer       0.88    0.83      0.85     8213\n",
      "3        microwave       0.91    0.87      0.89     9643\n",
      "4           kettle       0.97    0.93      0.95     9999\n",
      "5        micro avg       0.92    0.89      0.90    47988\n",
      "6        macro avg       0.92    0.88      0.90    47988\n",
      "7     weighted avg       0.92    0.89      0.90    47988\n",
      "8      samples avg       0.93    0.90      0.91    47988\n",
      "-------------------------------------------------\n",
      "Fold 28 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.99      0.95    60539\n",
      "1  washing machine       0.57    0.80      0.67    49848\n",
      "2      dish washer       0.61    0.68      0.64    31498\n",
      "3        microwave       0.64    0.92      0.76    45078\n",
      "4           kettle       0.81    0.64      0.71    53030\n",
      "5        micro avg       0.71    0.82      0.76   239993\n",
      "6        macro avg       0.71    0.80      0.74   239993\n",
      "7     weighted avg       0.73    0.82      0.76   239993\n",
      "8      samples avg       0.67    0.79      0.70   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 29 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.92      0.93    11744\n",
      "1  washing machine       0.89    0.87      0.88     8430\n",
      "2      dish washer       0.89    0.83      0.86     8249\n",
      "3        microwave       0.90    0.88      0.89     9546\n",
      "4           kettle       0.96    0.94      0.95     9980\n",
      "5        micro avg       0.92    0.89      0.90    47949\n",
      "6        macro avg       0.91    0.89      0.90    47949\n",
      "7     weighted avg       0.92    0.89      0.90    47949\n",
      "8      samples avg       0.93    0.91      0.91    47949\n",
      "-------------------------------------------------\n",
      "Fold 29 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.98      0.95    60539\n",
      "1  washing machine       0.57    0.84      0.68    49848\n",
      "2      dish washer       0.68    0.64      0.66    31498\n",
      "3        microwave       0.63    0.90      0.74    45078\n",
      "4           kettle       0.79    0.73      0.76    53030\n",
      "5        micro avg       0.71    0.84      0.77   239993\n",
      "6        macro avg       0.72    0.82      0.76   239993\n",
      "7     weighted avg       0.73    0.84      0.77   239993\n",
      "8      samples avg       0.69    0.82      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 30 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.91      0.93    11883\n",
      "1  washing machine       0.90    0.86      0.88     8425\n",
      "2      dish washer       0.88    0.82      0.85     8208\n",
      "3        microwave       0.92    0.85      0.89     9544\n",
      "4           kettle       0.96    0.93      0.95     9949\n",
      "5        micro avg       0.92    0.88      0.90    48009\n",
      "6        macro avg       0.92    0.88      0.90    48009\n",
      "7     weighted avg       0.92    0.88      0.90    48009\n",
      "8      samples avg       0.94    0.90      0.91    48009\n",
      "-------------------------------------------------\n",
      "Fold 30 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.98      0.96    60539\n",
      "1  washing machine       0.57    0.85      0.68    49848\n",
      "2      dish washer       0.70    0.64      0.67    31498\n",
      "3        microwave       0.70    0.89      0.78    45078\n",
      "4           kettle       0.89    0.68      0.77    53030\n",
      "5        micro avg       0.75    0.83      0.78   239993\n",
      "6        macro avg       0.76    0.81      0.77   239993\n",
      "7     weighted avg       0.77    0.83      0.79   239993\n",
      "8      samples avg       0.72    0.81      0.74   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 31 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.92      0.93    11875\n",
      "1  washing machine       0.92    0.85      0.89     8512\n",
      "2      dish washer       0.86    0.86      0.86     8137\n",
      "3        microwave       0.89    0.88      0.89     9475\n",
      "4           kettle       0.97    0.92      0.95     9969\n",
      "5        micro avg       0.92    0.89      0.90    47968\n",
      "6        macro avg       0.92    0.89      0.90    47968\n",
      "7     weighted avg       0.92    0.89      0.90    47968\n",
      "8      samples avg       0.93    0.91      0.91    47968\n",
      "-------------------------------------------------\n",
      "Fold 31 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.96      0.94    60539\n",
      "1  washing machine       0.58    0.81      0.67    49848\n",
      "2      dish washer       0.52    0.75      0.61    31498\n",
      "3        microwave       0.64    0.92      0.76    45078\n",
      "4           kettle       0.78    0.66      0.71    53030\n",
      "5        micro avg       0.69    0.83      0.75   239993\n",
      "6        macro avg       0.69    0.82      0.74   239993\n",
      "7     weighted avg       0.71    0.83      0.76   239993\n",
      "8      samples avg       0.66    0.80      0.70   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 32 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.92      0.93    11766\n",
      "1  washing machine       0.90    0.88      0.89     8431\n",
      "2      dish washer       0.89    0.84      0.86     8239\n",
      "3        microwave       0.92    0.88      0.89     9563\n",
      "4           kettle       0.97    0.94      0.95     9968\n",
      "5        micro avg       0.92    0.89      0.91    47967\n",
      "6        macro avg       0.92    0.89      0.91    47967\n",
      "7     weighted avg       0.92    0.89      0.91    47967\n",
      "8      samples avg       0.94    0.91      0.92    47967\n",
      "-------------------------------------------------\n",
      "Fold 32 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.97      0.95    60539\n",
      "1  washing machine       0.57    0.85      0.68    49848\n",
      "2      dish washer       0.59    0.67      0.63    31498\n",
      "3        microwave       0.65    0.90      0.75    45078\n",
      "4           kettle       0.83    0.70      0.76    53030\n",
      "5        micro avg       0.71    0.83      0.77   239993\n",
      "6        macro avg       0.71    0.82      0.75   239993\n",
      "7     weighted avg       0.73    0.83      0.77   239993\n",
      "8      samples avg       0.69    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 33 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.95    0.91      0.93    11780\n",
      "1  washing machine       0.90    0.87      0.88     8358\n",
      "2      dish washer       0.89    0.85      0.87     8275\n",
      "3        microwave       0.90    0.89      0.89     9670\n",
      "4           kettle       0.96    0.94      0.95     9962\n",
      "5        micro avg       0.92    0.89      0.91    48045\n",
      "6        macro avg       0.92    0.89      0.90    48045\n",
      "7     weighted avg       0.92    0.89      0.91    48045\n",
      "8      samples avg       0.93    0.91      0.91    48045\n",
      "-------------------------------------------------\n",
      "Fold 33 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.97      0.94    60539\n",
      "1  washing machine       0.57    0.83      0.68    49848\n",
      "2      dish washer       0.66    0.64      0.65    31498\n",
      "3        microwave       0.60    0.91      0.72    45078\n",
      "4           kettle       0.79    0.75      0.77    53030\n",
      "5        micro avg       0.70    0.84      0.76   239993\n",
      "6        macro avg       0.71    0.82      0.75   239993\n",
      "7     weighted avg       0.72    0.84      0.77   239993\n",
      "8      samples avg       0.67    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 34 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.93      0.92    11846\n",
      "1  washing machine       0.89    0.85      0.87     8455\n",
      "2      dish washer       0.87    0.81      0.84     8185\n",
      "3        microwave       0.91    0.85      0.87     9533\n",
      "4           kettle       0.95    0.94      0.95     9982\n",
      "5        micro avg       0.91    0.88      0.89    48001\n",
      "6        macro avg       0.91    0.87      0.89    48001\n",
      "7     weighted avg       0.91    0.88      0.89    48001\n",
      "8      samples avg       0.92    0.90      0.90    48001\n",
      "-------------------------------------------------\n",
      "Fold 34 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.99      0.95    60539\n",
      "1  washing machine       0.57    0.85      0.68    49848\n",
      "2      dish washer       0.71    0.63      0.67    31498\n",
      "3        microwave       0.62    0.93      0.74    45078\n",
      "4           kettle       0.78    0.75      0.77    53030\n",
      "5        micro avg       0.71    0.85      0.77   239993\n",
      "6        macro avg       0.72    0.83      0.76   239993\n",
      "7     weighted avg       0.73    0.85      0.78   239993\n",
      "8      samples avg       0.68    0.83      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 35 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.93      0.93    11775\n",
      "1  washing machine       0.89    0.87      0.88     8408\n",
      "2      dish washer       0.90    0.81      0.86     8286\n",
      "3        microwave       0.92    0.86      0.89     9575\n",
      "4           kettle       0.97    0.92      0.94     9975\n",
      "5        micro avg       0.92    0.88      0.90    48019\n",
      "6        macro avg       0.92    0.88      0.90    48019\n",
      "7     weighted avg       0.92    0.88      0.90    48019\n",
      "8      samples avg       0.93    0.90      0.91    48019\n",
      "-------------------------------------------------\n",
      "Fold 35 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.99      0.94    60539\n",
      "1  washing machine       0.57    0.84      0.68    49848\n",
      "2      dish washer       0.63    0.66      0.64    31498\n",
      "3        microwave       0.68    0.88      0.77    45078\n",
      "4           kettle       0.89    0.61      0.73    53030\n",
      "5        micro avg       0.73    0.81      0.77   239993\n",
      "6        macro avg       0.73    0.80      0.75   239993\n",
      "7     weighted avg       0.75    0.81      0.77   239993\n",
      "8      samples avg       0.69    0.79      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 36 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.73    0.70      0.71    11874\n",
      "1  washing machine       0.58    0.12      0.19     8429\n",
      "2      dish washer       0.59    0.12      0.19     8174\n",
      "3        microwave       0.71    0.30      0.42     9533\n",
      "4           kettle       0.59    0.29      0.39     9925\n",
      "5        micro avg       0.67    0.34      0.45    47935\n",
      "6        macro avg       0.64    0.31      0.38    47935\n",
      "7     weighted avg       0.64    0.34      0.41    47935\n",
      "8      samples avg       0.49    0.35      0.38    47935\n",
      "-------------------------------------------------\n",
      "Fold 36 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.79    0.75      0.77    60539\n",
      "1  washing machine       0.52    0.38      0.44    49848\n",
      "2      dish washer       0.35    0.29      0.32    31498\n",
      "3        microwave       0.52    0.63      0.57    45078\n",
      "4           kettle       0.63    0.41      0.50    53030\n",
      "5        micro avg       0.59    0.51      0.55   239993\n",
      "6        macro avg       0.56    0.49      0.52   239993\n",
      "7     weighted avg       0.59    0.51      0.54   239993\n",
      "8      samples avg       0.47    0.48      0.43   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 37 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.92      0.93    11808\n",
      "1  washing machine       0.89    0.88      0.88     8450\n",
      "2      dish washer       0.90    0.83      0.86     8240\n",
      "3        microwave       0.93    0.85      0.89     9680\n",
      "4           kettle       0.96    0.94      0.95     9961\n",
      "5        micro avg       0.92    0.89      0.90    48139\n",
      "6        macro avg       0.92    0.88      0.90    48139\n",
      "7     weighted avg       0.92    0.89      0.90    48139\n",
      "8      samples avg       0.93    0.90      0.91    48139\n",
      "-------------------------------------------------\n",
      "Fold 37 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.99      0.95    60539\n",
      "1  washing machine       0.57    0.84      0.68    49848\n",
      "2      dish washer       0.58    0.70      0.63    31498\n",
      "3        microwave       0.66    0.85      0.75    45078\n",
      "4           kettle       0.89    0.68      0.77    53030\n",
      "5        micro avg       0.72    0.83      0.77   239993\n",
      "6        macro avg       0.72    0.81      0.76   239993\n",
      "7     weighted avg       0.75    0.83      0.78   239993\n",
      "8      samples avg       0.69    0.81      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 38 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.86    0.85      0.86    11775\n",
      "1  washing machine       0.81    0.74      0.77     8381\n",
      "2      dish washer       0.90    0.49      0.63     8220\n",
      "3        microwave       0.51    0.97      0.67     9499\n",
      "4           kettle       0.97    0.78      0.87     9992\n",
      "5        micro avg       0.75    0.78      0.76    47867\n",
      "6        macro avg       0.81    0.77      0.76    47867\n",
      "7     weighted avg       0.81    0.78      0.77    47867\n",
      "8      samples avg       0.72    0.78      0.72    47867\n",
      "-------------------------------------------------\n",
      "Fold 38 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.99      0.95    60539\n",
      "1  washing machine       0.63    0.71      0.67    49848\n",
      "2      dish washer       0.74    0.59      0.65    31498\n",
      "3        microwave       0.47    1.00      0.64    45078\n",
      "4           kettle       0.96    0.61      0.75    53030\n",
      "5        micro avg       0.69    0.79      0.74   239993\n",
      "6        macro avg       0.74    0.78      0.73   239993\n",
      "7     weighted avg       0.76    0.79      0.75   239993\n",
      "8      samples avg       0.66    0.78      0.69   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 39 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.92      0.92    11747\n",
      "1  washing machine       0.91    0.87      0.89     8522\n",
      "2      dish washer       0.89    0.81      0.85     8233\n",
      "3        microwave       0.92    0.85      0.89     9541\n",
      "4           kettle       0.96    0.93      0.95    10000\n",
      "5        micro avg       0.92    0.88      0.90    48043\n",
      "6        macro avg       0.92    0.88      0.90    48043\n",
      "7     weighted avg       0.92    0.88      0.90    48043\n",
      "8      samples avg       0.94    0.90      0.91    48043\n",
      "-------------------------------------------------\n",
      "Fold 39 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.99      0.95    60539\n",
      "1  washing machine       0.57    0.82      0.67    49848\n",
      "2      dish washer       0.68    0.63      0.66    31498\n",
      "3        microwave       0.63    0.91      0.74    45078\n",
      "4           kettle       0.82    0.71      0.76    53030\n",
      "5        micro avg       0.72    0.83      0.77   239993\n",
      "6        macro avg       0.72    0.81      0.76   239993\n",
      "7     weighted avg       0.74    0.83      0.77   239993\n",
      "8      samples avg       0.69    0.81      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 40 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.85      0.88    11838\n",
      "1  washing machine       0.90    0.67      0.77     8382\n",
      "2      dish washer       0.88    0.58      0.70     8255\n",
      "3        microwave       0.59    0.94      0.72     9563\n",
      "4           kettle       0.94    0.85      0.90     9978\n",
      "5        micro avg       0.81    0.79      0.80    48016\n",
      "6        macro avg       0.84    0.78      0.79    48016\n",
      "7     weighted avg       0.84    0.79      0.80    48016\n",
      "8      samples avg       0.79    0.79      0.77    48016\n",
      "-------------------------------------------------\n",
      "Fold 40 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.96    0.97      0.96    60539\n",
      "1  washing machine       0.75    0.45      0.56    49848\n",
      "2      dish washer       0.72    0.63      0.67    31498\n",
      "3        microwave       0.51    0.98      0.67    45078\n",
      "4           kettle       0.83    0.71      0.77    53030\n",
      "5        micro avg       0.73    0.76      0.75   239993\n",
      "6        macro avg       0.75    0.75      0.73   239993\n",
      "7     weighted avg       0.77    0.76      0.74   239993\n",
      "8      samples avg       0.69    0.75      0.70   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 41 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.71    0.77      0.74    11773\n",
      "1  washing machine       0.52    0.33      0.40     8500\n",
      "2      dish washer       0.61    0.16      0.25     8251\n",
      "3        microwave       0.75    0.40      0.52     9529\n",
      "4           kettle       0.70    0.36      0.48     9958\n",
      "5        micro avg       0.67    0.43      0.52    48011\n",
      "6        macro avg       0.66    0.40      0.48    48011\n",
      "7     weighted avg       0.66    0.43      0.50    48011\n",
      "8      samples avg       0.48    0.41      0.41    48011\n",
      "-------------------------------------------------\n",
      "Fold 41 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.69    0.94      0.80    60539\n",
      "1  washing machine       0.51    0.58      0.55    49848\n",
      "2      dish washer       0.36    0.54      0.43    31498\n",
      "3        microwave       0.56    0.93      0.70    45078\n",
      "4           kettle       0.63    0.50      0.56    53030\n",
      "5        micro avg       0.57    0.71      0.63   239993\n",
      "6        macro avg       0.55    0.70      0.61   239993\n",
      "7     weighted avg       0.57    0.71      0.63   239993\n",
      "8      samples avg       0.48    0.66      0.53   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 42 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.89    0.88      0.88    11841\n",
      "1  washing machine       0.51    0.91      0.66     8504\n",
      "2      dish washer       0.85    0.60      0.70     8182\n",
      "3        microwave       0.68    0.85      0.75     9501\n",
      "4           kettle       0.98    0.72      0.83     9986\n",
      "5        micro avg       0.74    0.80      0.77    48014\n",
      "6        macro avg       0.78    0.79      0.77    48014\n",
      "7     weighted avg       0.79    0.80      0.78    48014\n",
      "8      samples avg       0.73    0.79      0.73    48014\n",
      "-------------------------------------------------\n",
      "Fold 42 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.98      0.95    60539\n",
      "1  washing machine       0.67    0.62      0.64    49848\n",
      "2      dish washer       0.68    0.64      0.66    31498\n",
      "3        microwave       0.52    0.98      0.68    45078\n",
      "4           kettle       0.91    0.54      0.68    53030\n",
      "5        micro avg       0.71    0.77      0.74   239993\n",
      "6        macro avg       0.74    0.75      0.72   239993\n",
      "7     weighted avg       0.76    0.77      0.74   239993\n",
      "8      samples avg       0.70    0.77      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 43 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.91      0.92    11789\n",
      "1  washing machine       0.92    0.84      0.88     8414\n",
      "2      dish washer       0.92    0.76      0.83     8194\n",
      "3        microwave       0.93    0.85      0.88     9689\n",
      "4           kettle       0.96    0.93      0.95     9896\n",
      "5        micro avg       0.93    0.86      0.90    47982\n",
      "6        macro avg       0.93    0.86      0.89    47982\n",
      "7     weighted avg       0.93    0.86      0.90    47982\n",
      "8      samples avg       0.94    0.88      0.90    47982\n",
      "-------------------------------------------------\n",
      "Fold 43 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.99      0.96    60539\n",
      "1  washing machine       0.58    0.78      0.66    49848\n",
      "2      dish washer       0.76    0.61      0.68    31498\n",
      "3        microwave       0.69    0.88      0.77    45078\n",
      "4           kettle       0.78    0.74      0.76    53030\n",
      "5        micro avg       0.74    0.82      0.78   239993\n",
      "6        macro avg       0.75    0.80      0.77   239993\n",
      "7     weighted avg       0.76    0.82      0.78   239993\n",
      "8      samples avg       0.71    0.80      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 44 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.73    0.84      0.78    11844\n",
      "1  washing machine       0.50    0.59      0.54     8439\n",
      "2      dish washer       0.51    0.47      0.49     8252\n",
      "3        microwave       0.66    0.51      0.58     9532\n",
      "4           kettle       0.65    0.79      0.71     9977\n",
      "5        micro avg       0.62    0.66      0.64    48044\n",
      "6        macro avg       0.61    0.64      0.62    48044\n",
      "7     weighted avg       0.62    0.66      0.63    48044\n",
      "8      samples avg       0.55    0.61      0.53    48044\n",
      "-------------------------------------------------\n",
      "Fold 44 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.70    0.94      0.80    60539\n",
      "1  washing machine       0.52    0.80      0.63    49848\n",
      "2      dish washer       0.33    0.79      0.47    31498\n",
      "3        microwave       0.56    0.93      0.70    45078\n",
      "4           kettle       0.58    0.86      0.69    53030\n",
      "5        micro avg       0.54    0.87      0.67   239993\n",
      "6        macro avg       0.54    0.86      0.66   239993\n",
      "7     weighted avg       0.56    0.87      0.68   239993\n",
      "8      samples avg       0.47    0.82      0.57   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 45 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.62    0.64      0.63    11795\n",
      "1  washing machine       0.83    0.01      0.01     8307\n",
      "2      dish washer       0.53    0.13      0.20     8243\n",
      "3        microwave       0.62    0.36      0.45     9565\n",
      "4           kettle       0.38    0.22      0.28    10039\n",
      "5        micro avg       0.56    0.30      0.39    47949\n",
      "6        macro avg       0.59    0.27      0.32    47949\n",
      "7     weighted avg       0.59    0.30      0.34    47949\n",
      "8      samples avg       0.34    0.32      0.31    47949\n",
      "-------------------------------------------------\n",
      "Fold 45 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.64    0.69      0.66    60539\n",
      "1  washing machine       0.41    0.03      0.06    49848\n",
      "2      dish washer       0.31    0.29      0.30    31498\n",
      "3        microwave       0.57    0.64      0.61    45078\n",
      "4           kettle       0.41    0.31      0.35    53030\n",
      "5        micro avg       0.52    0.41      0.46   239993\n",
      "6        macro avg       0.47    0.39      0.40   239993\n",
      "7     weighted avg       0.49    0.41      0.41   239993\n",
      "8      samples avg       0.34    0.43      0.35   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 46 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.83    0.92      0.87    11715\n",
      "1  washing machine       0.88    0.69      0.78     8418\n",
      "2      dish washer       0.91    0.55      0.68     8208\n",
      "3        microwave       0.51    0.99      0.67     9610\n",
      "4           kettle       0.94    0.84      0.89     9968\n",
      "5        micro avg       0.75    0.81      0.78    47919\n",
      "6        macro avg       0.81    0.80      0.78    47919\n",
      "7     weighted avg       0.81    0.81      0.79    47919\n",
      "8      samples avg       0.73    0.82      0.75    47919\n",
      "-------------------------------------------------\n",
      "Fold 46 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.85    1.00      0.91    60539\n",
      "1  washing machine       0.60    0.68      0.64    49848\n",
      "2      dish washer       0.68    0.61      0.64    31498\n",
      "3        microwave       0.52    0.97      0.68    45078\n",
      "4           kettle       0.79    0.73      0.76    53030\n",
      "5        micro avg       0.68    0.82      0.74   239993\n",
      "6        macro avg       0.69    0.80      0.73   239993\n",
      "7     weighted avg       0.70    0.82      0.74   239993\n",
      "8      samples avg       0.65    0.79      0.69   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 47 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.94      0.92    11872\n",
      "1  washing machine       0.92    0.85      0.88     8496\n",
      "2      dish washer       0.90    0.83      0.86     8167\n",
      "3        microwave       0.91    0.87      0.89     9611\n",
      "4           kettle       0.97    0.93      0.95     9948\n",
      "5        micro avg       0.92    0.89      0.90    48094\n",
      "6        macro avg       0.92    0.88      0.90    48094\n",
      "7     weighted avg       0.92    0.89      0.90    48094\n",
      "8      samples avg       0.93    0.91      0.91    48094\n",
      "-------------------------------------------------\n",
      "Fold 47 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.99      0.94    60539\n",
      "1  washing machine       0.57    0.81      0.67    49848\n",
      "2      dish washer       0.73    0.62      0.67    31498\n",
      "3        microwave       0.62    0.95      0.75    45078\n",
      "4           kettle       0.84    0.67      0.75    53030\n",
      "5        micro avg       0.72    0.83      0.77   239993\n",
      "6        macro avg       0.73    0.81      0.76   239993\n",
      "7     weighted avg       0.75    0.83      0.77   239993\n",
      "8      samples avg       0.69    0.81      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 48 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.93      0.93    11869\n",
      "1  washing machine       0.89    0.88      0.88     8413\n",
      "2      dish washer       0.90    0.80      0.85     8172\n",
      "3        microwave       0.89    0.88      0.88     9614\n",
      "4           kettle       0.97    0.93      0.95     9961\n",
      "5        micro avg       0.91    0.89      0.90    48029\n",
      "6        macro avg       0.91    0.88      0.90    48029\n",
      "7     weighted avg       0.91    0.89      0.90    48029\n",
      "8      samples avg       0.93    0.91      0.91    48029\n",
      "-------------------------------------------------\n",
      "Fold 48 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.99      0.94    60539\n",
      "1  washing machine       0.57    0.84      0.68    49848\n",
      "2      dish washer       0.76    0.61      0.68    31498\n",
      "3        microwave       0.58    0.95      0.72    45078\n",
      "4           kettle       0.82    0.70      0.75    53030\n",
      "5        micro avg       0.71    0.84      0.77   239993\n",
      "6        macro avg       0.73    0.82      0.76   239993\n",
      "7     weighted avg       0.73    0.84      0.77   239993\n",
      "8      samples avg       0.68    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 49 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.93      0.93    11878\n",
      "1  washing machine       0.89    0.88      0.89     8373\n",
      "2      dish washer       0.90    0.82      0.86     8220\n",
      "3        microwave       0.93    0.85      0.89     9496\n",
      "4           kettle       0.97    0.93      0.95     9963\n",
      "5        micro avg       0.92    0.89      0.91    47930\n",
      "6        macro avg       0.92    0.88      0.90    47930\n",
      "7     weighted avg       0.92    0.89      0.91    47930\n",
      "8      samples avg       0.94    0.90      0.91    47930\n",
      "-------------------------------------------------\n",
      "Fold 49 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.89    0.99      0.94    60539\n",
      "1  washing machine       0.57    0.84      0.67    49848\n",
      "2      dish washer       0.69    0.62      0.65    31498\n",
      "3        microwave       0.67    0.89      0.76    45078\n",
      "4           kettle       0.81    0.68      0.74    53030\n",
      "5        micro avg       0.72    0.82      0.77   239993\n",
      "6        macro avg       0.72    0.80      0.75   239993\n",
      "7     weighted avg       0.74    0.82      0.77   239993\n",
      "8      samples avg       0.69    0.80      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 50 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.61    0.53      0.57    11708\n",
      "1  washing machine       0.40    0.13      0.19     8464\n",
      "2      dish washer       0.36    0.04      0.07     8355\n",
      "3        microwave       0.82    0.19      0.31     9485\n",
      "4           kettle       0.50    0.41      0.45    10016\n",
      "5        micro avg       0.56    0.28      0.37    48028\n",
      "6        macro avg       0.54    0.26      0.32    48028\n",
      "7     weighted avg       0.55    0.28      0.34    48028\n",
      "8      samples avg       0.29    0.33      0.29    48028\n",
      "-------------------------------------------------\n",
      "Fold 50 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.63    0.70      0.66    60539\n",
      "1  washing machine       0.46    0.47      0.46    49848\n",
      "2      dish washer       0.19    0.18      0.18    31498\n",
      "3        microwave       0.57    0.64      0.60    45078\n",
      "4           kettle       0.54    0.61      0.57    53030\n",
      "5        micro avg       0.51    0.55      0.53   239993\n",
      "6        macro avg       0.48    0.52      0.50   239993\n",
      "7     weighted avg       0.50    0.55      0.53   239993\n",
      "8      samples avg       0.34    0.57      0.40   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 51 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.72    0.57      0.63    11778\n",
      "1  washing machine       0.00    0.00      0.00     8407\n",
      "2      dish washer       0.37    0.16      0.22     8234\n",
      "3        microwave       0.62    0.42      0.50     9616\n",
      "4           kettle       0.65    0.13      0.21     9945\n",
      "5        micro avg       0.62    0.28      0.38    47980\n",
      "6        macro avg       0.47    0.25      0.31    47980\n",
      "7     weighted avg       0.50    0.28      0.34    47980\n",
      "8      samples avg       0.30    0.28      0.27    47980\n",
      "-------------------------------------------------\n",
      "Fold 51 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.71    0.68      0.70    60539\n",
      "1  washing machine       0.00    0.00      0.00    49848\n",
      "2      dish washer       0.19    0.23      0.21    31498\n",
      "3        microwave       0.56    0.70      0.62    45078\n",
      "4           kettle       0.51    0.01      0.02    53030\n",
      "5        micro avg       0.53    0.34      0.41   239993\n",
      "6        macro avg       0.40    0.33      0.31   239993\n",
      "7     weighted avg       0.42    0.34      0.33   239993\n",
      "8      samples avg       0.33    0.35      0.32   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 52 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.60    0.57      0.59    11716\n",
      "1  washing machine       0.39    0.11      0.17     8502\n",
      "2      dish washer       0.29    0.04      0.07     8180\n",
      "3        microwave       0.64    0.30      0.41     9593\n",
      "4           kettle       0.50    0.24      0.33    10037\n",
      "5        micro avg       0.55    0.28      0.37    48028\n",
      "6        macro avg       0.48    0.25      0.31    48028\n",
      "7     weighted avg       0.50    0.28      0.33    48028\n",
      "8      samples avg       0.31    0.31      0.28    48028\n",
      "-------------------------------------------------\n",
      "Fold 52 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.63    0.65      0.64    60539\n",
      "1  washing machine       0.46    0.31      0.37    49848\n",
      "2      dish washer       0.20    0.13      0.16    31498\n",
      "3        microwave       0.55    0.59      0.57    45078\n",
      "4           kettle       0.56    0.45      0.50    53030\n",
      "5        micro avg       0.53    0.46      0.49   239993\n",
      "6        macro avg       0.48    0.43      0.45   239993\n",
      "7     weighted avg       0.51    0.46      0.48   239993\n",
      "8      samples avg       0.32    0.49      0.36   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 53 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.62    0.96      0.76    11969\n",
      "1  washing machine       0.53    0.16      0.24     8437\n",
      "2      dish washer       0.56    0.17      0.26     8227\n",
      "3        microwave       0.64    0.51      0.57     9470\n",
      "4           kettle       0.55    0.58      0.56    10024\n",
      "5        micro avg       0.60    0.51      0.55    48127\n",
      "6        macro avg       0.58    0.47      0.48    48127\n",
      "7     weighted avg       0.59    0.51      0.50    48127\n",
      "8      samples avg       0.55    0.50      0.48    48127\n",
      "-------------------------------------------------\n",
      "Fold 53 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.63    1.00      0.77    60539\n",
      "1  washing machine       0.53    0.50      0.52    49848\n",
      "2      dish washer       0.34    0.50      0.40    31498\n",
      "3        microwave       0.56    0.94      0.70    45078\n",
      "4           kettle       0.58    0.85      0.69    53030\n",
      "5        micro avg       0.55    0.79      0.65   239993\n",
      "6        macro avg       0.53    0.76      0.62   239993\n",
      "7     weighted avg       0.55    0.79      0.64   239993\n",
      "8      samples avg       0.51    0.74      0.56   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 54 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.92      0.92    11810\n",
      "1  washing machine       0.89    0.86      0.88     8419\n",
      "2      dish washer       0.87    0.84      0.85     8330\n",
      "3        microwave       0.89    0.86      0.88     9509\n",
      "4           kettle       0.96    0.93      0.95     9942\n",
      "5        micro avg       0.91    0.89      0.90    48010\n",
      "6        macro avg       0.91    0.88      0.89    48010\n",
      "7     weighted avg       0.91    0.89      0.90    48010\n",
      "8      samples avg       0.92    0.90      0.90    48010\n",
      "-------------------------------------------------\n",
      "Fold 54 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.99      0.95    60539\n",
      "1  washing machine       0.57    0.78      0.66    49848\n",
      "2      dish washer       0.64    0.67      0.65    31498\n",
      "3        microwave       0.61    0.93      0.74    45078\n",
      "4           kettle       0.86    0.68      0.76    53030\n",
      "5        micro avg       0.71    0.83      0.77   239993\n",
      "6        macro avg       0.72    0.81      0.75   239993\n",
      "7     weighted avg       0.74    0.83      0.77   239993\n",
      "8      samples avg       0.68    0.81      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 55 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.87    0.80      0.83    11769\n",
      "1  washing machine       0.70    0.46      0.55     8399\n",
      "2      dish washer       0.73    0.50      0.59     8151\n",
      "3        microwave       0.51    0.99      0.67     9628\n",
      "4           kettle       0.91    0.83      0.86     9908\n",
      "5        micro avg       0.70    0.73      0.72    47855\n",
      "6        macro avg       0.74    0.71      0.70    47855\n",
      "7     weighted avg       0.75    0.73      0.72    47855\n",
      "8      samples avg       0.68    0.72      0.67    47855\n",
      "-------------------------------------------------\n",
      "Fold 55 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.89    0.97      0.93    60539\n",
      "1  washing machine       0.70    0.41      0.51    49848\n",
      "2      dish washer       0.65    0.53      0.58    31498\n",
      "3        microwave       0.48    1.00      0.65    45078\n",
      "4           kettle       0.85    0.70      0.77    53030\n",
      "5        micro avg       0.69    0.74      0.72   239993\n",
      "6        macro avg       0.72    0.72      0.69   239993\n",
      "7     weighted avg       0.73    0.74      0.71   239993\n",
      "8      samples avg       0.67    0.73      0.67   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 56 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.62    0.87      0.72    11865\n",
      "1  washing machine       0.51    0.26      0.34     8390\n",
      "2      dish washer       0.48    0.38      0.42     8290\n",
      "3        microwave       0.70    0.38      0.49     9568\n",
      "4           kettle       0.55    0.42      0.48    10023\n",
      "5        micro avg       0.58    0.49      0.53    48136\n",
      "6        macro avg       0.57    0.46      0.49    48136\n",
      "7     weighted avg       0.58    0.49      0.51    48136\n",
      "8      samples avg       0.49    0.48      0.43    48136\n",
      "-------------------------------------------------\n",
      "Fold 56 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.63    0.95      0.76    60539\n",
      "1  washing machine       0.54    0.67      0.60    49848\n",
      "2      dish washer       0.33    0.68      0.44    31498\n",
      "3        microwave       0.56    0.89      0.69    45078\n",
      "4           kettle       0.62    0.76      0.68    53030\n",
      "5        micro avg       0.54    0.80      0.65   239993\n",
      "6        macro avg       0.54    0.79      0.63   239993\n",
      "7     weighted avg       0.56    0.80      0.65   239993\n",
      "8      samples avg       0.48    0.76      0.55   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 57 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.62    0.73      0.67    11794\n",
      "1  washing machine       0.50    0.39      0.44     8424\n",
      "2      dish washer       0.54    0.28      0.37     8275\n",
      "3        microwave       0.62    0.39      0.48     9555\n",
      "4           kettle       0.46    0.24      0.31     9992\n",
      "5        micro avg       0.56    0.42      0.48    48040\n",
      "6        macro avg       0.55    0.41      0.45    48040\n",
      "7     weighted avg       0.55    0.42      0.47    48040\n",
      "8      samples avg       0.39    0.43      0.37    48040\n",
      "-------------------------------------------------\n",
      "Fold 57 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.64    0.84      0.73    60539\n",
      "1  washing machine       0.52    0.64      0.57    49848\n",
      "2      dish washer       0.37    0.62      0.46    31498\n",
      "3        microwave       0.56    0.77      0.65    45078\n",
      "4           kettle       0.50    0.49      0.49    53030\n",
      "5        micro avg       0.53    0.68      0.60   239993\n",
      "6        macro avg       0.52    0.67      0.58   239993\n",
      "7     weighted avg       0.53    0.68      0.59   239993\n",
      "8      samples avg       0.40    0.65      0.47   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 58 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.62    0.90      0.73    11748\n",
      "1  washing machine       0.54    0.41      0.46     8446\n",
      "2      dish washer       0.56    0.10      0.17     8203\n",
      "3        microwave       0.77    0.36      0.49     9654\n",
      "4           kettle       0.57    0.50      0.53     9991\n",
      "5        micro avg       0.61    0.49      0.54    48042\n",
      "6        macro avg       0.61    0.45      0.48    48042\n",
      "7     weighted avg       0.61    0.49      0.50    48042\n",
      "8      samples avg       0.54    0.48      0.47    48042\n",
      "-------------------------------------------------\n",
      "Fold 58 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.71    0.91      0.80    60539\n",
      "1  washing machine       0.55    0.66      0.60    49848\n",
      "2      dish washer       0.34    0.46      0.39    31498\n",
      "3        microwave       0.56    0.93      0.70    45078\n",
      "4           kettle       0.56    0.61      0.58    53030\n",
      "5        micro avg       0.56    0.74      0.64   239993\n",
      "6        macro avg       0.54    0.71      0.61   239993\n",
      "7     weighted avg       0.57    0.74      0.64   239993\n",
      "8      samples avg       0.53    0.68      0.55   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 59 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.62    0.64      0.63    11808\n",
      "1  washing machine       0.49    0.05      0.09     8365\n",
      "2      dish washer       0.32    0.01      0.01     8138\n",
      "3        microwave       0.79    0.24      0.37     9422\n",
      "4           kettle       0.37    0.25      0.29     9944\n",
      "5        micro avg       0.56    0.27      0.36    47677\n",
      "6        macro avg       0.52    0.24      0.28    47677\n",
      "7     weighted avg       0.53    0.27      0.31    47677\n",
      "8      samples avg       0.34    0.30      0.29    47677\n",
      "-------------------------------------------------\n",
      "Fold 59 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.63    0.90      0.74    60539\n",
      "1  washing machine       0.62    0.13      0.22    49848\n",
      "2      dish washer       0.42    0.01      0.01    31498\n",
      "3        microwave       0.57    0.82      0.67    45078\n",
      "4           kettle       0.63    0.48      0.54    53030\n",
      "5        micro avg       0.61    0.51      0.56   239993\n",
      "6        macro avg       0.58    0.47      0.44   239993\n",
      "7     weighted avg       0.59    0.51      0.48   239993\n",
      "8      samples avg       0.51    0.52      0.49   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 60 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.93      0.92    11827\n",
      "1  washing machine       0.90    0.82      0.86     8539\n",
      "2      dish washer       0.89    0.77      0.83     8216\n",
      "3        microwave       0.91    0.85      0.87     9617\n",
      "4           kettle       0.95    0.93      0.94     9906\n",
      "5        micro avg       0.91    0.87      0.89    48105\n",
      "6        macro avg       0.91    0.86      0.88    48105\n",
      "7     weighted avg       0.91    0.87      0.89    48105\n",
      "8      samples avg       0.92    0.89      0.89    48105\n",
      "-------------------------------------------------\n",
      "Fold 60 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.88    0.99      0.93    60539\n",
      "1  washing machine       0.57    0.79      0.66    49848\n",
      "2      dish washer       0.60    0.66      0.63    31498\n",
      "3        microwave       0.65    0.87      0.75    45078\n",
      "4           kettle       0.87    0.70      0.78    53030\n",
      "5        micro avg       0.72    0.82      0.76   239993\n",
      "6        macro avg       0.72    0.80      0.75   239993\n",
      "7     weighted avg       0.74    0.82      0.77   239993\n",
      "8      samples avg       0.68    0.80      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Using koef 2.5\n",
      "GRU enabled\n",
      "600/600 [==============================] - 94s 156ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 94s 156ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 94s 156ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 94s 156ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 94s 156ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 94s 156ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 94s 156ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 94s 156ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 94s 156ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 94s 156ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 94s 157ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 94s 156ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 94s 156ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 94s 156ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.1036e-04\n",
      "600/600 [==============================] - 14s 15ms/step\n",
      "600/600 [==============================] - 93s 156ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 94s 156ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 94s 156ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 94s 156ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 94s 156ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 94s 156ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 94s 156ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 93s 156ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 93s 156ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 93s 156ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.1036e-04\n",
      "600/600 [==============================] - 10s 15ms/step\n",
      "600/600 [==============================] - 94s 156ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 94s 156ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 94s 156ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 94s 156ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 94s 156ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 94s 156ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 94s 156ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 94s 156ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 94s 156ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 94s 156ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 94s 156ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 94s 156ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.1036e-04\n",
      "600/600 [==============================] - 10s 15ms/step\n",
      "600/600 [==============================] - 93s 155ms/step - loss: inf - F1Score: 0.7867 - WeightedF1: 0.8033 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: inf - F1Score: 0.7867 - WeightedF1: 0.8033 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: inf - F1Score: 0.7867 - WeightedF1: 0.8033 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: inf - F1Score: 0.7865 - WeightedF1: 0.8032 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: inf - F1Score: 0.7865 - WeightedF1: 0.8031 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 93s 156ms/step - loss: inf - F1Score: 0.7865 - WeightedF1: 0.8032 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: inf - F1Score: 0.7864 - WeightedF1: 0.8031 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: inf - F1Score: 0.7866 - WeightedF1: 0.8032 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: inf - F1Score: 0.7866 - WeightedF1: 0.8033 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: inf - F1Score: 0.7866 - WeightedF1: 0.8032 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: inf - F1Score: 0.7866 - WeightedF1: 0.8032 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: inf - F1Score: 0.7866 - WeightedF1: 0.8032 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: inf - F1Score: 0.7867 - WeightedF1: 0.8033 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 14s 22ms/step\n",
      "600/600 [==============================] - 93s 156ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 93s 156ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 93s 156ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 93s 156ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 93s 156ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 93s 156ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 93s 156ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 93s 156ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.1036e-04\n",
      "600/600 [==============================] - 10s 15ms/step\n",
      "600/600 [==============================] - 95s 158ms/step - loss: inf - F1Score: 0.8574 - WeightedF1: 0.8628 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 94s 157ms/step - loss: inf - F1Score: 0.8565 - WeightedF1: 0.8618 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: inf - F1Score: 0.8297 - WeightedF1: 0.8357 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: inf - F1Score: 0.8297 - WeightedF1: 0.8357 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: inf - F1Score: 0.8296 - WeightedF1: 0.8357 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: inf - F1Score: 0.8296 - WeightedF1: 0.8357 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: inf - F1Score: 0.8298 - WeightedF1: 0.8359 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: inf - F1Score: 0.8298 - WeightedF1: 0.8359 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: inf - F1Score: 0.8298 - WeightedF1: 0.8358 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: inf - F1Score: 0.8296 - WeightedF1: 0.8357 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: inf - F1Score: 0.8296 - WeightedF1: 0.8357 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: inf - F1Score: 0.8296 - WeightedF1: 0.8357 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: inf - F1Score: 0.8297 - WeightedF1: 0.8357 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 93s 154ms/step - loss: inf - F1Score: 0.8296 - WeightedF1: 0.8357 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 10s 15ms/step\n",
      "600/600 [==============================] - 93s 155ms/step - loss: inf - F1Score: 0.7398 - WeightedF1: 0.7496 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: inf - F1Score: 0.7397 - WeightedF1: 0.7495 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: inf - F1Score: 0.7398 - WeightedF1: 0.7496 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: inf - F1Score: 0.7396 - WeightedF1: 0.7494 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: inf - F1Score: 0.7396 - WeightedF1: 0.7494 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: inf - F1Score: 0.7398 - WeightedF1: 0.7495 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: inf - F1Score: 0.7397 - WeightedF1: 0.7495 - lr: 1.1036e-04\n",
      "600/600 [==============================] - 10s 16ms/step\n",
      "600/600 [==============================] - 93s 155ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.1036e-04\n",
      "600/600 [==============================] - 10s 16ms/step\n",
      "600/600 [==============================] - 93s 154ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 93s 154ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 93s 154ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.1036e-04\n",
      "600/600 [==============================] - 10s 15ms/step\n",
      "600/600 [==============================] - 93s 155ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 93s 154ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 93s 154ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 93s 155ms/step - loss: nan - F1Score: nan - WeightedF1: nan - lr: 1.1036e-04\n",
      "600/600 [==============================] - 10s 15ms/step\n",
      "3000/3000 [==============================] - 47s 16ms/step\n",
      "Fold 1 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.87    0.92      0.89    11706\n",
      "1  washing machine       0.90    0.75      0.82     8507\n",
      "2      dish washer       0.83    0.73      0.78     8309\n",
      "3        microwave       0.88    0.82      0.85     9549\n",
      "4           kettle       0.96    0.89      0.92     9949\n",
      "5        micro avg       0.89    0.83      0.86    48020\n",
      "6        macro avg       0.89    0.82      0.85    48020\n",
      "7     weighted avg       0.89    0.83      0.86    48020\n",
      "8      samples avg       0.89    0.84      0.85    48020\n",
      "-------------------------------------------------\n",
      "Fold 1 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.99      0.96    60539\n",
      "1  washing machine       0.74    0.55      0.63    49848\n",
      "2      dish washer       0.55    0.73      0.63    31498\n",
      "3        microwave       0.63    0.93      0.75    45078\n",
      "4           kettle       0.73    0.82      0.77    53030\n",
      "5        micro avg       0.72    0.82      0.77   239993\n",
      "6        macro avg       0.71    0.81      0.75   239993\n",
      "7     weighted avg       0.74    0.82      0.77   239993\n",
      "8      samples avg       0.71    0.80      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 2 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.89    0.90      0.90    11903\n",
      "1  washing machine       0.88    0.76      0.82     8383\n",
      "2      dish washer       0.81    0.77      0.79     8279\n",
      "3        microwave       0.86    0.82      0.84     9584\n",
      "4           kettle       0.95    0.91      0.93     9899\n",
      "5        micro avg       0.88    0.84      0.86    48048\n",
      "6        macro avg       0.88    0.83      0.85    48048\n",
      "7     weighted avg       0.88    0.84      0.86    48048\n",
      "8      samples avg       0.89    0.85      0.86    48048\n",
      "-------------------------------------------------\n",
      "Fold 2 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.99      0.96    60539\n",
      "1  washing machine       0.62    0.69      0.66    49848\n",
      "2      dish washer       0.51    0.76      0.61    31498\n",
      "3        microwave       0.62    0.95      0.75    45078\n",
      "4           kettle       0.83    0.74      0.79    53030\n",
      "5        micro avg       0.71    0.83      0.77   239993\n",
      "6        macro avg       0.70    0.83      0.75   239993\n",
      "7     weighted avg       0.73    0.83      0.77   239993\n",
      "8      samples avg       0.69    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 3 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.85    0.92      0.88    11755\n",
      "1  washing machine       0.91    0.74      0.82     8482\n",
      "2      dish washer       0.82    0.71      0.76     8145\n",
      "3        microwave       0.88    0.73      0.80     9633\n",
      "4           kettle       0.95    0.90      0.92     9989\n",
      "5        micro avg       0.88    0.81      0.84    48004\n",
      "6        macro avg       0.88    0.80      0.84    48004\n",
      "7     weighted avg       0.88    0.81      0.84    48004\n",
      "8      samples avg       0.89    0.82      0.84    48004\n",
      "-------------------------------------------------\n",
      "Fold 3 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.98      0.94    60539\n",
      "1  washing machine       0.61    0.72      0.66    49848\n",
      "2      dish washer       0.62    0.68      0.65    31498\n",
      "3        microwave       0.66    0.85      0.74    45078\n",
      "4           kettle       0.77    0.76      0.77    53030\n",
      "5        micro avg       0.72    0.82      0.77   239993\n",
      "6        macro avg       0.71    0.80      0.75   239993\n",
      "7     weighted avg       0.73    0.82      0.77   239993\n",
      "8      samples avg       0.69    0.80      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 4 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.88    0.90      0.89    11880\n",
      "1  washing machine       0.90    0.75      0.82     8396\n",
      "2      dish washer       0.85    0.68      0.75     8215\n",
      "3        microwave       0.88    0.73      0.80     9566\n",
      "4           kettle       0.95    0.90      0.92    10018\n",
      "5        micro avg       0.89    0.80      0.85    48075\n",
      "6        macro avg       0.89    0.79      0.84    48075\n",
      "7     weighted avg       0.89    0.80      0.84    48075\n",
      "8      samples avg       0.90    0.82      0.84    48075\n",
      "-------------------------------------------------\n",
      "Fold 4 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.99      0.96    60539\n",
      "1  washing machine       0.59    0.75      0.66    49848\n",
      "2      dish washer       0.75    0.62      0.68    31498\n",
      "3        microwave       0.59    0.92      0.72    45078\n",
      "4           kettle       0.91    0.71      0.80    53030\n",
      "5        micro avg       0.74    0.82      0.78   239993\n",
      "6        macro avg       0.76    0.80      0.76   239993\n",
      "7     weighted avg       0.77    0.82      0.78   239993\n",
      "8      samples avg       0.72    0.81      0.74   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 5 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.88    0.90      0.89    11798\n",
      "1  washing machine       0.91    0.73      0.81     8396\n",
      "2      dish washer       0.84    0.69      0.75     8174\n",
      "3        microwave       0.85    0.79      0.82     9484\n",
      "4           kettle       0.96    0.87      0.91    10001\n",
      "5        micro avg       0.89    0.81      0.84    47853\n",
      "6        macro avg       0.89    0.79      0.84    47853\n",
      "7     weighted avg       0.89    0.81      0.84    47853\n",
      "8      samples avg       0.89    0.82      0.84    47853\n",
      "-------------------------------------------------\n",
      "Fold 5 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.98      0.96    60539\n",
      "1  washing machine       0.62    0.68      0.65    49848\n",
      "2      dish washer       0.70    0.64      0.67    31498\n",
      "3        microwave       0.57    0.96      0.72    45078\n",
      "4           kettle       0.85    0.72      0.78    53030\n",
      "5        micro avg       0.73    0.81      0.77   239993\n",
      "6        macro avg       0.74    0.80      0.75   239993\n",
      "7     weighted avg       0.75    0.81      0.77   239993\n",
      "8      samples avg       0.70    0.80      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 6 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.91      0.92    11828\n",
      "1  washing machine       0.91    0.82      0.86     8389\n",
      "2      dish washer       0.89    0.80      0.85     8207\n",
      "3        microwave       0.92    0.85      0.89     9542\n",
      "4           kettle       0.96    0.93      0.95     9968\n",
      "5        micro avg       0.93    0.87      0.90    47934\n",
      "6        macro avg       0.93    0.86      0.89    47934\n",
      "7     weighted avg       0.93    0.87      0.90    47934\n",
      "8      samples avg       0.93    0.88      0.90    47934\n",
      "-------------------------------------------------\n",
      "Fold 6 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.95    0.92      0.94    60539\n",
      "1  washing machine       0.60    0.70      0.65    49848\n",
      "2      dish washer       0.57    0.70      0.62    31498\n",
      "3        microwave       0.69    0.92      0.79    45078\n",
      "4           kettle       0.77    0.73      0.75    53030\n",
      "5        micro avg       0.72    0.80      0.76   239993\n",
      "6        macro avg       0.71    0.79      0.75   239993\n",
      "7     weighted avg       0.74    0.80      0.77   239993\n",
      "8      samples avg       0.69    0.78      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 7 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.91      0.91    11670\n",
      "1  washing machine       0.90    0.82      0.86     8394\n",
      "2      dish washer       0.87    0.78      0.82     8254\n",
      "3        microwave       0.89    0.85      0.87     9554\n",
      "4           kettle       0.96    0.92      0.94     9928\n",
      "5        micro avg       0.91    0.86      0.88    47800\n",
      "6        macro avg       0.91    0.86      0.88    47800\n",
      "7     weighted avg       0.91    0.86      0.88    47800\n",
      "8      samples avg       0.92    0.88      0.89    47800\n",
      "-------------------------------------------------\n",
      "Fold 7 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.98      0.96    60539\n",
      "1  washing machine       0.56    0.83      0.67    49848\n",
      "2      dish washer       0.71    0.65      0.67    31498\n",
      "3        microwave       0.63    0.90      0.74    45078\n",
      "4           kettle       0.80    0.73      0.76    53030\n",
      "5        micro avg       0.72    0.84      0.77   239993\n",
      "6        macro avg       0.73    0.82      0.76   239993\n",
      "7     weighted avg       0.74    0.84      0.78   239993\n",
      "8      samples avg       0.68    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 8 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.84      0.89    11782\n",
      "1  washing machine       0.63    0.91      0.74     8527\n",
      "2      dish washer       0.93    0.60      0.73     8269\n",
      "3        microwave       0.87    0.80      0.83     9595\n",
      "4           kettle       0.94    0.89      0.92     9911\n",
      "5        micro avg       0.84    0.81      0.83    48084\n",
      "6        macro avg       0.86    0.81      0.82    48084\n",
      "7     weighted avg       0.87    0.81      0.83    48084\n",
      "8      samples avg       0.84    0.83      0.82    48084\n",
      "-------------------------------------------------\n",
      "Fold 8 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.96    0.98      0.97    60539\n",
      "1  washing machine       0.57    0.85      0.68    49848\n",
      "2      dish washer       0.90    0.57      0.70    31498\n",
      "3        microwave       0.62    0.91      0.74    45078\n",
      "4           kettle       0.78    0.78      0.78    53030\n",
      "5        micro avg       0.73    0.84      0.78   239993\n",
      "6        macro avg       0.77    0.82      0.77   239993\n",
      "7     weighted avg       0.77    0.84      0.79   239993\n",
      "8      samples avg       0.72    0.84      0.75   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 9 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.93      0.92    11834\n",
      "1  washing machine       0.91    0.80      0.85     8478\n",
      "2      dish washer       0.85    0.79      0.82     8188\n",
      "3        microwave       0.93    0.83      0.87     9619\n",
      "4           kettle       0.96    0.93      0.94    10086\n",
      "5        micro avg       0.91    0.86      0.89    48205\n",
      "6        macro avg       0.91    0.85      0.88    48205\n",
      "7     weighted avg       0.91    0.86      0.89    48205\n",
      "8      samples avg       0.92    0.88      0.89    48205\n",
      "-------------------------------------------------\n",
      "Fold 9 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.89      0.90    60539\n",
      "1  washing machine       0.57    0.81      0.67    49848\n",
      "2      dish washer       0.58    0.71      0.64    31498\n",
      "3        microwave       0.67    0.85      0.75    45078\n",
      "4           kettle       0.86    0.72      0.78    53030\n",
      "5        micro avg       0.72    0.81      0.76   239993\n",
      "6        macro avg       0.72    0.80      0.75   239993\n",
      "7     weighted avg       0.74    0.81      0.76   239993\n",
      "8      samples avg       0.69    0.78      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 10 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.93      0.92    11928\n",
      "1  washing machine       0.90    0.81      0.85     8376\n",
      "2      dish washer       0.87    0.79      0.82     8204\n",
      "3        microwave       0.88    0.86      0.87     9506\n",
      "4           kettle       0.95    0.92      0.94     9963\n",
      "5        micro avg       0.91    0.87      0.89    47977\n",
      "6        macro avg       0.90    0.86      0.88    47977\n",
      "7     weighted avg       0.91    0.87      0.89    47977\n",
      "8      samples avg       0.92    0.88      0.89    47977\n",
      "-------------------------------------------------\n",
      "Fold 10 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.99      0.95    60539\n",
      "1  washing machine       0.58    0.80      0.67    49848\n",
      "2      dish washer       0.67    0.65      0.66    31498\n",
      "3        microwave       0.65    0.91      0.76    45078\n",
      "4           kettle       0.78    0.77      0.78    53030\n",
      "5        micro avg       0.72    0.84      0.78   239993\n",
      "6        macro avg       0.72    0.82      0.76   239993\n",
      "7     weighted avg       0.74    0.84      0.78   239993\n",
      "8      samples avg       0.70    0.82      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 11 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.91      0.92    11776\n",
      "1  washing machine       0.92    0.82      0.87     8517\n",
      "2      dish washer       0.86    0.82      0.84     8190\n",
      "3        microwave       0.89    0.87      0.88     9613\n",
      "4           kettle       0.97    0.92      0.95     9969\n",
      "5        micro avg       0.92    0.88      0.90    48065\n",
      "6        macro avg       0.91    0.87      0.89    48065\n",
      "7     weighted avg       0.92    0.88      0.90    48065\n",
      "8      samples avg       0.93    0.89      0.90    48065\n",
      "-------------------------------------------------\n",
      "Fold 11 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.94      0.94    60539\n",
      "1  washing machine       0.57    0.81      0.67    49848\n",
      "2      dish washer       0.62    0.68      0.64    31498\n",
      "3        microwave       0.67    0.90      0.77    45078\n",
      "4           kettle       0.81    0.70      0.75    53030\n",
      "5        micro avg       0.72    0.82      0.76   239993\n",
      "6        macro avg       0.72    0.80      0.75   239993\n",
      "7     weighted avg       0.74    0.82      0.77   239993\n",
      "8      samples avg       0.68    0.79      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 12 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.93      0.93    11825\n",
      "1  washing machine       0.92    0.83      0.87     8448\n",
      "2      dish washer       0.89    0.81      0.85     8210\n",
      "3        microwave       0.91    0.88      0.89     9562\n",
      "4           kettle       0.96    0.94      0.95     9927\n",
      "5        micro avg       0.92    0.88      0.90    47972\n",
      "6        macro avg       0.92    0.88      0.90    47972\n",
      "7     weighted avg       0.92    0.88      0.90    47972\n",
      "8      samples avg       0.93    0.90      0.91    47972\n",
      "-------------------------------------------------\n",
      "Fold 12 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.98      0.96    60539\n",
      "1  washing machine       0.58    0.82      0.68    49848\n",
      "2      dish washer       0.75    0.60      0.66    31498\n",
      "3        microwave       0.64    0.91      0.75    45078\n",
      "4           kettle       0.79    0.75      0.77    53030\n",
      "5        micro avg       0.73    0.83      0.78   239993\n",
      "6        macro avg       0.74    0.81      0.76   239993\n",
      "7     weighted avg       0.75    0.83      0.78   239993\n",
      "8      samples avg       0.71    0.82      0.74   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 13 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.94      0.92    11762\n",
      "1  washing machine       0.89    0.85      0.87     8396\n",
      "2      dish washer       0.83    0.86      0.84     8248\n",
      "3        microwave       0.91    0.86      0.88     9477\n",
      "4           kettle       0.94    0.94      0.94    10024\n",
      "5        micro avg       0.90    0.89      0.89    47907\n",
      "6        macro avg       0.89    0.89      0.89    47907\n",
      "7     weighted avg       0.90    0.89      0.89    47907\n",
      "8      samples avg       0.91    0.91      0.90    47907\n",
      "-------------------------------------------------\n",
      "Fold 13 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.88    0.96      0.92    60539\n",
      "1  washing machine       0.57    0.85      0.68    49848\n",
      "2      dish washer       0.61    0.70      0.65    31498\n",
      "3        microwave       0.65    0.88      0.74    45078\n",
      "4           kettle       0.66    0.83      0.74    53030\n",
      "5        micro avg       0.68    0.86      0.76   239993\n",
      "6        macro avg       0.67    0.84      0.75   239993\n",
      "7     weighted avg       0.69    0.86      0.76   239993\n",
      "8      samples avg       0.65    0.84      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 14 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.93      0.93    11786\n",
      "1  washing machine       0.93    0.82      0.87     8379\n",
      "2      dish washer       0.86    0.85      0.86     8269\n",
      "3        microwave       0.91    0.86      0.89     9574\n",
      "4           kettle       0.98    0.92      0.95     9978\n",
      "5        micro avg       0.92    0.88      0.90    47986\n",
      "6        macro avg       0.92    0.87      0.90    47986\n",
      "7     weighted avg       0.92    0.88      0.90    47986\n",
      "8      samples avg       0.93    0.90      0.90    47986\n",
      "-------------------------------------------------\n",
      "Fold 14 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.99      0.96    60539\n",
      "1  washing machine       0.57    0.78      0.66    49848\n",
      "2      dish washer       0.59    0.70      0.64    31498\n",
      "3        microwave       0.66    0.90      0.76    45078\n",
      "4           kettle       0.85    0.67      0.75    53030\n",
      "5        micro avg       0.72    0.82      0.77   239993\n",
      "6        macro avg       0.72    0.81      0.75   239993\n",
      "7     weighted avg       0.74    0.82      0.77   239993\n",
      "8      samples avg       0.69    0.80      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 15 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.92      0.93    11893\n",
      "1  washing machine       0.91    0.84      0.88     8424\n",
      "2      dish washer       0.86    0.86      0.86     8205\n",
      "3        microwave       0.90    0.88      0.89     9590\n",
      "4           kettle       0.97    0.93      0.95     9958\n",
      "5        micro avg       0.92    0.89      0.90    48070\n",
      "6        macro avg       0.91    0.89      0.90    48070\n",
      "7     weighted avg       0.92    0.89      0.90    48070\n",
      "8      samples avg       0.93    0.91      0.91    48070\n",
      "-------------------------------------------------\n",
      "Fold 15 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.99      0.96    60539\n",
      "1  washing machine       0.59    0.80      0.68    49848\n",
      "2      dish washer       0.60    0.71      0.65    31498\n",
      "3        microwave       0.63    0.93      0.75    45078\n",
      "4           kettle       0.85    0.69      0.76    53030\n",
      "5        micro avg       0.72    0.84      0.77   239993\n",
      "6        macro avg       0.72    0.82      0.76   239993\n",
      "7     weighted avg       0.74    0.84      0.78   239993\n",
      "8      samples avg       0.69    0.82      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 16 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.92      0.92    11865\n",
      "1  washing machine       0.92    0.84      0.88     8506\n",
      "2      dish washer       0.90    0.80      0.85     8222\n",
      "3        microwave       0.91    0.87      0.89     9541\n",
      "4           kettle       0.96    0.94      0.95     9954\n",
      "5        micro avg       0.93    0.88      0.90    48088\n",
      "6        macro avg       0.92    0.88      0.90    48088\n",
      "7     weighted avg       0.92    0.88      0.90    48088\n",
      "8      samples avg       0.93    0.90      0.91    48088\n",
      "-------------------------------------------------\n",
      "Fold 16 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.96      0.94    60539\n",
      "1  washing machine       0.57    0.81      0.67    49848\n",
      "2      dish washer       0.67    0.67      0.67    31498\n",
      "3        microwave       0.66    0.90      0.76    45078\n",
      "4           kettle       0.86    0.71      0.78    53030\n",
      "5        micro avg       0.73    0.82      0.77   239993\n",
      "6        macro avg       0.74    0.81      0.76   239993\n",
      "7     weighted avg       0.75    0.82      0.78   239993\n",
      "8      samples avg       0.70    0.80      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 17 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.76      0.84    11794\n",
      "1  washing machine       0.54    0.89      0.67     8394\n",
      "2      dish washer       0.85    0.57      0.68     8120\n",
      "3        microwave       0.86    0.60      0.71     9589\n",
      "4           kettle       0.95    0.82      0.88     9895\n",
      "5        micro avg       0.79    0.73      0.76    47792\n",
      "6        macro avg       0.83    0.73      0.76    47792\n",
      "7     weighted avg       0.84    0.73      0.77    47792\n",
      "8      samples avg       0.77    0.73      0.72    47792\n",
      "-------------------------------------------------\n",
      "Fold 17 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.96    0.96      0.96    60539\n",
      "1  washing machine       0.61    0.76      0.68    49848\n",
      "2      dish washer       0.62    0.65      0.63    31498\n",
      "3        microwave       0.56    0.95      0.70    45078\n",
      "4           kettle       0.88    0.70      0.78    53030\n",
      "5        micro avg       0.72    0.82      0.76   239993\n",
      "6        macro avg       0.73    0.80      0.75   239993\n",
      "7     weighted avg       0.75    0.82      0.77   239993\n",
      "8      samples avg       0.72    0.82      0.74   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 18 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.84      0.87    11818\n",
      "1  washing machine       0.52    0.92      0.67     8432\n",
      "2      dish washer       0.86    0.58      0.69     8328\n",
      "3        microwave       0.91    0.54      0.68     9480\n",
      "4           kettle       0.96    0.84      0.90     9933\n",
      "5        micro avg       0.79    0.75      0.77    47991\n",
      "6        macro avg       0.83    0.74      0.76    47991\n",
      "7     weighted avg       0.84    0.75      0.77    47991\n",
      "8      samples avg       0.77    0.75      0.73    47991\n",
      "-------------------------------------------------\n",
      "Fold 18 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.99      0.95    60539\n",
      "1  washing machine       0.64    0.79      0.71    49848\n",
      "2      dish washer       0.60    0.68      0.64    31498\n",
      "3        microwave       0.69    0.83      0.75    45078\n",
      "4           kettle       0.84    0.71      0.77    53030\n",
      "5        micro avg       0.75    0.82      0.78   239993\n",
      "6        macro avg       0.74    0.80      0.76   239993\n",
      "7     weighted avg       0.76    0.82      0.78   239993\n",
      "8      samples avg       0.75    0.82      0.76   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 19 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.92      0.93    11787\n",
      "1  washing machine       0.90    0.86      0.88     8464\n",
      "2      dish washer       0.88    0.82      0.85     8235\n",
      "3        microwave       0.92    0.86      0.89     9610\n",
      "4           kettle       0.97    0.93      0.95     9992\n",
      "5        micro avg       0.92    0.88      0.90    48088\n",
      "6        macro avg       0.92    0.88      0.90    48088\n",
      "7     weighted avg       0.92    0.88      0.90    48088\n",
      "8      samples avg       0.93    0.90      0.91    48088\n",
      "-------------------------------------------------\n",
      "Fold 19 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.96      0.95    60539\n",
      "1  washing machine       0.57    0.84      0.68    49848\n",
      "2      dish washer       0.53    0.73      0.61    31498\n",
      "3        microwave       0.68    0.83      0.75    45078\n",
      "4           kettle       0.73    0.76      0.74    53030\n",
      "5        micro avg       0.69    0.84      0.76   239993\n",
      "6        macro avg       0.69    0.82      0.75   239993\n",
      "7     weighted avg       0.71    0.84      0.77   239993\n",
      "8      samples avg       0.67    0.82      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 20 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.92      0.93    11778\n",
      "1  washing machine       0.91    0.84      0.87     8368\n",
      "2      dish washer       0.85    0.84      0.85     8217\n",
      "3        microwave       0.91    0.87      0.89     9596\n",
      "4           kettle       0.95    0.93      0.94    10082\n",
      "5        micro avg       0.91    0.89      0.90    48041\n",
      "6        macro avg       0.91    0.88      0.90    48041\n",
      "7     weighted avg       0.91    0.89      0.90    48041\n",
      "8      samples avg       0.93    0.90      0.90    48041\n",
      "-------------------------------------------------\n",
      "Fold 20 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.97      0.95    60539\n",
      "1  washing machine       0.57    0.82      0.67    49848\n",
      "2      dish washer       0.55    0.72      0.62    31498\n",
      "3        microwave       0.65    0.86      0.74    45078\n",
      "4           kettle       0.76    0.77      0.77    53030\n",
      "5        micro avg       0.70    0.84      0.76   239993\n",
      "6        macro avg       0.69    0.83      0.75   239993\n",
      "7     weighted avg       0.71    0.84      0.77   239993\n",
      "8      samples avg       0.67    0.82      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 21 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.86    0.90      0.88    11890\n",
      "1  washing machine       0.90    0.72      0.80     8479\n",
      "2      dish washer       0.88    0.58      0.70     8116\n",
      "3        microwave       0.55    0.93      0.69     9604\n",
      "4           kettle       0.96    0.77      0.85    10055\n",
      "5        micro avg       0.78    0.79      0.79    48144\n",
      "6        macro avg       0.83    0.78      0.78    48144\n",
      "7     weighted avg       0.83    0.79      0.79    48144\n",
      "8      samples avg       0.77    0.80      0.76    48144\n",
      "-------------------------------------------------\n",
      "Fold 21 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.99      0.95    60539\n",
      "1  washing machine       0.71    0.61      0.66    49848\n",
      "2      dish washer       0.57    0.70      0.63    31498\n",
      "3        microwave       0.58    0.91      0.71    45078\n",
      "4           kettle       0.94    0.53      0.68    53030\n",
      "5        micro avg       0.73    0.76      0.75   239993\n",
      "6        macro avg       0.74    0.75      0.72   239993\n",
      "7     weighted avg       0.77    0.76      0.74   239993\n",
      "8      samples avg       0.73    0.75      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 22 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.92      0.93    11862\n",
      "1  washing machine       0.88    0.89      0.89     8406\n",
      "2      dish washer       0.89    0.83      0.86     8269\n",
      "3        microwave       0.93    0.86      0.89     9586\n",
      "4           kettle       0.96    0.94      0.95     9876\n",
      "5        micro avg       0.92    0.89      0.91    47999\n",
      "6        macro avg       0.92    0.89      0.90    47999\n",
      "7     weighted avg       0.92    0.89      0.91    47999\n",
      "8      samples avg       0.93    0.91      0.91    47999\n",
      "-------------------------------------------------\n",
      "Fold 22 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.98      0.95    60539\n",
      "1  washing machine       0.57    0.87      0.68    49848\n",
      "2      dish washer       0.63    0.67      0.65    31498\n",
      "3        microwave       0.67    0.85      0.75    45078\n",
      "4           kettle       0.80    0.72      0.76    53030\n",
      "5        micro avg       0.72    0.84      0.77   239993\n",
      "6        macro avg       0.72    0.82      0.76   239993\n",
      "7     weighted avg       0.73    0.84      0.78   239993\n",
      "8      samples avg       0.69    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 23 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.91      0.93    11732\n",
      "1  washing machine       0.91    0.85      0.88     8519\n",
      "2      dish washer       0.90    0.84      0.87     8304\n",
      "3        microwave       0.91    0.87      0.89     9582\n",
      "4           kettle       0.95    0.94      0.95     9995\n",
      "5        micro avg       0.92    0.89      0.91    48132\n",
      "6        macro avg       0.92    0.88      0.90    48132\n",
      "7     weighted avg       0.92    0.89      0.91    48132\n",
      "8      samples avg       0.94    0.90      0.91    48132\n",
      "-------------------------------------------------\n",
      "Fold 23 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.98      0.96    60539\n",
      "1  washing machine       0.57    0.83      0.67    49848\n",
      "2      dish washer       0.76    0.62      0.68    31498\n",
      "3        microwave       0.64    0.92      0.75    45078\n",
      "4           kettle       0.75    0.78      0.76    53030\n",
      "5        micro avg       0.72    0.85      0.78   239993\n",
      "6        macro avg       0.73    0.82      0.77   239993\n",
      "7     weighted avg       0.74    0.85      0.78   239993\n",
      "8      samples avg       0.69    0.83      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 24 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.86      0.89    11836\n",
      "1  washing machine       0.78    0.85      0.81     8450\n",
      "2      dish washer       0.88    0.62      0.73     8204\n",
      "3        microwave       0.92    0.72      0.80     9561\n",
      "4           kettle       0.97    0.87      0.92     9908\n",
      "5        micro avg       0.90    0.79      0.84    47959\n",
      "6        macro avg       0.89    0.78      0.83    47959\n",
      "7     weighted avg       0.90    0.79      0.84    47959\n",
      "8      samples avg       0.89    0.80      0.83    47959\n",
      "-------------------------------------------------\n",
      "Fold 24 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.99      0.96    60539\n",
      "1  washing machine       0.60    0.82      0.69    49848\n",
      "2      dish washer       0.67    0.65      0.66    31498\n",
      "3        microwave       0.59    0.95      0.73    45078\n",
      "4           kettle       0.95    0.65      0.77    53030\n",
      "5        micro avg       0.73    0.83      0.77   239993\n",
      "6        macro avg       0.75    0.81      0.76   239993\n",
      "7     weighted avg       0.77    0.83      0.78   239993\n",
      "8      samples avg       0.72    0.82      0.74   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 25 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.93      0.92    11722\n",
      "1  washing machine       0.90    0.85      0.88     8310\n",
      "2      dish washer       0.86    0.87      0.86     8229\n",
      "3        microwave       0.92    0.86      0.89     9483\n",
      "4           kettle       0.97    0.93      0.95    10022\n",
      "5        micro avg       0.92    0.89      0.90    47766\n",
      "6        macro avg       0.91    0.89      0.90    47766\n",
      "7     weighted avg       0.92    0.89      0.90    47766\n",
      "8      samples avg       0.93    0.91      0.91    47766\n",
      "-------------------------------------------------\n",
      "Fold 25 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.98      0.94    60539\n",
      "1  washing machine       0.57    0.83      0.68    49848\n",
      "2      dish washer       0.60    0.70      0.64    31498\n",
      "3        microwave       0.64    0.91      0.75    45078\n",
      "4           kettle       0.85    0.70      0.77    53030\n",
      "5        micro avg       0.71    0.84      0.77   239993\n",
      "6        macro avg       0.71    0.82      0.76   239993\n",
      "7     weighted avg       0.73    0.84      0.77   239993\n",
      "8      samples avg       0.68    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 26 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.92      0.93    11834\n",
      "1  washing machine       0.89    0.88      0.89     8486\n",
      "2      dish washer       0.86    0.87      0.86     8217\n",
      "3        microwave       0.94    0.86      0.90     9608\n",
      "4           kettle       0.96    0.94      0.95     9991\n",
      "5        micro avg       0.92    0.90      0.91    48136\n",
      "6        macro avg       0.92    0.89      0.90    48136\n",
      "7     weighted avg       0.92    0.90      0.91    48136\n",
      "8      samples avg       0.93    0.91      0.91    48136\n",
      "-------------------------------------------------\n",
      "Fold 26 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.97      0.94    60539\n",
      "1  washing machine       0.57    0.82      0.67    49848\n",
      "2      dish washer       0.54    0.74      0.62    31498\n",
      "3        microwave       0.67    0.89      0.77    45078\n",
      "4           kettle       0.78    0.74      0.76    53030\n",
      "5        micro avg       0.70    0.84      0.76   239993\n",
      "6        macro avg       0.70    0.83      0.75   239993\n",
      "7     weighted avg       0.72    0.84      0.77   239993\n",
      "8      samples avg       0.67    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 27 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.92      0.93    11760\n",
      "1  washing machine       0.88    0.88      0.88     8511\n",
      "2      dish washer       0.88    0.85      0.86     8235\n",
      "3        microwave       0.90    0.87      0.89     9475\n",
      "4           kettle       0.98    0.92      0.95     9937\n",
      "5        micro avg       0.92    0.89      0.91    47918\n",
      "6        macro avg       0.92    0.89      0.90    47918\n",
      "7     weighted avg       0.92    0.89      0.91    47918\n",
      "8      samples avg       0.93    0.91      0.91    47918\n",
      "-------------------------------------------------\n",
      "Fold 27 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.98      0.94    60539\n",
      "1  washing machine       0.57    0.86      0.69    49848\n",
      "2      dish washer       0.57    0.69      0.63    31498\n",
      "3        microwave       0.66    0.90      0.76    45078\n",
      "4           kettle       0.83    0.65      0.73    53030\n",
      "5        micro avg       0.71    0.83      0.76   239993\n",
      "6        macro avg       0.71    0.82      0.75   239993\n",
      "7     weighted avg       0.73    0.83      0.77   239993\n",
      "8      samples avg       0.68    0.81      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 28 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.93      0.92    11821\n",
      "1  washing machine       0.91    0.85      0.88     8312\n",
      "2      dish washer       0.88    0.83      0.85     8213\n",
      "3        microwave       0.91    0.87      0.89     9643\n",
      "4           kettle       0.97    0.93      0.95     9999\n",
      "5        micro avg       0.92    0.89      0.90    47988\n",
      "6        macro avg       0.92    0.88      0.90    47988\n",
      "7     weighted avg       0.92    0.89      0.90    47988\n",
      "8      samples avg       0.93    0.90      0.91    47988\n",
      "-------------------------------------------------\n",
      "Fold 28 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.99      0.95    60539\n",
      "1  washing machine       0.57    0.80      0.67    49848\n",
      "2      dish washer       0.61    0.68      0.64    31498\n",
      "3        microwave       0.64    0.92      0.76    45078\n",
      "4           kettle       0.81    0.64      0.71    53030\n",
      "5        micro avg       0.71    0.82      0.76   239993\n",
      "6        macro avg       0.71    0.80      0.74   239993\n",
      "7     weighted avg       0.73    0.82      0.76   239993\n",
      "8      samples avg       0.67    0.79      0.70   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 29 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.92      0.93    11744\n",
      "1  washing machine       0.89    0.87      0.88     8430\n",
      "2      dish washer       0.89    0.83      0.86     8249\n",
      "3        microwave       0.90    0.88      0.89     9546\n",
      "4           kettle       0.96    0.94      0.95     9980\n",
      "5        micro avg       0.92    0.89      0.90    47949\n",
      "6        macro avg       0.91    0.89      0.90    47949\n",
      "7     weighted avg       0.92    0.89      0.90    47949\n",
      "8      samples avg       0.93    0.91      0.91    47949\n",
      "-------------------------------------------------\n",
      "Fold 29 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.98      0.95    60539\n",
      "1  washing machine       0.57    0.84      0.68    49848\n",
      "2      dish washer       0.68    0.64      0.66    31498\n",
      "3        microwave       0.63    0.90      0.74    45078\n",
      "4           kettle       0.79    0.73      0.76    53030\n",
      "5        micro avg       0.71    0.84      0.77   239993\n",
      "6        macro avg       0.72    0.82      0.76   239993\n",
      "7     weighted avg       0.73    0.84      0.77   239993\n",
      "8      samples avg       0.69    0.82      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 30 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.91      0.93    11883\n",
      "1  washing machine       0.90    0.86      0.88     8425\n",
      "2      dish washer       0.88    0.82      0.85     8208\n",
      "3        microwave       0.92    0.85      0.89     9544\n",
      "4           kettle       0.96    0.93      0.95     9949\n",
      "5        micro avg       0.92    0.88      0.90    48009\n",
      "6        macro avg       0.92    0.88      0.90    48009\n",
      "7     weighted avg       0.92    0.88      0.90    48009\n",
      "8      samples avg       0.94    0.90      0.91    48009\n",
      "-------------------------------------------------\n",
      "Fold 30 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.98      0.96    60539\n",
      "1  washing machine       0.57    0.85      0.68    49848\n",
      "2      dish washer       0.70    0.64      0.67    31498\n",
      "3        microwave       0.70    0.89      0.78    45078\n",
      "4           kettle       0.89    0.68      0.77    53030\n",
      "5        micro avg       0.75    0.83      0.78   239993\n",
      "6        macro avg       0.76    0.81      0.77   239993\n",
      "7     weighted avg       0.77    0.83      0.79   239993\n",
      "8      samples avg       0.72    0.81      0.74   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 31 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.92      0.93    11875\n",
      "1  washing machine       0.92    0.85      0.89     8512\n",
      "2      dish washer       0.86    0.86      0.86     8137\n",
      "3        microwave       0.89    0.88      0.89     9475\n",
      "4           kettle       0.97    0.92      0.95     9969\n",
      "5        micro avg       0.92    0.89      0.90    47968\n",
      "6        macro avg       0.92    0.89      0.90    47968\n",
      "7     weighted avg       0.92    0.89      0.90    47968\n",
      "8      samples avg       0.93    0.91      0.91    47968\n",
      "-------------------------------------------------\n",
      "Fold 31 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.96      0.94    60539\n",
      "1  washing machine       0.58    0.81      0.67    49848\n",
      "2      dish washer       0.52    0.75      0.61    31498\n",
      "3        microwave       0.64    0.92      0.76    45078\n",
      "4           kettle       0.78    0.66      0.71    53030\n",
      "5        micro avg       0.69    0.83      0.75   239993\n",
      "6        macro avg       0.69    0.82      0.74   239993\n",
      "7     weighted avg       0.71    0.83      0.76   239993\n",
      "8      samples avg       0.66    0.80      0.70   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 32 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.92      0.93    11766\n",
      "1  washing machine       0.90    0.88      0.89     8431\n",
      "2      dish washer       0.89    0.84      0.86     8239\n",
      "3        microwave       0.92    0.88      0.89     9563\n",
      "4           kettle       0.97    0.94      0.95     9968\n",
      "5        micro avg       0.92    0.89      0.91    47967\n",
      "6        macro avg       0.92    0.89      0.91    47967\n",
      "7     weighted avg       0.92    0.89      0.91    47967\n",
      "8      samples avg       0.94    0.91      0.92    47967\n",
      "-------------------------------------------------\n",
      "Fold 32 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.97      0.95    60539\n",
      "1  washing machine       0.57    0.85      0.68    49848\n",
      "2      dish washer       0.59    0.67      0.63    31498\n",
      "3        microwave       0.65    0.90      0.75    45078\n",
      "4           kettle       0.83    0.70      0.76    53030\n",
      "5        micro avg       0.71    0.83      0.77   239993\n",
      "6        macro avg       0.71    0.82      0.75   239993\n",
      "7     weighted avg       0.73    0.83      0.77   239993\n",
      "8      samples avg       0.69    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 33 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.95    0.91      0.93    11780\n",
      "1  washing machine       0.90    0.87      0.88     8358\n",
      "2      dish washer       0.89    0.85      0.87     8275\n",
      "3        microwave       0.90    0.89      0.89     9670\n",
      "4           kettle       0.96    0.94      0.95     9962\n",
      "5        micro avg       0.92    0.89      0.91    48045\n",
      "6        macro avg       0.92    0.89      0.90    48045\n",
      "7     weighted avg       0.92    0.89      0.91    48045\n",
      "8      samples avg       0.93    0.91      0.91    48045\n",
      "-------------------------------------------------\n",
      "Fold 33 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.97      0.94    60539\n",
      "1  washing machine       0.57    0.83      0.68    49848\n",
      "2      dish washer       0.66    0.64      0.65    31498\n",
      "3        microwave       0.60    0.91      0.72    45078\n",
      "4           kettle       0.79    0.75      0.77    53030\n",
      "5        micro avg       0.70    0.84      0.76   239993\n",
      "6        macro avg       0.71    0.82      0.75   239993\n",
      "7     weighted avg       0.72    0.84      0.77   239993\n",
      "8      samples avg       0.67    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 34 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.93      0.92    11846\n",
      "1  washing machine       0.89    0.85      0.87     8455\n",
      "2      dish washer       0.87    0.81      0.84     8185\n",
      "3        microwave       0.91    0.85      0.87     9533\n",
      "4           kettle       0.95    0.94      0.95     9982\n",
      "5        micro avg       0.91    0.88      0.89    48001\n",
      "6        macro avg       0.91    0.87      0.89    48001\n",
      "7     weighted avg       0.91    0.88      0.89    48001\n",
      "8      samples avg       0.92    0.90      0.90    48001\n",
      "-------------------------------------------------\n",
      "Fold 34 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.99      0.95    60539\n",
      "1  washing machine       0.57    0.85      0.68    49848\n",
      "2      dish washer       0.71    0.63      0.67    31498\n",
      "3        microwave       0.62    0.93      0.74    45078\n",
      "4           kettle       0.78    0.75      0.77    53030\n",
      "5        micro avg       0.71    0.85      0.77   239993\n",
      "6        macro avg       0.72    0.83      0.76   239993\n",
      "7     weighted avg       0.73    0.85      0.78   239993\n",
      "8      samples avg       0.68    0.83      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 35 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.93      0.93    11775\n",
      "1  washing machine       0.89    0.87      0.88     8408\n",
      "2      dish washer       0.90    0.81      0.86     8286\n",
      "3        microwave       0.92    0.86      0.89     9575\n",
      "4           kettle       0.97    0.92      0.94     9975\n",
      "5        micro avg       0.92    0.88      0.90    48019\n",
      "6        macro avg       0.92    0.88      0.90    48019\n",
      "7     weighted avg       0.92    0.88      0.90    48019\n",
      "8      samples avg       0.93    0.90      0.91    48019\n",
      "-------------------------------------------------\n",
      "Fold 35 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.99      0.94    60539\n",
      "1  washing machine       0.57    0.84      0.68    49848\n",
      "2      dish washer       0.63    0.66      0.64    31498\n",
      "3        microwave       0.68    0.88      0.77    45078\n",
      "4           kettle       0.89    0.61      0.73    53030\n",
      "5        micro avg       0.73    0.81      0.77   239993\n",
      "6        macro avg       0.73    0.80      0.75   239993\n",
      "7     weighted avg       0.75    0.81      0.77   239993\n",
      "8      samples avg       0.69    0.79      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 36 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.73    0.70      0.71    11874\n",
      "1  washing machine       0.58    0.12      0.19     8429\n",
      "2      dish washer       0.59    0.12      0.19     8174\n",
      "3        microwave       0.71    0.30      0.42     9533\n",
      "4           kettle       0.59    0.29      0.39     9925\n",
      "5        micro avg       0.67    0.34      0.45    47935\n",
      "6        macro avg       0.64    0.31      0.38    47935\n",
      "7     weighted avg       0.64    0.34      0.41    47935\n",
      "8      samples avg       0.49    0.35      0.38    47935\n",
      "-------------------------------------------------\n",
      "Fold 36 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.79    0.75      0.77    60539\n",
      "1  washing machine       0.52    0.38      0.44    49848\n",
      "2      dish washer       0.35    0.29      0.32    31498\n",
      "3        microwave       0.52    0.63      0.57    45078\n",
      "4           kettle       0.63    0.41      0.50    53030\n",
      "5        micro avg       0.59    0.51      0.55   239993\n",
      "6        macro avg       0.56    0.49      0.52   239993\n",
      "7     weighted avg       0.59    0.51      0.54   239993\n",
      "8      samples avg       0.47    0.48      0.43   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 37 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.92      0.93    11808\n",
      "1  washing machine       0.89    0.88      0.88     8450\n",
      "2      dish washer       0.90    0.83      0.86     8240\n",
      "3        microwave       0.93    0.85      0.89     9680\n",
      "4           kettle       0.96    0.94      0.95     9961\n",
      "5        micro avg       0.92    0.89      0.90    48139\n",
      "6        macro avg       0.92    0.88      0.90    48139\n",
      "7     weighted avg       0.92    0.89      0.90    48139\n",
      "8      samples avg       0.93    0.90      0.91    48139\n",
      "-------------------------------------------------\n",
      "Fold 37 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.99      0.95    60539\n",
      "1  washing machine       0.57    0.84      0.68    49848\n",
      "2      dish washer       0.58    0.70      0.63    31498\n",
      "3        microwave       0.66    0.85      0.75    45078\n",
      "4           kettle       0.89    0.68      0.77    53030\n",
      "5        micro avg       0.72    0.83      0.77   239993\n",
      "6        macro avg       0.72    0.81      0.76   239993\n",
      "7     weighted avg       0.75    0.83      0.78   239993\n",
      "8      samples avg       0.69    0.81      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 38 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.86    0.85      0.86    11775\n",
      "1  washing machine       0.81    0.74      0.77     8381\n",
      "2      dish washer       0.90    0.49      0.63     8220\n",
      "3        microwave       0.51    0.97      0.67     9499\n",
      "4           kettle       0.97    0.78      0.87     9992\n",
      "5        micro avg       0.75    0.78      0.76    47867\n",
      "6        macro avg       0.81    0.77      0.76    47867\n",
      "7     weighted avg       0.81    0.78      0.77    47867\n",
      "8      samples avg       0.72    0.78      0.72    47867\n",
      "-------------------------------------------------\n",
      "Fold 38 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.99      0.95    60539\n",
      "1  washing machine       0.63    0.71      0.67    49848\n",
      "2      dish washer       0.74    0.59      0.65    31498\n",
      "3        microwave       0.47    1.00      0.64    45078\n",
      "4           kettle       0.96    0.61      0.75    53030\n",
      "5        micro avg       0.69    0.79      0.74   239993\n",
      "6        macro avg       0.74    0.78      0.73   239993\n",
      "7     weighted avg       0.76    0.79      0.75   239993\n",
      "8      samples avg       0.66    0.78      0.69   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 39 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.92      0.92    11747\n",
      "1  washing machine       0.91    0.87      0.89     8522\n",
      "2      dish washer       0.89    0.81      0.85     8233\n",
      "3        microwave       0.92    0.85      0.89     9541\n",
      "4           kettle       0.96    0.93      0.95    10000\n",
      "5        micro avg       0.92    0.88      0.90    48043\n",
      "6        macro avg       0.92    0.88      0.90    48043\n",
      "7     weighted avg       0.92    0.88      0.90    48043\n",
      "8      samples avg       0.94    0.90      0.91    48043\n",
      "-------------------------------------------------\n",
      "Fold 39 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.99      0.95    60539\n",
      "1  washing machine       0.57    0.82      0.67    49848\n",
      "2      dish washer       0.68    0.63      0.66    31498\n",
      "3        microwave       0.63    0.91      0.74    45078\n",
      "4           kettle       0.82    0.71      0.76    53030\n",
      "5        micro avg       0.72    0.83      0.77   239993\n",
      "6        macro avg       0.72    0.81      0.76   239993\n",
      "7     weighted avg       0.74    0.83      0.77   239993\n",
      "8      samples avg       0.69    0.81      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 40 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.85      0.88    11838\n",
      "1  washing machine       0.90    0.67      0.77     8382\n",
      "2      dish washer       0.88    0.58      0.70     8255\n",
      "3        microwave       0.59    0.94      0.72     9563\n",
      "4           kettle       0.94    0.85      0.90     9978\n",
      "5        micro avg       0.81    0.79      0.80    48016\n",
      "6        macro avg       0.84    0.78      0.79    48016\n",
      "7     weighted avg       0.84    0.79      0.80    48016\n",
      "8      samples avg       0.79    0.79      0.77    48016\n",
      "-------------------------------------------------\n",
      "Fold 40 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.96    0.97      0.96    60539\n",
      "1  washing machine       0.75    0.45      0.56    49848\n",
      "2      dish washer       0.72    0.63      0.67    31498\n",
      "3        microwave       0.51    0.98      0.67    45078\n",
      "4           kettle       0.83    0.71      0.77    53030\n",
      "5        micro avg       0.73    0.76      0.75   239993\n",
      "6        macro avg       0.75    0.75      0.73   239993\n",
      "7     weighted avg       0.77    0.76      0.74   239993\n",
      "8      samples avg       0.69    0.75      0.70   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 41 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.71    0.77      0.74    11773\n",
      "1  washing machine       0.52    0.33      0.40     8500\n",
      "2      dish washer       0.61    0.16      0.25     8251\n",
      "3        microwave       0.75    0.40      0.52     9529\n",
      "4           kettle       0.70    0.36      0.48     9958\n",
      "5        micro avg       0.67    0.43      0.52    48011\n",
      "6        macro avg       0.66    0.40      0.48    48011\n",
      "7     weighted avg       0.66    0.43      0.50    48011\n",
      "8      samples avg       0.48    0.41      0.41    48011\n",
      "-------------------------------------------------\n",
      "Fold 41 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.69    0.94      0.80    60539\n",
      "1  washing machine       0.51    0.58      0.55    49848\n",
      "2      dish washer       0.36    0.54      0.43    31498\n",
      "3        microwave       0.56    0.93      0.70    45078\n",
      "4           kettle       0.63    0.50      0.56    53030\n",
      "5        micro avg       0.57    0.71      0.63   239993\n",
      "6        macro avg       0.55    0.70      0.61   239993\n",
      "7     weighted avg       0.57    0.71      0.63   239993\n",
      "8      samples avg       0.48    0.66      0.53   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 42 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.89    0.88      0.88    11841\n",
      "1  washing machine       0.51    0.91      0.66     8504\n",
      "2      dish washer       0.85    0.60      0.70     8182\n",
      "3        microwave       0.68    0.85      0.75     9501\n",
      "4           kettle       0.98    0.72      0.83     9986\n",
      "5        micro avg       0.74    0.80      0.77    48014\n",
      "6        macro avg       0.78    0.79      0.77    48014\n",
      "7     weighted avg       0.79    0.80      0.78    48014\n",
      "8      samples avg       0.73    0.79      0.73    48014\n",
      "-------------------------------------------------\n",
      "Fold 42 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.98      0.95    60539\n",
      "1  washing machine       0.67    0.62      0.64    49848\n",
      "2      dish washer       0.68    0.64      0.66    31498\n",
      "3        microwave       0.52    0.98      0.68    45078\n",
      "4           kettle       0.91    0.54      0.68    53030\n",
      "5        micro avg       0.71    0.77      0.74   239993\n",
      "6        macro avg       0.74    0.75      0.72   239993\n",
      "7     weighted avg       0.76    0.77      0.74   239993\n",
      "8      samples avg       0.70    0.77      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 43 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.91      0.92    11789\n",
      "1  washing machine       0.92    0.84      0.88     8414\n",
      "2      dish washer       0.92    0.76      0.83     8194\n",
      "3        microwave       0.93    0.85      0.88     9689\n",
      "4           kettle       0.96    0.93      0.95     9896\n",
      "5        micro avg       0.93    0.86      0.90    47982\n",
      "6        macro avg       0.93    0.86      0.89    47982\n",
      "7     weighted avg       0.93    0.86      0.90    47982\n",
      "8      samples avg       0.94    0.88      0.90    47982\n",
      "-------------------------------------------------\n",
      "Fold 43 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.99      0.96    60539\n",
      "1  washing machine       0.58    0.78      0.66    49848\n",
      "2      dish washer       0.76    0.61      0.68    31498\n",
      "3        microwave       0.69    0.88      0.77    45078\n",
      "4           kettle       0.78    0.74      0.76    53030\n",
      "5        micro avg       0.74    0.82      0.78   239993\n",
      "6        macro avg       0.75    0.80      0.77   239993\n",
      "7     weighted avg       0.76    0.82      0.78   239993\n",
      "8      samples avg       0.71    0.80      0.73   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 44 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.73    0.84      0.78    11844\n",
      "1  washing machine       0.50    0.59      0.54     8439\n",
      "2      dish washer       0.51    0.47      0.49     8252\n",
      "3        microwave       0.66    0.51      0.58     9532\n",
      "4           kettle       0.65    0.79      0.71     9977\n",
      "5        micro avg       0.62    0.66      0.64    48044\n",
      "6        macro avg       0.61    0.64      0.62    48044\n",
      "7     weighted avg       0.62    0.66      0.63    48044\n",
      "8      samples avg       0.55    0.61      0.53    48044\n",
      "-------------------------------------------------\n",
      "Fold 44 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.70    0.94      0.80    60539\n",
      "1  washing machine       0.52    0.80      0.63    49848\n",
      "2      dish washer       0.33    0.79      0.47    31498\n",
      "3        microwave       0.56    0.93      0.70    45078\n",
      "4           kettle       0.58    0.86      0.69    53030\n",
      "5        micro avg       0.54    0.87      0.67   239993\n",
      "6        macro avg       0.54    0.86      0.66   239993\n",
      "7     weighted avg       0.56    0.87      0.68   239993\n",
      "8      samples avg       0.47    0.82      0.57   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 45 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.62    0.64      0.63    11795\n",
      "1  washing machine       0.83    0.01      0.01     8307\n",
      "2      dish washer       0.53    0.13      0.20     8243\n",
      "3        microwave       0.62    0.36      0.45     9565\n",
      "4           kettle       0.38    0.22      0.28    10039\n",
      "5        micro avg       0.56    0.30      0.39    47949\n",
      "6        macro avg       0.59    0.27      0.32    47949\n",
      "7     weighted avg       0.59    0.30      0.34    47949\n",
      "8      samples avg       0.34    0.32      0.31    47949\n",
      "-------------------------------------------------\n",
      "Fold 45 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.64    0.69      0.66    60539\n",
      "1  washing machine       0.41    0.03      0.06    49848\n",
      "2      dish washer       0.31    0.29      0.30    31498\n",
      "3        microwave       0.57    0.64      0.61    45078\n",
      "4           kettle       0.41    0.31      0.35    53030\n",
      "5        micro avg       0.52    0.41      0.46   239993\n",
      "6        macro avg       0.47    0.39      0.40   239993\n",
      "7     weighted avg       0.49    0.41      0.41   239993\n",
      "8      samples avg       0.34    0.43      0.35   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 46 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.83    0.92      0.87    11715\n",
      "1  washing machine       0.88    0.69      0.78     8418\n",
      "2      dish washer       0.91    0.55      0.68     8208\n",
      "3        microwave       0.51    0.99      0.67     9610\n",
      "4           kettle       0.94    0.84      0.89     9968\n",
      "5        micro avg       0.75    0.81      0.78    47919\n",
      "6        macro avg       0.81    0.80      0.78    47919\n",
      "7     weighted avg       0.81    0.81      0.79    47919\n",
      "8      samples avg       0.73    0.82      0.75    47919\n",
      "-------------------------------------------------\n",
      "Fold 46 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.85    1.00      0.91    60539\n",
      "1  washing machine       0.60    0.68      0.64    49848\n",
      "2      dish washer       0.68    0.61      0.64    31498\n",
      "3        microwave       0.52    0.97      0.68    45078\n",
      "4           kettle       0.79    0.73      0.76    53030\n",
      "5        micro avg       0.68    0.82      0.74   239993\n",
      "6        macro avg       0.69    0.80      0.73   239993\n",
      "7     weighted avg       0.70    0.82      0.74   239993\n",
      "8      samples avg       0.65    0.79      0.69   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 47 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.94      0.92    11872\n",
      "1  washing machine       0.92    0.85      0.88     8496\n",
      "2      dish washer       0.90    0.83      0.86     8167\n",
      "3        microwave       0.91    0.87      0.89     9611\n",
      "4           kettle       0.97    0.93      0.95     9948\n",
      "5        micro avg       0.92    0.89      0.90    48094\n",
      "6        macro avg       0.92    0.88      0.90    48094\n",
      "7     weighted avg       0.92    0.89      0.90    48094\n",
      "8      samples avg       0.93    0.91      0.91    48094\n",
      "-------------------------------------------------\n",
      "Fold 47 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.99      0.94    60539\n",
      "1  washing machine       0.57    0.81      0.67    49848\n",
      "2      dish washer       0.73    0.62      0.67    31498\n",
      "3        microwave       0.62    0.95      0.75    45078\n",
      "4           kettle       0.84    0.67      0.75    53030\n",
      "5        micro avg       0.72    0.83      0.77   239993\n",
      "6        macro avg       0.73    0.81      0.76   239993\n",
      "7     weighted avg       0.75    0.83      0.77   239993\n",
      "8      samples avg       0.69    0.81      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 48 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.93      0.93    11869\n",
      "1  washing machine       0.89    0.88      0.88     8413\n",
      "2      dish washer       0.90    0.80      0.85     8172\n",
      "3        microwave       0.89    0.88      0.88     9614\n",
      "4           kettle       0.97    0.93      0.95     9961\n",
      "5        micro avg       0.91    0.89      0.90    48029\n",
      "6        macro avg       0.91    0.88      0.90    48029\n",
      "7     weighted avg       0.91    0.89      0.90    48029\n",
      "8      samples avg       0.93    0.91      0.91    48029\n",
      "-------------------------------------------------\n",
      "Fold 48 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.99      0.94    60539\n",
      "1  washing machine       0.57    0.84      0.68    49848\n",
      "2      dish washer       0.76    0.61      0.68    31498\n",
      "3        microwave       0.58    0.95      0.72    45078\n",
      "4           kettle       0.82    0.70      0.75    53030\n",
      "5        micro avg       0.71    0.84      0.77   239993\n",
      "6        macro avg       0.73    0.82      0.76   239993\n",
      "7     weighted avg       0.73    0.84      0.77   239993\n",
      "8      samples avg       0.68    0.82      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 49 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.93      0.93    11878\n",
      "1  washing machine       0.89    0.88      0.89     8373\n",
      "2      dish washer       0.90    0.82      0.86     8220\n",
      "3        microwave       0.93    0.85      0.89     9496\n",
      "4           kettle       0.97    0.93      0.95     9963\n",
      "5        micro avg       0.92    0.89      0.91    47930\n",
      "6        macro avg       0.92    0.88      0.90    47930\n",
      "7     weighted avg       0.92    0.89      0.91    47930\n",
      "8      samples avg       0.94    0.90      0.91    47930\n",
      "-------------------------------------------------\n",
      "Fold 49 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.89    0.99      0.94    60539\n",
      "1  washing machine       0.57    0.84      0.67    49848\n",
      "2      dish washer       0.69    0.62      0.65    31498\n",
      "3        microwave       0.67    0.89      0.76    45078\n",
      "4           kettle       0.81    0.68      0.74    53030\n",
      "5        micro avg       0.72    0.82      0.77   239993\n",
      "6        macro avg       0.72    0.80      0.75   239993\n",
      "7     weighted avg       0.74    0.82      0.77   239993\n",
      "8      samples avg       0.69    0.80      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 50 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.61    0.53      0.57    11708\n",
      "1  washing machine       0.40    0.13      0.19     8464\n",
      "2      dish washer       0.36    0.04      0.07     8355\n",
      "3        microwave       0.82    0.19      0.31     9485\n",
      "4           kettle       0.50    0.41      0.45    10016\n",
      "5        micro avg       0.56    0.28      0.37    48028\n",
      "6        macro avg       0.54    0.26      0.32    48028\n",
      "7     weighted avg       0.55    0.28      0.34    48028\n",
      "8      samples avg       0.29    0.33      0.29    48028\n",
      "-------------------------------------------------\n",
      "Fold 50 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.63    0.70      0.66    60539\n",
      "1  washing machine       0.46    0.47      0.46    49848\n",
      "2      dish washer       0.19    0.18      0.18    31498\n",
      "3        microwave       0.57    0.64      0.60    45078\n",
      "4           kettle       0.54    0.61      0.57    53030\n",
      "5        micro avg       0.51    0.55      0.53   239993\n",
      "6        macro avg       0.48    0.52      0.50   239993\n",
      "7     weighted avg       0.50    0.55      0.53   239993\n",
      "8      samples avg       0.34    0.57      0.40   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 51 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.72    0.57      0.63    11778\n",
      "1  washing machine       0.00    0.00      0.00     8407\n",
      "2      dish washer       0.37    0.16      0.22     8234\n",
      "3        microwave       0.62    0.42      0.50     9616\n",
      "4           kettle       0.65    0.13      0.21     9945\n",
      "5        micro avg       0.62    0.28      0.38    47980\n",
      "6        macro avg       0.47    0.25      0.31    47980\n",
      "7     weighted avg       0.50    0.28      0.34    47980\n",
      "8      samples avg       0.30    0.28      0.27    47980\n",
      "-------------------------------------------------\n",
      "Fold 51 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.71    0.68      0.70    60539\n",
      "1  washing machine       0.00    0.00      0.00    49848\n",
      "2      dish washer       0.19    0.23      0.21    31498\n",
      "3        microwave       0.56    0.70      0.62    45078\n",
      "4           kettle       0.51    0.01      0.02    53030\n",
      "5        micro avg       0.53    0.34      0.41   239993\n",
      "6        macro avg       0.40    0.33      0.31   239993\n",
      "7     weighted avg       0.42    0.34      0.33   239993\n",
      "8      samples avg       0.33    0.35      0.32   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 52 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.60    0.57      0.59    11716\n",
      "1  washing machine       0.39    0.11      0.17     8502\n",
      "2      dish washer       0.29    0.04      0.07     8180\n",
      "3        microwave       0.64    0.30      0.41     9593\n",
      "4           kettle       0.50    0.24      0.33    10037\n",
      "5        micro avg       0.55    0.28      0.37    48028\n",
      "6        macro avg       0.48    0.25      0.31    48028\n",
      "7     weighted avg       0.50    0.28      0.33    48028\n",
      "8      samples avg       0.31    0.31      0.28    48028\n",
      "-------------------------------------------------\n",
      "Fold 52 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.63    0.65      0.64    60539\n",
      "1  washing machine       0.46    0.31      0.37    49848\n",
      "2      dish washer       0.20    0.13      0.16    31498\n",
      "3        microwave       0.55    0.59      0.57    45078\n",
      "4           kettle       0.56    0.45      0.50    53030\n",
      "5        micro avg       0.53    0.46      0.49   239993\n",
      "6        macro avg       0.48    0.43      0.45   239993\n",
      "7     weighted avg       0.51    0.46      0.48   239993\n",
      "8      samples avg       0.32    0.49      0.36   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 53 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.62    0.96      0.76    11969\n",
      "1  washing machine       0.53    0.16      0.24     8437\n",
      "2      dish washer       0.56    0.17      0.26     8227\n",
      "3        microwave       0.64    0.51      0.57     9470\n",
      "4           kettle       0.55    0.58      0.56    10024\n",
      "5        micro avg       0.60    0.51      0.55    48127\n",
      "6        macro avg       0.58    0.47      0.48    48127\n",
      "7     weighted avg       0.59    0.51      0.50    48127\n",
      "8      samples avg       0.55    0.50      0.48    48127\n",
      "-------------------------------------------------\n",
      "Fold 53 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.63    1.00      0.77    60539\n",
      "1  washing machine       0.53    0.50      0.52    49848\n",
      "2      dish washer       0.34    0.50      0.40    31498\n",
      "3        microwave       0.56    0.94      0.70    45078\n",
      "4           kettle       0.58    0.85      0.69    53030\n",
      "5        micro avg       0.55    0.79      0.65   239993\n",
      "6        macro avg       0.53    0.76      0.62   239993\n",
      "7     weighted avg       0.55    0.79      0.64   239993\n",
      "8      samples avg       0.51    0.74      0.56   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 54 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.92    0.92      0.92    11810\n",
      "1  washing machine       0.89    0.86      0.88     8419\n",
      "2      dish washer       0.87    0.84      0.85     8330\n",
      "3        microwave       0.89    0.86      0.88     9509\n",
      "4           kettle       0.96    0.93      0.95     9942\n",
      "5        micro avg       0.91    0.89      0.90    48010\n",
      "6        macro avg       0.91    0.88      0.89    48010\n",
      "7     weighted avg       0.91    0.89      0.90    48010\n",
      "8      samples avg       0.92    0.90      0.90    48010\n",
      "-------------------------------------------------\n",
      "Fold 54 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.91    0.99      0.95    60539\n",
      "1  washing machine       0.57    0.78      0.66    49848\n",
      "2      dish washer       0.64    0.67      0.65    31498\n",
      "3        microwave       0.61    0.93      0.74    45078\n",
      "4           kettle       0.86    0.68      0.76    53030\n",
      "5        micro avg       0.71    0.83      0.77   239993\n",
      "6        macro avg       0.72    0.81      0.75   239993\n",
      "7     weighted avg       0.74    0.83      0.77   239993\n",
      "8      samples avg       0.68    0.81      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 55 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.87    0.80      0.83    11769\n",
      "1  washing machine       0.70    0.46      0.55     8399\n",
      "2      dish washer       0.73    0.50      0.59     8151\n",
      "3        microwave       0.51    0.99      0.67     9628\n",
      "4           kettle       0.91    0.83      0.86     9908\n",
      "5        micro avg       0.70    0.73      0.72    47855\n",
      "6        macro avg       0.74    0.71      0.70    47855\n",
      "7     weighted avg       0.75    0.73      0.72    47855\n",
      "8      samples avg       0.68    0.72      0.67    47855\n",
      "-------------------------------------------------\n",
      "Fold 55 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.89    0.97      0.93    60539\n",
      "1  washing machine       0.70    0.41      0.51    49848\n",
      "2      dish washer       0.65    0.53      0.58    31498\n",
      "3        microwave       0.48    1.00      0.65    45078\n",
      "4           kettle       0.85    0.70      0.77    53030\n",
      "5        micro avg       0.69    0.74      0.72   239993\n",
      "6        macro avg       0.72    0.72      0.69   239993\n",
      "7     weighted avg       0.73    0.74      0.71   239993\n",
      "8      samples avg       0.67    0.73      0.67   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 56 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.62    0.87      0.72    11865\n",
      "1  washing machine       0.51    0.26      0.34     8390\n",
      "2      dish washer       0.48    0.38      0.42     8290\n",
      "3        microwave       0.70    0.38      0.49     9568\n",
      "4           kettle       0.55    0.42      0.48    10023\n",
      "5        micro avg       0.58    0.49      0.53    48136\n",
      "6        macro avg       0.57    0.46      0.49    48136\n",
      "7     weighted avg       0.58    0.49      0.51    48136\n",
      "8      samples avg       0.49    0.48      0.43    48136\n",
      "-------------------------------------------------\n",
      "Fold 56 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.63    0.95      0.76    60539\n",
      "1  washing machine       0.54    0.67      0.60    49848\n",
      "2      dish washer       0.33    0.68      0.44    31498\n",
      "3        microwave       0.56    0.89      0.69    45078\n",
      "4           kettle       0.62    0.76      0.68    53030\n",
      "5        micro avg       0.54    0.80      0.65   239993\n",
      "6        macro avg       0.54    0.79      0.63   239993\n",
      "7     weighted avg       0.56    0.80      0.65   239993\n",
      "8      samples avg       0.48    0.76      0.55   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 57 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.62    0.73      0.67    11794\n",
      "1  washing machine       0.50    0.39      0.44     8424\n",
      "2      dish washer       0.54    0.28      0.37     8275\n",
      "3        microwave       0.62    0.39      0.48     9555\n",
      "4           kettle       0.46    0.24      0.31     9992\n",
      "5        micro avg       0.56    0.42      0.48    48040\n",
      "6        macro avg       0.55    0.41      0.45    48040\n",
      "7     weighted avg       0.55    0.42      0.47    48040\n",
      "8      samples avg       0.39    0.43      0.37    48040\n",
      "-------------------------------------------------\n",
      "Fold 57 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.64    0.84      0.73    60539\n",
      "1  washing machine       0.52    0.64      0.57    49848\n",
      "2      dish washer       0.37    0.62      0.46    31498\n",
      "3        microwave       0.56    0.77      0.65    45078\n",
      "4           kettle       0.50    0.49      0.49    53030\n",
      "5        micro avg       0.53    0.68      0.60   239993\n",
      "6        macro avg       0.52    0.67      0.58   239993\n",
      "7     weighted avg       0.53    0.68      0.59   239993\n",
      "8      samples avg       0.40    0.65      0.47   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 58 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.62    0.90      0.73    11748\n",
      "1  washing machine       0.54    0.41      0.46     8446\n",
      "2      dish washer       0.56    0.10      0.17     8203\n",
      "3        microwave       0.77    0.36      0.49     9654\n",
      "4           kettle       0.57    0.50      0.53     9991\n",
      "5        micro avg       0.61    0.49      0.54    48042\n",
      "6        macro avg       0.61    0.45      0.48    48042\n",
      "7     weighted avg       0.61    0.49      0.50    48042\n",
      "8      samples avg       0.54    0.48      0.47    48042\n",
      "-------------------------------------------------\n",
      "Fold 58 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.71    0.91      0.80    60539\n",
      "1  washing machine       0.55    0.66      0.60    49848\n",
      "2      dish washer       0.34    0.46      0.39    31498\n",
      "3        microwave       0.56    0.93      0.70    45078\n",
      "4           kettle       0.56    0.61      0.58    53030\n",
      "5        micro avg       0.56    0.74      0.64   239993\n",
      "6        macro avg       0.54    0.71      0.61   239993\n",
      "7     weighted avg       0.57    0.74      0.64   239993\n",
      "8      samples avg       0.53    0.68      0.55   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 59 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.62    0.64      0.63    11808\n",
      "1  washing machine       0.49    0.05      0.09     8365\n",
      "2      dish washer       0.32    0.01      0.01     8138\n",
      "3        microwave       0.79    0.24      0.37     9422\n",
      "4           kettle       0.37    0.25      0.29     9944\n",
      "5        micro avg       0.56    0.27      0.36    47677\n",
      "6        macro avg       0.52    0.24      0.28    47677\n",
      "7     weighted avg       0.53    0.27      0.31    47677\n",
      "8      samples avg       0.34    0.30      0.29    47677\n",
      "-------------------------------------------------\n",
      "Fold 59 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.63    0.90      0.74    60539\n",
      "1  washing machine       0.62    0.13      0.22    49848\n",
      "2      dish washer       0.42    0.01      0.01    31498\n",
      "3        microwave       0.57    0.82      0.67    45078\n",
      "4           kettle       0.63    0.48      0.54    53030\n",
      "5        micro avg       0.61    0.51      0.56   239993\n",
      "6        macro avg       0.58    0.47      0.44   239993\n",
      "7     weighted avg       0.59    0.51      0.48   239993\n",
      "8      samples avg       0.51    0.52      0.49   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 60 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.93      0.92    11827\n",
      "1  washing machine       0.90    0.82      0.86     8539\n",
      "2      dish washer       0.89    0.77      0.83     8216\n",
      "3        microwave       0.91    0.85      0.87     9617\n",
      "4           kettle       0.95    0.93      0.94     9906\n",
      "5        micro avg       0.91    0.87      0.89    48105\n",
      "6        macro avg       0.91    0.86      0.88    48105\n",
      "7     weighted avg       0.91    0.87      0.89    48105\n",
      "8      samples avg       0.92    0.89      0.89    48105\n",
      "-------------------------------------------------\n",
      "Fold 60 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.88    0.99      0.93    60539\n",
      "1  washing machine       0.57    0.79      0.66    49848\n",
      "2      dish washer       0.60    0.66      0.63    31498\n",
      "3        microwave       0.65    0.87      0.75    45078\n",
      "4           kettle       0.87    0.70      0.78    53030\n",
      "5        micro avg       0.72    0.82      0.76   239993\n",
      "6        macro avg       0.72    0.80      0.75   239993\n",
      "7     weighted avg       0.74    0.82      0.77   239993\n",
      "8      samples avg       0.68    0.80      0.72   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 61 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.93    0.88      0.90    11823\n",
      "1  washing machine       0.92    0.73      0.82     8333\n",
      "2      dish washer       0.91    0.65      0.76     8177\n",
      "3        microwave       0.56    0.97      0.71     9593\n",
      "4           kettle       0.97    0.88      0.92     9931\n",
      "5        micro avg       0.81    0.83      0.82    47857\n",
      "6        macro avg       0.86    0.82      0.82    47857\n",
      "7     weighted avg       0.86    0.83      0.83    47857\n",
      "8      samples avg       0.80    0.84      0.80    47857\n",
      "-------------------------------------------------\n",
      "Fold 61 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.94    0.99      0.97    60539\n",
      "1  washing machine       0.57    0.77      0.66    49848\n",
      "2      dish washer       0.71    0.63      0.67    31498\n",
      "3        microwave       0.56    0.94      0.70    45078\n",
      "4           kettle       0.98    0.59      0.74    53030\n",
      "5        micro avg       0.72    0.80      0.76   239993\n",
      "6        macro avg       0.75    0.79      0.75   239993\n",
      "7     weighted avg       0.77    0.80      0.76   239993\n",
      "8      samples avg       0.69    0.79      0.71   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 62 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.87    0.80      0.84    11825\n",
      "1  washing machine       0.89    0.52      0.66     8361\n",
      "2      dish washer       0.86    0.52      0.65     8242\n",
      "3        microwave       0.52    0.96      0.67     9556\n",
      "4           kettle       0.91    0.84      0.87     9918\n",
      "5        micro avg       0.75    0.74      0.75    47902\n",
      "6        macro avg       0.81    0.73      0.74    47902\n",
      "7     weighted avg       0.81    0.74      0.75    47902\n",
      "8      samples avg       0.72    0.73      0.70    47902\n",
      "-------------------------------------------------\n",
      "Fold 62 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.90    0.99      0.94    60539\n",
      "1  washing machine       0.77    0.45      0.57    49848\n",
      "2      dish washer       0.72    0.60      0.65    31498\n",
      "3        microwave       0.50    0.98      0.66    45078\n",
      "4           kettle       0.85    0.71      0.77    53030\n",
      "5        micro avg       0.72    0.76      0.74   239993\n",
      "6        macro avg       0.75    0.75      0.72   239993\n",
      "7     weighted avg       0.76    0.76      0.74   239993\n",
      "8      samples avg       0.69    0.75      0.70   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 63 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.62    0.99      0.76    11830\n",
      "1  washing machine       0.53    0.00      0.01     8445\n",
      "2      dish washer       0.62    0.02      0.04     8246\n",
      "3        microwave       0.60    0.58      0.59     9513\n",
      "4           kettle       0.55    0.49      0.52    10056\n",
      "5        micro avg       0.59    0.47      0.52    48090\n",
      "6        macro avg       0.58    0.42      0.38    48090\n",
      "7     weighted avg       0.58    0.47      0.42    48090\n",
      "8      samples avg       0.56    0.45      0.46    48090\n",
      "-------------------------------------------------\n",
      "Fold 63 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.63    1.00      0.77    60539\n",
      "1  washing machine       0.53    0.04      0.08    49848\n",
      "2      dish washer       0.36    0.06      0.10    31498\n",
      "3        microwave       0.55    0.94      0.70    45078\n",
      "4           kettle       0.58    0.60      0.59    53030\n",
      "5        micro avg       0.59    0.58      0.58   239993\n",
      "6        macro avg       0.53    0.53      0.45   239993\n",
      "7     weighted avg       0.55    0.58      0.49   239993\n",
      "8      samples avg       0.54    0.55      0.52   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 64 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.62    0.92      0.74    11866\n",
      "1  washing machine       0.52    0.36      0.42     8487\n",
      "2      dish washer       0.46    0.46      0.46     8217\n",
      "3        microwave       0.72    0.39      0.50     9572\n",
      "4           kettle       0.60    0.32      0.42     9988\n",
      "5        micro avg       0.58    0.51      0.55    48130\n",
      "6        macro avg       0.58    0.49      0.51    48130\n",
      "7     weighted avg       0.59    0.51      0.52    48130\n",
      "8      samples avg       0.51    0.50      0.45    48130\n",
      "-------------------------------------------------\n",
      "Fold 64 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.63    0.83      0.72    60539\n",
      "1  washing machine       0.51    0.63      0.56    49848\n",
      "2      dish washer       0.21    0.41      0.28    31498\n",
      "3        microwave       0.57    0.78      0.66    45078\n",
      "4           kettle       0.68    0.28      0.40    53030\n",
      "5        micro avg       0.50    0.60      0.55   239993\n",
      "6        macro avg       0.52    0.59      0.52   239993\n",
      "7     weighted avg       0.55    0.60      0.54   239993\n",
      "8      samples avg       0.39    0.61      0.44   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Fold 65 evaluation results for REF dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.78    0.55      0.64    11698\n",
      "1  washing machine       0.78    0.00      0.01     8538\n",
      "2      dish washer       0.35    0.07      0.12     8240\n",
      "3        microwave       0.71    0.36      0.48     9582\n",
      "4           kettle       0.57    0.63      0.60     9963\n",
      "5        micro avg       0.65    0.35      0.45    48021\n",
      "6        macro avg       0.64    0.32      0.37    48021\n",
      "7     weighted avg       0.65    0.35      0.40    48021\n",
      "8      samples avg       0.39    0.35      0.35    48021\n",
      "-------------------------------------------------\n",
      "Fold 65 evaluation results for UKD dataset:\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.60    0.40      0.48    60539\n",
      "1  washing machine       0.71    0.00      0.01    49848\n",
      "2      dish washer       0.22    0.18      0.19    31498\n",
      "3        microwave       0.56    0.73      0.64    45078\n",
      "4           kettle       0.59    0.69      0.63    53030\n",
      "5        micro avg       0.53    0.42      0.47   239993\n",
      "6        macro avg       0.53    0.40      0.39   239993\n",
      "7     weighted avg       0.56    0.42      0.41   239993\n",
      "8      samples avg       0.35    0.41      0.35   239993\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "               USES THE HOLY DATASET, OUR, EXPERIMENT WITH KFOLD!!!!!\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from sklearn.model_selection import KFold\n",
    "import pickle\n",
    "\n",
    "# Define a learning rate scheduler function\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "\n",
    "# Load the datasets\n",
    "HolyDataset_UKD = pickle.load(open('./datasets/HolyDatasetDALE.pkl', 'rb'))\n",
    "HolyDataset_REF = pickle.load(open('./datasets/HolyDataset.pkl', 'rb'))\n",
    "\n",
    "x_UKD, y_UKD, labels_UKD = HolyDataset_UKD[0], HolyDataset_UKD[2], HolyDataset_UKD[4]\n",
    "class_weights_UKD = class_weights_tool(y_UKD)\n",
    "\n",
    "x_REF, y_REF, labels_REF = HolyDataset_REF[0], HolyDataset_REF[2], HolyDataset_REF[4]\n",
    "class_weights_REF = class_weights_tool(y_REF)\n",
    "\n",
    "# Set the number of folds\n",
    "n_folds = 5\n",
    "\n",
    "# Initialize the KFold cross-validator\n",
    "kf = KFold(n_splits=n_folds, shuffle=True)\n",
    "\n",
    "# Lists to store the evaluation results for each fold\n",
    "evaluation_results_UKD_UKD, evaluation_results_UKD_REF, evaluation_results_REF_UKD, evaluation_results_REF_REF = [], [], [], []\n",
    "\n",
    "# List to store all of the results in tuples\n",
    "all_results = []\n",
    "\n",
    "test_koef = [0.1, 0.3, 0.5, 0.7, 0.9, 1.1, 1.3, 1.5, 1.7, 1.9, 2.1, 2.3, 2.5]\n",
    "\n",
    "for i in range(len(test_koef)):\n",
    "    k = test_koef[i]\n",
    "    print(f'Using koef {k}')\n",
    "\n",
    "    # Perform 5-fold cross-validation\n",
    "    for train_idx, val_idx in kf.split(x_UKD):\n",
    "        x_train_UKD, x_val_UKD = x_UKD[train_idx], x_UKD[val_idx]\n",
    "        y_train_UKD, y_val_UKD = y_UKD[train_idx], y_UKD[val_idx]\n",
    "\n",
    "        model = TEST(k, NmDevices, window_size, 'gru', 128)\n",
    "        model.build((len(y_train_UKD) + len(y_test_UKD), window_size, 1))\n",
    "        #model.summary()\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003), loss='binary_crossentropy', metrics=[NUK.F1Score, NUK.WeightedF1Score(NUK.class_weights_tool(y_test_UKD))])\n",
    "        lr_scheduler = LearningRateScheduler(scheduler)\n",
    "        model.fit(x_train_UKD, y_train_UKD, batch_size=batch_size, epochs=epochs, class_weight=class_weights_UKD, callbacks=[lr_scheduler])\n",
    "\n",
    "        # Evaluate the model on the UKD dataset\n",
    "        y_pred_UKD = model.predict(x_val_UKD)\n",
    "        y_pred_tf_UKD = (y_pred_UKD > 0.5)\n",
    "        report_UKD = metrics.classification_report(y_val_UKD, y_pred_tf_UKD, target_names=labels_UKD, zero_division=0)\n",
    "        # I prefer to save class. reports in pandas dataframes so i use this function\n",
    "        report_UKD_DF = NUK.ClassificationReportToDF(report_UKD, labels_UKD)\n",
    "        report_UKD_DF.rename(columns={report_UKD_DF.columns[0]: \"device\"}, inplace=True)\n",
    "        evaluation_results_UKD_UKD.append(report_UKD_DF)\n",
    "\n",
    "        # Evaluate the model on the REF dataset\n",
    "        y_pred_REF = model.predict(x_REF)\n",
    "        y_pred_tf_REF = (y_pred_REF > 0.5)\n",
    "        report_REF = metrics.classification_report(y_REF, y_pred_tf_REF, target_names=labels_REF, zero_division=0)\n",
    "        # I prefer to save class. reports in pandas dataframes so i use this function\n",
    "        report_REF_DF = NUK.ClassificationReportToDF(report_REF, labels_REF)\n",
    "        report_REF_DF.rename(columns={report_REF_DF.columns[0]: \"device\"}, inplace = True)\n",
    "        evaluation_results_UKD_REF.append(report_REF_DF)\n",
    "\n",
    "    # Print the evaluation results for each fold\n",
    "    for j, (result_UKD, result_REF) in enumerate(zip(evaluation_results_UKD, evaluation_results_REF)):\n",
    "        print(f\"Fold {j+1} evaluation results for UKD dataset:\")\n",
    "        print(result_UKD_UKD)\n",
    "        print(\"-------------------------------------------------\")\n",
    "        print(f\"Fold {j+1} evaluation results for REF dataset:\")\n",
    "        print(result_UKD_REF)\n",
    "        print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\n",
    "        \n",
    "    # Perform 5-fold cross-validation\n",
    "    for train_idx, val_idx in kf.split(x_REF):  # Swap 'x_UKD' with 'x_REF'\n",
    "        x_train_REF, x_val_REF = x_REF[train_idx], x_REF[val_idx]  # Swap 'x_train_UKD' with 'x_train_REF' and 'x_val_UKD' with 'x_val_REF'\n",
    "        y_train_REF, y_val_REF = y_REF[train_idx], y_REF[val_idx]  # Swap 'y_train_UKD' with 'y_train_REF' and 'y_val_UKD' with 'y_val_REF'\n",
    "\n",
    "        model = TEST(k, NmDevices, window_size, 'gru', 128)\n",
    "        model.build((len(y_train_REF) + len(y_test_REF), window_size, 1))  # Swap 'y_train_UKD' with 'y_train_REF'\n",
    "        #model.summary()\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003), loss='binary_crossentropy', metrics=[NUK.F1Score, NUK.WeightedF1Score(NUK.class_weights_tool(y_test_REF))])  # Swap 'y_test_UKD' with 'y_test_REF'\n",
    "        lr_scheduler = LearningRateScheduler(scheduler)\n",
    "        model.fit(x_train_REF, y_train_REF, batch_size=batch_size, epochs=epochs, class_weight=class_weights_REF, callbacks=[lr_scheduler])  # Swap 'x_train_UKD' with 'x_train_REF' and 'y_train_UKD' with 'y_train_REF'\n",
    "\n",
    "        # Evaluate the model on the REF dataset  # Swap 'UKD' with 'REF'\n",
    "        y_pred_REF = model.predict(x_val_REF)  # Swap 'x_val_UKD' with 'x_val_REF'\n",
    "        y_pred_tf_REF = (y_pred_REF > 0.5)\n",
    "        report_REF = metrics.classification_report(y_val_REF, y_pred_tf_REF, target_names=labels_REF, zero_division=0)  # Swap 'y_val_UKD' with 'y_val_REF'\n",
    "        # I prefer to save class. reports in pandas dataframes so i use this function\n",
    "        report_REF_DF = NUK.ClassificationReportToDF(report_REF, labels_REF)\n",
    "        report_REF_DF.rename(columns={report_REF_DF.columns[0]: \"device\"}, inplace=True)\n",
    "        evaluation_results_REF_REF.append(report_REF_DF)  # Swap 'evaluation_results_UKD_REF' with 'evaluation_results_REF_REF'\n",
    "\n",
    "        # Evaluate the model on the UKD dataset  # Swap 'REF' with 'UKD'\n",
    "        y_pred_UKD = model.predict(x_UKD)  # Swap 'x_REF' with 'x_UKD'\n",
    "        y_pred_tf_UKD = (y_pred_UKD > 0.5)\n",
    "        report_UKD = metrics.classification_report(y_UKD, y_pred_tf_UKD, target_names=labels_UKD, zero_division=0)  # Swap 'y_REF' with 'y_UKD'\n",
    "        # I prefer to save class. reports in pandas dataframes so i use this function\n",
    "        report_UKD_DF = NUK.ClassificationReportToDF(report_UKD, labels_UKD)\n",
    "        report_UKD_DF.rename(columns={report_UKD_DF.columns[0]: \"device\"}, inplace=True)\n",
    "        evaluation_results_REF_UKD.append(report_UKD_DF)  # Swap 'evaluation_results_UKD_UKD' with 'evaluation_results_REF_UKD'\n",
    "\n",
    "    # Print the evaluation results for each fold\n",
    "    for j, (result_REF, result_UKD) in enumerate(zip(evaluation_results_REF_REF, evaluation_results_REF_UKD)):  # Swap 'evaluation_results_UKD_REF' with 'evaluation_results_REF_REF' and 'evaluation_results_REF_UKD' with 'evaluation_results_REF_UKD'\n",
    "        print(f\"Fold {j+1} evaluation results for REF dataset:\")  # Swap 'UKD' with 'REF'\n",
    "        print(result_REF)  # Swap 'result_UKD_REF' with 'result_REF'\n",
    "        print(\"-------------------------------------------------\")\n",
    "        print(f\"Fold {j+1} evaluation results for UKD dataset:\")  # Swap 'REF' with 'UKD'\n",
    "        print(result_UKD)  # Swap 'result_REF_UKD' with 'result_UKD'\n",
    "        print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\n",
    "    \n",
    "    all_results.append((evaluation_results_UKD_UKD,  evaluation_results_UKD_REF, evaluation_results_REF_UKD, evaluation_results_REF_REF))\n",
    "    \n",
    "pickle.dump(all_results, open('all_results.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e74bc5ab-f0cd-4a3f-874c-b23c2dd40e48",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(all_results) =  13\n",
      "len(all_results[0]) =  4\n",
      "len(all_results[0][0]) =  65\n",
      "evaluation_results_UKD_UKD, evaluation_results_UKD_REF, evaluation_results_REF_UKD, evaluation_results_REF_REF\n",
      " \n",
      " \n",
      " \n",
      "||||||||||||||||||||||||||||0.5|||||||||||||||||||||||||||||\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.81    0.48      0.60    59042\n",
      "1  washing machine       0.56    0.90      0.69    42164\n",
      "2      dish washer       0.52    0.67      0.59    41122\n",
      "3        microwave       0.70    0.57      0.63    47816\n",
      "4           kettle       0.64    0.94      0.76    49856\n",
      "5        micro avg       0.63    0.70      0.66   240000\n",
      "6        macro avg       0.65    0.71      0.65   240000\n",
      "7     weighted avg       0.66    0.70      0.65   240000\n",
      "8      samples avg       0.62    0.68      0.62   240000\n",
      " \n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.83    0.34      0.49    59042\n",
      "1  washing machine       0.55    0.89      0.68    42164\n",
      "2      dish washer       0.55    0.59      0.57    41122\n",
      "3        microwave       0.70    0.52      0.60    47816\n",
      "4           kettle       0.70    0.93      0.80    49856\n",
      "5        micro avg       0.64    0.64      0.64   240000\n",
      "6        macro avg       0.67    0.65      0.63   240000\n",
      "7     weighted avg       0.68    0.64      0.62   240000\n",
      "8      samples avg       0.62    0.61      0.59   240000\n",
      " \n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.79    0.52      0.62    59042\n",
      "1  washing machine       0.55    0.90      0.68    42164\n",
      "2      dish washer       0.51    0.68      0.58    41122\n",
      "3        microwave       0.70    0.58      0.63    47816\n",
      "4           kettle       0.66    0.94      0.77    49856\n",
      "5        micro avg       0.62    0.71      0.66   240000\n",
      "6        macro avg       0.64    0.72      0.66   240000\n",
      "7     weighted avg       0.65    0.71      0.66   240000\n",
      "8      samples avg       0.61    0.68      0.61   240000\n",
      " \n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.83    0.47      0.60    59042\n",
      "1  washing machine       0.58    0.86      0.69    42164\n",
      "2      dish washer       0.43    0.89      0.58    41122\n",
      "3        microwave       0.68    0.53      0.59    47816\n",
      "4           kettle       0.68    0.89      0.77    49856\n",
      "5        micro avg       0.60    0.71      0.65   240000\n",
      "6        macro avg       0.64    0.73      0.65   240000\n",
      "7     weighted avg       0.66    0.71      0.65   240000\n",
      "8      samples avg       0.57    0.69      0.60   240000\n",
      " \n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.77    0.39      0.52    59042\n",
      "1  washing machine       0.53    0.91      0.67    42164\n",
      "2      dish washer       0.57    0.58      0.57    41122\n",
      "3        microwave       0.74    0.44      0.55    47816\n",
      "4           kettle       0.70    0.92      0.80    49856\n",
      "5        micro avg       0.64    0.63      0.64   240000\n",
      "6        macro avg       0.66    0.65      0.62   240000\n",
      "7     weighted avg       0.67    0.63      0.62   240000\n",
      "8      samples avg       0.62    0.61      0.59   240000\n",
      " \n",
      "||||||||||||||||||||||||||||0.7|||||||||||||||||||||||||||||\n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.71    0.22      0.34    59042\n",
      "1  washing machine       0.52    0.92      0.67    42164\n",
      "2      dish washer       0.56    0.69      0.62    41122\n",
      "3        microwave       0.74    0.52      0.61    47816\n",
      "4           kettle       0.68    0.93      0.79    49856\n",
      "5        micro avg       0.62    0.63      0.62   240000\n",
      "6        macro avg       0.64    0.66      0.60   240000\n",
      "7     weighted avg       0.65    0.63      0.59   240000\n",
      "8      samples avg       0.60    0.60      0.58   240000\n",
      " \n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.73    0.07      0.13    59042\n",
      "1  washing machine       0.38    0.49      0.43    42164\n",
      "2      dish washer       0.00    0.00      0.00    41122\n",
      "3        microwave       0.83    0.05      0.09    47816\n",
      "4           kettle       0.47    0.08      0.13    49856\n",
      "5        micro avg       0.43    0.13      0.20   240000\n",
      "6        macro avg       0.48    0.14      0.16   240000\n",
      "7     weighted avg       0.51    0.13      0.15   240000\n",
      "8      samples avg       0.25    0.13      0.16   240000\n",
      " \n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.76    0.29      0.42    59042\n",
      "1  washing machine       0.51    0.93      0.66    42164\n",
      "2      dish washer       0.55    0.64      0.59    41122\n",
      "3        microwave       0.70    0.48      0.57    47816\n",
      "4           kettle       0.72    0.91      0.81    49856\n",
      "5        micro avg       0.62    0.63      0.63   240000\n",
      "6        macro avg       0.65    0.65      0.61   240000\n",
      "7     weighted avg       0.66    0.63      0.60   240000\n",
      "8      samples avg       0.60    0.60      0.58   240000\n",
      " \n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.82    0.43      0.56    59042\n",
      "1  washing machine       0.53    0.93      0.67    42164\n",
      "2      dish washer       0.57    0.61      0.59    41122\n",
      "3        microwave       0.73    0.60      0.66    47816\n",
      "4           kettle       0.69    0.93      0.79    49856\n",
      "5        micro avg       0.64    0.69      0.66   240000\n",
      "6        macro avg       0.67    0.70      0.66   240000\n",
      "7     weighted avg       0.68    0.69      0.65   240000\n",
      "8      samples avg       0.63    0.67      0.62   240000\n",
      " \n",
      "            device  precision  recall  f1-score  support\n",
      "0           fridge       0.80    0.63      0.70    59042\n",
      "1  washing machine       0.54    0.82      0.65    42164\n",
      "2      dish washer       0.46    0.59      0.52    41122\n",
      "3        microwave       0.51    0.85      0.64    47816\n",
      "4           kettle       0.54    0.86      0.66    49856\n",
      "5        micro avg       0.56    0.75      0.64   240000\n",
      "6        macro avg       0.57    0.75      0.63   240000\n",
      "7     weighted avg       0.58    0.75      0.64   240000\n",
      "8      samples avg       0.55    0.72      0.59   240000\n",
      " \n",
      " \n",
      " \n",
      " \n",
      "||||||||||||||||||||||||||||0.1|||||||||||||||||||||||||||||\n",
      "65.0\n",
      " \n",
      "||||||||||||||||||||||||||||0.3|||||||||||||||||||||||||||||\n",
      "60.8\n",
      " \n",
      "||||||||||||||||||||||||||||0.5|||||||||||||||||||||||||||||\n",
      "64.0\n",
      " \n",
      "||||||||||||||||||||||||||||0.7|||||||||||||||||||||||||||||\n",
      "52.6\n",
      " \n",
      "||||||||||||||||||||||||||||0.9|||||||||||||||||||||||||||||\n",
      "59.8\n",
      " \n",
      "||||||||||||||||||||||||||||1.1|||||||||||||||||||||||||||||\n",
      "54.2\n",
      " \n",
      "||||||||||||||||||||||||||||1.3|||||||||||||||||||||||||||||\n",
      "47.2\n",
      " \n",
      "||||||||||||||||||||||||||||1.5|||||||||||||||||||||||||||||\n",
      "45.8\n",
      " \n",
      "||||||||||||||||||||||||||||1.7|||||||||||||||||||||||||||||\n",
      "54.6\n",
      " \n",
      "||||||||||||||||||||||||||||1.9|||||||||||||||||||||||||||||\n",
      "43.0\n",
      " \n",
      "||||||||||||||||||||||||||||2.1|||||||||||||||||||||||||||||\n",
      "40.0\n",
      " \n",
      "||||||||||||||||||||||||||||2.3|||||||||||||||||||||||||||||\n",
      "44.2\n",
      " \n",
      "||||||||||||||||||||||||||||2.5|||||||||||||||||||||||||||||\n",
      "40.2\n",
      " \n"
     ]
    }
   ],
   "source": [
    "all_results = pickle.load(open('all_results.pkl', 'rb'))\n",
    "\n",
    "print('len(all_results) = ', len(all_results))\n",
    "print('len(all_results[0]) = ', len(all_results[12]))\n",
    "print('len(all_results[0][0]) = ', len(all_results[12][0]))\n",
    "print('evaluation_results_UKD_UKD, evaluation_results_UKD_REF, evaluation_results_REF_UKD, evaluation_results_REF_REF')\n",
    "print(' ')\n",
    "print(' ')\n",
    "print(' ')\n",
    "\n",
    "test_koef = [0.1, 0.3, 0.5, 0.7, 0.9, 1.1, 1.3, 1.5, 1.7, 1.9, 2.1, 2.3, 2.5]\n",
    "for i in range(len(test_koef)):\n",
    "    \n",
    "    if i not in [2, 3]: continue\n",
    "    \n",
    "    print(f'||||||||||||||||||||||||||||{test_koef[i]}|||||||||||||||||||||||||||||')\n",
    "    for j in range(5):\n",
    "        print(all_results[0][1][i*5+j])\n",
    "        print(' ')\n",
    "\n",
    "        \n",
    "print(' ')\n",
    "print(' ')\n",
    "print(' ')\n",
    "\n",
    "test_koef = [0.1, 0.3, 0.5, 0.7, 0.9, 1.1, 1.3, 1.5, 1.7, 1.9, 2.1, 2.3, 2.5]\n",
    "for i in range(len(test_koef)):\n",
    "    print(f'||||||||||||||||||||||||||||{test_koef[i]}|||||||||||||||||||||||||||||')\n",
    "    helper_list = []\n",
    "    for j in range(5):\n",
    "        res_df = all_results[0][1][i*5+j]\n",
    "        helper_list.append(res_df['f1-score'][7])\n",
    "    print(round(NUK.ListAverage(helper_list)*100, 4))\n",
    "    print(' ')\n",
    "\n",
    "        \n",
    "#for i in range(len(all_results)):\n",
    "#    print(all_results[i][1][0])\n",
    "#    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "87ae20ad-9f08-4af5-82c8-a1812fd24ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['device', 'precision', 'recall', 'f1-score', 'support'], dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#type(report_REF)\n",
    "report_REF_DF = NUK.ClassificationReportToDF(report_REF, labels_REF)\n",
    "report_REF_DF.rename(columns={report_REF_DF.columns[0]: \"device\"}, inplace = True)\n",
    "report_REF_DF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "673685b6-1b49-434f-a470-15009a99344f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 4s 5ms/step\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         fridge       0.80      0.43      0.56     14772\n",
      "washing machine       0.54      0.88      0.67     10509\n",
      "    dish washer       0.55      0.67      0.61     10465\n",
      "      microwave       0.69      0.53      0.60     11878\n",
      "         kettle       0.71      0.93      0.80     12376\n",
      "\n",
      "      micro avg       0.64      0.67      0.66     60000\n",
      "      macro avg       0.66      0.69      0.65     60000\n",
      "   weighted avg       0.67      0.67      0.65     60000\n",
      "    samples avg       0.62      0.64      0.61     60000\n",
      "\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('./models/rawTS/HolyDataset/ComplexityAnalysis/PC1*0.7_DALE')\n",
    "# |||||||||||||||||||||||||||||||| prediction ||||||||||||||||||||||||||||||||\n",
    "y_pred_REF = model.predict(x_test_REF)\n",
    "y_pred_tf_REF = (y_pred_REF > 0.5)\n",
    "print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\n",
    "print(metrics.classification_report(y_test_REF, y_pred_tf_REF, target_names=labels_REF, zero_division=0))\n",
    "print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e5fd380-b50d-4a0c-8c0f-e34024144b03",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU enabled\n",
      "Epoch 1/20\n",
      "713/713 [==============================] - 38s 49ms/step - loss: inf - F1Score: 0.6735 - WeightedF1: 0.7098 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "713/713 [==============================] - 35s 49ms/step - loss: inf - F1Score: 0.8019 - WeightedF1: 0.8200 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.8475 - WeightedF1: 0.8634 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.8718 - WeightedF1: 0.8866 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "713/713 [==============================] - 38s 53ms/step - loss: inf - F1Score: 0.8884 - WeightedF1: 0.9007 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "713/713 [==============================] - 46s 64ms/step - loss: inf - F1Score: 0.8995 - WeightedF1: 0.9106 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "713/713 [==============================] - 42s 59ms/step - loss: inf - F1Score: 0.9053 - WeightedF1: 0.9159 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "713/713 [==============================] - 43s 60ms/step - loss: inf - F1Score: 0.9109 - WeightedF1: 0.9211 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "713/713 [==============================] - 44s 61ms/step - loss: inf - F1Score: 0.9166 - WeightedF1: 0.9261 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "713/713 [==============================] - 42s 59ms/step - loss: inf - F1Score: 0.9197 - WeightedF1: 0.9291 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "713/713 [==============================] - 39s 55ms/step - loss: inf - F1Score: 0.9242 - WeightedF1: 0.9332 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "713/713 [==============================] - 39s 55ms/step - loss: inf - F1Score: 0.9287 - WeightedF1: 0.9374 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "713/713 [==============================] - 37s 51ms/step - loss: inf - F1Score: 0.9323 - WeightedF1: 0.9405 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9355 - WeightedF1: 0.9435 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9387 - WeightedF1: 0.9463 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "713/713 [==============================] - 37s 52ms/step - loss: inf - F1Score: 0.9412 - WeightedF1: 0.9486 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "713/713 [==============================] - 45s 63ms/step - loss: inf - F1Score: 0.9435 - WeightedF1: 0.9507 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "713/713 [==============================] - 49s 68ms/step - loss: inf - F1Score: 0.9459 - WeightedF1: 0.9528 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "713/713 [==============================] - 44s 61ms/step - loss: inf - F1Score: 0.9485 - WeightedF1: 0.9553 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "713/713 [==============================] - 35s 50ms/step - loss: inf - F1Score: 0.9502 - WeightedF1: 0.9568 - lr: 1.1036e-04\n",
      "150/150 [==============================] - 1s 5ms/step\n",
      "  (fridge, washing machine, dish washer, microwave, kettle)  precision  \\\n",
      "0                                             fridge              1.00   \n",
      "1                                    washing machine              0.93   \n",
      "2                                        dish washer              0.93   \n",
      "3                                          microwave              0.97   \n",
      "4                                             kettle              0.93   \n",
      "5                                          micro avg              0.96   \n",
      "6                                          macro avg              0.95   \n",
      "7                                       weighted avg              0.96   \n",
      "8                                        samples avg              0.96   \n",
      "\n",
      "   recall  f1-score  support  \n",
      "0    0.99      1.00     2996  \n",
      "1    0.90      0.92     2515  \n",
      "2    0.79      0.86     1531  \n",
      "3    0.93      0.95     2240  \n",
      "4    0.91      0.92     2565  \n",
      "5    0.92      0.94    11847  \n",
      "6    0.90      0.93    11847  \n",
      "7    0.92      0.94    11847  \n",
      "8    0.93      0.94    11847  \n",
      "3000/3000 [==============================] - 14s 5ms/step\n",
      "  (fridge, washing machine, dish washer, microwave, kettle)  precision  \\\n",
      "0                                             fridge              0.74   \n",
      "1                                    washing machine              0.53   \n",
      "2                                        dish washer              0.60   \n",
      "3                                          microwave              0.65   \n",
      "4                                             kettle              0.72   \n",
      "5                                          micro avg              0.64   \n",
      "6                                          macro avg              0.65   \n",
      "7                                       weighted avg              0.66   \n",
      "8                                        samples avg              0.61   \n",
      "\n",
      "   recall  f1-score  support  \n",
      "0    0.33      0.46    59042  \n",
      "1    0.89      0.67    42164  \n",
      "2    0.49      0.54    41122  \n",
      "3    0.62      0.64    47816  \n",
      "4    0.89      0.80    49856  \n",
      "5    0.63      0.63   240000  \n",
      "6    0.64      0.62   240000  \n",
      "7    0.63      0.61   240000  \n",
      "8    0.60      0.58   240000  \n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "713/713 [==============================] - 38s 51ms/step - loss: inf - F1Score: 0.6830 - WeightedF1: 0.7140 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.7822 - WeightedF1: 0.8025 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.8338 - WeightedF1: 0.8488 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.8636 - WeightedF1: 0.8778 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.8802 - WeightedF1: 0.8931 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.8938 - WeightedF1: 0.9049 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9017 - WeightedF1: 0.9120 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9079 - WeightedF1: 0.9177 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9113 - WeightedF1: 0.9210 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9143 - WeightedF1: 0.9239 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9214 - WeightedF1: 0.9303 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9258 - WeightedF1: 0.9342 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9303 - WeightedF1: 0.9383 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9328 - WeightedF1: 0.9407 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9361 - WeightedF1: 0.9437 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9388 - WeightedF1: 0.9461 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9417 - WeightedF1: 0.9488 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9445 - WeightedF1: 0.9514 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9469 - WeightedF1: 0.9537 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9498 - WeightedF1: 0.9562 - lr: 1.1036e-04\n",
      "150/150 [==============================] - 1s 5ms/step\n",
      "  (fridge, washing machine, dish washer, microwave, kettle)  precision  \\\n",
      "0                                             fridge              1.00   \n",
      "1                                    washing machine              0.95   \n",
      "2                                        dish washer              0.95   \n",
      "3                                          microwave              0.98   \n",
      "4                                             kettle              0.92   \n",
      "5                                          micro avg              0.96   \n",
      "6                                          macro avg              0.96   \n",
      "7                                       weighted avg              0.96   \n",
      "8                                        samples avg              0.97   \n",
      "\n",
      "   recall  f1-score  support  \n",
      "0    1.00      1.00     2977  \n",
      "1    0.88      0.92     2431  \n",
      "2    0.81      0.87     1612  \n",
      "3    0.94      0.96     2293  \n",
      "4    0.94      0.93     2626  \n",
      "5    0.93      0.94    11939  \n",
      "6    0.92      0.94    11939  \n",
      "7    0.93      0.94    11939  \n",
      "8    0.94      0.95    11939  \n",
      "3000/3000 [==============================] - 14s 5ms/step\n",
      "  (fridge, washing machine, dish washer, microwave, kettle)  precision  \\\n",
      "0                                             fridge              0.82   \n",
      "1                                    washing machine              0.55   \n",
      "2                                        dish washer              0.57   \n",
      "3                                          microwave              0.69   \n",
      "4                                             kettle              0.73   \n",
      "5                                          micro avg              0.67   \n",
      "6                                          macro avg              0.67   \n",
      "7                                       weighted avg              0.69   \n",
      "8                                        samples avg              0.65   \n",
      "\n",
      "   recall  f1-score  support  \n",
      "0    0.64      0.72    59042  \n",
      "1    0.90      0.68    42164  \n",
      "2    0.62      0.59    41122  \n",
      "3    0.61      0.64    47816  \n",
      "4    0.92      0.81    49856  \n",
      "5    0.73      0.70   240000  \n",
      "6    0.74      0.69   240000  \n",
      "7    0.73      0.70   240000  \n",
      "8    0.72      0.66   240000  \n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "713/713 [==============================] - 40s 50ms/step - loss: inf - F1Score: 0.6742 - WeightedF1: 0.7085 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.7714 - WeightedF1: 0.7941 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.8294 - WeightedF1: 0.8456 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.8549 - WeightedF1: 0.8709 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.8742 - WeightedF1: 0.8886 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.8842 - WeightedF1: 0.8979 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.8922 - WeightedF1: 0.9049 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9026 - WeightedF1: 0.9134 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9082 - WeightedF1: 0.9188 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9122 - WeightedF1: 0.9226 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9174 - WeightedF1: 0.9274 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "713/713 [==============================] - 37s 51ms/step - loss: inf - F1Score: 0.9206 - WeightedF1: 0.9303 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9251 - WeightedF1: 0.9344 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9285 - WeightedF1: 0.9375 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9307 - WeightedF1: 0.9396 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9339 - WeightedF1: 0.9425 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9371 - WeightedF1: 0.9452 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9404 - WeightedF1: 0.9483 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9428 - WeightedF1: 0.9504 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9456 - WeightedF1: 0.9529 - lr: 1.1036e-04\n",
      "150/150 [==============================] - 1s 5ms/step\n",
      "  (fridge, washing machine, dish washer, microwave, kettle)  precision  \\\n",
      "0                                             fridge              1.00   \n",
      "1                                    washing machine              0.92   \n",
      "2                                        dish washer              0.93   \n",
      "3                                          microwave              0.97   \n",
      "4                                             kettle              0.94   \n",
      "5                                          micro avg              0.95   \n",
      "6                                          macro avg              0.95   \n",
      "7                                       weighted avg              0.95   \n",
      "8                                        samples avg              0.96   \n",
      "\n",
      "   recall  f1-score  support  \n",
      "0    1.00      1.00     2994  \n",
      "1    0.90      0.91     2470  \n",
      "2    0.79      0.85     1565  \n",
      "3    0.94      0.95     2283  \n",
      "4    0.92      0.93     2641  \n",
      "5    0.92      0.94    11953  \n",
      "6    0.91      0.93    11953  \n",
      "7    0.92      0.94    11953  \n",
      "8    0.94      0.94    11953  \n",
      "3000/3000 [==============================] - 14s 5ms/step\n",
      "  (fridge, washing machine, dish washer, microwave, kettle)  precision  \\\n",
      "0                                             fridge              0.80   \n",
      "1                                    washing machine              0.56   \n",
      "2                                        dish washer              0.59   \n",
      "3                                          microwave              0.73   \n",
      "4                                             kettle              0.70   \n",
      "5                                          micro avg              0.67   \n",
      "6                                          macro avg              0.68   \n",
      "7                                       weighted avg              0.69   \n",
      "8                                        samples avg              0.65   \n",
      "\n",
      "   recall  f1-score  support  \n",
      "0    0.56      0.66    59042  \n",
      "1    0.88      0.69    42164  \n",
      "2    0.62      0.60    41122  \n",
      "3    0.54      0.62    47816  \n",
      "4    0.93      0.80    49856  \n",
      "5    0.70      0.68   240000  \n",
      "6    0.71      0.67   240000  \n",
      "7    0.70      0.68   240000  \n",
      "8    0.68      0.64   240000  \n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "713/713 [==============================] - 38s 50ms/step - loss: inf - F1Score: 0.6791 - WeightedF1: 0.7123 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.7978 - WeightedF1: 0.8153 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.8462 - WeightedF1: 0.8619 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.8660 - WeightedF1: 0.8809 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.8813 - WeightedF1: 0.8948 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.8950 - WeightedF1: 0.9070 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9033 - WeightedF1: 0.9145 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9083 - WeightedF1: 0.9191 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9124 - WeightedF1: 0.9228 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9169 - WeightedF1: 0.9267 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9216 - WeightedF1: 0.9310 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9256 - WeightedF1: 0.9347 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9290 - WeightedF1: 0.9377 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9334 - WeightedF1: 0.9417 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "713/713 [==============================] - 35s 50ms/step - loss: inf - F1Score: 0.9358 - WeightedF1: 0.9439 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9389 - WeightedF1: 0.9467 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "713/713 [==============================] - 37s 52ms/step - loss: inf - F1Score: 0.9421 - WeightedF1: 0.9496 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9455 - WeightedF1: 0.9525 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9497 - WeightedF1: 0.9560 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9525 - WeightedF1: 0.9585 - lr: 1.1036e-04\n",
      "150/150 [==============================] - 1s 5ms/step\n",
      "  (fridge, washing machine, dish washer, microwave, kettle)  precision  \\\n",
      "0                                             fridge              1.00   \n",
      "1                                    washing machine              0.93   \n",
      "2                                        dish washer              0.95   \n",
      "3                                          microwave              0.96   \n",
      "4                                             kettle              0.92   \n",
      "5                                          micro avg              0.95   \n",
      "6                                          macro avg              0.95   \n",
      "7                                       weighted avg              0.95   \n",
      "8                                        samples avg              0.96   \n",
      "\n",
      "   recall  f1-score  support  \n",
      "0    1.00      1.00     3021  \n",
      "1    0.91      0.92     2523  \n",
      "2    0.80      0.87     1568  \n",
      "3    0.95      0.95     2243  \n",
      "4    0.95      0.93     2588  \n",
      "5    0.93      0.94    11943  \n",
      "6    0.92      0.93    11943  \n",
      "7    0.93      0.94    11943  \n",
      "8    0.95      0.95    11943  \n",
      "3000/3000 [==============================] - 14s 5ms/step\n",
      "  (fridge, washing machine, dish washer, microwave, kettle)  precision  \\\n",
      "0                                             fridge              0.78   \n",
      "1                                    washing machine              0.57   \n",
      "2                                        dish washer              0.53   \n",
      "3                                          microwave              0.71   \n",
      "4                                             kettle              0.71   \n",
      "5                                          micro avg              0.64   \n",
      "6                                          macro avg              0.66   \n",
      "7                                       weighted avg              0.67   \n",
      "8                                        samples avg              0.63   \n",
      "\n",
      "   recall  f1-score  support  \n",
      "0    0.47      0.58    59042  \n",
      "1    0.88      0.69    42164  \n",
      "2    0.68      0.59    41122  \n",
      "3    0.57      0.63    47816  \n",
      "4    0.93      0.80    49856  \n",
      "5    0.69      0.67   240000  \n",
      "6    0.70      0.66   240000  \n",
      "7    0.69      0.66   240000  \n",
      "8    0.66      0.62   240000  \n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "713/713 [==============================] - 38s 50ms/step - loss: inf - F1Score: 0.6951 - WeightedF1: 0.7247 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "713/713 [==============================] - 35s 49ms/step - loss: inf - F1Score: 0.8095 - WeightedF1: 0.8263 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "713/713 [==============================] - 35s 50ms/step - loss: inf - F1Score: 0.8432 - WeightedF1: 0.8588 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "713/713 [==============================] - 35s 49ms/step - loss: inf - F1Score: 0.8424 - WeightedF1: 0.8573 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "713/713 [==============================] - 35s 49ms/step - loss: inf - F1Score: 0.8422 - WeightedF1: 0.8571 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "713/713 [==============================] - 35s 49ms/step - loss: inf - F1Score: 0.8421 - WeightedF1: 0.8570 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "713/713 [==============================] - 35s 49ms/step - loss: inf - F1Score: 0.8422 - WeightedF1: 0.8571 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "713/713 [==============================] - 35s 49ms/step - loss: inf - F1Score: 0.8422 - WeightedF1: 0.8571 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "713/713 [==============================] - 35s 49ms/step - loss: inf - F1Score: 0.8423 - WeightedF1: 0.8572 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "713/713 [==============================] - 35s 49ms/step - loss: inf - F1Score: 0.8422 - WeightedF1: 0.8571 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "713/713 [==============================] - 35s 49ms/step - loss: inf - F1Score: 0.8423 - WeightedF1: 0.8572 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "713/713 [==============================] - 35s 49ms/step - loss: inf - F1Score: 0.8423 - WeightedF1: 0.8572 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "713/713 [==============================] - 35s 49ms/step - loss: inf - F1Score: 0.8424 - WeightedF1: 0.8573 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "713/713 [==============================] - 35s 48ms/step - loss: inf - F1Score: 0.8424 - WeightedF1: 0.8572 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "713/713 [==============================] - 35s 49ms/step - loss: inf - F1Score: 0.8422 - WeightedF1: 0.8571 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "713/713 [==============================] - 35s 49ms/step - loss: inf - F1Score: 0.8423 - WeightedF1: 0.8572 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "713/713 [==============================] - 35s 49ms/step - loss: inf - F1Score: 0.8423 - WeightedF1: 0.8572 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "713/713 [==============================] - 35s 49ms/step - loss: inf - F1Score: 0.8422 - WeightedF1: 0.8571 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "713/713 [==============================] - 35s 49ms/step - loss: inf - F1Score: 0.8425 - WeightedF1: 0.8573 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "713/713 [==============================] - 47s 66ms/step - loss: inf - F1Score: 0.8424 - WeightedF1: 0.8572 - lr: 1.1036e-04\n",
      "150/150 [==============================] - 2s 6ms/step\n",
      "  (fridge, washing machine, dish washer, microwave, kettle)  precision  \\\n",
      "0                                             fridge              0.99   \n",
      "1                                    washing machine              0.83   \n",
      "2                                        dish washer              0.87   \n",
      "3                                          microwave              0.86   \n",
      "4                                             kettle              0.82   \n",
      "5                                          micro avg              0.88   \n",
      "6                                          macro avg              0.87   \n",
      "7                                       weighted avg              0.88   \n",
      "8                                        samples avg              0.88   \n",
      "\n",
      "   recall  f1-score  support  \n",
      "0    0.99      0.99     3007  \n",
      "1    0.80      0.82     2486  \n",
      "2    0.60      0.71     1607  \n",
      "3    0.85      0.85     2222  \n",
      "4    0.86      0.84     2648  \n",
      "5    0.84      0.86    11970  \n",
      "6    0.82      0.84    11970  \n",
      "7    0.84      0.86    11970  \n",
      "8    0.85      0.85    11970  \n",
      "3000/3000 [==============================] - 20s 7ms/step\n",
      "  (fridge, washing machine, dish washer, microwave, kettle)  precision  \\\n",
      "0                                             fridge              0.76   \n",
      "1                                    washing machine              0.52   \n",
      "2                                        dish washer              0.63   \n",
      "3                                          microwave              0.64   \n",
      "4                                             kettle              0.65   \n",
      "5                                          micro avg              0.62   \n",
      "6                                          macro avg              0.64   \n",
      "7                                       weighted avg              0.65   \n",
      "8                                        samples avg              0.60   \n",
      "\n",
      "   recall  f1-score  support  \n",
      "0    0.42      0.54    59042  \n",
      "1    0.91      0.66    42164  \n",
      "2    0.44      0.52    41122  \n",
      "3    0.50      0.56    47816  \n",
      "4    0.90      0.75    49856  \n",
      "5    0.63      0.62   240000  \n",
      "6    0.64      0.61   240000  \n",
      "7    0.63      0.61   240000  \n",
      "8    0.61      0.58   240000  \n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "713/713 [==============================] - 51s 59ms/step - loss: inf - F1Score: 0.6762 - WeightedF1: 0.7075 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "713/713 [==============================] - 43s 60ms/step - loss: inf - F1Score: 0.8041 - WeightedF1: 0.8201 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "713/713 [==============================] - 38s 53ms/step - loss: inf - F1Score: 0.8323 - WeightedF1: 0.8476 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "713/713 [==============================] - 37s 52ms/step - loss: inf - F1Score: 0.8352 - WeightedF1: 0.8502 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "713/713 [==============================] - 38s 53ms/step - loss: inf - F1Score: 0.8601 - WeightedF1: 0.8736 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "713/713 [==============================] - 37s 52ms/step - loss: inf - F1Score: 0.8629 - WeightedF1: 0.8761 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "713/713 [==============================] - 35s 50ms/step - loss: inf - F1Score: 0.8629 - WeightedF1: 0.8761 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.8628 - WeightedF1: 0.8760 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "713/713 [==============================] - 37s 52ms/step - loss: inf - F1Score: 0.8628 - WeightedF1: 0.8761 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "713/713 [==============================] - 49s 69ms/step - loss: inf - F1Score: 0.8627 - WeightedF1: 0.8760 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "713/713 [==============================] - 45s 63ms/step - loss: inf - F1Score: 0.8661 - WeightedF1: 0.8792 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "713/713 [==============================] - 38s 54ms/step - loss: inf - F1Score: 0.8807 - WeightedF1: 0.8935 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "713/713 [==============================] - 35s 49ms/step - loss: inf - F1Score: 0.8829 - WeightedF1: 0.8955 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "713/713 [==============================] - 35s 49ms/step - loss: inf - F1Score: 0.8830 - WeightedF1: 0.8956 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "713/713 [==============================] - 35s 48ms/step - loss: inf - F1Score: 0.8829 - WeightedF1: 0.8956 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "713/713 [==============================] - 35s 49ms/step - loss: inf - F1Score: 0.8831 - WeightedF1: 0.8957 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "713/713 [==============================] - 35s 49ms/step - loss: inf - F1Score: 0.8829 - WeightedF1: 0.8955 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "713/713 [==============================] - 35s 49ms/step - loss: inf - F1Score: 0.8830 - WeightedF1: 0.8956 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "713/713 [==============================] - 35s 49ms/step - loss: inf - F1Score: 0.8829 - WeightedF1: 0.8956 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "713/713 [==============================] - 35s 49ms/step - loss: inf - F1Score: 0.8829 - WeightedF1: 0.8955 - lr: 1.1036e-04\n",
      "150/150 [==============================] - 1s 5ms/step\n",
      "  (fridge, washing machine, dish washer, microwave, kettle)  precision  \\\n",
      "0                                             fridge              0.99   \n",
      "1                                    washing machine              0.84   \n",
      "2                                        dish washer              0.93   \n",
      "3                                          microwave              0.93   \n",
      "4                                             kettle              0.87   \n",
      "5                                          micro avg              0.91   \n",
      "6                                          macro avg              0.91   \n",
      "7                                       weighted avg              0.92   \n",
      "8                                        samples avg              0.92   \n",
      "\n",
      "   recall  f1-score  support  \n",
      "0    0.99      0.99     2997  \n",
      "1    0.89      0.86     2481  \n",
      "2    0.65      0.77     1627  \n",
      "3    0.88      0.91     2236  \n",
      "4    0.90      0.89     2689  \n",
      "5    0.88      0.90    12030  \n",
      "6    0.86      0.88    12030  \n",
      "7    0.88      0.89    12030  \n",
      "8    0.90      0.90    12030  \n",
      "3000/3000 [==============================] - 14s 5ms/step\n",
      "  (fridge, washing machine, dish washer, microwave, kettle)  precision  \\\n",
      "0                                             fridge              0.77   \n",
      "1                                    washing machine              0.52   \n",
      "2                                        dish washer              0.56   \n",
      "3                                          microwave              0.78   \n",
      "4                                             kettle              0.65   \n",
      "5                                          micro avg              0.63   \n",
      "6                                          macro avg              0.66   \n",
      "7                                       weighted avg              0.67   \n",
      "8                                        samples avg              0.62   \n",
      "\n",
      "   recall  f1-score  support  \n",
      "0    0.48      0.59    59042  \n",
      "1    0.93      0.66    42164  \n",
      "2    0.39      0.46    41122  \n",
      "3    0.42      0.55    47816  \n",
      "4    0.93      0.77    49856  \n",
      "5    0.63      0.63   240000  \n",
      "6    0.63      0.61   240000  \n",
      "7    0.63      0.61   240000  \n",
      "8    0.61      0.59   240000  \n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "713/713 [==============================] - 38s 50ms/step - loss: inf - F1Score: 0.6718 - WeightedF1: 0.7062 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.7940 - WeightedF1: 0.8127 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.8460 - WeightedF1: 0.8613 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "713/713 [==============================] - 35s 50ms/step - loss: inf - F1Score: 0.8693 - WeightedF1: 0.8836 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.8848 - WeightedF1: 0.8978 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.8968 - WeightedF1: 0.9081 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9040 - WeightedF1: 0.9147 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9093 - WeightedF1: 0.9196 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9141 - WeightedF1: 0.9240 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9184 - WeightedF1: 0.9279 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9228 - WeightedF1: 0.9320 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9269 - WeightedF1: 0.9356 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9304 - WeightedF1: 0.9389 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "713/713 [==============================] - 55s 77ms/step - loss: inf - F1Score: 0.9339 - WeightedF1: 0.9421 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "713/713 [==============================] - 75s 105ms/step - loss: inf - F1Score: 0.9376 - WeightedF1: 0.9452 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "713/713 [==============================] - 55s 77ms/step - loss: inf - F1Score: 0.9419 - WeightedF1: 0.9485 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "713/713 [==============================] - 72s 102ms/step - loss: inf - F1Score: 0.9451 - WeightedF1: 0.9514 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "713/713 [==============================] - 73s 102ms/step - loss: inf - F1Score: 0.9481 - WeightedF1: 0.9541 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "713/713 [==============================] - 71s 99ms/step - loss: inf - F1Score: 0.9507 - WeightedF1: 0.9565 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "713/713 [==============================] - 73s 103ms/step - loss: inf - F1Score: 0.9531 - WeightedF1: 0.9586 - lr: 1.1036e-04\n",
      "150/150 [==============================] - 8s 24ms/step\n",
      "  (fridge, washing machine, dish washer, microwave, kettle)  precision  \\\n",
      "0                                             fridge              1.00   \n",
      "1                                    washing machine              0.94   \n",
      "2                                        dish washer              0.91   \n",
      "3                                          microwave              0.97   \n",
      "4                                             kettle              0.93   \n",
      "5                                          micro avg              0.96   \n",
      "6                                          macro avg              0.95   \n",
      "7                                       weighted avg              0.96   \n",
      "8                                        samples avg              0.96   \n",
      "\n",
      "   recall  f1-score  support  \n",
      "0    1.00      1.00     2985  \n",
      "1    0.87      0.90     2449  \n",
      "2    0.83      0.87     1548  \n",
      "3    0.95      0.96     2297  \n",
      "4    0.94      0.93     2698  \n",
      "5    0.93      0.94    11977  \n",
      "6    0.92      0.93    11977  \n",
      "7    0.93      0.94    11977  \n",
      "8    0.94      0.95    11977  \n",
      "3000/3000 [==============================] - 71s 24ms/step\n",
      "  (fridge, washing machine, dish washer, microwave, kettle)  precision  \\\n",
      "0                                             fridge              0.74   \n",
      "1                                    washing machine              0.54   \n",
      "2                                        dish washer              0.57   \n",
      "3                                          microwave              0.70   \n",
      "4                                             kettle              0.71   \n",
      "5                                          micro avg              0.63   \n",
      "6                                          macro avg              0.65   \n",
      "7                                       weighted avg              0.66   \n",
      "8                                        samples avg              0.62   \n",
      "\n",
      "   recall  f1-score  support  \n",
      "0    0.28      0.41    59042  \n",
      "1    0.91      0.68    42164  \n",
      "2    0.66      0.61    41122  \n",
      "3    0.56      0.62    47816  \n",
      "4    0.92      0.80    49856  \n",
      "5    0.65      0.64   240000  \n",
      "6    0.67      0.62   240000  \n",
      "7    0.65      0.62   240000  \n",
      "8    0.62      0.59   240000  \n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "713/713 [==============================] - 82s 108ms/step - loss: inf - F1Score: 0.6606 - WeightedF1: 0.6983 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "713/713 [==============================] - 75s 105ms/step - loss: inf - F1Score: 0.7874 - WeightedF1: 0.8067 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "713/713 [==============================] - 78s 109ms/step - loss: inf - F1Score: 0.8456 - WeightedF1: 0.8608 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "713/713 [==============================] - 78s 109ms/step - loss: inf - F1Score: 0.8701 - WeightedF1: 0.8848 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "713/713 [==============================] - 74s 104ms/step - loss: inf - F1Score: 0.8855 - WeightedF1: 0.8989 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "713/713 [==============================] - 57s 80ms/step - loss: inf - F1Score: 0.8979 - WeightedF1: 0.9095 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9056 - WeightedF1: 0.9166 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "713/713 [==============================] - 35s 50ms/step - loss: inf - F1Score: 0.9110 - WeightedF1: 0.9217 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "713/713 [==============================] - 35s 50ms/step - loss: inf - F1Score: 0.9156 - WeightedF1: 0.9257 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9199 - WeightedF1: 0.9296 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "713/713 [==============================] - 35s 50ms/step - loss: inf - F1Score: 0.9249 - WeightedF1: 0.9339 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9290 - WeightedF1: 0.9377 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "713/713 [==============================] - 37s 52ms/step - loss: inf - F1Score: 0.9330 - WeightedF1: 0.9412 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "713/713 [==============================] - 37s 52ms/step - loss: inf - F1Score: 0.9364 - WeightedF1: 0.9443 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "713/713 [==============================] - 37s 52ms/step - loss: inf - F1Score: 0.9390 - WeightedF1: 0.9467 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "713/713 [==============================] - 37s 52ms/step - loss: inf - F1Score: 0.9422 - WeightedF1: 0.9496 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "713/713 [==============================] - 37s 52ms/step - loss: inf - F1Score: 0.9452 - WeightedF1: 0.9521 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "713/713 [==============================] - 37s 52ms/step - loss: inf - F1Score: 0.9497 - WeightedF1: 0.9556 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "713/713 [==============================] - 37s 51ms/step - loss: inf - F1Score: 0.9528 - WeightedF1: 0.9584 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "713/713 [==============================] - 37s 51ms/step - loss: inf - F1Score: 0.9557 - WeightedF1: 0.9610 - lr: 1.1036e-04\n",
      "150/150 [==============================] - 1s 5ms/step\n",
      "  (fridge, washing machine, dish washer, microwave, kettle)  precision  \\\n",
      "0                                             fridge              1.00   \n",
      "1                                    washing machine              0.94   \n",
      "2                                        dish washer              0.96   \n",
      "3                                          microwave              0.98   \n",
      "4                                             kettle              0.93   \n",
      "5                                          micro avg              0.96   \n",
      "6                                          macro avg              0.96   \n",
      "7                                       weighted avg              0.96   \n",
      "8                                        samples avg              0.97   \n",
      "\n",
      "   recall  f1-score  support  \n",
      "0    1.00      1.00     3047  \n",
      "1    0.91      0.92     2504  \n",
      "2    0.82      0.89     1571  \n",
      "3    0.95      0.96     2275  \n",
      "4    0.92      0.93     2664  \n",
      "5    0.93      0.95    12061  \n",
      "6    0.92      0.94    12061  \n",
      "7    0.93      0.95    12061  \n",
      "8    0.94      0.95    12061  \n",
      "3000/3000 [==============================] - 14s 5ms/step\n",
      "  (fridge, washing machine, dish washer, microwave, kettle)  precision  \\\n",
      "0                                             fridge              0.73   \n",
      "1                                    washing machine              0.54   \n",
      "2                                        dish washer              0.57   \n",
      "3                                          microwave              0.71   \n",
      "4                                             kettle              0.75   \n",
      "5                                          micro avg              0.64   \n",
      "6                                          macro avg              0.66   \n",
      "7                                       weighted avg              0.67   \n",
      "8                                        samples avg              0.62   \n",
      "\n",
      "   recall  f1-score  support  \n",
      "0    0.19      0.30    59042  \n",
      "1    0.88      0.67    42164  \n",
      "2    0.64      0.60    41122  \n",
      "3    0.56      0.63    47816  \n",
      "4    0.91      0.82    49856  \n",
      "5    0.61      0.63   240000  \n",
      "6    0.64      0.61   240000  \n",
      "7    0.61      0.59   240000  \n",
      "8    0.59      0.58   240000  \n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "713/713 [==============================] - 40s 52ms/step - loss: inf - F1Score: 0.6830 - WeightedF1: 0.7190 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "713/713 [==============================] - 37s 51ms/step - loss: inf - F1Score: 0.7764 - WeightedF1: 0.8001 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "713/713 [==============================] - 37s 51ms/step - loss: inf - F1Score: 0.8334 - WeightedF1: 0.8493 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.8699 - WeightedF1: 0.8848 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.8840 - WeightedF1: 0.8977 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "713/713 [==============================] - 37s 51ms/step - loss: inf - F1Score: 0.8971 - WeightedF1: 0.9088 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9062 - WeightedF1: 0.9169 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "713/713 [==============================] - 37s 52ms/step - loss: inf - F1Score: 0.9123 - WeightedF1: 0.9224 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "713/713 [==============================] - 37s 51ms/step - loss: inf - F1Score: 0.9180 - WeightedF1: 0.9274 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "713/713 [==============================] - 37s 51ms/step - loss: inf - F1Score: 0.9221 - WeightedF1: 0.9311 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9263 - WeightedF1: 0.9349 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9300 - WeightedF1: 0.9383 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9332 - WeightedF1: 0.9413 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9365 - WeightedF1: 0.9444 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9394 - WeightedF1: 0.9469 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9426 - WeightedF1: 0.9499 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9452 - WeightedF1: 0.9524 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9477 - WeightedF1: 0.9547 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9503 - WeightedF1: 0.9571 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9527 - WeightedF1: 0.9592 - lr: 1.1036e-04\n",
      "150/150 [==============================] - 1s 5ms/step\n",
      "  (fridge, washing machine, dish washer, microwave, kettle)  precision  \\\n",
      "0                                             fridge              1.00   \n",
      "1                                    washing machine              0.94   \n",
      "2                                        dish washer              0.92   \n",
      "3                                          microwave              0.98   \n",
      "4                                             kettle              0.92   \n",
      "5                                          micro avg              0.96   \n",
      "6                                          macro avg              0.95   \n",
      "7                                       weighted avg              0.96   \n",
      "8                                        samples avg              0.97   \n",
      "\n",
      "   recall  f1-score  support  \n",
      "0    1.00      1.00     3056  \n",
      "1    0.89      0.92     2550  \n",
      "2    0.83      0.87     1547  \n",
      "3    0.95      0.96     2306  \n",
      "4    0.95      0.94     2697  \n",
      "5    0.93      0.95    12156  \n",
      "6    0.92      0.94    12156  \n",
      "7    0.93      0.94    12156  \n",
      "8    0.95      0.95    12156  \n",
      "3000/3000 [==============================] - 14s 5ms/step\n",
      "  (fridge, washing machine, dish washer, microwave, kettle)  precision  \\\n",
      "0                                             fridge              0.79   \n",
      "1                                    washing machine              0.51   \n",
      "2                                        dish washer              0.64   \n",
      "3                                          microwave              0.70   \n",
      "4                                             kettle              0.70   \n",
      "5                                          micro avg              0.64   \n",
      "6                                          macro avg              0.67   \n",
      "7                                       weighted avg              0.68   \n",
      "8                                        samples avg              0.63   \n",
      "\n",
      "   recall  f1-score  support  \n",
      "0    0.43      0.55    59042  \n",
      "1    0.94      0.66    42164  \n",
      "2    0.57      0.60    41122  \n",
      "3    0.52      0.60    47816  \n",
      "4    0.92      0.80    49856  \n",
      "5    0.66      0.65   240000  \n",
      "6    0.67      0.64   240000  \n",
      "7    0.66      0.64   240000  \n",
      "8    0.65      0.61   240000  \n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "713/713 [==============================] - 38s 50ms/step - loss: inf - F1Score: 0.7003 - WeightedF1: 0.7278 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.8319 - WeightedF1: 0.8480 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.8682 - WeightedF1: 0.8819 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.8868 - WeightedF1: 0.8987 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.8985 - WeightedF1: 0.9092 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9049 - WeightedF1: 0.9150 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9112 - WeightedF1: 0.9209 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9156 - WeightedF1: 0.9248 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9211 - WeightedF1: 0.9298 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9241 - WeightedF1: 0.9325 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9291 - WeightedF1: 0.9372 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9328 - WeightedF1: 0.9406 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "713/713 [==============================] - 35s 50ms/step - loss: inf - F1Score: 0.9360 - WeightedF1: 0.9436 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9385 - WeightedF1: 0.9458 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9408 - WeightedF1: 0.9480 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9444 - WeightedF1: 0.9512 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9477 - WeightedF1: 0.9543 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9505 - WeightedF1: 0.9569 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9534 - WeightedF1: 0.9595 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9562 - WeightedF1: 0.9621 - lr: 1.1036e-04\n",
      "150/150 [==============================] - 1s 5ms/step\n",
      "  (fridge, washing machine, dish washer, microwave, kettle)  precision  \\\n",
      "0                                             fridge              1.00   \n",
      "1                                    washing machine              0.92   \n",
      "2                                        dish washer              0.95   \n",
      "3                                          microwave              0.98   \n",
      "4                                             kettle              0.94   \n",
      "5                                          micro avg              0.96   \n",
      "6                                          macro avg              0.96   \n",
      "7                                       weighted avg              0.96   \n",
      "8                                        samples avg              0.97   \n",
      "\n",
      "   recall  f1-score  support  \n",
      "0    1.00      1.00     3024  \n",
      "1    0.91      0.92     2512  \n",
      "2    0.80      0.87     1598  \n",
      "3    0.94      0.96     2253  \n",
      "4    0.93      0.93     2636  \n",
      "5    0.93      0.94    12023  \n",
      "6    0.92      0.93    12023  \n",
      "7    0.93      0.94    12023  \n",
      "8    0.94      0.95    12023  \n",
      "3000/3000 [==============================] - 14s 5ms/step\n",
      "  (fridge, washing machine, dish washer, microwave, kettle)  precision  \\\n",
      "0                                             fridge              0.77   \n",
      "1                                    washing machine              0.54   \n",
      "2                                        dish washer              0.50   \n",
      "3                                          microwave              0.67   \n",
      "4                                             kettle              0.73   \n",
      "5                                          micro avg              0.63   \n",
      "6                                          macro avg              0.64   \n",
      "7                                       weighted avg              0.66   \n",
      "8                                        samples avg              0.61   \n",
      "\n",
      "   recall  f1-score  support  \n",
      "0    0.32      0.45    59042  \n",
      "1    0.92      0.68    42164  \n",
      "2    0.52      0.51    41122  \n",
      "3    0.67      0.67    47816  \n",
      "4    0.90      0.81    49856  \n",
      "5    0.65      0.64   240000  \n",
      "6    0.67      0.62   240000  \n",
      "7    0.65      0.62   240000  \n",
      "8    0.63      0.59   240000  \n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "713/713 [==============================] - 39s 50ms/step - loss: inf - F1Score: 0.6760 - WeightedF1: 0.7106 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.7863 - WeightedF1: 0.8074 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.8422 - WeightedF1: 0.8577 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.8675 - WeightedF1: 0.8820 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.8850 - WeightedF1: 0.8978 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.8962 - WeightedF1: 0.9078 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9041 - WeightedF1: 0.9150 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9085 - WeightedF1: 0.9190 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9133 - WeightedF1: 0.9235 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9166 - WeightedF1: 0.9263 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9216 - WeightedF1: 0.9312 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9270 - WeightedF1: 0.9361 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9311 - WeightedF1: 0.9397 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "713/713 [==============================] - 35s 50ms/step - loss: inf - F1Score: 0.9342 - WeightedF1: 0.9426 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9373 - WeightedF1: 0.9452 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9408 - WeightedF1: 0.9483 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9451 - WeightedF1: 0.9518 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9484 - WeightedF1: 0.9546 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9505 - WeightedF1: 0.9566 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "713/713 [==============================] - 35s 50ms/step - loss: inf - F1Score: 0.9538 - WeightedF1: 0.9596 - lr: 1.1036e-04\n",
      "150/150 [==============================] - 1s 5ms/step\n",
      "  (fridge, washing machine, dish washer, microwave, kettle)  precision  \\\n",
      "0                                             fridge              1.00   \n",
      "1                                    washing machine              0.92   \n",
      "2                                        dish washer              0.91   \n",
      "3                                          microwave              0.99   \n",
      "4                                             kettle              0.94   \n",
      "5                                          micro avg              0.96   \n",
      "6                                          macro avg              0.95   \n",
      "7                                       weighted avg              0.96   \n",
      "8                                        samples avg              0.97   \n",
      "\n",
      "   recall  f1-score  support  \n",
      "0    1.00      1.00     2968  \n",
      "1    0.90      0.91     2446  \n",
      "2    0.86      0.88     1534  \n",
      "3    0.94      0.96     2277  \n",
      "4    0.93      0.93     2550  \n",
      "5    0.93      0.95    11775  \n",
      "6    0.93      0.94    11775  \n",
      "7    0.93      0.94    11775  \n",
      "8    0.95      0.95    11775  \n",
      "3000/3000 [==============================] - 14s 5ms/step\n",
      "  (fridge, washing machine, dish washer, microwave, kettle)  precision  \\\n",
      "0                                             fridge              0.72   \n",
      "1                                    washing machine              0.53   \n",
      "2                                        dish washer              0.54   \n",
      "3                                          microwave              0.68   \n",
      "4                                             kettle              0.71   \n",
      "5                                          micro avg              0.62   \n",
      "6                                          macro avg              0.64   \n",
      "7                                       weighted avg              0.65   \n",
      "8                                        samples avg              0.59   \n",
      "\n",
      "   recall  f1-score  support  \n",
      "0    0.27      0.39    59042  \n",
      "1    0.92      0.67    42164  \n",
      "2    0.54      0.54    41122  \n",
      "3    0.56      0.61    47816  \n",
      "4    0.91      0.80    49856  \n",
      "5    0.62      0.62   240000  \n",
      "6    0.64      0.60   240000  \n",
      "7    0.62      0.59   240000  \n",
      "8    0.59      0.57   240000  \n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "713/713 [==============================] - 38s 50ms/step - loss: inf - F1Score: 0.6815 - WeightedF1: 0.7173 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.7794 - WeightedF1: 0.8014 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.8296 - WeightedF1: 0.8461 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.8591 - WeightedF1: 0.8747 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.8747 - WeightedF1: 0.8894 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.8891 - WeightedF1: 0.9020 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "713/713 [==============================] - 35s 50ms/step - loss: inf - F1Score: 0.8989 - WeightedF1: 0.9104 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "713/713 [==============================] - 35s 50ms/step - loss: inf - F1Score: 0.9064 - WeightedF1: 0.9173 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9110 - WeightedF1: 0.9215 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9153 - WeightedF1: 0.9254 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9206 - WeightedF1: 0.9301 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9247 - WeightedF1: 0.9338 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9288 - WeightedF1: 0.9376 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9322 - WeightedF1: 0.9408 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9349 - WeightedF1: 0.9432 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9379 - WeightedF1: 0.9459 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9409 - WeightedF1: 0.9486 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9437 - WeightedF1: 0.9511 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "713/713 [==============================] - 37s 51ms/step - loss: inf - F1Score: 0.9463 - WeightedF1: 0.9534 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9489 - WeightedF1: 0.9558 - lr: 1.1036e-04\n",
      "150/150 [==============================] - 1s 5ms/step\n",
      "  (fridge, washing machine, dish washer, microwave, kettle)  precision  \\\n",
      "0                                             fridge              1.00   \n",
      "1                                    washing machine              0.92   \n",
      "2                                        dish washer              0.92   \n",
      "3                                          microwave              0.98   \n",
      "4                                             kettle              0.93   \n",
      "5                                          micro avg              0.95   \n",
      "6                                          macro avg              0.95   \n",
      "7                                       weighted avg              0.95   \n",
      "8                                        samples avg              0.96   \n",
      "\n",
      "   recall  f1-score  support  \n",
      "0    1.00      1.00     3076  \n",
      "1    0.90      0.91     2482  \n",
      "2    0.81      0.86     1545  \n",
      "3    0.91      0.95     2249  \n",
      "4    0.92      0.93     2671  \n",
      "5    0.92      0.94    12023  \n",
      "6    0.91      0.93    12023  \n",
      "7    0.92      0.94    12023  \n",
      "8    0.93      0.94    12023  \n",
      "3000/3000 [==============================] - 15s 5ms/step\n",
      "  (fridge, washing machine, dish washer, microwave, kettle)  precision  \\\n",
      "0                                             fridge              0.77   \n",
      "1                                    washing machine              0.54   \n",
      "2                                        dish washer              0.56   \n",
      "3                                          microwave              0.75   \n",
      "4                                             kettle              0.70   \n",
      "5                                          micro avg              0.65   \n",
      "6                                          macro avg              0.66   \n",
      "7                                       weighted avg              0.67   \n",
      "8                                        samples avg              0.63   \n",
      "\n",
      "   recall  f1-score  support  \n",
      "0    0.50      0.60    59042  \n",
      "1    0.91      0.68    42164  \n",
      "2    0.62      0.59    41122  \n",
      "3    0.51      0.60    47816  \n",
      "4    0.93      0.80    49856  \n",
      "5    0.68      0.66   240000  \n",
      "6    0.69      0.65   240000  \n",
      "7    0.68      0.65   240000  \n",
      "8    0.66      0.62   240000  \n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "713/713 [==============================] - 38s 50ms/step - loss: inf - F1Score: 0.7155 - WeightedF1: 0.7406 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.8453 - WeightedF1: 0.8617 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.8707 - WeightedF1: 0.8849 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.8894 - WeightedF1: 0.9021 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "713/713 [==============================] - 35s 50ms/step - loss: inf - F1Score: 0.8984 - WeightedF1: 0.9101 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9067 - WeightedF1: 0.9177 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9125 - WeightedF1: 0.9228 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "713/713 [==============================] - 35s 50ms/step - loss: inf - F1Score: 0.9171 - WeightedF1: 0.9270 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9214 - WeightedF1: 0.9309 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9256 - WeightedF1: 0.9346 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9298 - WeightedF1: 0.9383 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9336 - WeightedF1: 0.9418 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9372 - WeightedF1: 0.9450 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9406 - WeightedF1: 0.9481 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9429 - WeightedF1: 0.9503 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9463 - WeightedF1: 0.9533 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "713/713 [==============================] - 35s 50ms/step - loss: inf - F1Score: 0.9498 - WeightedF1: 0.9565 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9523 - WeightedF1: 0.9588 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9558 - WeightedF1: 0.9620 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9592 - WeightedF1: 0.9650 - lr: 1.1036e-04\n",
      "150/150 [==============================] - 1s 5ms/step\n",
      "  (fridge, washing machine, dish washer, microwave, kettle)  precision  \\\n",
      "0                                             fridge              1.00   \n",
      "1                                    washing machine              0.94   \n",
      "2                                        dish washer              0.90   \n",
      "3                                          microwave              0.97   \n",
      "4                                             kettle              0.94   \n",
      "5                                          micro avg              0.95   \n",
      "6                                          macro avg              0.95   \n",
      "7                                       weighted avg              0.95   \n",
      "8                                        samples avg              0.96   \n",
      "\n",
      "   recall  f1-score  support  \n",
      "0    1.00      1.00     3076  \n",
      "1    0.91      0.93     2461  \n",
      "2    0.84      0.87     1615  \n",
      "3    0.95      0.96     2253  \n",
      "4    0.93      0.93     2599  \n",
      "5    0.94      0.94    12004  \n",
      "6    0.93      0.94    12004  \n",
      "7    0.94      0.94    12004  \n",
      "8    0.95      0.95    12004  \n",
      "3000/3000 [==============================] - 14s 5ms/step\n",
      "  (fridge, washing machine, dish washer, microwave, kettle)  precision  \\\n",
      "0                                             fridge              0.76   \n",
      "1                                    washing machine              0.52   \n",
      "2                                        dish washer              0.57   \n",
      "3                                          microwave              0.67   \n",
      "4                                             kettle              0.74   \n",
      "5                                          micro avg              0.64   \n",
      "6                                          macro avg              0.65   \n",
      "7                                       weighted avg              0.66   \n",
      "8                                        samples avg              0.62   \n",
      "\n",
      "   recall  f1-score  support  \n",
      "0    0.42      0.54    59042  \n",
      "1    0.93      0.66    42164  \n",
      "2    0.62      0.59    41122  \n",
      "3    0.70      0.69    47816  \n",
      "4    0.91      0.81    49856  \n",
      "5    0.70      0.67   240000  \n",
      "6    0.72      0.66   240000  \n",
      "7    0.70      0.66   240000  \n",
      "8    0.68      0.62   240000  \n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "713/713 [==============================] - 39s 50ms/step - loss: inf - F1Score: 0.6739 - WeightedF1: 0.7072 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.7877 - WeightedF1: 0.8075 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.8425 - WeightedF1: 0.8583 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.8680 - WeightedF1: 0.8824 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.8799 - WeightedF1: 0.8936 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.8889 - WeightedF1: 0.9019 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.8973 - WeightedF1: 0.9092 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9055 - WeightedF1: 0.9160 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9110 - WeightedF1: 0.9209 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9162 - WeightedF1: 0.9255 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9210 - WeightedF1: 0.9300 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9259 - WeightedF1: 0.9345 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9286 - WeightedF1: 0.9369 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9328 - WeightedF1: 0.9408 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9356 - WeightedF1: 0.9433 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9385 - WeightedF1: 0.9459 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9413 - WeightedF1: 0.9484 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9438 - WeightedF1: 0.9507 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9464 - WeightedF1: 0.9530 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9485 - WeightedF1: 0.9550 - lr: 1.1036e-04\n",
      "150/150 [==============================] - 1s 5ms/step\n",
      "  (fridge, washing machine, dish washer, microwave, kettle)  precision  \\\n",
      "0                                             fridge              1.00   \n",
      "1                                    washing machine              0.93   \n",
      "2                                        dish washer              0.93   \n",
      "3                                          microwave              0.99   \n",
      "4                                             kettle              0.93   \n",
      "5                                          micro avg              0.96   \n",
      "6                                          macro avg              0.95   \n",
      "7                                       weighted avg              0.96   \n",
      "8                                        samples avg              0.97   \n",
      "\n",
      "   recall  f1-score  support  \n",
      "0    1.00      1.00     3055  \n",
      "1    0.90      0.91     2502  \n",
      "2    0.80      0.86     1625  \n",
      "3    0.93      0.96     2232  \n",
      "4    0.94      0.93     2720  \n",
      "5    0.92      0.94    12134  \n",
      "6    0.91      0.93    12134  \n",
      "7    0.92      0.94    12134  \n",
      "8    0.94      0.95    12134  \n",
      "3000/3000 [==============================] - 14s 5ms/step\n",
      "  (fridge, washing machine, dish washer, microwave, kettle)  precision  \\\n",
      "0                                             fridge              0.76   \n",
      "1                                    washing machine              0.52   \n",
      "2                                        dish washer              0.53   \n",
      "3                                          microwave              0.76   \n",
      "4                                             kettle              0.71   \n",
      "5                                          micro avg              0.62   \n",
      "6                                          macro avg              0.66   \n",
      "7                                       weighted avg              0.67   \n",
      "8                                        samples avg              0.60   \n",
      "\n",
      "   recall  f1-score  support  \n",
      "0    0.36      0.49    59042  \n",
      "1    0.93      0.66    42164  \n",
      "2    0.68      0.59    41122  \n",
      "3    0.47      0.58    47816  \n",
      "4    0.91      0.80    49856  \n",
      "5    0.65      0.64   240000  \n",
      "6    0.67      0.63   240000  \n",
      "7    0.65      0.62   240000  \n",
      "8    0.62      0.59   240000  \n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "713/713 [==============================] - 38s 50ms/step - loss: inf - F1Score: 0.6878 - WeightedF1: 0.7204 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.8071 - WeightedF1: 0.8239 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.8522 - WeightedF1: 0.8672 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.8756 - WeightedF1: 0.8897 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.8916 - WeightedF1: 0.9040 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9025 - WeightedF1: 0.9134 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9092 - WeightedF1: 0.9195 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9147 - WeightedF1: 0.9246 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9187 - WeightedF1: 0.9282 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9232 - WeightedF1: 0.9323 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9276 - WeightedF1: 0.9363 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9312 - WeightedF1: 0.9395 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9352 - WeightedF1: 0.9430 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9382 - WeightedF1: 0.9458 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9414 - WeightedF1: 0.9487 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9442 - WeightedF1: 0.9512 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9481 - WeightedF1: 0.9545 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9520 - WeightedF1: 0.9576 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9552 - WeightedF1: 0.9606 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9581 - WeightedF1: 0.9631 - lr: 1.1036e-04\n",
      "150/150 [==============================] - 1s 5ms/step\n",
      "  (fridge, washing machine, dish washer, microwave, kettle)  precision  \\\n",
      "0                                             fridge              1.00   \n",
      "1                                    washing machine              0.94   \n",
      "2                                        dish washer              0.96   \n",
      "3                                          microwave              0.99   \n",
      "4                                             kettle              0.93   \n",
      "5                                          micro avg              0.96   \n",
      "6                                          macro avg              0.96   \n",
      "7                                       weighted avg              0.96   \n",
      "8                                        samples avg              0.97   \n",
      "\n",
      "   recall  f1-score  support  \n",
      "0    1.00      1.00     3020  \n",
      "1    0.91      0.92     2502  \n",
      "2    0.83      0.89     1582  \n",
      "3    0.94      0.97     2272  \n",
      "4    0.94      0.94     2701  \n",
      "5    0.93      0.95    12077  \n",
      "6    0.92      0.94    12077  \n",
      "7    0.93      0.95    12077  \n",
      "8    0.95      0.96    12077  \n",
      "3000/3000 [==============================] - 15s 5ms/step\n",
      "  (fridge, washing machine, dish washer, microwave, kettle)  precision  \\\n",
      "0                                             fridge              0.74   \n",
      "1                                    washing machine              0.51   \n",
      "2                                        dish washer              0.63   \n",
      "3                                          microwave              0.73   \n",
      "4                                             kettle              0.70   \n",
      "5                                          micro avg              0.64   \n",
      "6                                          macro avg              0.66   \n",
      "7                                       weighted avg              0.67   \n",
      "8                                        samples avg              0.61   \n",
      "\n",
      "   recall  f1-score  support  \n",
      "0    0.37      0.49    59042  \n",
      "1    0.93      0.66    42164  \n",
      "2    0.51      0.57    41122  \n",
      "3    0.50      0.59    47816  \n",
      "4    0.93      0.80    49856  \n",
      "5    0.63      0.64   240000  \n",
      "6    0.65      0.62   240000  \n",
      "7    0.63      0.62   240000  \n",
      "8    0.61      0.59   240000  \n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "713/713 [==============================] - 39s 50ms/step - loss: inf - F1Score: 0.7025 - WeightedF1: 0.7317 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.8373 - WeightedF1: 0.8542 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.8724 - WeightedF1: 0.8873 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.8928 - WeightedF1: 0.9052 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9025 - WeightedF1: 0.9134 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9111 - WeightedF1: 0.9211 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9160 - WeightedF1: 0.9255 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9195 - WeightedF1: 0.9286 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9245 - WeightedF1: 0.9332 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9273 - WeightedF1: 0.9359 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9325 - WeightedF1: 0.9406 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9349 - WeightedF1: 0.9428 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9387 - WeightedF1: 0.9462 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9411 - WeightedF1: 0.9483 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9442 - WeightedF1: 0.9511 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9469 - WeightedF1: 0.9536 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9501 - WeightedF1: 0.9565 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9531 - WeightedF1: 0.9592 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9567 - WeightedF1: 0.9621 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9609 - WeightedF1: 0.9658 - lr: 1.1036e-04\n",
      "150/150 [==============================] - 1s 5ms/step\n",
      "  (fridge, washing machine, dish washer, microwave, kettle)  precision  \\\n",
      "0                                             fridge              1.00   \n",
      "1                                    washing machine              0.94   \n",
      "2                                        dish washer              0.93   \n",
      "3                                          microwave              0.97   \n",
      "4                                             kettle              0.94   \n",
      "5                                          micro avg              0.96   \n",
      "6                                          macro avg              0.96   \n",
      "7                                       weighted avg              0.96   \n",
      "8                                        samples avg              0.97   \n",
      "\n",
      "   recall  f1-score  support  \n",
      "0    1.00      1.00     3076  \n",
      "1    0.91      0.92     2515  \n",
      "2    0.84      0.88     1587  \n",
      "3    0.95      0.96     2226  \n",
      "4    0.94      0.94     2642  \n",
      "5    0.94      0.95    12046  \n",
      "6    0.93      0.94    12046  \n",
      "7    0.94      0.95    12046  \n",
      "8    0.95      0.95    12046  \n",
      "3000/3000 [==============================] - 14s 5ms/step\n",
      "  (fridge, washing machine, dish washer, microwave, kettle)  precision  \\\n",
      "0                                             fridge              0.70   \n",
      "1                                    washing machine              0.53   \n",
      "2                                        dish washer              0.55   \n",
      "3                                          microwave              0.68   \n",
      "4                                             kettle              0.74   \n",
      "5                                          micro avg              0.62   \n",
      "6                                          macro avg              0.64   \n",
      "7                                       weighted avg              0.65   \n",
      "8                                        samples avg              0.61   \n",
      "\n",
      "   recall  f1-score  support  \n",
      "0    0.16      0.26    59042  \n",
      "1    0.91      0.67    42164  \n",
      "2    0.73      0.63    41122  \n",
      "3    0.65      0.66    47816  \n",
      "4    0.91      0.82    49856  \n",
      "5    0.64      0.63   240000  \n",
      "6    0.67      0.61   240000  \n",
      "7    0.64      0.59   240000  \n",
      "8    0.62      0.59   240000  \n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "713/713 [==============================] - 38s 51ms/step - loss: inf - F1Score: 0.6897 - WeightedF1: 0.7184 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.7982 - WeightedF1: 0.8158 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.8524 - WeightedF1: 0.8674 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.8726 - WeightedF1: 0.8864 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.8830 - WeightedF1: 0.8959 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.8953 - WeightedF1: 0.9066 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9028 - WeightedF1: 0.9133 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9092 - WeightedF1: 0.9193 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9145 - WeightedF1: 0.9240 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9175 - WeightedF1: 0.9267 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9229 - WeightedF1: 0.9317 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9265 - WeightedF1: 0.9349 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9303 - WeightedF1: 0.9385 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9341 - WeightedF1: 0.9419 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9367 - WeightedF1: 0.9443 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9404 - WeightedF1: 0.9476 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9429 - WeightedF1: 0.9499 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9459 - WeightedF1: 0.9525 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9483 - WeightedF1: 0.9548 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9513 - WeightedF1: 0.9575 - lr: 1.1036e-04\n",
      "150/150 [==============================] - 1s 5ms/step\n",
      "  (fridge, washing machine, dish washer, microwave, kettle)  precision  \\\n",
      "0                                             fridge              1.00   \n",
      "1                                    washing machine              0.95   \n",
      "2                                        dish washer              0.94   \n",
      "3                                          microwave              0.98   \n",
      "4                                             kettle              0.93   \n",
      "5                                          micro avg              0.96   \n",
      "6                                          macro avg              0.96   \n",
      "7                                       weighted avg              0.96   \n",
      "8                                        samples avg              0.97   \n",
      "\n",
      "   recall  f1-score  support  \n",
      "0    1.00      1.00     2996  \n",
      "1    0.89      0.92     2488  \n",
      "2    0.78      0.85     1603  \n",
      "3    0.94      0.96     2237  \n",
      "4    0.94      0.94     2676  \n",
      "5    0.92      0.94    12000  \n",
      "6    0.91      0.93    12000  \n",
      "7    0.92      0.94    12000  \n",
      "8    0.94      0.95    12000  \n",
      "3000/3000 [==============================] - 15s 5ms/step\n",
      "  (fridge, washing machine, dish washer, microwave, kettle)  precision  \\\n",
      "0                                             fridge              0.75   \n",
      "1                                    washing machine              0.52   \n",
      "2                                        dish washer              0.59   \n",
      "3                                          microwave              0.65   \n",
      "4                                             kettle              0.68   \n",
      "5                                          micro avg              0.62   \n",
      "6                                          macro avg              0.64   \n",
      "7                                       weighted avg              0.65   \n",
      "8                                        samples avg              0.61   \n",
      "\n",
      "   recall  f1-score  support  \n",
      "0    0.31      0.44    59042  \n",
      "1    0.93      0.67    42164  \n",
      "2    0.63      0.61    41122  \n",
      "3    0.63      0.64    47816  \n",
      "4    0.93      0.79    49856  \n",
      "5    0.67      0.64   240000  \n",
      "6    0.69      0.63   240000  \n",
      "7    0.67      0.62   240000  \n",
      "8    0.64      0.60   240000  \n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "713/713 [==============================] - 38s 51ms/step - loss: inf - F1Score: 0.6661 - WeightedF1: 0.7018 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.7552 - WeightedF1: 0.7826 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.8236 - WeightedF1: 0.8404 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.8582 - WeightedF1: 0.8732 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.8755 - WeightedF1: 0.8900 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.8847 - WeightedF1: 0.8985 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.8953 - WeightedF1: 0.9074 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9040 - WeightedF1: 0.9151 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "713/713 [==============================] - 35s 50ms/step - loss: inf - F1Score: 0.9094 - WeightedF1: 0.9200 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9144 - WeightedF1: 0.9247 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9201 - WeightedF1: 0.9299 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9246 - WeightedF1: 0.9339 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9288 - WeightedF1: 0.9377 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9324 - WeightedF1: 0.9407 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9363 - WeightedF1: 0.9443 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9387 - WeightedF1: 0.9465 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9412 - WeightedF1: 0.9488 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9444 - WeightedF1: 0.9517 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9465 - WeightedF1: 0.9536 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "713/713 [==============================] - 35s 50ms/step - loss: inf - F1Score: 0.9495 - WeightedF1: 0.9563 - lr: 1.1036e-04\n",
      "150/150 [==============================] - 1s 5ms/step\n",
      "  (fridge, washing machine, dish washer, microwave, kettle)  precision  \\\n",
      "0                                             fridge              1.00   \n",
      "1                                    washing machine              0.94   \n",
      "2                                        dish washer              0.94   \n",
      "3                                          microwave              0.98   \n",
      "4                                             kettle              0.95   \n",
      "5                                          micro avg              0.97   \n",
      "6                                          macro avg              0.96   \n",
      "7                                       weighted avg              0.96   \n",
      "8                                        samples avg              0.97   \n",
      "\n",
      "   recall  f1-score  support  \n",
      "0    1.00      1.00     3069  \n",
      "1    0.89      0.92     2552  \n",
      "2    0.79      0.86     1565  \n",
      "3    0.94      0.96     2258  \n",
      "4    0.92      0.93     2654  \n",
      "5    0.92      0.94    12098  \n",
      "6    0.91      0.93    12098  \n",
      "7    0.92      0.94    12098  \n",
      "8    0.93      0.95    12098  \n",
      "3000/3000 [==============================] - 15s 5ms/step\n",
      "  (fridge, washing machine, dish washer, microwave, kettle)  precision  \\\n",
      "0                                             fridge              0.72   \n",
      "1                                    washing machine              0.52   \n",
      "2                                        dish washer              0.58   \n",
      "3                                          microwave              0.75   \n",
      "4                                             kettle              0.72   \n",
      "5                                          micro avg              0.64   \n",
      "6                                          macro avg              0.66   \n",
      "7                                       weighted avg              0.67   \n",
      "8                                        samples avg              0.61   \n",
      "\n",
      "   recall  f1-score  support  \n",
      "0    0.30      0.42    59042  \n",
      "1    0.91      0.67    42164  \n",
      "2    0.69      0.63    41122  \n",
      "3    0.46      0.57    47816  \n",
      "4    0.91      0.81    49856  \n",
      "5    0.63      0.63   240000  \n",
      "6    0.65      0.62   240000  \n",
      "7    0.63      0.61   240000  \n",
      "8    0.60      0.58   240000  \n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "713/713 [==============================] - 39s 51ms/step - loss: inf - F1Score: 0.6947 - WeightedF1: 0.7255 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.8150 - WeightedF1: 0.8318 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.8523 - WeightedF1: 0.8679 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.8683 - WeightedF1: 0.8832 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.8804 - WeightedF1: 0.8943 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.8936 - WeightedF1: 0.9051 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9009 - WeightedF1: 0.9120 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9072 - WeightedF1: 0.9176 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9132 - WeightedF1: 0.9232 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9169 - WeightedF1: 0.9266 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9227 - WeightedF1: 0.9317 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9273 - WeightedF1: 0.9359 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9300 - WeightedF1: 0.9384 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9338 - WeightedF1: 0.9419 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9375 - WeightedF1: 0.9452 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9395 - WeightedF1: 0.9469 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9427 - WeightedF1: 0.9498 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9456 - WeightedF1: 0.9525 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "713/713 [==============================] - 36s 51ms/step - loss: inf - F1Score: 0.9489 - WeightedF1: 0.9554 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9512 - WeightedF1: 0.9576 - lr: 1.1036e-04\n",
      "150/150 [==============================] - 1s 5ms/step\n",
      "  (fridge, washing machine, dish washer, microwave, kettle)  precision  \\\n",
      "0                                             fridge              1.00   \n",
      "1                                    washing machine              0.93   \n",
      "2                                        dish washer              0.90   \n",
      "3                                          microwave              0.98   \n",
      "4                                             kettle              0.94   \n",
      "5                                          micro avg              0.95   \n",
      "6                                          macro avg              0.95   \n",
      "7                                       weighted avg              0.95   \n",
      "8                                        samples avg              0.96   \n",
      "\n",
      "   recall  f1-score  support  \n",
      "0    1.00      1.00     3018  \n",
      "1    0.92      0.93     2478  \n",
      "2    0.85      0.87     1542  \n",
      "3    0.94      0.96     2212  \n",
      "4    0.93      0.93     2699  \n",
      "5    0.94      0.95    11949  \n",
      "6    0.93      0.94    11949  \n",
      "7    0.94      0.95    11949  \n",
      "8    0.95      0.95    11949  \n",
      "3000/3000 [==============================] - 15s 5ms/step\n",
      "  (fridge, washing machine, dish washer, microwave, kettle)  precision  \\\n",
      "0                                             fridge              0.80   \n",
      "1                                    washing machine              0.53   \n",
      "2                                        dish washer              0.56   \n",
      "3                                          microwave              0.74   \n",
      "4                                             kettle              0.71   \n",
      "5                                          micro avg              0.65   \n",
      "6                                          macro avg              0.67   \n",
      "7                                       weighted avg              0.68   \n",
      "8                                        samples avg              0.63   \n",
      "\n",
      "   recall  f1-score  support  \n",
      "0    0.53      0.64    59042  \n",
      "1    0.93      0.68    42164  \n",
      "2    0.57      0.57    41122  \n",
      "3    0.50      0.60    47816  \n",
      "4    0.92      0.80    49856  \n",
      "5    0.68      0.67   240000  \n",
      "6    0.69      0.66   240000  \n",
      "7    0.68      0.66   240000  \n",
      "8    0.66      0.62   240000  \n",
      "GRU enabled\n",
      "Epoch 1/20\n",
      "713/713 [==============================] - 38s 50ms/step - loss: inf - F1Score: 0.6673 - WeightedF1: 0.7054 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.7709 - WeightedF1: 0.7966 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.8349 - WeightedF1: 0.8509 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.8620 - WeightedF1: 0.8775 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.8780 - WeightedF1: 0.8929 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.8912 - WeightedF1: 0.9046 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "713/713 [==============================] - 35s 50ms/step - loss: inf - F1Score: 0.9001 - WeightedF1: 0.9123 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "713/713 [==============================] - 35s 49ms/step - loss: inf - F1Score: 0.8920 - WeightedF1: 0.9076 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9075 - WeightedF1: 0.9189 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9126 - WeightedF1: 0.9232 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9191 - WeightedF1: 0.9292 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9232 - WeightedF1: 0.9329 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9279 - WeightedF1: 0.9371 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "713/713 [==============================] - 35s 50ms/step - loss: inf - F1Score: 0.9310 - WeightedF1: 0.9399 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9345 - WeightedF1: 0.9430 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "713/713 [==============================] - 35s 50ms/step - loss: inf - F1Score: 0.9372 - WeightedF1: 0.9454 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9390 - WeightedF1: 0.9470 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9419 - WeightedF1: 0.9496 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "713/713 [==============================] - 35s 50ms/step - loss: inf - F1Score: 0.9448 - WeightedF1: 0.9523 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "713/713 [==============================] - 36s 50ms/step - loss: inf - F1Score: 0.9466 - WeightedF1: 0.9539 - lr: 1.1036e-04\n",
      "150/150 [==============================] - 1s 5ms/step\n",
      "  (fridge, washing machine, dish washer, microwave, kettle)  precision  \\\n",
      "0                                             fridge              1.00   \n",
      "1                                    washing machine              0.92   \n",
      "2                                        dish washer              0.95   \n",
      "3                                          microwave              0.98   \n",
      "4                                             kettle              0.93   \n",
      "5                                          micro avg              0.96   \n",
      "6                                          macro avg              0.96   \n",
      "7                                       weighted avg              0.96   \n",
      "8                                        samples avg              0.96   \n",
      "\n",
      "   recall  f1-score  support  \n",
      "0    0.99      1.00     3081  \n",
      "1    0.92      0.92     2501  \n",
      "2    0.77      0.85     1526  \n",
      "3    0.94      0.96     2214  \n",
      "4    0.95      0.94     2666  \n",
      "5    0.93      0.94    11988  \n",
      "6    0.91      0.93    11988  \n",
      "7    0.93      0.94    11988  \n",
      "8    0.94      0.95    11988  \n",
      "3000/3000 [==============================] - 15s 5ms/step\n",
      "  (fridge, washing machine, dish washer, microwave, kettle)  precision  \\\n",
      "0                                             fridge              0.76   \n",
      "1                                    washing machine              0.55   \n",
      "2                                        dish washer              0.54   \n",
      "3                                          microwave              0.67   \n",
      "4                                             kettle              0.70   \n",
      "5                                          micro avg              0.64   \n",
      "6                                          macro avg              0.65   \n",
      "7                                       weighted avg              0.66   \n",
      "8                                        samples avg              0.62   \n",
      "\n",
      "   recall  f1-score  support  \n",
      "0    0.38      0.51    59042  \n",
      "1    0.89      0.68    42164  \n",
      "2    0.54      0.54    41122  \n",
      "3    0.59      0.63    47816  \n",
      "4    0.92      0.80    49856  \n",
      "5    0.65      0.64   240000  \n",
      "6    0.67      0.63   240000  \n",
      "7    0.65      0.63   240000  \n",
      "8    0.63      0.60   240000  \n",
      " \n",
      " \n",
      " \n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      " \n",
      " \n",
      " \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:165\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[0;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/computation/expressions.py:241\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_numexpr:\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;66;03m# error: \"None\" not callable\u001b[39;00m\n\u001b[0;32m--> 241\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/computation/expressions.py:129\u001b[0m, in \u001b[0;36m_evaluate_numexpr\u001b[0;34m(op, op_str, a, b)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_evaluate_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/computation/expressions.py:70\u001b[0m, in \u001b[0;36m_evaluate_standard\u001b[0;34m(op, op_str, a, b)\u001b[0m\n\u001b[1;32m     69\u001b[0m     _store_test_result(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/roperator.py:11\u001b[0m, in \u001b[0;36mradd\u001b[0;34m(left, right)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mradd\u001b[39m(left, right):\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mright\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mleft\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'str'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 77\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     76\u001b[0m random_list \u001b[38;5;241m=\u001b[39m [df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1-score\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m7\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m df \u001b[38;5;129;01min\u001b[39;00m random_results[\u001b[38;5;241m1\u001b[39m]]\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMean = \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mNUK\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mListAverage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom_results\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Projects/NILM/NUK.py:428\u001b[0m, in \u001b[0;36mListAverage\u001b[0;34m(lst)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mListAverage\u001b[39m(lst):\n\u001b[1;32m    419\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;124;03m    This function returns the average number in the list\u001b[39;00m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;124;03m        avg (int): average number calculated from numbers in the list\u001b[39;00m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 428\u001b[0m     avg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlst\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(lst)\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m avg\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/ops/common.py:72\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     70\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/arraylike.py:106\u001b[0m, in \u001b[0;36mOpsMixin.__radd__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__radd__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__radd__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m--> 106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mradd\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:7591\u001b[0m, in \u001b[0;36mDataFrame._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   7587\u001b[0m other \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mmaybe_prepare_scalar_for_op(other, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[axis],))\n\u001b[1;32m   7589\u001b[0m \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39malign_method_FRAME(\u001b[38;5;28mself\u001b[39m, other, axis, flex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, level\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 7591\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch_frame_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   7592\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(new_data)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:7618\u001b[0m, in \u001b[0;36mDataFrame._dispatch_frame_op\u001b[0;34m(self, right, func, axis)\u001b[0m\n\u001b[1;32m   7615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(right):\n\u001b[1;32m   7616\u001b[0m     \u001b[38;5;66;03m# i.e. scalar, faster than checking np.ndim(right) == 0\u001b[39;00m\n\u001b[1;32m   7617\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 7618\u001b[0m         bm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   7619\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(bm)\n\u001b[1;32m   7621\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(right, DataFrame):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/internals/managers.py:350\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callable(f):\n\u001b[0;32m--> 350\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[43mb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    352\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/internals/blocks.py:351\u001b[0m, in \u001b[0;36mBlock.apply\u001b[0;34m(self, func, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;124;03m    apply the function to my values; return a block if we are not\u001b[39;00m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;124;03m    one\u001b[39;00m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_op_result(result)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:226\u001b[0m, in \u001b[0;36marithmetic_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    222\u001b[0m     _bool_arith_check(op, left, right)\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;66;03m# error: Argument 1 to \"_na_arithmetic_op\" has incompatible type\u001b[39;00m\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;66;03m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected \"ndarray[Any, Any]\"\u001b[39;00m\n\u001b[0;32m--> 226\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43m_na_arithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res_values\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:172\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[0;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cmp \u001b[38;5;129;01mand\u001b[39;00m (is_object_dtype(left\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mor\u001b[39;00m is_object_dtype(right)):\n\u001b[1;32m    168\u001b[0m         \u001b[38;5;66;03m# For object dtype, fallback to a masked operation (only operating\u001b[39;00m\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;66;03m#  on the non-missing values)\u001b[39;00m\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;66;03m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[1;32m    171\u001b[0m         \u001b[38;5;66;03m#  incorrectly, see GH#32047\u001b[39;00m\n\u001b[0;32m--> 172\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43m_masked_arith_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    174\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:129\u001b[0m, in \u001b[0;36m_masked_arith_op\u001b[0;34m(x, y, op)\u001b[0m\n\u001b[1;32m    126\u001b[0m         mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(y \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m, mask)\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m--> 129\u001b[0m         result[mask] \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxrav\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m np\u001b[38;5;241m.\u001b[39mputmask(result, \u001b[38;5;241m~\u001b[39mmask, np\u001b[38;5;241m.\u001b[39mnan)\n\u001b[1;32m    132\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape)  \u001b[38;5;66;03m# 2D compat\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/roperator.py:11\u001b[0m, in \u001b[0;36mradd\u001b[0;34m(left, right)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mradd\u001b[39m(left, right):\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mright\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mleft\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from sklearn.model_selection import KFold\n",
    "import pickle\n",
    "\n",
    "epochs = 20\n",
    "window_size = 2550\n",
    "batch_size = 128\n",
    "NmDevices = 5\n",
    "table_of_options = [1,2,3,4]\n",
    "\n",
    "# Define a learning rate scheduler function\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "\n",
    "# Load the datasets\n",
    "HolyDataset_UKD = pickle.load(open('./datasets/rawTS/HolyDatasetDALE.pkl', 'rb'))\n",
    "HolyDataset_REF = pickle.load(open('./datasets/rawTS/HolyDataset.pkl', 'rb'))\n",
    "\n",
    "x_UKD, y_UKD, labels_UKD = HolyDataset_UKD[0], HolyDataset_UKD[2], HolyDataset_UKD[4]\n",
    "class_weights_UKD = class_weights_tool(y_UKD)\n",
    "\n",
    "x_REF, y_REF, labels_REF = HolyDataset_REF[0], HolyDataset_REF[2], HolyDataset_REF[4]\n",
    "class_weights_REF = class_weights_tool(y_REF)\n",
    "\n",
    "# Set the number of folds\n",
    "n_folds = 20\n",
    "\n",
    "# Initialize the KFold cross-validator\n",
    "kf = KFold(n_splits=n_folds, shuffle=True)\n",
    "\n",
    "random_results = [\n",
    "    [],\n",
    "    []\n",
    "]\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "for train_idx, val_idx in kf.split(x_UKD):\n",
    "    x_train_UKD, x_val_UKD = x_UKD[train_idx], x_UKD[val_idx]\n",
    "    y_train_UKD, y_val_UKD = y_UKD[train_idx], y_UKD[val_idx]\n",
    "\n",
    "    model = TEST(0.7, NmDevices, window_size, 'gru', 128)\n",
    "    model.build((len(y_train_UKD) + len(y_val_UKD), window_size, 1))\n",
    "    #model.summary()\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003), loss='binary_crossentropy', metrics=[NUK.F1Score, NUK.WeightedF1Score(NUK.class_weights_tool(y_val_UKD))])\n",
    "    lr_scheduler = LearningRateScheduler(scheduler)\n",
    "    model.fit(x_train_UKD, y_train_UKD, batch_size=batch_size, epochs=epochs, class_weight=class_weights_UKD, callbacks=[lr_scheduler])\n",
    "\n",
    "    # Evaluate the model on the UKD dataset\n",
    "    y_pred_UKD = model.predict(x_val_UKD)\n",
    "    y_pred_tf_UKD = (y_pred_UKD > 0.5)\n",
    "    classification_report = metrics.classification_report(y_val_UKD, y_pred_tf_UKD, target_names=labels_UKD, zero_division=0)\n",
    "    classification_report_df = NUK.ClassificationReportToDF(classification_report, labels_UKD)\n",
    "    print(classification_report_df)\n",
    "    random_results[0].append(classification_report_df)\n",
    "    \n",
    "\n",
    "    # Evaluate the model on the REF dataset\n",
    "    y_pred_REF = model.predict(x_REF)\n",
    "    y_pred_tf_REF = (y_pred_REF > 0.5)\n",
    "    classification_report = metrics.classification_report(y_REF, y_pred_tf_REF, target_names=labels_REF, zero_division=0)\n",
    "    classification_report_df = NUK.ClassificationReportToDF(classification_report, labels_REF)\n",
    "    print(classification_report_df)\n",
    "    random_results[1].append(classification_report_df)\n",
    "    \n",
    "print(' ')\n",
    "print(' ')\n",
    "print(' ')\n",
    "print('||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||')\n",
    "print(' ')\n",
    "print(' ')\n",
    "print(' ')\n",
    "random_list = [df['f1-score'][7] for df in random_results[1]]\n",
    "print('Mean = ', NUK.ListAverage(random_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00096768-3702-4a64-934c-6698b15b377c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean =  0.6295\n"
     ]
    }
   ],
   "source": [
    "random_list = [df['f1-score'][7] for df in random_results[1]]\n",
    "print('Mean = ', NUK.ListAverage(random_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "109c5783-8084-4a6d-a2b6-8c43c555e42f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "750/750 [==============================] - 28s 36ms/step - loss: inf - F1Score: 0.4717 - WeightedF1: 0.4735 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "409/750 [===============>..............] - ETA: 12s - loss: inf - F1Score: 0.4712 - WeightedF1: 0.4729"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 45\u001b[0m\n\u001b[1;32m     43\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0003\u001b[39m),loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,metrics\u001b[38;5;241m=\u001b[39m[NUK\u001b[38;5;241m.\u001b[39mF1Score, NUK\u001b[38;5;241m.\u001b[39mWeightedF1Score(NUK\u001b[38;5;241m.\u001b[39mclass_weights_tool(y_test))])\n\u001b[1;32m     44\u001b[0m lr_scheduler \u001b[38;5;241m=\u001b[39m LearningRateScheduler(scheduler)\n\u001b[0;32m---> 45\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# |||||||||||||||||||||||||||||||| prediction ||||||||||||||||||||||||||||||||\u001b[39;00m\n\u001b[1;32m     47\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(x_test)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "               USES THE HOLY DATASET, OUR\n",
    "\"\"\"\n",
    "import NUK\n",
    "import importlib\n",
    "importlib.reload(NUK)\n",
    "import NUK\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "epochs = 20\n",
    "window_size = 2550\n",
    "batch_size = 128\n",
    "NmDevices = 5\n",
    "table_of_options = [1,2,3,4]\n",
    "\n",
    "\n",
    "\n",
    "# Define a learning rate scheduler function\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "\n",
    "\n",
    "\n",
    "HolyDataset = pickle.load(open('./datasets/rawTS/HolyDatasetDALE.pkl', 'rb'))\n",
    "\n",
    "x_train = HolyDataset[0]\n",
    "x_test = HolyDataset[1]\n",
    "y_train = HolyDataset[2]\n",
    "y_test = HolyDataset[3]\n",
    "labels = HolyDataset[4]\n",
    "\n",
    "class_weights = class_weights_tool(y_test)\n",
    "\n",
    "# |||||||||||||||||||||||||||||||| DL ||||||||||||||||||||||||||||||||\n",
    "#model = TEST(0.7, NmDevices, window_size, 'gru', 64)\n",
    "model = NUK.VGG11_1D(NmDevices, window_size)\n",
    "model.build((len(y_train)+len(y_test),window_size,1))\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003),loss='binary_crossentropy',metrics=[NUK.F1Score, NUK.WeightedF1Score(NUK.class_weights_tool(y_test))])\n",
    "lr_scheduler = LearningRateScheduler(scheduler)\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, class_weight=class_weights, callbacks=[lr_scheduler])\n",
    "# |||||||||||||||||||||||||||||||| prediction ||||||||||||||||||||||||||||||||\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_tf = (y_pred > 0.5)\n",
    "print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\n",
    "print(metrics.classification_report(y_test, y_pred_tf, target_names=labels, zero_division=0))\n",
    "print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fe4bcb-2ee0-4e8a-b55c-fa7f64accb14",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Trained on UK-DALE, tested on REFIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e14001b-a73b-4c7e-90cb-5af5e518fae1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 4s 4ms/step\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "PirnatEco2\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         fridge       0.65      0.19      0.29     14772\n",
      "washing machine       0.51      0.94      0.66     10509\n",
      "    dish washer       0.56      0.36      0.44     10465\n",
      "      microwave       0.73      0.37      0.49     11878\n",
      "         kettle       0.73      0.92      0.81     12376\n",
      "\n",
      "      micro avg       0.62      0.54      0.57     60000\n",
      "      macro avg       0.64      0.56      0.54     60000\n",
      "   weighted avg       0.64      0.54      0.53     60000\n",
      "    samples avg       0.58      0.51      0.52     60000\n",
      "\n",
      "0.5290041319920675\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "750/750 [==============================] - 49s 64ms/step\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "TanoniCRNN\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         fridge       0.71      0.13      0.22     14772\n",
      "washing machine       0.51      0.92      0.66     10509\n",
      "    dish washer       0.55      0.38      0.45     10465\n",
      "      microwave       0.51      0.78      0.62     11878\n",
      "         kettle       0.66      0.86      0.74     12376\n",
      "\n",
      "      micro avg       0.56      0.59      0.58     60000\n",
      "      macro avg       0.59      0.61      0.54     60000\n",
      "   weighted avg       0.60      0.59      0.52     60000\n",
      "    samples avg       0.54      0.56      0.53     60000\n",
      "\n",
      "0.522261612916714\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "750/750 [==============================] - 3s 4ms/step\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "VGG11\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         fridge       0.76      0.27      0.40     14772\n",
      "washing machine       0.52      0.86      0.65     10509\n",
      "    dish washer       0.51      0.40      0.45     10465\n",
      "      microwave       0.72      0.39      0.50     11878\n",
      "         kettle       0.71      0.90      0.79     12376\n",
      "\n",
      "      micro avg       0.62      0.55      0.58     60000\n",
      "      macro avg       0.64      0.56      0.56     60000\n",
      "   weighted avg       0.65      0.55      0.55     60000\n",
      "    samples avg       0.60      0.52      0.53     60000\n",
      "\n",
      "0.5527061969609696\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "750/750 [==============================] - 5s 5ms/step\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "PirnatEco3\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         fridge       0.77      0.49      0.60     14772\n",
      "washing machine       0.55      0.89      0.68     10509\n",
      "    dish washer       0.55      0.68      0.61     10465\n",
      "      microwave       0.70      0.61      0.65     11878\n",
      "         kettle       0.68      0.93      0.78     12376\n",
      "\n",
      "      micro avg       0.64      0.71      0.67     60000\n",
      "      macro avg       0.65      0.72      0.66     60000\n",
      "   weighted avg       0.66      0.71      0.66     60000\n",
      "    samples avg       0.62      0.68      0.62     60000\n",
      "\n",
      "0.6616147052674443\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "750/750 [==============================] - 4s 5ms/step\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "PirnatEco3.1\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         fridge       0.76      0.37      0.50     14772\n",
      "washing machine       0.53      0.91      0.67     10509\n",
      "    dish washer       0.57      0.65      0.61     10465\n",
      "      microwave       0.74      0.49      0.59     11878\n",
      "         kettle       0.72      0.92      0.81     12376\n",
      "\n",
      "      micro avg       0.64      0.65      0.65     60000\n",
      "      macro avg       0.67      0.67      0.63     60000\n",
      "   weighted avg       0.68      0.65      0.63     60000\n",
      "    samples avg       0.61      0.61      0.59     60000\n",
      "\n",
      "0.6283777967841014\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "750/750 [==============================] - 6s 7ms/step\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "PirnatEco4\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         fridge       0.82      0.24      0.38     14772\n",
      "washing machine       0.60      0.82      0.69     10509\n",
      "    dish washer       0.55      0.74      0.63     10465\n",
      "      microwave       0.66      0.69      0.68     11878\n",
      "         kettle       0.67      0.95      0.78     12376\n",
      "\n",
      "      micro avg       0.63      0.67      0.65     60000\n",
      "      macro avg       0.66      0.69      0.63     60000\n",
      "   weighted avg       0.67      0.67      0.62     60000\n",
      "    samples avg       0.62      0.64      0.61     60000\n",
      "\n",
      "0.6197275263727458\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "750/750 [==============================] - 4s 5ms/step\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "PirnatCross1\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         fridge       0.80      0.43      0.56     14772\n",
      "washing machine       0.54      0.88      0.67     10509\n",
      "    dish washer       0.55      0.67      0.61     10465\n",
      "      microwave       0.69      0.53      0.60     11878\n",
      "         kettle       0.71      0.93      0.80     12376\n",
      "\n",
      "      micro avg       0.64      0.67      0.66     60000\n",
      "      macro avg       0.66      0.69      0.65     60000\n",
      "   weighted avg       0.67      0.67      0.65     60000\n",
      "    samples avg       0.62      0.64      0.61     60000\n",
      "\n",
      "0.6465037504584835\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "               USES THE HOLY DATASET, OUR\n",
    "\"\"\"\n",
    "\n",
    "iteration = 10\n",
    "date = \"22.9.2022\"\n",
    "epochs = 20\n",
    "net_name = 'VGG191D'\n",
    "window_size = 2550\n",
    "batch_size = 128\n",
    "NmDevices = 5\n",
    "table_of_options = [1,2,3,4]\n",
    "gru = True\n",
    "gru_num = 64\n",
    "\n",
    "\n",
    "\n",
    "HolyDataset = pickle.load(open('./datasets/rawTS/HolyDataset.pkl', 'rb'))\n",
    "x_train = HolyDataset[0]\n",
    "x_test = HolyDataset[1]\n",
    "y_train = HolyDataset[2]\n",
    "y_test = HolyDataset[3]\n",
    "labels = HolyDataset[4]\n",
    "\n",
    "class_weights = class_weights_tool(y_test)\n",
    "\n",
    "# |||||||||||||||||||||||||||||||| DL ||||||||||||||||||||||||||||||||\n",
    "model = keras.models.load_model('./models/rawTS/HolyDataset/LOL2_DALE')\n",
    "# |||||||||||||||||||||||||||||||| prediction ||||||||||||||||||||||||||||||||\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_tf = (y_pred > 0.5)\n",
    "print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\n",
    "print(\"PirnatEco2\")\n",
    "print(metrics.classification_report(y_test, y_pred_tf, target_names=labels, zero_division=0))\n",
    "print(metrics.f1_score(y_test, \n",
    "                                   y_pred_tf, \n",
    "                                   labels=None, \n",
    "                                   pos_label=1, \n",
    "                                   average='weighted', \n",
    "                                   sample_weight=None, \n",
    "                                   zero_division=0))\n",
    "pickle.dump(metrics.f1_score(y_test, \n",
    "                                   y_pred_tf, \n",
    "                                   labels=None, \n",
    "                                   pos_label=1, \n",
    "                                   average='weighted', \n",
    "                                   sample_weight=None, \n",
    "                                   zero_division=0), \n",
    "            open('./datasets/rawTS/| HolyDataset |/LOL2_DALE.pkl', 'wb'))\n",
    "print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\n",
    "\n",
    "\n",
    "# |||||||||||||||||||||||||||||||| DL ||||||||||||||||||||||||||||||||\n",
    "model = keras.models.load_model('./models/rawTS/HolyDataset/Tanoni_DALE')\n",
    "# |||||||||||||||||||||||||||||||| prediction ||||||||||||||||||||||||||||||||\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_tf = (y_pred > 0.5)\n",
    "print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\n",
    "print(\"TanoniCRNN\")\n",
    "print(metrics.classification_report(y_test, y_pred_tf, target_names=labels, zero_division=0))\n",
    "print(metrics.f1_score(y_test, \n",
    "                                   y_pred_tf, \n",
    "                                   labels=None, \n",
    "                                   pos_label=1, \n",
    "                                   average='weighted', \n",
    "                                   sample_weight=None, \n",
    "                                   zero_division=0))\n",
    "pickle.dump(metrics.f1_score(y_test, \n",
    "                                   y_pred_tf, \n",
    "                                   labels=None, \n",
    "                                   pos_label=1, \n",
    "                                   average='weighted', \n",
    "                                   sample_weight=None, \n",
    "                                   zero_division=0), \n",
    "            open('./datasets/rawTS/| HolyDataset |/Tanoni_DALE.pkl', 'wb'))\n",
    "print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\n",
    "\n",
    "\n",
    "# |||||||||||||||||||||||||||||||| DL ||||||||||||||||||||||||||||||||\n",
    "model = keras.models.load_model('./models/rawTS/HolyDataset/VGG11_DALE')\n",
    "# |||||||||||||||||||||||||||||||| prediction ||||||||||||||||||||||||||||||||\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_tf = (y_pred > 0.5)\n",
    "print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\n",
    "print(\"VGG11\")\n",
    "print(metrics.classification_report(y_test, y_pred_tf, target_names=labels, zero_division=0))\n",
    "print(metrics.f1_score(y_test, \n",
    "                                   y_pred_tf, \n",
    "                                   labels=None, \n",
    "                                   pos_label=1, \n",
    "                                   average='weighted', \n",
    "                                   sample_weight=None, \n",
    "                                   zero_division=0))\n",
    "pickle.dump(metrics.f1_score(y_test, \n",
    "                                   y_pred_tf, \n",
    "                                   labels=None, \n",
    "                                   pos_label=1, \n",
    "                                   average='weighted', \n",
    "                                   sample_weight=None, \n",
    "                                   zero_division=0), \n",
    "            open('./datasets/rawTS/| HolyDataset |/VGG11_DALE.pkl', 'wb'))\n",
    "print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\n",
    "\n",
    "\n",
    "# |||||||||||||||||||||||||||||||| DL ||||||||||||||||||||||||||||||||\n",
    "model = keras.models.load_model('./models/rawTS/HolyDataset/LOL3_DALE')\n",
    "# |||||||||||||||||||||||||||||||| prediction ||||||||||||||||||||||||||||||||\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_tf = (y_pred > 0.5)\n",
    "print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\n",
    "print(\"PirnatEco3\")\n",
    "print(metrics.classification_report(y_test, y_pred_tf, target_names=labels, zero_division=0))\n",
    "print(metrics.f1_score(y_test, \n",
    "                                   y_pred_tf, \n",
    "                                   labels=None, \n",
    "                                   pos_label=1, \n",
    "                                   average='weighted', \n",
    "                                   sample_weight=None, \n",
    "                                   zero_division=0))\n",
    "pickle.dump(metrics.f1_score(y_test, \n",
    "                                   y_pred_tf, \n",
    "                                   labels=None, \n",
    "                                   pos_label=1, \n",
    "                                   average='weighted', \n",
    "                                   sample_weight=None, \n",
    "                                   zero_division=0), \n",
    "            open('./datasets/rawTS/| HolyDataset |/LOL3_DALE.pkl', 'wb'))\n",
    "print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\n",
    "\n",
    "\n",
    "# |||||||||||||||||||||||||||||||| DL ||||||||||||||||||||||||||||||||\n",
    "model = keras.models.load_model('./models/rawTS/HolyDataset/LOL3.1_DALE')\n",
    "# |||||||||||||||||||||||||||||||| prediction ||||||||||||||||||||||||||||||||\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_tf = (y_pred > 0.5)\n",
    "print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\n",
    "print(\"PirnatEco3.1\")\n",
    "print(metrics.classification_report(y_test, y_pred_tf, target_names=labels, zero_division=0))\n",
    "print(metrics.f1_score(y_test, \n",
    "                                   y_pred_tf, \n",
    "                                   labels=None, \n",
    "                                   pos_label=1, \n",
    "                                   average='weighted', \n",
    "                                   sample_weight=None, \n",
    "                                   zero_division=0))\n",
    "print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\n",
    "\n",
    "\n",
    "# |||||||||||||||||||||||||||||||| DL ||||||||||||||||||||||||||||||||\n",
    "model = keras.models.load_model('./models/rawTS/HolyDataset/LOL4_DALE')\n",
    "# |||||||||||||||||||||||||||||||| prediction ||||||||||||||||||||||||||||||||\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_tf = (y_pred > 0.5)\n",
    "print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\n",
    "print(\"PirnatEco4\")\n",
    "print(metrics.classification_report(y_test, y_pred_tf, target_names=labels, zero_division=0))\n",
    "print(metrics.f1_score(y_test, \n",
    "                                   y_pred_tf, \n",
    "                                   labels=None, \n",
    "                                   pos_label=1, \n",
    "                                   average='weighted', \n",
    "                                   sample_weight=None, \n",
    "                                   zero_division=0))\n",
    "print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\n",
    "\n",
    "\n",
    "# |||||||||||||||||||||||||||||||| DL ||||||||||||||||||||||||||||||||\n",
    "model = keras.models.load_model('./models/rawTS/HolyDataset/ComplexityAnalysis/PC1*0.7_DALE')\n",
    "# |||||||||||||||||||||||||||||||| prediction ||||||||||||||||||||||||||||||||\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_tf = (y_pred > 0.5)\n",
    "print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\n",
    "print(\"PirnatCross1\")\n",
    "print(metrics.classification_report(y_test, y_pred_tf, target_names=labels, zero_division=0))\n",
    "print(metrics.f1_score(y_test, \n",
    "                                   y_pred_tf, \n",
    "                                   labels=None, \n",
    "                                   pos_label=1, \n",
    "                                   average='weighted', \n",
    "                                   sample_weight=None, \n",
    "                                   zero_division=0))\n",
    "#pickle.dump(metrics.f1_score(y_test, \n",
    "#                                   y_pred_tf, \n",
    "#                                   labels=None, \n",
    "#                                   pos_label=1, \n",
    "#                                   average='weighted', \n",
    "#                                   sample_weight=None, \n",
    "#                                   zero_division=0), \n",
    "#            open('./datasets/rawTS/| HolyDataset |/LOL3_DALE.pkl', 'wb'))\n",
    "print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0d83f10-c3b4-495a-9610-f01f15170b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-14 16:42:35.059278: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-14 16:42:35.330920: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38336 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe MIG 3g.40gb, pci bus id: 0000:e1:00.0, compute capability: 8.0\n",
      "2023-05-14 16:42:38.872306: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8800\n",
      "2023-05-14 16:42:39.290463: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-05-14 16:42:39.291271: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-05-14 16:42:39.291288: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2023-05-14 16:42:39.291721: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-05-14 16:42:39.291781: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 4s 3ms/step\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "PirnatCross2\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         fridge       0.78      0.42      0.55     14772\n",
      "washing machine       0.57      0.88      0.70     10509\n",
      "    dish washer       0.55      0.65      0.60     10465\n",
      "      microwave       0.69      0.51      0.59     11878\n",
      "         kettle       0.74      0.92      0.82     12376\n",
      "\n",
      "      micro avg       0.66      0.66      0.66     60000\n",
      "      macro avg       0.67      0.68      0.65     60000\n",
      "   weighted avg       0.68      0.66      0.65     60000\n",
      "    samples avg       0.64      0.64      0.61     60000\n",
      "\n",
      "0.6453254201120794\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "               USES THE HOLY DATASET, OUR\n",
    "\"\"\"\n",
    "\n",
    "iteration = 10\n",
    "date = \"22.9.2022\"\n",
    "epochs = 20\n",
    "net_name = 'VGG191D'\n",
    "window_size = 2550\n",
    "batch_size = 128\n",
    "NmDevices = 5\n",
    "table_of_options = [1,2,3,4]\n",
    "gru = True\n",
    "gru_num = 64\n",
    "\n",
    "\n",
    "\n",
    "HolyDataset = pickle.load(open('./datasets/rawTS/HolyDataset.pkl', 'rb'))\n",
    "x_train = HolyDataset[0]\n",
    "x_test = HolyDataset[1]\n",
    "y_train = HolyDataset[2]\n",
    "y_test = HolyDataset[3]\n",
    "labels = HolyDataset[4]\n",
    "\n",
    "class_weights = class_weights_tool(y_test)\n",
    "\n",
    "# |||||||||||||||||||||||||||||||| DL ||||||||||||||||||||||||||||||||\n",
    "model = keras.models.load_model('./models/rawTS/HolyDataset/ComplexityAnalysis/PC1*0.5_DALE')\n",
    "# |||||||||||||||||||||||||||||||| prediction ||||||||||||||||||||||||||||||||\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_tf = (y_pred > 0.5)\n",
    "print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\n",
    "print(\"PirnatCross2\")\n",
    "print(metrics.classification_report(y_test, y_pred_tf, target_names=labels, zero_division=0))\n",
    "print(metrics.f1_score(y_test, \n",
    "                                   y_pred_tf, \n",
    "                                   labels=None, \n",
    "                                   pos_label=1, \n",
    "                                   average='weighted', \n",
    "                                   sample_weight=None, \n",
    "                                   zero_division=0))\n",
    "#pickle.dump(metrics.f1_score(y_test, \n",
    "#                                   y_pred_tf, \n",
    "#                                   labels=None, \n",
    "#                                   pos_label=1, \n",
    "#                                   average='weighted', \n",
    "#                                   sample_weight=None, \n",
    "#                                   zero_division=0), \n",
    "#            open('./datasets/rawTS/| HolyDataset |/LOL3_DALE.pkl', 'wb'))\n",
    "print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c960669-f1c4-447a-b60d-7ae4672516e4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Trained on REFIT and tested on UK-DALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d591f0fb-5c35-4293-ab81-de51024d742a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 4s 5ms/step\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "PirnatEco2\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         fridge       0.92      0.92      0.92     15058\n",
      "washing machine       0.57      0.85      0.68     12498\n",
      "    dish washer       0.59      0.72      0.65      7843\n",
      "      microwave       0.65      0.92      0.77     11228\n",
      "         kettle       0.79      0.74      0.76     13368\n",
      "\n",
      "      micro avg       0.70      0.84      0.77     59995\n",
      "      macro avg       0.70      0.83      0.76     59995\n",
      "   weighted avg       0.73      0.84      0.77     59995\n",
      "    samples avg       0.67      0.82      0.72     59995\n",
      "\n",
      "0.7711605793801147\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "750/750 [==============================] - 4s 5ms/step\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "PirnatEco3\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         fridge       0.89      0.99      0.94     15058\n",
      "washing machine       0.57      0.84      0.68     12498\n",
      "    dish washer       0.67      0.64      0.65      7843\n",
      "      microwave       0.61      0.95      0.74     11228\n",
      "         kettle       0.88      0.70      0.78     13368\n",
      "\n",
      "      micro avg       0.71      0.84      0.77     59995\n",
      "      macro avg       0.72      0.82      0.76     59995\n",
      "   weighted avg       0.74      0.84      0.77     59995\n",
      "    samples avg       0.68      0.82      0.72     59995\n",
      "\n",
      "0.7744563524158381\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "750/750 [==============================] - 3s 4ms/step\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "VGG11\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         fridge       0.90      0.93      0.92     15058\n",
      "washing machine       0.63      0.64      0.63     12498\n",
      "    dish washer       0.63      0.66      0.65      7843\n",
      "      microwave       0.56      0.87      0.68     11228\n",
      "         kettle       0.76      0.77      0.76     13368\n",
      "\n",
      "      micro avg       0.70      0.79      0.74     59995\n",
      "      macro avg       0.70      0.78      0.73     59995\n",
      "   weighted avg       0.71      0.79      0.75     59995\n",
      "    samples avg       0.68      0.77      0.70     59995\n",
      "\n",
      "0.7451157729557017\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "750/750 [==============================] - 44s 58ms/step\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Tanoni\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         fridge       0.98      0.99      0.99     15058\n",
      "washing machine       0.59      0.80      0.68     12498\n",
      "    dish washer       0.63      0.68      0.65      7843\n",
      "      microwave       0.58      0.95      0.72     11228\n",
      "         kettle       0.94      0.53      0.68     13368\n",
      "\n",
      "      micro avg       0.72      0.80      0.76     59995\n",
      "      macro avg       0.74      0.79      0.75     59995\n",
      "   weighted avg       0.77      0.80      0.76     59995\n",
      "    samples avg       0.70      0.80      0.72     59995\n",
      "\n",
      "0.7620940143783325\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "750/750 [==============================] - 4s 5ms/step\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "PirnatEco3\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         fridge       0.91      0.98      0.94     15058\n",
      "washing machine       0.58      0.83      0.68     12498\n",
      "    dish washer       0.80      0.59      0.68      7843\n",
      "      microwave       0.67      0.85      0.75     11228\n",
      "         kettle       0.84      0.72      0.78     13368\n",
      "\n",
      "      micro avg       0.74      0.82      0.78     59995\n",
      "      macro avg       0.76      0.80      0.77     59995\n",
      "   weighted avg       0.77      0.82      0.78     59995\n",
      "    samples avg       0.71      0.80      0.73     59995\n",
      "\n",
      "0.7806925971793661\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "               USES THE HOLY DATASET, OUR\n",
    "\"\"\"\n",
    "\n",
    "iteration = 10\n",
    "date = \"22.9.2022\"\n",
    "epochs = 20\n",
    "net_name = 'VGG191D'\n",
    "window_size = 2550\n",
    "batch_size = 128\n",
    "NmDevices = 5\n",
    "table_of_options = [1,2,3,4]\n",
    "gru = True\n",
    "gru_num = 64\n",
    "\n",
    "\n",
    "\n",
    "HolyDataset = pickle.load(open('./datasets/rawTS/HolyDatasetDALE.pkl', 'rb'))\n",
    "x_train = HolyDataset[0]\n",
    "x_test = HolyDataset[1]\n",
    "y_train = HolyDataset[2]\n",
    "y_test = HolyDataset[3]\n",
    "labels = HolyDataset[4]\n",
    "\n",
    "class_weights = class_weights_tool(y_test)\n",
    "\n",
    "# |||||||||||||||||||||||||||||||| DL ||||||||||||||||||||||||||||||||\n",
    "model = keras.models.load_model('./models/rawTS/HolyDataset/LOL2')\n",
    "# |||||||||||||||||||||||||||||||| prediction ||||||||||||||||||||||||||||||||\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_tf = (y_pred > 0.5)\n",
    "print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\n",
    "print(\"PirnatEco2\")\n",
    "print(metrics.classification_report(y_test, y_pred_tf, target_names=labels, zero_division=0))\n",
    "print(metrics.f1_score(y_test, \n",
    "                                   y_pred_tf, \n",
    "                                   labels=None, \n",
    "                                   pos_label=1, \n",
    "                                   average='weighted', \n",
    "                                   sample_weight=None, \n",
    "                                   zero_division=0))\n",
    "pickle.dump(metrics.f1_score(y_test, \n",
    "                                   y_pred_tf, \n",
    "                                   labels=None, \n",
    "                                   pos_label=1, \n",
    "                                   average='weighted', \n",
    "                                   sample_weight=None, \n",
    "                                   zero_division=0), \n",
    "            open('./datasets/rawTS/| HolyDataset |/LOL2.pkl', 'wb'))\n",
    "print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\n",
    "\n",
    "\n",
    "# |||||||||||||||||||||||||||||||| DL ||||||||||||||||||||||||||||||||\n",
    "model = keras.models.load_model('./models/rawTS/HolyDataset/LOL3')\n",
    "# |||||||||||||||||||||||||||||||| prediction ||||||||||||||||||||||||||||||||\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_tf = (y_pred > 0.5)\n",
    "print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\n",
    "print(\"PirnatEco3\")\n",
    "print(metrics.classification_report(y_test, y_pred_tf, target_names=labels, zero_division=0))\n",
    "print(metrics.f1_score(y_test, \n",
    "                                   y_pred_tf, \n",
    "                                   labels=None, \n",
    "                                   pos_label=1, \n",
    "                                   average='weighted', \n",
    "                                   sample_weight=None, \n",
    "                                   zero_division=0))\n",
    "pickle.dump(metrics.f1_score(y_test, \n",
    "                                   y_pred_tf, \n",
    "                                   labels=None, \n",
    "                                   pos_label=1, \n",
    "                                   average='weighted', \n",
    "                                   sample_weight=None, \n",
    "                                   zero_division=0), \n",
    "            open('./datasets/rawTS/| HolyDataset |/LOL3.pkl', 'wb'))\n",
    "print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\n",
    "\n",
    "\n",
    "# |||||||||||||||||||||||||||||||| DL ||||||||||||||||||||||||||||||||\n",
    "model = keras.models.load_model('./models/rawTS/HolyDataset/VGG11')\n",
    "# |||||||||||||||||||||||||||||||| prediction ||||||||||||||||||||||||||||||||\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_tf = (y_pred > 0.5)\n",
    "print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\n",
    "print(\"VGG11\")\n",
    "print(metrics.classification_report(y_test, y_pred_tf, target_names=labels, zero_division=0))\n",
    "print(metrics.f1_score(y_test, \n",
    "                                   y_pred_tf, \n",
    "                                   labels=None, \n",
    "                                   pos_label=1, \n",
    "                                   average='weighted', \n",
    "                                   sample_weight=None, \n",
    "                                   zero_division=0))\n",
    "pickle.dump(metrics.f1_score(y_test, \n",
    "                                   y_pred_tf, \n",
    "                                   labels=None, \n",
    "                                   pos_label=1, \n",
    "                                   average='weighted', \n",
    "                                   sample_weight=None, \n",
    "                                   zero_division=0), \n",
    "            open('./datasets/rawTS/| HolyDataset |/VGG11.pkl', 'wb'))\n",
    "print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\n",
    "\n",
    "\n",
    "# |||||||||||||||||||||||||||||||| DL ||||||||||||||||||||||||||||||||\n",
    "model = keras.models.load_model('./models/rawTS/HolyDataset/Tanoni')\n",
    "# |||||||||||||||||||||||||||||||| prediction ||||||||||||||||||||||||||||||||\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_tf = (y_pred > 0.5)\n",
    "print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\n",
    "print(\"Tanoni\")\n",
    "print(metrics.classification_report(y_test, y_pred_tf, target_names=labels, zero_division=0))\n",
    "print(metrics.f1_score(y_test, \n",
    "                                   y_pred_tf, \n",
    "                                   labels=None, \n",
    "                                   pos_label=1, \n",
    "                                   average='weighted', \n",
    "                                   sample_weight=None, \n",
    "                                   zero_division=0))\n",
    "pickle.dump(metrics.f1_score(y_test, \n",
    "                                   y_pred_tf, \n",
    "                                   labels=None, \n",
    "                                   pos_label=1, \n",
    "                                   average='weighted', \n",
    "                                   sample_weight=None, \n",
    "                                   zero_division=0), \n",
    "            open('./datasets/rawTS/| HolyDataset |/Tanoni.pkl', 'wb'))\n",
    "print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\n",
    "\n",
    "# |||||||||||||||||||||||||||||||| DL ||||||||||||||||||||||||||||||||\n",
    "model = keras.models.load_model('./models/rawTS/HolyDataset/ComplexityAnalysis/PC1*0.7')\n",
    "# |||||||||||||||||||||||||||||||| prediction ||||||||||||||||||||||||||||||||\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_tf = (y_pred > 0.5)\n",
    "print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\n",
    "print(\"PirnatEco3\")\n",
    "print(metrics.classification_report(y_test, y_pred_tf, target_names=labels, zero_division=0))\n",
    "print(metrics.f1_score(y_test, \n",
    "                                   y_pred_tf, \n",
    "                                   labels=None, \n",
    "                                   pos_label=1, \n",
    "                                   average='weighted', \n",
    "                                   sample_weight=None, \n",
    "                                   zero_division=0))\n",
    "#pickle.dump(metrics.f1_score(y_test, \n",
    "#                                   y_pred_tf, \n",
    "#                                   labels=None, \n",
    "#                                   pos_label=1, \n",
    "#                                   average='weighted', \n",
    "#                                   sample_weight=None, \n",
    "#                                   zero_division=0), \n",
    "#            open('./datasets/rawTS/| HolyDataset |/LOL3_DALE.pkl', 'wb'))\n",
    "print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5e47398-995b-4c63-a711-e30612f0a7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 3s 3ms/step\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "PirnatCross2\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         fridge       0.93      0.97      0.95     15058\n",
      "washing machine       0.57      0.80      0.67     12498\n",
      "    dish washer       0.63      0.67      0.65      7843\n",
      "      microwave       0.69      0.89      0.78     11228\n",
      "         kettle       0.82      0.69      0.75     13368\n",
      "\n",
      "      micro avg       0.73      0.82      0.77     59995\n",
      "      macro avg       0.73      0.80      0.76     59995\n",
      "   weighted avg       0.75      0.82      0.77     59995\n",
      "    samples avg       0.70      0.80      0.72     59995\n",
      "\n",
      "0.7738663997170039\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n"
     ]
    }
   ],
   "source": [
    "HolyDataset = pickle.load(open('./datasets/rawTS/HolyDatasetDALE.pkl', 'rb'))\n",
    "x_train = HolyDataset[0]\n",
    "x_test = HolyDataset[1]\n",
    "y_train = HolyDataset[2]\n",
    "y_test = HolyDataset[3]\n",
    "labels = HolyDataset[4]\n",
    "\n",
    "class_weights = class_weights_tool(y_test)\n",
    "\n",
    "# |||||||||||||||||||||||||||||||| DL ||||||||||||||||||||||||||||||||\n",
    "model = keras.models.load_model('./models/rawTS/HolyDataset/ComplexityAnalysis/PC1*0.5')\n",
    "# |||||||||||||||||||||||||||||||| prediction ||||||||||||||||||||||||||||||||\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_tf = (y_pred > 0.5)\n",
    "print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\n",
    "print(\"PirnatCross2\")\n",
    "print(metrics.classification_report(y_test, y_pred_tf, target_names=labels, zero_division=0))\n",
    "print(metrics.f1_score(y_test, \n",
    "                                   y_pred_tf, \n",
    "                                   labels=None, \n",
    "                                   pos_label=1, \n",
    "                                   average='weighted', \n",
    "                                   sample_weight=None, \n",
    "                                   zero_division=0))\n",
    "#pickle.dump(metrics.f1_score(y_test, \n",
    "#                                   y_pred_tf, \n",
    "#                                   labels=None, \n",
    "#                                   pos_label=1, \n",
    "#                                   average='weighted', \n",
    "#                                   sample_weight=None, \n",
    "#                                   zero_division=0), \n",
    "#            open('./datasets/rawTS/| HolyDataset |/LOL3_DALE.pkl', 'wb'))\n",
    "print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15a56b26-1e2b-43ee-807f-d6ff6642bbb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"TEST\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 2550, 1)]         0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv1D)       (None, 2550, 32)          128       \n",
      "                                                                 \n",
      " block1_conv2 (Conv1D)       (None, 2550, 32)          3104      \n",
      "                                                                 \n",
      " block1_pool (MaxPooling1D)  (None, 1275, 32)          0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv1D)       (None, 1275, 64)          6208      \n",
      "                                                                 \n",
      " block2_conv2 (Conv1D)       (None, 1275, 64)          12352     \n",
      "                                                                 \n",
      " block2_pool (MaxPooling1D)  (None, 637, 64)           0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv1D)       (None, 637, 128)          24704     \n",
      "                                                                 \n",
      " block3_conv2 (Conv1D)       (None, 637, 128)          49280     \n",
      "                                                                 \n",
      " block3_conv3 (Conv1D)       (None, 637, 128)          49280     \n",
      "                                                                 \n",
      " block3_conv4 (Conv1D)       (None, 637, 128)          49280     \n",
      "                                                                 \n",
      " block3_pool (MaxPooling1D)  (None, 318, 128)          0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv1D)       (None, 318, 256)          98560     \n",
      "                                                                 \n",
      " block4_conv2 (Conv1D)       (None, 318, 256)          196864    \n",
      "                                                                 \n",
      " block4_conv3 (Conv1D)       (None, 318, 256)          196864    \n",
      "                                                                 \n",
      " block4_conv4 (Conv1D)       (None, 318, 256)          196864    \n",
      "                                                                 \n",
      " block4_pool (MaxPooling1D)  (None, 159, 256)          0         \n",
      "                                                                 \n",
      " block5_tran_conv1 (Conv1DTr  (None, 159, 256)         196864    \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_tran_conv2 (Conv1DTr  (None, 159, 256)         196864    \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_tran_conv3 (Conv1DTr  (None, 159, 256)         196864    \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_tran_conv4 (Conv1DTr  (None, 159, 256)         196864    \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_pool (AveragePooling  (None, 79, 256)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " gru_7 (GRU)                 (None, 64)                61824     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              266240    \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 5)                 20485     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,800,805\n",
      "Trainable params: 18,800,805\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ccea6b-f5fa-4347-bb00-7ffe83b14d38",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89504bcd-5b30-4757-b78b-c05dbc4c7c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7744563524158381,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "ref_PC2 = pickle.load(open('./datasets/rawTS/| HolyDataset |/LOL3.pkl','rb')),\n",
    "#ref_PC2 = pickle.load(open('./datasets/rawTS/| HolyDataset |/Tanoni.pkl','rb')),\n",
    "#ref_PC2 = pickle.load(open('./datasets/rawTS/| HolyDataset |/VGG11.pkl','rb')),\n",
    "#ref_PC2 = pickle.load(open('./datasets/rawTS/| HolyDataset |/LOL2_DALE.pkl','rb')),\n",
    "#ref_PC2 = pickle.load(open('./datasets/rawTS/| HolyDataset |/Tanoni_DALE.pkl','rb')),\n",
    "#ref_PC2 = pickle.load(open('./datasets/rawTS/| HolyDataset |/VGG11_DALE.pkl','rb'))\n",
    "ref_PC2\n",
    "#[0.7679269918128679, 0.7711605793801147, 0.7620940143783325, 0.7451157729557017, 0.6363779589937109, 0.5290041319920675, 0.522261612916714, 0.5527061969609696]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0bbbdd03-50c9-4426-ae44-5051e5dcc285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7679269918128679, 0.7711605793801147, 0.7620940143783325, 0.7451157729557017, 0.6363779589937109, 0.5290041319920675, 0.522261612916714, 0.5527061969609696]\n",
      "[-0.0032335875672467873, 0.00583297743453548, 0.022811218857166193, 0.10737382700164333, 0.11411634607699683, 0.08367176203274129]\n",
      "5.51 %\n",
      "[0.7704236685467205, 0.7711605793801147, 0.7620940143783325, 0.7451157729557017, 0.6058517124537073, 0.5290041319920675, 0.522261612916714, 0.5527061969609696]\n",
      "[-0.000736910833394222, 0.008329654168388045, 0.02530789559101876, 0.07684758046163975, 0.08359009953699326, 0.053145515492737716]\n",
      "4.11 %\n",
      "[0.7738570352768156, 0.7711605793801147, 0.7620940143783325, 0.7451157729557017, 0.6453254201120794, 0.5290041319920675, 0.522261612916714, 0.5527061969609696]\n",
      "[0.0026964558967008667, 0.011763020898483134, 0.028741262321113847, 0.11632128812001186, 0.12306380719536536, 0.09261922315110982]\n",
      "6.25 %\n",
      "[0.7806925971793661, 0.7711605793801147, 0.7620940143783325, 0.7451157729557017, 0.6465227528300028, 0.5290041319920675, 0.522261612916714, 0.5527061969609696]\n",
      "[0.009532017799251391, 0.01859858280103366, 0.03557682422366437, 0.1175186208379353, 0.1242611399132888, 0.09381655586903326]\n",
      "6.66 %\n",
      "[0.7704840704683499, 0.7711605793801147, 0.7620940143783325, 0.7451157729557017, 0.6330287467674053, 0.5290041319920675, 0.522261612916714, 0.5527061969609696]\n",
      "[-0.0006765089117648504, 0.008390056090017417, 0.02536829751264813, 0.10402461477533775, 0.11076713385069126, 0.08032254980643572]\n",
      "5.47 %\n",
      "[0.7760211595398606, 0.7711605793801147, 0.7620940143783325, 0.7451157729557017, 0.5733920494143419, 0.5290041319920675, 0.522261612916714, 0.5527061969609696]\n",
      "[0.004860580159745886, 0.013927145161528154, 0.030905386584158867, 0.044387917422274326, 0.05113043649762783, 0.02068585245337229]\n",
      "2.76 %\n",
      "[0.7721638946239641, 0.7711605793801147, 0.7620940143783325, 0.7451157729557017, 0.6496605686214515, 0.5290041319920675, 0.522261612916714, 0.5527061969609696]\n",
      "[0.0010033152438493342, 0.010069880245631602, 0.027048121668262315, 0.12065643662938397, 0.12739895570473747, 0.09695437166048193]\n",
      "6.39 %\n",
      "[0.6618498806246019, 0.7711605793801147, 0.7620940143783325, 0.7451157729557017, 0.4895533912559791, 0.5290041319920675, 0.522261612916714, 0.5527061969609696]\n",
      "[-0.1093106987555128, -0.10024413375373054, -0.08326589233109982, -0.03945074073608845, -0.03270822166073495, -0.06315280570499049]\n",
      "-7.14 %\n",
      "[0.7848689190115881, 0.7711605793801147, 0.7620940143783325, 0.7451157729557017, 0.6009290381644974, 0.5290041319920675, 0.522261612916714, 0.5527061969609696]\n",
      "[0.013708339631473332, 0.0227749046332556, 0.03975314605588631, 0.07192490617242986, 0.07866742524778336, 0.04822284120352782]\n",
      "4.58 %\n",
      "[0.43495783859106, 0.7711605793801147, 0.7620940143783325, 0.7451157729557017, 0.2702555138805472, 0.5290041319920675, 0.522261612916714, 0.5527061969609696]\n",
      "[-0.3362027407890547, -0.32713617578727244, -0.31015793436464173, -0.25874861811152033, -0.25200609903616683, -0.28245068308042237]\n",
      "-29.45 %\n",
      "[0.4726756976341457, 0.7711605793801147, 0.7620940143783325, 0.7451157729557017, 0.43605691242071676, 0.5290041319920675, 0.522261612916714, 0.5527061969609696]\n",
      "[-0.29848488174596904, -0.2894183167441868, -0.27244007532155606, -0.09294721957135077, -0.08620470049599727, -0.1166492845402528]\n",
      "-19.27 %\n",
      "[0.31500359994918786, 0.7711605793801147, 0.7620940143783325, 0.7451157729557017, 0.2595595394230016, 0.5290041319920675, 0.522261612916714, 0.5527061969609696]\n",
      "[-0.45615697943092687, -0.4470904144291446, -0.4301121730065139, -0.26944459256906594, -0.26270207349371244, -0.293146657537968]\n",
      "-35.98 %\n",
      "[0.3362936932422124, 0.7711605793801147, 0.7620940143783325, 0.7451157729557017, 0.5578784143096115, 0.5290041319920675, 0.522261612916714, 0.5527061969609696]\n",
      "[-0.4348668861379023, -0.42580032113612004, -0.40882207971348933, 0.028874282317543964, 0.03561680139289747, 0.005172217348641928]\n",
      "-20.0 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "def avg(lst):\n",
    "    return sum(lst)/len(lst)\n",
    "# We make a list of weighted f1_scores that we saved from different models while testing on different datasets\n",
    "RU = pickle.load(open(f'./datasets/rawTS/| HolyDataset |/ComplexityAnalysis/R->U/RU.pkl', 'rb'))\n",
    "UR = pickle.load(open(f'./datasets/rawTS/| HolyDataset |/ComplexityAnalysis/U->R/UR.pkl', 'rb')) \n",
    "\n",
    "res_tab = []\n",
    "\n",
    "for j in range(len(RU)):\n",
    "    data = [\n",
    "        #pickle.load(open('./datasets/rawTS/| HolyDataset |/LOL3.pkl','rb')),\n",
    "        RU[j],\n",
    "        pickle.load(open('./datasets/rawTS/| HolyDataset |/LOL2.pkl','rb')),\n",
    "        pickle.load(open('./datasets/rawTS/| HolyDataset |/Tanoni.pkl','rb')),\n",
    "        pickle.load(open('./datasets/rawTS/| HolyDataset |/VGG11.pkl','rb')),\n",
    "\n",
    "        #pickle.load(open('./datasets/rawTS/| HolyDataset |/LOL3_DALE.pkl','rb')),\n",
    "        UR[j],\n",
    "        pickle.load(open('./datasets/rawTS/| HolyDataset |/LOL2_DALE.pkl','rb')),\n",
    "        pickle.load(open('./datasets/rawTS/| HolyDataset |/Tanoni_DALE.pkl','rb')),\n",
    "        pickle.load(open('./datasets/rawTS/| HolyDataset |/VGG11_DALE.pkl','rb'))\n",
    "    ]\n",
    "    results = []\n",
    "    for i in range(len(data)):\n",
    "        # when i = 0 or i = 4 we are on the PirnatCross1 f1_score\n",
    "        if i == 0 or i == 4:\n",
    "            continue\n",
    "        else: \n",
    "            # we calculate the difference between the scores from PirnatCross1 and other models and then append it to results tabel\n",
    "            if i < 4:\n",
    "                results.append(data[0]-data[i])\n",
    "            else:\n",
    "                results.append(data[4]-data[i])\n",
    "\n",
    "    print(data)\n",
    "    print(results)\n",
    "    print(f\"{round(avg(results)*100, 2)} %\")\n",
    "    res_tab.append(round(avg(results)*100, 2))\n",
    "    \n",
    "flops_tab = []\n",
    "test_koef = [0.1, 0.3, 0.5, 0.7, 0.9, 1.1, 1.3, 1.5, 1.7, 1.9, 2.1, 2.3, 2.5]\n",
    "for i in range(len(test_koef)):\n",
    "    flops_tab.append(round(test_koef[i]*1.92, 2))\n",
    "    \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\"\"\"\n",
    "    WE MAKE A GRAPH THAT HAS THE BEST KOEF MARKED\n",
    "\"\"\"\n",
    "G1, G2, G3, G4, G5 = '#5c5c5c', '#757575', '#8f8f8f', '#a8a8a8', '#b5b5b5'\n",
    "C1, C2, C3, C4 = '#2a3f78', '#7a72d2', '#96b5f6', '#3c2323'\n",
    "color_list = [G4]\n",
    "plt.rcParams['axes.prop_cycle'] = plt.cycler(color=color_list)\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()\n",
    "ax1.plot(flops_tab, res_tab, \"+\", linewidth = 2, label=\"trained: REFIT, tested: UK-DALE\")\n",
    "ax1.plot(flops_tab, res_tab, linewidth = 1)\n",
    "ax1.scatter(1.34, 6.66, zorder = 5, linewidth = 2, color = \"grey\")\n",
    "ax1.scatter(0.96, 6.25, zorder = 5, linewidth = 2, color = \"grey\")\n",
    "ax2.scatter(0.85, 53, zorder = 5, linewidth = 1, color = \"blue\", label = \"PirnatEco2\")\n",
    "ax2.scatter(0.85, 77, zorder = 5, linewidth = 1, color = \"blue\", label = \"PirnatEco2\")\n",
    "ax2.scatter(1.11, 52, zorder = 5, linewidth = 1, color = \"green\", label = \"Tanoni CRNN\")\n",
    "ax2.scatter(1.11, 76, zorder = 5, linewidth = 1, color = \"green\", label = \"Tanoni CRNN\")\n",
    "ax2.scatter(1.21, 55, zorder = 5, linewidth = 1, color = \"yellow\", label = \"VGG1\")\n",
    "ax2.scatter(1.21, 75, zorder = 5, linewidth = 1, color = \"yellow\", label = \"VGG1\")\n",
    "ax2.scatter(1.34, 78, zorder = 5, linewidth = 1, color = \"orange\", label = \"PirnatC\")\n",
    "ax2.scatter(1.34, 65, zorder = 5, linewidth = 1, color = \"orange\")\n",
    "ax2.scatter(0.96, 77, zorder = 5, linewidth = 1, color = \"red\")\n",
    "ax2.scatter(0.96, 65, zorder = 5, linewidth = 1, color = \"red\")\n",
    "\n",
    "ax1.set_ylabel('average improvement [percentage points]')\n",
    "ax2.set_ylabel('weighted F1 score [%]')\n",
    "plt.xlabel('GFLOPs')\n",
    "plt.xticks(flops_tab)  # set x-axis tick values\n",
    "ax1.set_yticks([-35,-30,-25,-20,-15,-10,-5,0,5,10])  # set x-axis tick values\n",
    "ax2.set_yticks([30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90])\n",
    "plt.legend()\n",
    "plt.savefig(\"FINAL_ANALYSIS4.pdf\")\n",
    "display(plt.show())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf72b864-4f32-4b21-a989-d5175b27693e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Complexity analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bbf822-582a-42a7-a9bf-e0fd49832efe",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "GRU enabled\n",
      "Model: \"TEST\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 2550, 1)]         0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv1D)       (None, 2550, 6)           24        \n",
      "                                                                 \n",
      " block1_conv2 (Conv1D)       (None, 2550, 6)           114       \n",
      "                                                                 \n",
      " block1_pool (MaxPooling1D)  (None, 1275, 6)           0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv1D)       (None, 1275, 12)          228       \n",
      "                                                                 \n",
      " block2_conv2 (Conv1D)       (None, 1275, 12)          444       \n",
      "                                                                 \n",
      " block2_pool (MaxPooling1D)  (None, 637, 12)           0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv1D)       (None, 637, 25)           925       \n",
      "                                                                 \n",
      " block3_conv2 (Conv1D)       (None, 637, 25)           1900      \n",
      "                                                                 \n",
      " block3_conv3 (Conv1D)       (None, 637, 25)           1900      \n",
      "                                                                 \n",
      " block3_conv4 (Conv1D)       (None, 637, 25)           1900      \n",
      "                                                                 \n",
      " block3_pool (MaxPooling1D)  (None, 318, 25)           0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv1D)       (None, 318, 51)           3876      \n",
      "                                                                 \n",
      " block4_conv2 (Conv1D)       (None, 318, 51)           7854      \n",
      "                                                                 \n",
      " block4_conv3 (Conv1D)       (None, 318, 51)           7854      \n",
      "                                                                 \n",
      " block4_conv4 (Conv1D)       (None, 318, 51)           7854      \n",
      "                                                                 \n",
      " block4_pool (MaxPooling1D)  (None, 159, 51)           0         \n",
      "                                                                 \n",
      " block5_tran_conv1 (Conv1DTr  (None, 159, 51)          7854      \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_tran_conv2 (Conv1DTr  (None, 159, 51)          7854      \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_tran_conv3 (Conv1DTr  (None, 159, 51)          7854      \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_tran_conv4 (Conv1DTr  (None, 159, 51)          7854      \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_pool (AveragePooling  (None, 79, 51)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " gru_4 (GRU)                 (None, 64)                22464     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              266240    \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 5)                 20485     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,156,790\n",
      "Trainable params: 17,156,790\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "750/750 [==============================] - 12s 14ms/step - loss: inf - accuracy: 0.4372 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "750/750 [==============================] - 11s 15ms/step - loss: inf - accuracy: 0.4773 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "750/750 [==============================] - 11s 14ms/step - loss: inf - accuracy: 0.5077 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "750/750 [==============================] - 11s 14ms/step - loss: inf - accuracy: 0.5258 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "750/750 [==============================] - 11s 14ms/step - loss: inf - accuracy: 0.5374 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "750/750 [==============================] - 10s 14ms/step - loss: inf - accuracy: 0.5473 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "750/750 [==============================] - 10s 14ms/step - loss: inf - accuracy: 0.5567 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "750/750 [==============================] - 10s 14ms/step - loss: inf - accuracy: 0.5670 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "750/750 [==============================] - 10s 14ms/step - loss: inf - accuracy: 0.5773 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "750/750 [==============================] - 10s 13ms/step - loss: inf - accuracy: 0.5844 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "750/750 [==============================] - 11s 14ms/step - loss: inf - accuracy: 0.5941 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "750/750 [==============================] - 11s 14ms/step - loss: inf - accuracy: 0.5992 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "750/750 [==============================] - 11s 14ms/step - loss: inf - accuracy: 0.6063 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "750/750 [==============================] - 10s 13ms/step - loss: inf - accuracy: 0.6138 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "750/750 [==============================] - 10s 13ms/step - loss: inf - accuracy: 0.6181 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "750/750 [==============================] - 10s 13ms/step - loss: inf - accuracy: 0.6228 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "750/750 [==============================] - 10s 14ms/step - loss: inf - accuracy: 0.6264 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "750/750 [==============================] - 10s 14ms/step - loss: inf - accuracy: 0.6306 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "750/750 [==============================] - 10s 14ms/step - loss: inf - accuracy: 0.6334 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "750/750 [==============================] - 11s 14ms/step - loss: inf - accuracy: 0.6378 - lr: 1.1036e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 18). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/rawTS/HolyDataset/ComplexityAnalysisAL/PC1*0.1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/rawTS/HolyDataset/ComplexityAnalysisAL/PC1*0.1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 3s 3ms/step\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "PC1*0.1\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         fridge       0.90      0.89      0.90     14772\n",
      "washing machine       0.89      0.76      0.82     10509\n",
      "    dish washer       0.86      0.70      0.77     10465\n",
      "      microwave       0.86      0.82      0.84     11878\n",
      "         kettle       0.95      0.91      0.93     12376\n",
      "\n",
      "      micro avg       0.90      0.82      0.86     60000\n",
      "      macro avg       0.89      0.82      0.85     60000\n",
      "   weighted avg       0.89      0.82      0.86     60000\n",
      "    samples avg       0.90      0.84      0.85     60000\n",
      "\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "750/750 [==============================] - 2s 3ms/step\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "PC1*0.1\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         fridge       0.95      0.96      0.96     15058\n",
      "washing machine       0.57      0.79      0.67     12498\n",
      "    dish washer       0.67      0.63      0.65      7843\n",
      "      microwave       0.65      0.91      0.76     11228\n",
      "         kettle       0.77      0.78      0.77     13368\n",
      "\n",
      "      micro avg       0.72      0.83      0.77     59995\n",
      "      macro avg       0.72      0.81      0.76     59995\n",
      "   weighted avg       0.74      0.83      0.78     59995\n",
      "    samples avg       0.70      0.81      0.73     59995\n",
      "\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "0.3\n",
      "GRU enabled\n",
      "Model: \"TEST\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 2550, 1)]         0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv1D)       (None, 2550, 19)          76        \n",
      "                                                                 \n",
      " block1_conv2 (Conv1D)       (None, 2550, 19)          1102      \n",
      "                                                                 \n",
      " block1_pool (MaxPooling1D)  (None, 1275, 19)          0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv1D)       (None, 1275, 38)          2204      \n",
      "                                                                 \n",
      " block2_conv2 (Conv1D)       (None, 1275, 38)          4370      \n",
      "                                                                 \n",
      " block2_pool (MaxPooling1D)  (None, 637, 38)           0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv1D)       (None, 637, 76)           8740      \n",
      "                                                                 \n",
      " block3_conv2 (Conv1D)       (None, 637, 76)           17404     \n",
      "                                                                 \n",
      " block3_conv3 (Conv1D)       (None, 637, 76)           17404     \n",
      "                                                                 \n",
      " block3_conv4 (Conv1D)       (None, 637, 76)           17404     \n",
      "                                                                 \n",
      " block3_pool (MaxPooling1D)  (None, 318, 76)           0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv1D)       (None, 318, 153)          35037     \n",
      "                                                                 \n",
      " block4_conv2 (Conv1D)       (None, 318, 153)          70380     \n",
      "                                                                 \n",
      " block4_conv3 (Conv1D)       (None, 318, 153)          70380     \n",
      "                                                                 \n",
      " block4_conv4 (Conv1D)       (None, 318, 153)          70380     \n",
      "                                                                 \n",
      " block4_pool (MaxPooling1D)  (None, 159, 153)          0         \n",
      "                                                                 \n",
      " block5_tran_conv1 (Conv1DTr  (None, 159, 153)         70380     \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_tran_conv2 (Conv1DTr  (None, 159, 153)         70380     \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_tran_conv3 (Conv1DTr  (None, 159, 153)         70380     \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_tran_conv4 (Conv1DTr  (None, 159, 153)         70380     \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_pool (AveragePooling  (None, 79, 153)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " gru_5 (GRU)                 (None, 64)                42048     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              266240    \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 5)                 20485     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,706,486\n",
      "Trainable params: 17,706,486\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "750/750 [==============================] - 20s 23ms/step - loss: inf - accuracy: 0.4717 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "750/750 [==============================] - 17s 23ms/step - loss: inf - accuracy: 0.4942 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "750/750 [==============================] - 17s 23ms/step - loss: inf - accuracy: 0.5242 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "750/750 [==============================] - 18s 23ms/step - loss: inf - accuracy: 0.5562 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "750/750 [==============================] - 18s 24ms/step - loss: inf - accuracy: 0.5752 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "750/750 [==============================] - 18s 24ms/step - loss: inf - accuracy: 0.5916 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "750/750 [==============================] - 18s 24ms/step - loss: inf - accuracy: 0.6063 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "750/750 [==============================] - 18s 23ms/step - loss: inf - accuracy: 0.6060 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "750/750 [==============================] - 17s 23ms/step - loss: inf - accuracy: 0.6122 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "750/750 [==============================] - 17s 23ms/step - loss: inf - accuracy: 0.6179 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "750/750 [==============================] - 17s 23ms/step - loss: inf - accuracy: 0.6211 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "750/750 [==============================] - 18s 24ms/step - loss: inf - accuracy: 0.6277 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "750/750 [==============================] - 18s 24ms/step - loss: inf - accuracy: 0.6396 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "750/750 [==============================] - 18s 23ms/step - loss: inf - accuracy: 0.6466 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "750/750 [==============================] - 17s 23ms/step - loss: inf - accuracy: 0.6649 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "750/750 [==============================] - 17s 23ms/step - loss: inf - accuracy: 0.6733 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "750/750 [==============================] - 17s 23ms/step - loss: inf - accuracy: 0.6823 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "750/750 [==============================] - 18s 23ms/step - loss: inf - accuracy: 0.6957 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "750/750 [==============================] - 17s 23ms/step - loss: inf - accuracy: 0.7044 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "750/750 [==============================] - 18s 24ms/step - loss: inf - accuracy: 0.7153 - lr: 1.1036e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 18). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/rawTS/HolyDataset/ComplexityAnalysisAL/PC1*0.3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/rawTS/HolyDataset/ComplexityAnalysisAL/PC1*0.3/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 3s 3ms/step\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "PC1*0.3\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         fridge       0.91      0.93      0.92     14772\n",
      "washing machine       0.91      0.83      0.87     10509\n",
      "    dish washer       0.89      0.81      0.85     10465\n",
      "      microwave       0.92      0.86      0.88     11878\n",
      "         kettle       0.97      0.93      0.95     12376\n",
      "\n",
      "      micro avg       0.92      0.88      0.90     60000\n",
      "      macro avg       0.92      0.87      0.89     60000\n",
      "   weighted avg       0.92      0.88      0.90     60000\n",
      "    samples avg       0.93      0.90      0.90     60000\n",
      "\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "750/750 [==============================] - 3s 3ms/step\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "PC1*0.3\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         fridge       0.93      0.97      0.95     15058\n",
      "washing machine       0.58      0.81      0.68     12498\n",
      "    dish washer       0.68      0.64      0.66      7843\n",
      "      microwave       0.63      0.94      0.75     11228\n",
      "         kettle       0.75      0.76      0.76     13368\n",
      "\n",
      "      micro avg       0.71      0.84      0.77     59995\n",
      "      macro avg       0.71      0.83      0.76     59995\n",
      "   weighted avg       0.73      0.84      0.77     59995\n",
      "    samples avg       0.68      0.82      0.72     59995\n",
      "\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "0.5\n",
      "GRU enabled\n",
      "Model: \"TEST\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 2550, 1)]         0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv1D)       (None, 2550, 32)          128       \n",
      "                                                                 \n",
      " block1_conv2 (Conv1D)       (None, 2550, 32)          3104      \n",
      "                                                                 \n",
      " block1_pool (MaxPooling1D)  (None, 1275, 32)          0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv1D)       (None, 1275, 64)          6208      \n",
      "                                                                 \n",
      " block2_conv2 (Conv1D)       (None, 1275, 64)          12352     \n",
      "                                                                 \n",
      " block2_pool (MaxPooling1D)  (None, 637, 64)           0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv1D)       (None, 637, 128)          24704     \n",
      "                                                                 \n",
      " block3_conv2 (Conv1D)       (None, 637, 128)          49280     \n",
      "                                                                 \n",
      " block3_conv3 (Conv1D)       (None, 637, 128)          49280     \n",
      "                                                                 \n",
      " block3_conv4 (Conv1D)       (None, 637, 128)          49280     \n",
      "                                                                 \n",
      " block3_pool (MaxPooling1D)  (None, 318, 128)          0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv1D)       (None, 318, 256)          98560     \n",
      "                                                                 \n",
      " block4_conv2 (Conv1D)       (None, 318, 256)          196864    \n",
      "                                                                 \n",
      " block4_conv3 (Conv1D)       (None, 318, 256)          196864    \n",
      "                                                                 \n",
      " block4_conv4 (Conv1D)       (None, 318, 256)          196864    \n",
      "                                                                 \n",
      " block4_pool (MaxPooling1D)  (None, 159, 256)          0         \n",
      "                                                                 \n",
      " block5_tran_conv1 (Conv1DTr  (None, 159, 256)         196864    \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_tran_conv2 (Conv1DTr  (None, 159, 256)         196864    \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_tran_conv3 (Conv1DTr  (None, 159, 256)         196864    \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_tran_conv4 (Conv1DTr  (None, 159, 256)         196864    \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_pool (AveragePooling  (None, 79, 256)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " gru_6 (GRU)                 (None, 64)                61824     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              266240    \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 5)                 20485     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,800,805\n",
      "Trainable params: 18,800,805\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "750/750 [==============================] - 22s 23ms/step - loss: inf - accuracy: 0.5032 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "750/750 [==============================] - 18s 23ms/step - loss: inf - accuracy: 0.5194 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "750/750 [==============================] - 18s 23ms/step - loss: inf - accuracy: 0.5445 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "750/750 [==============================] - 18s 23ms/step - loss: inf - accuracy: 0.5712 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "750/750 [==============================] - 18s 23ms/step - loss: inf - accuracy: 0.5912 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "750/750 [==============================] - 18s 23ms/step - loss: inf - accuracy: 0.6060 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "750/750 [==============================] - 17s 23ms/step - loss: inf - accuracy: 0.6126 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "750/750 [==============================] - 17s 23ms/step - loss: inf - accuracy: 0.6138 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "750/750 [==============================] - 17s 23ms/step - loss: inf - accuracy: 0.6205 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "750/750 [==============================] - 17s 23ms/step - loss: inf - accuracy: 0.6272 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "750/750 [==============================] - 17s 23ms/step - loss: inf - accuracy: 0.6349 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "750/750 [==============================] - 18s 23ms/step - loss: inf - accuracy: 0.6394 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "750/750 [==============================] - 17s 23ms/step - loss: inf - accuracy: 0.6522 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "750/750 [==============================] - 17s 23ms/step - loss: inf - accuracy: 0.6615 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "750/750 [==============================] - 17s 23ms/step - loss: inf - accuracy: 0.6797 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "750/750 [==============================] - 17s 23ms/step - loss: inf - accuracy: 0.6946 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "750/750 [==============================] - 17s 23ms/step - loss: inf - accuracy: 0.7055 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "750/750 [==============================] - 17s 23ms/step - loss: inf - accuracy: 0.7229 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "750/750 [==============================] - 17s 23ms/step - loss: inf - accuracy: 0.7392 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "750/750 [==============================] - 17s 23ms/step - loss: inf - accuracy: 0.7543 - lr: 1.1036e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 18). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/rawTS/HolyDataset/ComplexityAnalysisAL/PC1*0.5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/rawTS/HolyDataset/ComplexityAnalysisAL/PC1*0.5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 3s 3ms/step\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "PC1*0.5\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         fridge       0.93      0.92      0.93     14772\n",
      "washing machine       0.90      0.86      0.88     10509\n",
      "    dish washer       0.89      0.83      0.86     10465\n",
      "      microwave       0.92      0.86      0.89     11878\n",
      "         kettle       0.95      0.95      0.95     12376\n",
      "\n",
      "      micro avg       0.92      0.89      0.90     60000\n",
      "      macro avg       0.92      0.88      0.90     60000\n",
      "   weighted avg       0.92      0.89      0.90     60000\n",
      "    samples avg       0.93      0.91      0.91     60000\n",
      "\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "750/750 [==============================] - 3s 3ms/step\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "PC1*0.5\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         fridge       0.93      0.94      0.93     15058\n",
      "washing machine       0.57      0.83      0.68     12498\n",
      "    dish washer       0.58      0.70      0.63      7843\n",
      "      microwave       0.65      0.89      0.75     11228\n",
      "         kettle       0.79      0.76      0.78     13368\n",
      "\n",
      "      micro avg       0.70      0.84      0.76     59995\n",
      "      macro avg       0.70      0.82      0.75     59995\n",
      "   weighted avg       0.73      0.84      0.77     59995\n",
      "    samples avg       0.68      0.81      0.71     59995\n",
      "\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "0.7\n",
      "GRU enabled\n",
      "Model: \"TEST\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 2550, 1)]         0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv1D)       (None, 2550, 44)          176       \n",
      "                                                                 \n",
      " block1_conv2 (Conv1D)       (None, 2550, 44)          5852      \n",
      "                                                                 \n",
      " block1_pool (MaxPooling1D)  (None, 1275, 44)          0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv1D)       (None, 1275, 89)          11837     \n",
      "                                                                 \n",
      " block2_conv2 (Conv1D)       (None, 1275, 89)          23852     \n",
      "                                                                 \n",
      " block2_pool (MaxPooling1D)  (None, 637, 89)           0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv1D)       (None, 637, 179)          47972     \n",
      "                                                                 \n",
      " block3_conv2 (Conv1D)       (None, 637, 179)          96302     \n",
      "                                                                 \n",
      " block3_conv3 (Conv1D)       (None, 637, 179)          96302     \n",
      "                                                                 \n",
      " block3_conv4 (Conv1D)       (None, 637, 179)          96302     \n",
      "                                                                 \n",
      " block3_pool (MaxPooling1D)  (None, 318, 179)          0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv1D)       (None, 318, 358)          192604    \n",
      "                                                                 \n",
      " block4_conv2 (Conv1D)       (None, 318, 358)          384850    \n",
      "                                                                 \n",
      " block4_conv3 (Conv1D)       (None, 318, 358)          384850    \n",
      "                                                                 \n",
      " block4_conv4 (Conv1D)       (None, 318, 358)          384850    \n",
      "                                                                 \n",
      " block4_pool (MaxPooling1D)  (None, 159, 358)          0         \n",
      "                                                                 \n",
      " block5_tran_conv1 (Conv1DTr  (None, 159, 358)         384850    \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_tran_conv2 (Conv1DTr  (None, 159, 358)         384850    \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_tran_conv3 (Conv1DTr  (None, 159, 358)         384850    \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_tran_conv4 (Conv1DTr  (None, 159, 358)         384850    \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_pool (AveragePooling  (None, 79, 358)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " gru_7 (GRU)                 (None, 64)                81408     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              266240    \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 5)                 20485     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,414,594\n",
      "Trainable params: 20,414,594\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "750/750 [==============================] - 43s 50ms/step - loss: inf - accuracy: 0.5167 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "750/750 [==============================] - 37s 50ms/step - loss: inf - accuracy: 0.5356 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "750/750 [==============================] - 38s 50ms/step - loss: inf - accuracy: 0.5735 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "750/750 [==============================] - 38s 50ms/step - loss: inf - accuracy: 0.5882 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "750/750 [==============================] - 38s 50ms/step - loss: inf - accuracy: 0.6015 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "750/750 [==============================] - 38s 50ms/step - loss: inf - accuracy: 0.6034 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "750/750 [==============================] - 38s 50ms/step - loss: inf - accuracy: 0.6093 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "750/750 [==============================] - 38s 50ms/step - loss: inf - accuracy: 0.6131 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "750/750 [==============================] - 38s 50ms/step - loss: inf - accuracy: 0.6210 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "750/750 [==============================] - 38s 50ms/step - loss: inf - accuracy: 0.6310 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "750/750 [==============================] - 37s 50ms/step - loss: inf - accuracy: 0.6473 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "750/750 [==============================] - 38s 50ms/step - loss: inf - accuracy: 0.6662 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "750/750 [==============================] - 38s 50ms/step - loss: inf - accuracy: 0.6788 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "750/750 [==============================] - 38s 50ms/step - loss: inf - accuracy: 0.7068 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "750/750 [==============================] - 38s 50ms/step - loss: inf - accuracy: 0.7248 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "750/750 [==============================] - 38s 50ms/step - loss: inf - accuracy: 0.7433 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "750/750 [==============================] - 38s 50ms/step - loss: inf - accuracy: 0.7596 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "750/750 [==============================] - 47s 63ms/step - loss: inf - accuracy: 0.6564 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "750/750 [==============================] - 47s 63ms/step - loss: inf - accuracy: 0.6716 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "750/750 [==============================] - 46s 62ms/step - loss: inf - accuracy: 0.6877 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "750/750 [==============================] - 46s 62ms/step - loss: inf - accuracy: 0.7076 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "750/750 [==============================] - 47s 63ms/step - loss: inf - accuracy: 0.7242 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "750/750 [==============================] - 47s 63ms/step - loss: inf - accuracy: 0.7420 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "750/750 [==============================] - 47s 63ms/step - loss: inf - accuracy: 0.7623 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "750/750 [==============================] - 47s 63ms/step - loss: inf - accuracy: 0.7783 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "750/750 [==============================] - 47s 63ms/step - loss: inf - accuracy: 0.7943 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "750/750 [==============================] - 47s 63ms/step - loss: inf - accuracy: 0.8083 - lr: 1.1036e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 18). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/rawTS/HolyDataset/ComplexityAnalysisAL/PC1*0.9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/rawTS/HolyDataset/ComplexityAnalysisAL/PC1*0.9/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 5s 6ms/step\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "PC1*0.9\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         fridge       0.92      0.93      0.93     14772\n",
      "washing machine       0.89      0.88      0.89     10509\n",
      "    dish washer       0.88      0.85      0.86     10465\n",
      "      microwave       0.91      0.87      0.89     11878\n",
      "         kettle       0.96      0.94      0.95     12376\n",
      "\n",
      "      micro avg       0.92      0.90      0.91     60000\n",
      "      macro avg       0.91      0.90      0.90     60000\n",
      "   weighted avg       0.92      0.90      0.91     60000\n",
      "    samples avg       0.93      0.91      0.91     60000\n",
      "\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "750/750 [==============================] - 5s 7ms/step\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "PC1*0.9\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         fridge       0.91      0.97      0.94     15058\n",
      "washing machine       0.57      0.86      0.68     12498\n",
      "    dish washer       0.56      0.72      0.63      7843\n",
      "      microwave       0.64      0.91      0.75     11228\n",
      "         kettle       0.80      0.73      0.76     13368\n",
      "\n",
      "      micro avg       0.70      0.85      0.76     59995\n",
      "      macro avg       0.70      0.84      0.75     59995\n",
      "   weighted avg       0.72      0.85      0.77     59995\n",
      "    samples avg       0.67      0.83      0.72     59995\n",
      "\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "1.1\n",
      "GRU enabled\n",
      "Model: \"TEST\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 2550, 1)]         0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv1D)       (None, 2550, 70)          280       \n",
      "                                                                 \n",
      " block1_conv2 (Conv1D)       (None, 2550, 70)          14770     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling1D)  (None, 1275, 70)          0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv1D)       (None, 1275, 140)         29540     \n",
      "                                                                 \n",
      " block2_conv2 (Conv1D)       (None, 1275, 140)         58940     \n",
      "                                                                 \n",
      " block2_pool (MaxPooling1D)  (None, 637, 140)          0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv1D)       (None, 637, 281)          118301    \n",
      "                                                                 \n",
      " block3_conv2 (Conv1D)       (None, 637, 281)          237164    \n",
      "                                                                 \n",
      " block3_conv3 (Conv1D)       (None, 637, 281)          237164    \n",
      "                                                                 \n",
      " block3_conv4 (Conv1D)       (None, 637, 281)          237164    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling1D)  (None, 318, 281)          0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv1D)       (None, 318, 563)          475172    \n",
      "                                                                 \n",
      " block4_conv2 (Conv1D)       (None, 318, 563)          951470    \n",
      "                                                                 \n",
      " block4_conv3 (Conv1D)       (None, 318, 563)          951470    \n",
      "                                                                 \n",
      " block4_conv4 (Conv1D)       (None, 318, 563)          951470    \n",
      "                                                                 \n",
      " block4_pool (MaxPooling1D)  (None, 159, 563)          0         \n",
      "                                                                 \n",
      " block5_tran_conv1 (Conv1DTr  (None, 159, 563)         951470    \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_tran_conv2 (Conv1DTr  (None, 159, 563)         951470    \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_tran_conv3 (Conv1DTr  (None, 159, 563)         951470    \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_tran_conv4 (Conv1DTr  (None, 159, 563)         951470    \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_pool (AveragePooling  (None, 79, 563)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " gru_9 (GRU)                 (None, 64)                120768    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              266240    \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 5)                 20485     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,257,590\n",
      "Trainable params: 25,257,590\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "750/750 [==============================] - 71s 81ms/step - loss: inf - accuracy: 0.5338 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "750/750 [==============================] - 61s 81ms/step - loss: inf - accuracy: 0.5429 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "750/750 [==============================] - 61s 81ms/step - loss: inf - accuracy: 0.5678 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "750/750 [==============================] - 61s 81ms/step - loss: inf - accuracy: 0.5764 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "750/750 [==============================] - 61s 81ms/step - loss: inf - accuracy: 0.5958 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "750/750 [==============================] - 61s 81ms/step - loss: inf - accuracy: 0.6088 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "750/750 [==============================] - 61s 81ms/step - loss: inf - accuracy: 0.6216 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "750/750 [==============================] - 61s 81ms/step - loss: inf - accuracy: 0.6193 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "750/750 [==============================] - 61s 81ms/step - loss: inf - accuracy: 0.6372 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "750/750 [==============================] - 61s 81ms/step - loss: inf - accuracy: 0.6352 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "750/750 [==============================] - 61s 81ms/step - loss: inf - accuracy: 0.6539 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "750/750 [==============================] - 61s 81ms/step - loss: inf - accuracy: 0.6632 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "750/750 [==============================] - 61s 81ms/step - loss: inf - accuracy: 0.6797 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "750/750 [==============================] - 61s 81ms/step - loss: inf - accuracy: 0.6951 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "750/750 [==============================] - 61s 81ms/step - loss: inf - accuracy: 0.7147 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "750/750 [==============================] - 61s 81ms/step - loss: inf - accuracy: 0.7318 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "750/750 [==============================] - 61s 81ms/step - loss: inf - accuracy: 0.7499 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "750/750 [==============================] - 61s 81ms/step - loss: inf - accuracy: 0.7707 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "750/750 [==============================] - 61s 81ms/step - loss: inf - accuracy: 0.7876 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "750/750 [==============================] - 61s 81ms/step - loss: inf - accuracy: 0.8038 - lr: 1.1036e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 18). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/rawTS/HolyDataset/ComplexityAnalysisAL/PC1*1.1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/rawTS/HolyDataset/ComplexityAnalysisAL/PC1*1.1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 7s 8ms/step\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "PC1*1.1\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         fridge       0.93      0.92      0.93     14772\n",
      "washing machine       0.92      0.86      0.89     10509\n",
      "    dish washer       0.86      0.86      0.86     10465\n",
      "      microwave       0.90      0.88      0.89     11878\n",
      "         kettle       0.98      0.93      0.95     12376\n",
      "\n",
      "      micro avg       0.92      0.89      0.91     60000\n",
      "      macro avg       0.92      0.89      0.90     60000\n",
      "   weighted avg       0.92      0.89      0.91     60000\n",
      "    samples avg       0.93      0.91      0.91     60000\n",
      "\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "750/750 [==============================] - 6s 8ms/step\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "PC1*1.1\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         fridge       0.93      0.99      0.96     15058\n",
      "washing machine       0.57      0.85      0.68     12498\n",
      "    dish washer       0.56      0.73      0.64      7843\n",
      "      microwave       0.66      0.90      0.76     11228\n",
      "         kettle       0.84      0.67      0.75     13368\n",
      "\n",
      "      micro avg       0.71      0.84      0.77     59995\n",
      "      macro avg       0.71      0.83      0.76     59995\n",
      "   weighted avg       0.74      0.84      0.78     59995\n",
      "    samples avg       0.68      0.82      0.72     59995\n",
      "\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "1.3\n",
      "GRU enabled\n",
      "Model: \"TEST\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_11 (InputLayer)       [(None, 2550, 1)]         0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv1D)       (None, 2550, 83)          332       \n",
      "                                                                 \n",
      " block1_conv2 (Conv1D)       (None, 2550, 83)          20750     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling1D)  (None, 1275, 83)          0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv1D)       (None, 1275, 166)         41500     \n",
      "                                                                 \n",
      " block2_conv2 (Conv1D)       (None, 1275, 166)         82834     \n",
      "                                                                 \n",
      " block2_pool (MaxPooling1D)  (None, 637, 166)          0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv1D)       (None, 637, 332)          165668    \n",
      "                                                                 \n",
      " block3_conv2 (Conv1D)       (None, 637, 332)          331004    \n",
      "                                                                 \n",
      " block3_conv3 (Conv1D)       (None, 637, 332)          331004    \n",
      "                                                                 \n",
      " block3_conv4 (Conv1D)       (None, 637, 332)          331004    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling1D)  (None, 318, 332)          0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv1D)       (None, 318, 665)          663005    \n",
      "                                                                 \n",
      " block4_conv2 (Conv1D)       (None, 318, 665)          1327340   \n",
      "                                                                 \n",
      " block4_conv3 (Conv1D)       (None, 318, 665)          1327340   \n",
      "                                                                 \n",
      " block4_conv4 (Conv1D)       (None, 318, 665)          1327340   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling1D)  (None, 159, 665)          0         \n",
      "                                                                 \n",
      " block5_tran_conv1 (Conv1DTr  (None, 159, 665)         1327340   \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_tran_conv2 (Conv1DTr  (None, 159, 665)         1327340   \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_tran_conv3 (Conv1DTr  (None, 159, 665)         1327340   \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_tran_conv4 (Conv1DTr  (None, 159, 665)         1327340   \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_pool (AveragePooling  (None, 79, 665)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " gru_10 (GRU)                (None, 64)                140352    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              266240    \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 5)                 20485     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,466,870\n",
      "Trainable params: 28,466,870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "750/750 [==============================] - 87s 97ms/step - loss: inf - accuracy: 0.5377 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "750/750 [==============================] - 72s 96ms/step - loss: inf - accuracy: 0.5478 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "750/750 [==============================] - 72s 96ms/step - loss: inf - accuracy: 0.5729 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "750/750 [==============================] - 72s 96ms/step - loss: inf - accuracy: 0.5821 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "750/750 [==============================] - 72s 96ms/step - loss: inf - accuracy: 0.5861 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "750/750 [==============================] - 72s 96ms/step - loss: inf - accuracy: 0.5886 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "750/750 [==============================] - 72s 96ms/step - loss: inf - accuracy: 0.5972 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "750/750 [==============================] - 72s 96ms/step - loss: inf - accuracy: 0.6075 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "750/750 [==============================] - 72s 96ms/step - loss: inf - accuracy: 0.6092 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "750/750 [==============================] - 72s 96ms/step - loss: inf - accuracy: 0.6276 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "750/750 [==============================] - 72s 96ms/step - loss: inf - accuracy: 0.6425 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "750/750 [==============================] - 72s 96ms/step - loss: inf - accuracy: 0.6507 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "750/750 [==============================] - 72s 96ms/step - loss: inf - accuracy: 0.6726 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "750/750 [==============================] - 72s 96ms/step - loss: inf - accuracy: 0.6867 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "750/750 [==============================] - 72s 96ms/step - loss: inf - accuracy: 0.7128 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "750/750 [==============================] - 72s 96ms/step - loss: inf - accuracy: 0.7327 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "750/750 [==============================] - 72s 96ms/step - loss: inf - accuracy: 0.7551 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "750/750 [==============================] - 72s 96ms/step - loss: inf - accuracy: 0.7736 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "750/750 [==============================] - 72s 96ms/step - loss: inf - accuracy: 0.7922 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "750/750 [==============================] - 72s 96ms/step - loss: inf - accuracy: 0.8099 - lr: 1.1036e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 18). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/rawTS/HolyDataset/ComplexityAnalysisAL/PC1*1.3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/rawTS/HolyDataset/ComplexityAnalysisAL/PC1*1.3/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 8s 9ms/step\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "PC1*1.3\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         fridge       0.95      0.91      0.93     14772\n",
      "washing machine       0.93      0.85      0.89     10509\n",
      "    dish washer       0.89      0.85      0.87     10465\n",
      "      microwave       0.91      0.87      0.89     11878\n",
      "         kettle       0.95      0.95      0.95     12376\n",
      "\n",
      "      micro avg       0.93      0.89      0.91     60000\n",
      "      macro avg       0.93      0.89      0.91     60000\n",
      "   weighted avg       0.93      0.89      0.91     60000\n",
      "    samples avg       0.94      0.91      0.91     60000\n",
      "\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "750/750 [==============================] - 8s 10ms/step\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "PC1*1.3\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         fridge       0.94      0.97      0.95     15058\n",
      "washing machine       0.57      0.81      0.67     12498\n",
      "    dish washer       0.60      0.69      0.64      7843\n",
      "      microwave       0.63      0.87      0.73     11228\n",
      "         kettle       0.78      0.76      0.77     13368\n",
      "\n",
      "      micro avg       0.71      0.83      0.77     59995\n",
      "      macro avg       0.70      0.82      0.75     59995\n",
      "   weighted avg       0.72      0.83      0.77     59995\n",
      "    samples avg       0.68      0.82      0.72     59995\n",
      "\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "1.5\n",
      "GRU enabled\n",
      "Model: \"TEST\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_12 (InputLayer)       [(None, 2550, 1)]         0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv1D)       (None, 2550, 96)          384       \n",
      "                                                                 \n",
      " block1_conv2 (Conv1D)       (None, 2550, 96)          27744     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling1D)  (None, 1275, 96)          0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv1D)       (None, 1275, 192)         55488     \n",
      "                                                                 \n",
      " block2_conv2 (Conv1D)       (None, 1275, 192)         110784    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling1D)  (None, 637, 192)          0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv1D)       (None, 637, 384)          221568    \n",
      "                                                                 \n",
      " block3_conv2 (Conv1D)       (None, 637, 384)          442752    \n",
      "                                                                 \n",
      " block3_conv3 (Conv1D)       (None, 637, 384)          442752    \n",
      "                                                                 \n",
      " block3_conv4 (Conv1D)       (None, 637, 384)          442752    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling1D)  (None, 318, 384)          0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv1D)       (None, 318, 768)          885504    \n",
      "                                                                 \n",
      " block4_conv2 (Conv1D)       (None, 318, 768)          1770240   \n",
      "                                                                 \n",
      " block4_conv3 (Conv1D)       (None, 318, 768)          1770240   \n",
      "                                                                 \n",
      " block4_conv4 (Conv1D)       (None, 318, 768)          1770240   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling1D)  (None, 159, 768)          0         \n",
      "                                                                 \n",
      " block5_tran_conv1 (Conv1DTr  (None, 159, 768)         1770240   \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_tran_conv2 (Conv1DTr  (None, 159, 768)         1770240   \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_tran_conv3 (Conv1DTr  (None, 159, 768)         1770240   \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_tran_conv4 (Conv1DTr  (None, 159, 768)         1770240   \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_pool (AveragePooling  (None, 79, 768)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " gru_11 (GRU)                (None, 64)                160128    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              266240    \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 5)                 20485     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,249,573\n",
      "Trainable params: 32,249,573\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "750/750 [==============================] - 80s 75ms/step - loss: inf - accuracy: 0.5311 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "750/750 [==============================] - 56s 75ms/step - loss: inf - accuracy: 0.5316 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "750/750 [==============================] - 56s 75ms/step - loss: inf - accuracy: 0.5603 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "750/750 [==============================] - 56s 75ms/step - loss: inf - accuracy: 0.5911 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "750/750 [==============================] - 56s 75ms/step - loss: inf - accuracy: 0.6028 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "750/750 [==============================] - 57s 75ms/step - loss: inf - accuracy: 0.6095 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "750/750 [==============================] - 56s 75ms/step - loss: inf - accuracy: 0.6164 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "750/750 [==============================] - 56s 75ms/step - loss: inf - accuracy: 0.6255 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "750/750 [==============================] - 57s 76ms/step - loss: inf - accuracy: 0.6274 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "750/750 [==============================] - 57s 76ms/step - loss: inf - accuracy: 0.6382 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "750/750 [==============================] - 57s 76ms/step - loss: inf - accuracy: 0.6499 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "750/750 [==============================] - 57s 76ms/step - loss: inf - accuracy: 0.6586 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "750/750 [==============================] - 57s 76ms/step - loss: inf - accuracy: 0.6800 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "750/750 [==============================] - 57s 76ms/step - loss: inf - accuracy: 0.7024 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "750/750 [==============================] - 57s 76ms/step - loss: inf - accuracy: 0.7248 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "750/750 [==============================] - 57s 76ms/step - loss: inf - accuracy: 0.7469 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "750/750 [==============================] - 57s 75ms/step - loss: inf - accuracy: 0.7652 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "750/750 [==============================] - 57s 76ms/step - loss: inf - accuracy: 0.7845 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "750/750 [==============================] - 57s 76ms/step - loss: inf - accuracy: 0.8013 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "750/750 [==============================] - 57s 76ms/step - loss: inf - accuracy: 0.8171 - lr: 1.1036e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 18). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/rawTS/HolyDataset/ComplexityAnalysisAL/PC1*1.5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/rawTS/HolyDataset/ComplexityAnalysisAL/PC1*1.5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 7s 7ms/step\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "PC1*1.5\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         fridge       0.93      0.92      0.93     14772\n",
      "washing machine       0.91      0.88      0.89     10509\n",
      "    dish washer       0.90      0.86      0.88     10465\n",
      "      microwave       0.92      0.87      0.89     11878\n",
      "         kettle       0.97      0.94      0.95     12376\n",
      "\n",
      "      micro avg       0.93      0.89      0.91     60000\n",
      "      macro avg       0.93      0.89      0.91     60000\n",
      "   weighted avg       0.93      0.89      0.91     60000\n",
      "    samples avg       0.94      0.91      0.92     60000\n",
      "\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "750/750 [==============================] - 7s 9ms/step\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "PC1*1.5\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         fridge       0.89      0.97      0.93     15058\n",
      "washing machine       0.57      0.84      0.68     12498\n",
      "    dish washer       0.58      0.68      0.62      7843\n",
      "      microwave       0.66      0.88      0.76     11228\n",
      "         kettle       0.77      0.73      0.75     13368\n",
      "\n",
      "      micro avg       0.70      0.83      0.76     59995\n",
      "      macro avg       0.69      0.82      0.75     59995\n",
      "   weighted avg       0.71      0.83      0.76     59995\n",
      "    samples avg       0.67      0.81      0.71     59995\n",
      "\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "1.7\n",
      "GRU enabled\n",
      "Model: \"TEST\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_13 (InputLayer)       [(None, 2550, 1)]         0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv1D)       (None, 2550, 108)         432       \n",
      "                                                                 \n",
      " block1_conv2 (Conv1D)       (None, 2550, 108)         35100     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling1D)  (None, 1275, 108)         0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv1D)       (None, 1275, 217)         70525     \n",
      "                                                                 \n",
      " block2_conv2 (Conv1D)       (None, 1275, 217)         141484    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling1D)  (None, 637, 217)          0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv1D)       (None, 637, 435)          283620    \n",
      "                                                                 \n",
      " block3_conv2 (Conv1D)       (None, 637, 435)          568110    \n",
      "                                                                 \n",
      " block3_conv3 (Conv1D)       (None, 637, 435)          568110    \n",
      "                                                                 \n",
      " block3_conv4 (Conv1D)       (None, 637, 435)          568110    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling1D)  (None, 318, 435)          0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv1D)       (None, 318, 870)          1136220   \n",
      "                                                                 \n",
      " block4_conv2 (Conv1D)       (None, 318, 870)          2271570   \n",
      "                                                                 \n",
      " block4_conv3 (Conv1D)       (None, 318, 870)          2271570   \n",
      "                                                                 \n",
      " block4_conv4 (Conv1D)       (None, 318, 870)          2271570   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling1D)  (None, 159, 870)          0         \n",
      "                                                                 \n",
      " block5_tran_conv1 (Conv1DTr  (None, 159, 870)         2271570   \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_tran_conv2 (Conv1DTr  (None, 159, 870)         2271570   \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_tran_conv3 (Conv1DTr  (None, 159, 870)         2271570   \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_tran_conv4 (Conv1DTr  (None, 159, 870)         2271570   \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_pool (AveragePooling  (None, 79, 870)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " gru_12 (GRU)                (None, 64)                179712    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              266240    \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 5)                 20485     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 36,520,450\n",
      "Trainable params: 36,520,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "750/750 [==============================] - 124s 132ms/step - loss: inf - accuracy: 0.5063 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "750/750 [==============================] - 99s 132ms/step - loss: inf - accuracy: 0.5578 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "750/750 [==============================] - 98s 130ms/step - loss: inf - accuracy: 0.6098 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "750/750 [==============================] - 98s 131ms/step - loss: inf - accuracy: 0.6098 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "750/750 [==============================] - 98s 131ms/step - loss: inf - accuracy: 0.6098 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "750/750 [==============================] - 98s 131ms/step - loss: inf - accuracy: 0.6098 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "750/750 [==============================] - 98s 130ms/step - loss: inf - accuracy: 0.6098 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "750/750 [==============================] - 98s 130ms/step - loss: inf - accuracy: 0.6098 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "750/750 [==============================] - 98s 131ms/step - loss: inf - accuracy: 0.6098 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "750/750 [==============================] - 98s 131ms/step - loss: inf - accuracy: 0.6098 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "750/750 [==============================] - 98s 131ms/step - loss: inf - accuracy: 0.6098 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "750/750 [==============================] - 98s 130ms/step - loss: inf - accuracy: 0.6098 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "750/750 [==============================] - 98s 131ms/step - loss: inf - accuracy: 0.6098 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "750/750 [==============================] - 98s 130ms/step - loss: inf - accuracy: 0.6098 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "750/750 [==============================] - 98s 131ms/step - loss: inf - accuracy: 0.6098 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "750/750 [==============================] - 98s 130ms/step - loss: inf - accuracy: 0.6098 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "750/750 [==============================] - 98s 131ms/step - loss: inf - accuracy: 0.6098 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "750/750 [==============================] - 98s 130ms/step - loss: inf - accuracy: 0.6098 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "750/750 [==============================] - 98s 130ms/step - loss: inf - accuracy: 0.6098 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "750/750 [==============================] - 98s 130ms/step - loss: inf - accuracy: 0.6098 - lr: 1.1036e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 18). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/rawTS/HolyDataset/ComplexityAnalysisAL/PC1*1.7/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/rawTS/HolyDataset/ComplexityAnalysisAL/PC1*1.7/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 11s 12ms/step\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "PC1*1.7\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         fridge       0.63      1.00      0.77     14772\n",
      "washing machine       0.89      0.37      0.52     10509\n",
      "    dish washer       0.93      0.38      0.54     10465\n",
      "      microwave       0.78      0.44      0.56     11878\n",
      "         kettle       0.98      0.64      0.77     12376\n",
      "\n",
      "      micro avg       0.76      0.59      0.67     60000\n",
      "      macro avg       0.84      0.56      0.63     60000\n",
      "   weighted avg       0.83      0.59      0.65     60000\n",
      "    samples avg       0.72      0.59      0.62     60000\n",
      "\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "750/750 [==============================] - 11s 14ms/step\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "PC1*1.7\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         fridge       0.69      1.00      0.81     15058\n",
      "washing machine       0.87      0.25      0.39     12498\n",
      "    dish washer       0.82      0.50      0.62      7843\n",
      "      microwave       0.58      0.94      0.72     11228\n",
      "         kettle       0.95      0.47      0.63     13368\n",
      "\n",
      "      micro avg       0.71      0.65      0.68     59995\n",
      "      macro avg       0.78      0.63      0.64     59995\n",
      "   weighted avg       0.78      0.65      0.64     59995\n",
      "    samples avg       0.67      0.64      0.63     59995\n",
      "\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "1.9\n",
      "GRU enabled\n",
      "Model: \"TEST\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_14 (InputLayer)       [(None, 2550, 1)]         0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv1D)       (None, 2550, 121)         484       \n",
      "                                                                 \n",
      " block1_conv2 (Conv1D)       (None, 2550, 121)         44044     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling1D)  (None, 1275, 121)         0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv1D)       (None, 1275, 243)         88452     \n",
      "                                                                 \n",
      " block2_conv2 (Conv1D)       (None, 1275, 243)         177390    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling1D)  (None, 637, 243)          0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv1D)       (None, 637, 486)          354780    \n",
      "                                                                 \n",
      " block3_conv2 (Conv1D)       (None, 637, 486)          709074    \n",
      "                                                                 \n",
      " block3_conv3 (Conv1D)       (None, 637, 486)          709074    \n",
      "                                                                 \n",
      " block3_conv4 (Conv1D)       (None, 637, 486)          709074    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling1D)  (None, 318, 486)          0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv1D)       (None, 318, 972)          1418148   \n",
      "                                                                 \n",
      " block4_conv2 (Conv1D)       (None, 318, 972)          2835324   \n",
      "                                                                 \n",
      " block4_conv3 (Conv1D)       (None, 318, 972)          2835324   \n",
      "                                                                 \n",
      " block4_conv4 (Conv1D)       (None, 318, 972)          2835324   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling1D)  (None, 159, 972)          0         \n",
      "                                                                 \n",
      " block5_tran_conv1 (Conv1DTr  (None, 159, 972)         2835324   \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_tran_conv2 (Conv1DTr  (None, 159, 972)         2835324   \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_tran_conv3 (Conv1DTr  (None, 159, 972)         2835324   \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_tran_conv4 (Conv1DTr  (None, 159, 972)         2835324   \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_pool (AveragePooling  (None, 79, 972)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " gru_13 (GRU)                (None, 64)                199296    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              266240    \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 5)                 20485     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41,325,121\n",
      "Trainable params: 41,325,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "750/750 [==============================] - 140s 147ms/step - loss: nan - accuracy: 0.5136 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "750/750 [==============================] - 110s 147ms/step - loss: nan - accuracy: 0.5107 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "750/750 [==============================] - 110s 147ms/step - loss: nan - accuracy: 0.5107 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "750/750 [==============================] - 110s 147ms/step - loss: nan - accuracy: 0.5107 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "750/750 [==============================] - 110s 147ms/step - loss: nan - accuracy: 0.5107 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "750/750 [==============================] - 110s 147ms/step - loss: nan - accuracy: 0.5107 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "750/750 [==============================] - 111s 148ms/step - loss: nan - accuracy: 0.5107 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "750/750 [==============================] - 111s 148ms/step - loss: nan - accuracy: 0.5107 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "750/750 [==============================] - 111s 147ms/step - loss: nan - accuracy: 0.5107 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "750/750 [==============================] - 111s 148ms/step - loss: nan - accuracy: 0.5107 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "750/750 [==============================] - 111s 148ms/step - loss: nan - accuracy: 0.5107 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "750/750 [==============================] - 110s 147ms/step - loss: nan - accuracy: 0.5107 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "750/750 [==============================] - 110s 147ms/step - loss: nan - accuracy: 0.5107 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "750/750 [==============================] - 110s 147ms/step - loss: nan - accuracy: 0.5107 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "750/750 [==============================] - 111s 148ms/step - loss: nan - accuracy: 0.5107 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "750/750 [==============================] - 111s 147ms/step - loss: nan - accuracy: 0.5107 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "750/750 [==============================] - 110s 147ms/step - loss: nan - accuracy: 0.5107 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "750/750 [==============================] - 111s 147ms/step - loss: nan - accuracy: 0.5107 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "750/750 [==============================] - 111s 147ms/step - loss: nan - accuracy: 0.5107 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "750/750 [==============================] - 110s 147ms/step - loss: nan - accuracy: 0.5107 - lr: 1.1036e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 18). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/rawTS/HolyDataset/ComplexityAnalysisAL/PC1*1.9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/rawTS/HolyDataset/ComplexityAnalysisAL/PC1*1.9/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 12s 14ms/step\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "PC1*1.9\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         fridge       0.63      0.90      0.74     14772\n",
      "washing machine       0.62      0.00      0.00     10509\n",
      "    dish washer       0.53      0.26      0.35     10465\n",
      "      microwave       0.77      0.35      0.48     11878\n",
      "         kettle       0.53      0.52      0.53     12376\n",
      "\n",
      "      micro avg       0.61      0.44      0.51     60000\n",
      "      macro avg       0.62      0.41      0.42     60000\n",
      "   weighted avg       0.62      0.44      0.45     60000\n",
      "    samples avg       0.54      0.44      0.45     60000\n",
      "\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "750/750 [==============================] - 12s 16ms/step\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "PC1*1.9\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         fridge       0.69      0.92      0.79     15058\n",
      "washing machine       0.69      0.00      0.01     12498\n",
      "    dish washer       0.33      0.54      0.41      7843\n",
      "      microwave       0.56      0.89      0.69     11228\n",
      "         kettle       0.59      0.84      0.69     13368\n",
      "\n",
      "      micro avg       0.56      0.66      0.61     59995\n",
      "      macro avg       0.57      0.64      0.52     59995\n",
      "   weighted avg       0.60      0.66      0.54     59995\n",
      "    samples avg       0.53      0.63      0.54     59995\n",
      "\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "2.1\n",
      "GRU enabled\n",
      "Model: \"TEST\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_15 (InputLayer)       [(None, 2550, 1)]         0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv1D)       (None, 2550, 134)         536       \n",
      "                                                                 \n",
      " block1_conv2 (Conv1D)       (None, 2550, 134)         54002     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling1D)  (None, 1275, 134)         0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv1D)       (None, 1275, 268)         108004    \n",
      "                                                                 \n",
      " block2_conv2 (Conv1D)       (None, 1275, 268)         215740    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling1D)  (None, 637, 268)          0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv1D)       (None, 637, 537)          432285    \n",
      "                                                                 \n",
      " block3_conv2 (Conv1D)       (None, 637, 537)          865644    \n",
      "                                                                 \n",
      " block3_conv3 (Conv1D)       (None, 637, 537)          865644    \n",
      "                                                                 \n",
      " block3_conv4 (Conv1D)       (None, 637, 537)          865644    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling1D)  (None, 318, 537)          0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv1D)       (None, 318, 1075)         1732900   \n",
      "                                                                 \n",
      " block4_conv2 (Conv1D)       (None, 318, 1075)         3467950   \n",
      "                                                                 \n",
      " block4_conv3 (Conv1D)       (None, 318, 1075)         3467950   \n",
      "                                                                 \n",
      " block4_conv4 (Conv1D)       (None, 318, 1075)         3467950   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling1D)  (None, 159, 1075)         0         \n",
      "                                                                 \n",
      " block5_tran_conv1 (Conv1DTr  (None, 159, 1075)        3467950   \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_tran_conv2 (Conv1DTr  (None, 159, 1075)        3467950   \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_tran_conv3 (Conv1DTr  (None, 159, 1075)        3467950   \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_tran_conv4 (Conv1DTr  (None, 159, 1075)        3467950   \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_pool (AveragePooling  (None, 79, 1075)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " gru_14 (GRU)                (None, 64)                219072    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              266240    \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 5)                 20485     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 46,703,158\n",
      "Trainable params: 46,703,158\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "750/750 [==============================] - 171s 178ms/step - loss: inf - accuracy: 0.5353 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "750/750 [==============================] - 134s 178ms/step - loss: inf - accuracy: 0.5441 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "750/750 [==============================] - 134s 178ms/step - loss: inf - accuracy: 0.5692 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "750/750 [==============================] - 134s 178ms/step - loss: inf - accuracy: 0.5758 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "750/750 [==============================] - 134s 178ms/step - loss: inf - accuracy: 0.5839 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "750/750 [==============================] - 134s 178ms/step - loss: inf - accuracy: 0.5923 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "750/750 [==============================] - 134s 178ms/step - loss: inf - accuracy: 0.6066 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "750/750 [==============================] - 134s 178ms/step - loss: inf - accuracy: 0.6142 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "750/750 [==============================] - 134s 178ms/step - loss: inf - accuracy: 0.6175 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "750/750 [==============================] - 133s 178ms/step - loss: inf - accuracy: 0.6275 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "750/750 [==============================] - 133s 178ms/step - loss: inf - accuracy: 0.6444 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "750/750 [==============================] - 133s 178ms/step - loss: inf - accuracy: 0.6612 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "750/750 [==============================] - 133s 178ms/step - loss: inf - accuracy: 0.6875 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "750/750 [==============================] - 133s 178ms/step - loss: inf - accuracy: 0.7080 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "750/750 [==============================] - 133s 178ms/step - loss: inf - accuracy: 0.7297 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "750/750 [==============================] - 133s 178ms/step - loss: inf - accuracy: 0.7490 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "750/750 [==============================] - 133s 178ms/step - loss: inf - accuracy: 0.7681 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "750/750 [==============================] - 133s 178ms/step - loss: inf - accuracy: 0.7873 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "750/750 [==============================] - 133s 178ms/step - loss: inf - accuracy: 0.8057 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "750/750 [==============================] - 133s 177ms/step - loss: inf - accuracy: 0.8218 - lr: 1.1036e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 18). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/rawTS/HolyDataset/ComplexityAnalysisAL/PC1*2.1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/rawTS/HolyDataset/ComplexityAnalysisAL/PC1*2.1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 15s 17ms/step\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "PC1*2.1\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         fridge       0.94      0.92      0.93     14772\n",
      "washing machine       0.88      0.86      0.87     10509\n",
      "    dish washer       0.86      0.83      0.85     10465\n",
      "      microwave       0.90      0.87      0.88     11878\n",
      "         kettle       0.96      0.94      0.95     12376\n",
      "\n",
      "      micro avg       0.91      0.89      0.90     60000\n",
      "      macro avg       0.91      0.88      0.90     60000\n",
      "   weighted avg       0.91      0.89      0.90     60000\n",
      "    samples avg       0.93      0.90      0.91     60000\n",
      "\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "750/750 [==============================] - 15s 19ms/step\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "PC1*2.1\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         fridge       0.89      0.99      0.93     15058\n",
      "washing machine       0.56      0.85      0.68     12498\n",
      "    dish washer       0.55      0.71      0.62      7843\n",
      "      microwave       0.62      0.90      0.73     11228\n",
      "         kettle       0.85      0.65      0.74     13368\n",
      "\n",
      "      micro avg       0.69      0.83      0.75     59995\n",
      "      macro avg       0.70      0.82      0.74     59995\n",
      "   weighted avg       0.72      0.83      0.76     59995\n",
      "    samples avg       0.67      0.82      0.71     59995\n",
      "\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "2.3\n",
      "GRU enabled\n",
      "Model: \"TEST\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_16 (InputLayer)       [(None, 2550, 1)]         0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv1D)       (None, 2550, 147)         588       \n",
      "                                                                 \n",
      " block1_conv2 (Conv1D)       (None, 2550, 147)         64974     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling1D)  (None, 1275, 147)         0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv1D)       (None, 1275, 294)         129948    \n",
      "                                                                 \n",
      " block2_conv2 (Conv1D)       (None, 1275, 294)         259602    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling1D)  (None, 637, 294)          0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv1D)       (None, 637, 588)          519204    \n",
      "                                                                 \n",
      " block3_conv2 (Conv1D)       (None, 637, 588)          1037820   \n",
      "                                                                 \n",
      " block3_conv3 (Conv1D)       (None, 637, 588)          1037820   \n",
      "                                                                 \n",
      " block3_conv4 (Conv1D)       (None, 637, 588)          1037820   \n",
      "                                                                 \n",
      " block3_pool (MaxPooling1D)  (None, 318, 588)          0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv1D)       (None, 318, 1177)         2077405   \n",
      "                                                                 \n",
      " block4_conv2 (Conv1D)       (None, 318, 1177)         4157164   \n",
      "                                                                 \n",
      " block4_conv3 (Conv1D)       (None, 318, 1177)         4157164   \n",
      "                                                                 \n",
      " block4_conv4 (Conv1D)       (None, 318, 1177)         4157164   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling1D)  (None, 159, 1177)         0         \n",
      "                                                                 \n",
      " block5_tran_conv1 (Conv1DTr  (None, 159, 1177)        4157164   \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_tran_conv2 (Conv1DTr  (None, 159, 1177)        4157164   \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_tran_conv3 (Conv1DTr  (None, 159, 1177)        4157164   \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_tran_conv4 (Conv1DTr  (None, 159, 1177)        4157164   \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_pool (AveragePooling  (None, 79, 1177)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " gru_15 (GRU)                (None, 64)                238656    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              266240    \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 5)                 20485     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 52,572,022\n",
      "Trainable params: 52,572,022\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "750/750 [==============================] - 188s 193ms/step - loss: nan - accuracy: 0.6114 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "750/750 [==============================] - 145s 193ms/step - loss: nan - accuracy: 0.6150 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "750/750 [==============================] - 145s 193ms/step - loss: nan - accuracy: 0.6150 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "750/750 [==============================] - 145s 193ms/step - loss: nan - accuracy: 0.6150 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "750/750 [==============================] - 145s 193ms/step - loss: nan - accuracy: 0.6150 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "750/750 [==============================] - 145s 193ms/step - loss: nan - accuracy: 0.6150 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "750/750 [==============================] - 145s 193ms/step - loss: nan - accuracy: 0.6150 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "750/750 [==============================] - 145s 193ms/step - loss: nan - accuracy: 0.6150 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "750/750 [==============================] - 144s 193ms/step - loss: nan - accuracy: 0.6150 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "750/750 [==============================] - 145s 193ms/step - loss: nan - accuracy: 0.6150 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "750/750 [==============================] - 145s 193ms/step - loss: nan - accuracy: 0.6150 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "750/750 [==============================] - 144s 193ms/step - loss: nan - accuracy: 0.6150 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "750/750 [==============================] - 145s 193ms/step - loss: nan - accuracy: 0.6150 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "750/750 [==============================] - 144s 193ms/step - loss: nan - accuracy: 0.6150 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "750/750 [==============================] - 144s 193ms/step - loss: nan - accuracy: 0.6150 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "750/750 [==============================] - 144s 193ms/step - loss: nan - accuracy: 0.6150 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "750/750 [==============================] - 144s 193ms/step - loss: nan - accuracy: 0.6150 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "750/750 [==============================] - 144s 193ms/step - loss: nan - accuracy: 0.6150 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "750/750 [==============================] - 145s 193ms/step - loss: nan - accuracy: 0.6150 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "750/750 [==============================] - 145s 193ms/step - loss: nan - accuracy: 0.6150 - lr: 1.1036e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 18). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/rawTS/HolyDataset/ComplexityAnalysisAL/PC1*2.3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/rawTS/HolyDataset/ComplexityAnalysisAL/PC1*2.3/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 16s 19ms/step\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "PC1*2.3\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         fridge       0.61      0.66      0.64     14772\n",
      "washing machine       0.43      0.24      0.31     10509\n",
      "    dish washer       0.00      0.00      0.00     10465\n",
      "      microwave       0.62      0.36      0.45     11878\n",
      "         kettle       0.53      0.37      0.44     12376\n",
      "\n",
      "      micro avg       0.57      0.35      0.43     60000\n",
      "      macro avg       0.44      0.33      0.37     60000\n",
      "   weighted avg       0.46      0.35      0.39     60000\n",
      "    samples avg       0.36      0.38      0.33     60000\n",
      "\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "750/750 [==============================] - 16s 21ms/step\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "PC1*2.3\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         fridge       0.62      0.79      0.70     15058\n",
      "washing machine       0.49      0.57      0.53     12498\n",
      "    dish washer       0.00      0.00      0.00      7843\n",
      "      microwave       0.56      0.74      0.63     11228\n",
      "         kettle       0.58      0.65      0.62     13368\n",
      "\n",
      "      micro avg       0.57      0.60      0.58     59995\n",
      "      macro avg       0.45      0.55      0.49     59995\n",
      "   weighted avg       0.49      0.60      0.54     59995\n",
      "    samples avg       0.42      0.61      0.46     59995\n",
      "\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "2.5\n",
      "GRU enabled\n",
      "Model: \"TEST\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_17 (InputLayer)       [(None, 2550, 1)]         0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv1D)       (None, 2550, 160)         640       \n",
      "                                                                 \n",
      " block1_conv2 (Conv1D)       (None, 2550, 160)         76960     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling1D)  (None, 1275, 160)         0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv1D)       (None, 1275, 320)         153920    \n",
      "                                                                 \n",
      " block2_conv2 (Conv1D)       (None, 1275, 320)         307520    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling1D)  (None, 637, 320)          0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv1D)       (None, 637, 640)          615040    \n",
      "                                                                 \n",
      " block3_conv2 (Conv1D)       (None, 637, 640)          1229440   \n",
      "                                                                 \n",
      " block3_conv3 (Conv1D)       (None, 637, 640)          1229440   \n",
      "                                                                 \n",
      " block3_conv4 (Conv1D)       (None, 637, 640)          1229440   \n",
      "                                                                 \n",
      " block3_pool (MaxPooling1D)  (None, 318, 640)          0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv1D)       (None, 318, 1280)         2458880   \n",
      "                                                                 \n",
      " block4_conv2 (Conv1D)       (None, 318, 1280)         4916480   \n",
      "                                                                 \n",
      " block4_conv3 (Conv1D)       (None, 318, 1280)         4916480   \n",
      "                                                                 \n",
      " block4_conv4 (Conv1D)       (None, 318, 1280)         4916480   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling1D)  (None, 159, 1280)         0         \n",
      "                                                                 \n",
      " block5_tran_conv1 (Conv1DTr  (None, 159, 1280)        4916480   \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_tran_conv2 (Conv1DTr  (None, 159, 1280)        4916480   \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_tran_conv3 (Conv1DTr  (None, 159, 1280)        4916480   \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_tran_conv4 (Conv1DTr  (None, 159, 1280)        4916480   \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_pool (AveragePooling  (None, 79, 1280)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " gru_16 (GRU)                (None, 64)                258432    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              266240    \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 5)                 20485     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 59,043,109\n",
      "Trainable params: 59,043,109\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "750/750 [==============================] - 186s 156ms/step - loss: nan - accuracy: 0.5307 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "750/750 [==============================] - 116s 155ms/step - loss: nan - accuracy: 0.5300 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "750/750 [==============================] - 116s 155ms/step - loss: nan - accuracy: 0.5300 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "750/750 [==============================] - 116s 155ms/step - loss: nan - accuracy: 0.5300 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "750/750 [==============================] - 116s 155ms/step - loss: nan - accuracy: 0.5300 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "750/750 [==============================] - 116s 155ms/step - loss: nan - accuracy: 0.5300 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "750/750 [==============================] - 116s 155ms/step - loss: nan - accuracy: 0.5300 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "750/750 [==============================] - 116s 155ms/step - loss: nan - accuracy: 0.5300 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "750/750 [==============================] - 116s 155ms/step - loss: nan - accuracy: 0.5300 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "750/750 [==============================] - 116s 155ms/step - loss: nan - accuracy: 0.5300 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "750/750 [==============================] - 116s 155ms/step - loss: nan - accuracy: 0.5300 - lr: 2.7145e-04\n",
      "Epoch 12/20\n",
      "750/750 [==============================] - 116s 155ms/step - loss: nan - accuracy: 0.5300 - lr: 2.4562e-04\n",
      "Epoch 13/20\n",
      "750/750 [==============================] - 116s 155ms/step - loss: nan - accuracy: 0.5300 - lr: 2.2225e-04\n",
      "Epoch 14/20\n",
      "750/750 [==============================] - 116s 155ms/step - loss: nan - accuracy: 0.5300 - lr: 2.0110e-04\n",
      "Epoch 15/20\n",
      "750/750 [==============================] - 116s 155ms/step - loss: nan - accuracy: 0.5300 - lr: 1.8196e-04\n",
      "Epoch 16/20\n",
      "750/750 [==============================] - 116s 155ms/step - loss: nan - accuracy: 0.5300 - lr: 1.6464e-04\n",
      "Epoch 17/20\n",
      "750/750 [==============================] - 116s 155ms/step - loss: nan - accuracy: 0.5300 - lr: 1.4898e-04\n",
      "Epoch 18/20\n",
      "750/750 [==============================] - 116s 155ms/step - loss: nan - accuracy: 0.5300 - lr: 1.3480e-04\n",
      "Epoch 19/20\n",
      "750/750 [==============================] - 116s 155ms/step - loss: nan - accuracy: 0.5300 - lr: 1.2197e-04\n",
      "Epoch 20/20\n",
      "750/750 [==============================] - 116s 155ms/step - loss: nan - accuracy: 0.5300 - lr: 1.1036e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 18). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/rawTS/HolyDataset/ComplexityAnalysisAL/PC1*2.5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/rawTS/HolyDataset/ComplexityAnalysisAL/PC1*2.5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 16s 15ms/step\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "PC1*2.5\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         fridge       0.61      0.84      0.71     14772\n",
      "washing machine       0.00      0.00      0.00     10509\n",
      "    dish washer       0.40      0.33      0.36     10465\n",
      "      microwave       0.49      0.83      0.62     11878\n",
      "         kettle       0.54      0.42      0.48     12376\n",
      "\n",
      "      micro avg       0.53      0.52      0.52     60000\n",
      "      macro avg       0.41      0.48      0.43     60000\n",
      "   weighted avg       0.43      0.52      0.46     60000\n",
      "    samples avg       0.43      0.53      0.44     60000\n",
      "\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "750/750 [==============================] - 16s 20ms/step\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "PC1*2.5\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         fridge       0.63      0.83      0.71     15058\n",
      "washing machine       0.00      0.00      0.00     12498\n",
      "    dish washer       0.21      0.42      0.28      7843\n",
      "      microwave       0.46      0.83      0.60     11228\n",
      "         kettle       0.59      0.69      0.64     13368\n",
      "\n",
      "      micro avg       0.48      0.57      0.52     59995\n",
      "      macro avg       0.38      0.55      0.45     59995\n",
      "   weighted avg       0.40      0.57      0.47     59995\n",
      "    samples avg       0.38      0.58      0.44     59995\n",
      "\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "0.1\n",
      "GRU enabled\n",
      "Model: \"TEST\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_18 (InputLayer)       [(None, 2550, 1)]         0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv1D)       (None, 2550, 6)           24        \n",
      "                                                                 \n",
      " block1_conv2 (Conv1D)       (None, 2550, 6)           114       \n",
      "                                                                 \n",
      " block1_pool (MaxPooling1D)  (None, 1275, 6)           0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv1D)       (None, 1275, 12)          228       \n",
      "                                                                 \n",
      " block2_conv2 (Conv1D)       (None, 1275, 12)          444       \n",
      "                                                                 \n",
      " block2_pool (MaxPooling1D)  (None, 637, 12)           0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv1D)       (None, 637, 25)           925       \n",
      "                                                                 \n",
      " block3_conv2 (Conv1D)       (None, 637, 25)           1900      \n",
      "                                                                 \n",
      " block3_conv3 (Conv1D)       (None, 637, 25)           1900      \n",
      "                                                                 \n",
      " block3_conv4 (Conv1D)       (None, 637, 25)           1900      \n",
      "                                                                 \n",
      " block3_pool (MaxPooling1D)  (None, 318, 25)           0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv1D)       (None, 318, 51)           3876      \n",
      "                                                                 \n",
      " block4_conv2 (Conv1D)       (None, 318, 51)           7854      \n",
      "                                                                 \n",
      " block4_conv3 (Conv1D)       (None, 318, 51)           7854      \n",
      "                                                                 \n",
      " block4_conv4 (Conv1D)       (None, 318, 51)           7854      \n",
      "                                                                 \n",
      " block4_pool (MaxPooling1D)  (None, 159, 51)           0         \n",
      "                                                                 \n",
      " block5_tran_conv1 (Conv1DTr  (None, 159, 51)          7854      \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_tran_conv2 (Conv1DTr  (None, 159, 51)          7854      \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_tran_conv3 (Conv1DTr  (None, 159, 51)          7854      \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_tran_conv4 (Conv1DTr  (None, 159, 51)          7854      \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_pool (AveragePooling  (None, 79, 51)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " gru_17 (GRU)                (None, 64)                22464     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              266240    \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 5)                 20485     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,156,790\n",
      "Trainable params: 17,156,790\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "750/750 [==============================] - 14s 17ms/step - loss: inf - accuracy: 0.6753\n",
      "Epoch 2/20\n",
      "750/750 [==============================] - 11s 15ms/step - loss: inf - accuracy: 0.7521\n",
      "Epoch 3/20\n",
      "750/750 [==============================] - 12s 15ms/step - loss: inf - accuracy: 0.7609\n",
      "Epoch 4/20\n",
      "750/750 [==============================] - 12s 16ms/step - loss: inf - accuracy: 0.7693\n",
      "Epoch 5/20\n",
      "750/750 [==============================] - 12s 15ms/step - loss: inf - accuracy: 0.7853\n",
      "Epoch 6/20\n",
      "750/750 [==============================] - 11s 15ms/step - loss: inf - accuracy: 0.8002\n",
      "Epoch 7/20\n",
      "750/750 [==============================] - 11s 15ms/step - loss: inf - accuracy: 0.8040\n",
      "Epoch 8/20\n",
      "750/750 [==============================] - 11s 15ms/step - loss: inf - accuracy: 0.8149\n",
      "Epoch 9/20\n",
      "750/750 [==============================] - 12s 15ms/step - loss: inf - accuracy: 0.8196\n",
      "Epoch 10/20\n",
      "750/750 [==============================] - 11s 15ms/step - loss: inf - accuracy: 0.8257\n",
      "Epoch 11/20\n",
      "750/750 [==============================] - 12s 16ms/step - loss: inf - accuracy: 0.8306\n",
      "Epoch 12/20\n",
      "750/750 [==============================] - 12s 15ms/step - loss: inf - accuracy: 0.8311\n",
      "Epoch 13/20\n",
      "750/750 [==============================] - 12s 15ms/step - loss: inf - accuracy: 0.8349\n",
      "Epoch 14/20\n",
      "750/750 [==============================] - 12s 16ms/step - loss: inf - accuracy: 0.8387\n",
      "Epoch 15/20\n",
      "750/750 [==============================] - 12s 15ms/step - loss: inf - accuracy: 0.8421\n",
      "Epoch 16/20\n",
      "750/750 [==============================] - 11s 15ms/step - loss: inf - accuracy: 0.8463\n",
      "Epoch 17/20\n",
      "750/750 [==============================] - 11s 15ms/step - loss: inf - accuracy: 0.8471\n",
      "Epoch 18/20\n",
      "750/750 [==============================] - 11s 15ms/step - loss: inf - accuracy: 0.8534\n",
      "Epoch 19/20\n",
      "750/750 [==============================] - 12s 15ms/step - loss: inf - accuracy: 0.8571\n",
      "Epoch 20/20\n",
      "750/750 [==============================] - 11s 15ms/step - loss: inf - accuracy: 0.8565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 18). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/rawTS/HolyDataset/ComplexityAnalysisAL/PC1*0.1_DALE/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/rawTS/HolyDataset/ComplexityAnalysisAL/PC1*0.1_DALE/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 3s 4ms/step\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "PC1*0.1\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         fridge       0.77      0.33      0.46     14772\n",
      "washing machine       0.53      0.88      0.66     10509\n",
      "    dish washer       0.50      0.62      0.56     10465\n",
      "      microwave       0.78      0.38      0.51     11878\n",
      "         kettle       0.67      0.95      0.78     12376\n",
      "\n",
      "      micro avg       0.61      0.62      0.61     60000\n",
      "      macro avg       0.65      0.63      0.60     60000\n",
      "   weighted avg       0.66      0.62      0.59     60000\n",
      "    samples avg       0.60      0.59      0.57     60000\n",
      "\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "750/750 [==============================] - 3s 4ms/step\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "PC1*0.1\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         fridge       1.00      0.99      1.00     15058\n",
      "washing machine       0.93      0.87      0.90     12498\n",
      "    dish washer       0.91      0.76      0.83      7843\n",
      "      microwave       0.97      0.92      0.94     11228\n",
      "         kettle       0.92      0.91      0.91     13368\n",
      "\n",
      "      micro avg       0.95      0.90      0.93     59995\n",
      "      macro avg       0.95      0.89      0.92     59995\n",
      "   weighted avg       0.95      0.90      0.92     59995\n",
      "    samples avg       0.95      0.91      0.93     59995\n",
      "\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "0.3\n",
      "GRU enabled\n",
      "Model: \"TEST\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_19 (InputLayer)       [(None, 2550, 1)]         0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv1D)       (None, 2550, 19)          76        \n",
      "                                                                 \n",
      " block1_conv2 (Conv1D)       (None, 2550, 19)          1102      \n",
      "                                                                 \n",
      " block1_pool (MaxPooling1D)  (None, 1275, 19)          0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv1D)       (None, 1275, 38)          2204      \n",
      "                                                                 \n",
      " block2_conv2 (Conv1D)       (None, 1275, 38)          4370      \n",
      "                                                                 \n",
      " block2_pool (MaxPooling1D)  (None, 637, 38)           0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv1D)       (None, 637, 76)           8740      \n",
      "                                                                 \n",
      " block3_conv2 (Conv1D)       (None, 637, 76)           17404     \n",
      "                                                                 \n",
      " block3_conv3 (Conv1D)       (None, 637, 76)           17404     \n",
      "                                                                 \n",
      " block3_conv4 (Conv1D)       (None, 637, 76)           17404     \n",
      "                                                                 \n",
      " block3_pool (MaxPooling1D)  (None, 318, 76)           0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv1D)       (None, 318, 153)          35037     \n",
      "                                                                 \n",
      " block4_conv2 (Conv1D)       (None, 318, 153)          70380     \n",
      "                                                                 \n",
      " block4_conv3 (Conv1D)       (None, 318, 153)          70380     \n",
      "                                                                 \n",
      " block4_conv4 (Conv1D)       (None, 318, 153)          70380     \n",
      "                                                                 \n",
      " block4_pool (MaxPooling1D)  (None, 159, 153)          0         \n",
      "                                                                 \n",
      " block5_tran_conv1 (Conv1DTr  (None, 159, 153)         70380     \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_tran_conv2 (Conv1DTr  (None, 159, 153)         70380     \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_tran_conv3 (Conv1DTr  (None, 159, 153)         70380     \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_tran_conv4 (Conv1DTr  (None, 159, 153)         70380     \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_pool (AveragePooling  (None, 79, 153)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " gru_18 (GRU)                (None, 64)                42048     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              266240    \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 5)                 20485     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,706,486\n",
      "Trainable params: 17,706,486\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "750/750 [==============================] - 21s 26ms/step - loss: inf - accuracy: 0.6852\n",
      "Epoch 2/20\n",
      "750/750 [==============================] - 18s 24ms/step - loss: inf - accuracy: 0.7869\n",
      "Epoch 3/20\n",
      "750/750 [==============================] - 18s 24ms/step - loss: inf - accuracy: 0.7808\n",
      "Epoch 4/20\n",
      "750/750 [==============================] - 18s 24ms/step - loss: inf - accuracy: 0.7853\n",
      "Epoch 5/20\n",
      "750/750 [==============================] - 18s 24ms/step - loss: inf - accuracy: 0.7943\n",
      "Epoch 6/20\n",
      "750/750 [==============================] - 18s 24ms/step - loss: inf - accuracy: 0.8053\n",
      "Epoch 7/20\n",
      "750/750 [==============================] - 18s 24ms/step - loss: inf - accuracy: 0.8166\n",
      "Epoch 8/20\n",
      "750/750 [==============================] - 18s 24ms/step - loss: inf - accuracy: 0.8294\n",
      "Epoch 9/20\n",
      "750/750 [==============================] - 18s 24ms/step - loss: inf - accuracy: 0.8326\n",
      "Epoch 10/20\n",
      "750/750 [==============================] - 18s 24ms/step - loss: inf - accuracy: 0.8457\n",
      "Epoch 11/20\n",
      "750/750 [==============================] - 18s 24ms/step - loss: inf - accuracy: 0.8559\n",
      "Epoch 12/20\n",
      "750/750 [==============================] - 19s 25ms/step - loss: inf - accuracy: 0.8576\n",
      "Epoch 13/20\n",
      "750/750 [==============================] - 18s 24ms/step - loss: inf - accuracy: 0.8654\n",
      "Epoch 14/20\n",
      "750/750 [==============================] - 18s 24ms/step - loss: inf - accuracy: 0.8708\n",
      "Epoch 15/20\n",
      "750/750 [==============================] - 18s 24ms/step - loss: inf - accuracy: 0.8684\n",
      "Epoch 16/20\n",
      "750/750 [==============================] - 18s 24ms/step - loss: inf - accuracy: 0.8808\n",
      "Epoch 17/20\n",
      "750/750 [==============================] - 18s 24ms/step - loss: inf - accuracy: 0.8846\n",
      "Epoch 18/20\n",
      "750/750 [==============================] - 18s 24ms/step - loss: inf - accuracy: 0.8909\n",
      "Epoch 19/20\n",
      "750/750 [==============================] - 18s 24ms/step - loss: inf - accuracy: 0.8944\n",
      "Epoch 20/20\n",
      "750/750 [==============================] - 18s 24ms/step - loss: inf - accuracy: 0.8997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 18). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/rawTS/HolyDataset/ComplexityAnalysisAL/PC1*0.3_DALE/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/rawTS/HolyDataset/ComplexityAnalysisAL/PC1*0.3_DALE/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 3s 4ms/step\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "PC1*0.3\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         fridge       0.76      0.43      0.55     14772\n",
      "washing machine       0.54      0.90      0.67     10509\n",
      "    dish washer       0.61      0.53      0.57     10465\n",
      "      microwave       0.76      0.47      0.58     11878\n",
      "         kettle       0.67      0.94      0.79     12376\n",
      "\n",
      "      micro avg       0.65      0.64      0.65     60000\n",
      "      macro avg       0.67      0.65      0.63     60000\n",
      "   weighted avg       0.68      0.64      0.63     60000\n",
      "    samples avg       0.63      0.62      0.60     60000\n",
      "\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "750/750 [==============================] - 3s 4ms/step\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "PC1*0.3\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         fridge       1.00      1.00      1.00     15058\n",
      "washing machine       0.96      0.86      0.91     12498\n",
      "    dish washer       0.93      0.80      0.86      7843\n",
      "      microwave       0.97      0.93      0.95     11228\n",
      "         kettle       0.91      0.95      0.93     13368\n",
      "\n",
      "      micro avg       0.96      0.92      0.94     59995\n",
      "      macro avg       0.95      0.91      0.93     59995\n",
      "   weighted avg       0.96      0.92      0.94     59995\n",
      "    samples avg       0.96      0.93      0.94     59995\n",
      "\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "0.5\n",
      "GRU enabled\n",
      "Model: \"TEST\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_20 (InputLayer)       [(None, 2550, 1)]         0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv1D)       (None, 2550, 32)          128       \n",
      "                                                                 \n",
      " block1_conv2 (Conv1D)       (None, 2550, 32)          3104      \n",
      "                                                                 \n",
      " block1_pool (MaxPooling1D)  (None, 1275, 32)          0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv1D)       (None, 1275, 64)          6208      \n",
      "                                                                 \n",
      " block2_conv2 (Conv1D)       (None, 1275, 64)          12352     \n",
      "                                                                 \n",
      " block2_pool (MaxPooling1D)  (None, 637, 64)           0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv1D)       (None, 637, 128)          24704     \n",
      "                                                                 \n",
      " block3_conv2 (Conv1D)       (None, 637, 128)          49280     \n",
      "                                                                 \n",
      " block3_conv3 (Conv1D)       (None, 637, 128)          49280     \n",
      "                                                                 \n",
      " block3_conv4 (Conv1D)       (None, 637, 128)          49280     \n",
      "                                                                 \n",
      " block3_pool (MaxPooling1D)  (None, 318, 128)          0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv1D)       (None, 318, 256)          98560     \n",
      "                                                                 \n",
      " block4_conv2 (Conv1D)       (None, 318, 256)          196864    \n",
      "                                                                 \n",
      " block4_conv3 (Conv1D)       (None, 318, 256)          196864    \n",
      "                                                                 \n",
      " block4_conv4 (Conv1D)       (None, 318, 256)          196864    \n",
      "                                                                 \n",
      " block4_pool (MaxPooling1D)  (None, 159, 256)          0         \n",
      "                                                                 \n",
      " block5_tran_conv1 (Conv1DTr  (None, 159, 256)         196864    \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_tran_conv2 (Conv1DTr  (None, 159, 256)         196864    \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_tran_conv3 (Conv1DTr  (None, 159, 256)         196864    \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_tran_conv4 (Conv1DTr  (None, 159, 256)         196864    \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_pool (AveragePooling  (None, 79, 256)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " gru_19 (GRU)                (None, 64)                61824     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              266240    \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 5)                 20485     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,800,805\n",
      "Trainable params: 18,800,805\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "750/750 [==============================] - 22s 27ms/step - loss: inf - accuracy: 0.6573\n",
      "Epoch 2/20\n",
      "750/750 [==============================] - 18s 23ms/step - loss: inf - accuracy: 0.7682\n",
      "Epoch 3/20\n",
      "750/750 [==============================] - 18s 23ms/step - loss: inf - accuracy: 0.7869\n",
      "Epoch 4/20\n",
      "750/750 [==============================] - 18s 24ms/step - loss: inf - accuracy: 0.7840\n",
      "Epoch 5/20\n",
      "750/750 [==============================] - 18s 23ms/step - loss: inf - accuracy: 0.7926\n",
      "Epoch 6/20\n",
      "750/750 [==============================] - 17s 23ms/step - loss: inf - accuracy: 0.7788\n",
      "Epoch 7/20\n",
      "750/750 [==============================] - 18s 23ms/step - loss: inf - accuracy: 0.8019\n",
      "Epoch 8/20\n",
      "750/750 [==============================] - 18s 23ms/step - loss: inf - accuracy: 0.8179\n",
      "Epoch 9/20\n",
      "750/750 [==============================] - 18s 24ms/step - loss: inf - accuracy: 0.8312\n",
      "Epoch 10/20\n",
      "750/750 [==============================] - 18s 23ms/step - loss: inf - accuracy: 0.8332\n",
      "Epoch 11/20\n",
      "750/750 [==============================] - 17s 23ms/step - loss: inf - accuracy: 0.8398\n",
      "Epoch 12/20\n",
      "750/750 [==============================] - 18s 23ms/step - loss: inf - accuracy: 0.8523\n",
      "Epoch 13/20\n",
      "750/750 [==============================] - 18s 24ms/step - loss: inf - accuracy: 0.8528\n",
      "Epoch 14/20\n",
      "750/750 [==============================] - 18s 24ms/step - loss: inf - accuracy: 0.8569\n",
      "Epoch 15/20\n",
      "750/750 [==============================] - 18s 24ms/step - loss: inf - accuracy: 0.8657\n",
      "Epoch 16/20\n",
      "750/750 [==============================] - 18s 24ms/step - loss: inf - accuracy: 0.8710\n",
      "Epoch 17/20\n",
      "750/750 [==============================] - 18s 23ms/step - loss: inf - accuracy: 0.8692\n",
      "Epoch 18/20\n",
      "750/750 [==============================] - 18s 23ms/step - loss: inf - accuracy: 0.8801\n",
      "Epoch 19/20\n",
      "750/750 [==============================] - 18s 23ms/step - loss: inf - accuracy: 0.8849\n",
      "Epoch 20/20\n",
      "750/750 [==============================] - 18s 23ms/step - loss: inf - accuracy: 0.8832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 18). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/rawTS/HolyDataset/ComplexityAnalysisAL/PC1*0.5_DALE/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/rawTS/HolyDataset/ComplexityAnalysisAL/PC1*0.5_DALE/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 3s 4ms/step\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "PC1*0.5\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         fridge       0.73      0.36      0.48     14772\n",
      "washing machine       0.51      0.92      0.66     10509\n",
      "    dish washer       0.63      0.50      0.56     10465\n",
      "      microwave       0.71      0.49      0.58     11878\n",
      "         kettle       0.66      0.95      0.78     12376\n",
      "\n",
      "      micro avg       0.63      0.63      0.63     60000\n",
      "      macro avg       0.65      0.64      0.61     60000\n",
      "   weighted avg       0.66      0.63      0.61     60000\n",
      "    samples avg       0.60      0.61      0.58     60000\n",
      "\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "750/750 [==============================] - 3s 4ms/step\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "PC1*0.5\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         fridge       1.00      1.00      1.00     15058\n",
      "washing machine       0.93      0.91      0.92     12498\n",
      "    dish washer       0.95      0.77      0.85      7843\n",
      "      microwave       0.97      0.94      0.96     11228\n",
      "         kettle       0.91      0.94      0.92     13368\n",
      "\n",
      "      micro avg       0.95      0.93      0.94     59995\n",
      "      macro avg       0.95      0.91      0.93     59995\n",
      "   weighted avg       0.95      0.93      0.94     59995\n",
      "    samples avg       0.96      0.94      0.94     59995\n",
      "\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "0.7\n",
      "GRU enabled\n",
      "Model: \"TEST\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_21 (InputLayer)       [(None, 2550, 1)]         0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv1D)       (None, 2550, 44)          176       \n",
      "                                                                 \n",
      " block1_conv2 (Conv1D)       (None, 2550, 44)          5852      \n",
      "                                                                 \n",
      " block1_pool (MaxPooling1D)  (None, 1275, 44)          0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv1D)       (None, 1275, 89)          11837     \n",
      "                                                                 \n",
      " block2_conv2 (Conv1D)       (None, 1275, 89)          23852     \n",
      "                                                                 \n",
      " block2_pool (MaxPooling1D)  (None, 637, 89)           0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv1D)       (None, 637, 179)          47972     \n",
      "                                                                 \n",
      " block3_conv2 (Conv1D)       (None, 637, 179)          96302     \n",
      "                                                                 \n",
      " block3_conv3 (Conv1D)       (None, 637, 179)          96302     \n",
      "                                                                 \n",
      " block3_conv4 (Conv1D)       (None, 637, 179)          96302     \n",
      "                                                                 \n",
      " block3_pool (MaxPooling1D)  (None, 318, 179)          0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv1D)       (None, 318, 358)          192604    \n",
      "                                                                 \n",
      " block4_conv2 (Conv1D)       (None, 318, 358)          384850    \n",
      "                                                                 \n",
      " block4_conv3 (Conv1D)       (None, 318, 358)          384850    \n",
      "                                                                 \n",
      " block4_conv4 (Conv1D)       (None, 318, 358)          384850    \n",
      "                                                                 \n",
      " block4_pool (MaxPooling1D)  (None, 159, 358)          0         \n",
      "                                                                 \n",
      " block5_tran_conv1 (Conv1DTr  (None, 159, 358)         384850    \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_tran_conv2 (Conv1DTr  (None, 159, 358)         384850    \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_tran_conv3 (Conv1DTr  (None, 159, 358)         384850    \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_tran_conv4 (Conv1DTr  (None, 159, 358)         384850    \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " block5_pool (AveragePooling  (None, 79, 358)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " gru_20 (GRU)                (None, 64)                81408     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              266240    \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 5)                 20485     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,414,594\n",
      "Trainable params: 20,414,594\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "750/750 [==============================] - 44s 56ms/step - loss: inf - accuracy: 0.6670\n",
      "Epoch 2/20\n",
      "750/750 [==============================] - 38s 51ms/step - loss: inf - accuracy: 0.7715\n",
      "Epoch 3/20\n",
      "750/750 [==============================] - 38s 51ms/step - loss: inf - accuracy: 0.7895\n",
      "Epoch 4/20\n",
      "750/750 [==============================] - 39s 51ms/step - loss: inf - accuracy: 0.7941\n",
      "Epoch 5/20\n",
      "750/750 [==============================] - 38s 51ms/step - loss: inf - accuracy: 0.8145\n",
      "Epoch 6/20\n",
      "750/750 [==============================] - 38s 51ms/step - loss: inf - accuracy: 0.8288\n",
      "Epoch 7/20\n",
      "750/750 [==============================] - 38s 51ms/step - loss: inf - accuracy: 0.8379\n",
      "Epoch 8/20\n",
      "750/750 [==============================] - 39s 51ms/step - loss: inf - accuracy: 0.8449\n",
      "Epoch 9/20\n",
      "750/750 [==============================] - 39s 52ms/step - loss: inf - accuracy: 0.8483\n",
      "Epoch 10/20\n",
      "122/750 [===>..........................] - ETA: 32s - loss: inf - accuracy: 0.8491"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "# define a learning rate scheduler function\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "\n",
    "epochs = 20\n",
    "window_size = 2550\n",
    "batch_size = 128\n",
    "NmDevices = 5\n",
    "table_of_options = [1,2,3,4]\n",
    "gru = True\n",
    "gru_num = 64\n",
    "\n",
    "\n",
    "\n",
    "HolyDataset = pickle.load(open('./datasets/rawTS/HolyDataset.pkl', 'rb'))\n",
    "\n",
    "\"\"\"\n",
    "# sanity checks\n",
    "print(HolyDataset[0].shape, HolyDataset[1].shape, HolyDataset[2].shape, HolyDataset[3].shape, HolyDataset[4])\n",
    "for i in range(10):\n",
    "    print(HolyDataset[3][i])\n",
    "\"\"\"\n",
    "x_train = HolyDataset[0]\n",
    "x_test = HolyDataset[1]\n",
    "y_train = HolyDataset[2]\n",
    "y_test = HolyDataset[3]\n",
    "labels = HolyDataset[4]\n",
    "\n",
    "HolyDataset_DALE = pickle.load(open('./datasets/rawTS/HolyDatasetDALE.pkl', 'rb'))\n",
    "x_train_DALE = HolyDataset_DALE[0]\n",
    "x_test_DALE = HolyDataset_DALE[1]\n",
    "y_train_DALE = HolyDataset_DALE[2]\n",
    "y_test_DALE = HolyDataset_DALE[3]\n",
    "labels_DALE = HolyDataset_DALE[4]\n",
    "\n",
    "class_weights = class_weights_tool(y_test)\n",
    "\n",
    "test_koef = [0.1, 0.3, 0.5, 0.7, 0.9, 1.1, 1.3, 1.5, 1.7, 1.9, 2.1, 2.3, 2.5]\n",
    "\n",
    "RR, RU, UR, UU = [], [], [], []\n",
    "\n",
    "for i in range(len(test_koef)):\n",
    "    k = test_koef[i]\n",
    "    print(k)\n",
    "    # create a learning rate scheduler object\n",
    "    lr_scheduler = LearningRateScheduler(scheduler)\n",
    "    # |||||||||||||||||||||||||||||||| DL ||||||||||||||||||||||||||||||||\n",
    "    model = TEST(k,NmDevices, window_size, 'gru', 64)\n",
    "    model.build((len(y_train)+len(y_test),window_size,1))\n",
    "    model.summary()\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    #model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, class_weight=class_weights)\n",
    "    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, class_weight=class_weights, callbacks=[lr_scheduler])\n",
    "    # |||||||||||||||||||||||||||||||| save ||||||||||||||||||||||||||||||||\n",
    "    model.save(f'./models/rawTS/HolyDataset/ComplexityAnalysisAL/PC1*{k}/')\n",
    "    \n",
    "    \n",
    "    # |||||||||||||||||||||||||||||||| prediction RR ||||||||||||||||||||||||||||||||\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred_tf = (y_pred > 0.5)\n",
    "    print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\n",
    "    print(f\"PC1*{k}\")\n",
    "    print(metrics.classification_report(y_test, y_pred_tf, target_names=labels, zero_division=0))\n",
    "    wf1 = metrics.f1_score(y_test, \n",
    "                           y_pred_tf, \n",
    "                           labels=None, \n",
    "                           pos_label=1, \n",
    "                           average='weighted', \n",
    "                           sample_weight=None, \n",
    "                           zero_division=0)\n",
    "    RR.append(wf1)\n",
    "    pickle.dump(wf1, open(f'./datasets/rawTS/| HolyDataset |/ComplexityAnalysisAL/R->R/PC1*{k}.pkl', 'wb'))\n",
    "    print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\n",
    "    # |||||||||||||||||||||||||||||||| prediction RU ||||||||||||||||||||||||||||||||\n",
    "    y_pred = model.predict(x_test_DALE)\n",
    "    y_pred_tf = (y_pred > 0.5)\n",
    "    print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\n",
    "    print(f\"PC1*{k}\")\n",
    "    print(metrics.classification_report(y_test_DALE, y_pred_tf, target_names=labels, zero_division=0))\n",
    "    wf1 = metrics.f1_score(y_test_DALE, \n",
    "                           y_pred_tf, \n",
    "                           labels=None, \n",
    "                           pos_label=1, \n",
    "                           average='weighted', \n",
    "                           sample_weight=None, \n",
    "                           zero_division=0)\n",
    "    RU.append(wf1)\n",
    "    pickle.dump(wf1, open(f'./datasets/rawTS/| HolyDataset |/ComplexityAnalysisAL/R->U/PC1*{k}.pkl', 'wb'))\n",
    "    print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\n",
    "    \n",
    "for i in range(len(test_koef)):\n",
    "    k = test_koef[i]\n",
    "    print(k)\n",
    "    # |||||||||||||||||||||||||||||||| DL ||||||||||||||||||||||||||||||||\n",
    "    model = TEST(k,NmDevices, window_size, 'gru', 64)\n",
    "    model.build((len(y_train)+len(y_test),window_size,1))\n",
    "    model.summary()\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    model.fit(x_train_DALE, y_train_DALE, batch_size=batch_size, epochs=epochs, class_weight=class_weights)\n",
    "    # |||||||||||||||||||||||||||||||| save ||||||||||||||||||||||||||||||||\n",
    "    model.save(f'./models/rawTS/HolyDataset/ComplexityAnalysisAL/PC1*{k}_DALE/')\n",
    "    \n",
    "    \n",
    "    # |||||||||||||||||||||||||||||||| prediction UR ||||||||||||||||||||||||||||||||\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred_tf = (y_pred > 0.5)\n",
    "    print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\n",
    "    print(f\"PC1*{k}\")\n",
    "    print(metrics.classification_report(y_test, y_pred_tf, target_names=labels, zero_division=0))\n",
    "    wf1 = metrics.f1_score(y_test, \n",
    "                           y_pred_tf, \n",
    "                           labels=None, \n",
    "                           pos_label=1, \n",
    "                           average='weighted', \n",
    "                           sample_weight=None, \n",
    "                           zero_division=0)\n",
    "    UR.append(wf1)\n",
    "    pickle.dump(wf1, open(f'./datasets/rawTS/| HolyDataset |/ComplexityAnalysisAL/U->R/PC1*{k}.pkl', 'wb'))\n",
    "    print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\n",
    "    # |||||||||||||||||||||||||||||||| prediction UU ||||||||||||||||||||||||||||||||\n",
    "    y_pred = model.predict(x_test_DALE)\n",
    "    y_pred_tf = (y_pred > 0.5)\n",
    "    print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\n",
    "    print(f\"PC1*{k}\")\n",
    "    print(metrics.classification_report(y_test_DALE, y_pred_tf, target_names=labels, zero_division=0))\n",
    "    wf1 = metrics.f1_score(y_test_DALE, \n",
    "                           y_pred_tf, \n",
    "                           labels=None, \n",
    "                           pos_label=1, \n",
    "                           average='weighted', \n",
    "                           sample_weight=None, \n",
    "                           zero_division=0)\n",
    "    UU.append(wf1)\n",
    "    pickle.dump(wf1, open(f'./datasets/rawTS/| HolyDataset |/ComplexityAnalysisAL/U->U/PC1*{k}.pkl', 'wb'))\n",
    "    print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\n",
    "\n",
    "pickle.dump(RR, open(f'./datasets/rawTS/| HolyDataset |/ComplexityAnalysisAL/R->R/RR.pkl', 'wb'))    \n",
    "pickle.dump(RU, open(f'./datasets/rawTS/| HolyDataset |/ComplexityAnalysisAL/R->U/RU.pkl', 'wb'))\n",
    "pickle.dump(UR, open(f'./datasets/rawTS/| HolyDataset |/ComplexityAnalysisAL/U->R/UR.pkl', 'wb'))\n",
    "pickle.dump(UU, open(f'./datasets/rawTS/| HolyDataset |/ComplexityAnalysisAL/U->U/UU.pkl', 'wb'))\n",
    "print(RR)\n",
    "print(RU)\n",
    "print(UR)\n",
    "print(UU)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    WE ANALYSE THE RELATION BETWEEN NM.FILTERS AND PERFORMANCE\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = test_koef\n",
    "\n",
    "plt.plot(x, RR, \"x\", linewidth = 3, label=\"RR\")\n",
    "plt.plot(x, RU, \"o\", linewidth = 3, label=\"RU\")\n",
    "plt.plot(x, UR, \"s\", linewidth = 3, label=\"UR\")\n",
    "plt.plot(x, UU, \"^\", linewidth = 3, label=\"UU\")\n",
    "\n",
    "plt.plot(x, RR, linewidth = 1)\n",
    "plt.plot(x, RU, linewidth = 1)\n",
    "plt.plot(x, UR, linewidth = 1)\n",
    "plt.plot(x, UU, linewidth = 1)\n",
    "\n",
    "plt.ylabel('weighted F1 score')\n",
    "plt.xlabel('koeficient of multiplication')\n",
    "plt.legend()\n",
    "plt.savefig(\"ANALYSIS2.pdf\")\n",
    "display(plt.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c46c825c-f003-449e-91d1-d8a8cc5f0c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[85.68309310126354, 90.02695933288686, 90.48852308493292, 90.38654799249926, 90.75418503763666, 90.92969916281423, 90.62071640864836, 53.54437769927214, 83.9145868165733, 31.34144615286698, 39.89701952017457, 24.720104334020057, 34.91648820074532]\n",
      "[76.79269918128679, 77.04236685467205, 77.38570352768156, 78.06925971793662, 77.04840704683498, 77.60211595398606, 77.2163894623964, 66.18498806246019, 78.4868919011588, 43.495783859106005, 47.26756976341457, 31.500359994918785, 33.629369324221244]\n",
      "[63.637795899371085, 60.58517124537073, 64.53254201120794, 64.65227528300028, 63.30287467674053, 57.33920494143418, 64.96605686214515, 48.95533912559791, 60.09290381644974, 27.02555138805472, 43.60569124207168, 25.95595394230016, 55.78784143096115]\n",
      "[92.04767318301357, 93.12388600453822, 93.96048262955301, 93.81276448166179, 94.65140121535913, 70.11871519378022, 93.88475581691279, 56.22886225173659, 94.57557859210148, 48.96320970817942, 63.56935728908096, 31.164974632261387, 95.21942955546557]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7 0.9\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def BestKoef(lst1, lst2):\n",
    "    # We find the test that had the highest number in sum of 2 lists\n",
    "    sum_list = []\n",
    "    M, bestKoef = 0, 0\n",
    "    for i in range(len(lst1)):\n",
    "        sum_list.append(lst1[i]+lst2[i])\n",
    "    for j in range(len(sum_list)):\n",
    "        if sum_list[j] == max(sum_list): M = j \n",
    "    test_koef = [0.1, 0.3, 0.5, 0.7, 0.9, 1.1, 1.3, 1.5, 1.7, 1.9, 2.1, 2.3, 2.5]\n",
    "    bestKoef = test_koef[M]\n",
    "    return bestKoef\n",
    "\n",
    "def BestElement(lst1, lst2):\n",
    "    # We find the test that had the highest number in sum of 2 lists\n",
    "    sum_list = []\n",
    "    M, bestKoef = 0, 0\n",
    "    for i in range(len(lst1)):\n",
    "        sum_list.append(lst1[i]+lst2[i])\n",
    "    for j in range(len(sum_list)):\n",
    "        if sum_list[j] == max(sum_list): M = j \n",
    "    test_koef = [0.1, 0.3, 0.5, 0.7, 0.9, 1.1, 1.3, 1.5, 1.7, 1.9, 2.1, 2.3, 2.5]\n",
    "    bestKoef = test_koef[M]\n",
    "    return M\n",
    "\n",
    "def MultiplyElements(lst, multiplier):\n",
    "    result = []\n",
    "    for num in lst:\n",
    "        result.append(num * multiplier)\n",
    "    return result\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "test_koef = [0.1, 0.3, 0.5, 0.7, 0.9, 1.1, 1.3, 1.5, 1.7, 1.9, 2.1, 2.3, 2.5]\n",
    "\n",
    "RR = pickle.load(open(f'./datasets/rawTS/| HolyDataset |/ComplexityAnalysis/R->R/RR.pkl', 'rb'))    \n",
    "RU = pickle.load(open(f'./datasets/rawTS/| HolyDataset |/ComplexityAnalysis/R->U/RU.pkl', 'rb'))\n",
    "UR = pickle.load(open(f'./datasets/rawTS/| HolyDataset |/ComplexityAnalysis/U->R/UR.pkl', 'rb'))\n",
    "UU = pickle.load(open(f'./datasets/rawTS/| HolyDataset |/ComplexityAnalysis/U->U/UU.pkl', 'rb'))\n",
    "RR = MultiplyElements(RR, 100)\n",
    "RU = MultiplyElements(RU, 100)\n",
    "UR = MultiplyElements(UR, 100)\n",
    "UU = MultiplyElements(UU, 100)\n",
    "print(RR)\n",
    "print(RU)\n",
    "print(UR)\n",
    "print(UU)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    WE ANALYSE THE RELATION BETWEEN NM.FILTERS AND PERFORMANCE\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = test_koef\n",
    "\n",
    "C1, C4 = '#2a3f78', '#3c2323'\n",
    "C2, C3 = '#2c3c3f', '#74989e'\n",
    "#C5, C6 = '#6fe9f3', '#2bdf79'\n",
    "color_list = [C1, C2, C3, C4]#, C5, C6]\n",
    "plt.rcParams['axes.prop_cycle'] = plt.cycler(color=color_list)\n",
    "\n",
    "# Lines\n",
    "plt.plot(x, RR, \"x\", linewidth = 3, label=\"trained: REFIT, evaluated: REFIT\")\n",
    "plt.plot(x, RU, \"v\", linewidth = 3, label=\"trained: REFIT, evaluated: UK-DALE\")\n",
    "plt.plot(x, UR, \"^\", linewidth = 3, label=\"trained: UK-DALE, evaluated: REFIT\")\n",
    "plt.plot(x, UU, \"s\", linewidth = 3, label=\"trained: UK-DALE, evaluated: UK-DALE\")\n",
    "\n",
    "# Marks\n",
    "plt.plot(x, RR, linewidth = 2)\n",
    "plt.plot(x, RU, linewidth = 2)\n",
    "plt.plot(x, UR, linewidth = 2)\n",
    "plt.plot(x, UU, linewidth = 2)\n",
    "\n",
    "# Squares around PC1 and PC2\n",
    "# PC1\n",
    "xs1 = [0.64, 0.64, 0.76, 0.76, 0.64]\n",
    "ys1 = [60, 99, 99, 60, 60]\n",
    "plt.plot(xs1, ys1, color = C5, label = 'best cross evaluation performance: PirnatCross1')\n",
    "# PC2\n",
    "xs2 = [0.44, 0.44, 0.56, 0.56, 0.44]\n",
    "ys2 = [60, 99, 99, 60, 60]\n",
    "plt.plot(xs2, ys2, color = C6, label = 'best cross evaluation compromise: PirnatCross2')\n",
    "\n",
    "plt.ylabel('average weighted F1 score [%]')\n",
    "plt.yticks([20, 30, 40, 50, 60, 70, 80, 90, 100])\n",
    "plt.xlabel('scaling factor')\n",
    "plt.xticks([0.1, 0.3, 0.5, 0.7, 0.9, 1.1, 1.3, 1.5, 1.7, 1.9, 2.1, 2.3, 2.5])  # set x-axis tick values\n",
    "plt.legend()\n",
    "#plt.savefig(\"ANALYSIS.pdf\")\n",
    "plt.savefig(\"ANALYSIS_colored_WPC1PC2.pdf\")\n",
    "display(plt.show())\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    WE DECIDE ON THE BEST NM.FILTERS PURELY ON PERFORMANCE\n",
    "\"\"\"\n",
    "\n",
    "print(BestKoef(UR, RU), BestKoef(UU, RR))\n",
    "\n",
    "\"\"\"\n",
    "    WE MAKE A GRAPH THAT HAS THE BEST KOEF MARKED\n",
    "\"\"\"\n",
    "G1, G2, G3, G4, G5 = '#5c5c5c', '#757575', '#8f8f8f', '#a8a8a8', '#b5b5b5'\n",
    "#C1, C2, C3, C4 = '#2a3f78', '#7a72d2', '#96b5f6', '#3c2323'\n",
    "C1, C2 = '#2a3f78', '#3c2323'\n",
    "C2, C3 = '#2c3c3f', '#74989e'\n",
    "C5, C6 = '#6fe9f3', '#2bdf79'\n",
    "\n",
    "\n",
    "#color_list = [G1,G2,G3,G4,G5]\n",
    "#color_list = [G1,G4]\n",
    "#color_list = [C1,C2,C3,C4]\n",
    "color_list = [C2, C3]\n",
    "plt.rcParams['axes.prop_cycle'] = plt.cycler(color=color_list)\n",
    "\n",
    "# Lines\n",
    "plt.plot(x, RU, \"v\", linewidth = 3, label=\"trained: REFIT, tested: UK-DALE\")#, label=\"trained: REFIT, tested: UK-DALE\")\n",
    "plt.plot(x, UR, \"^\", linewidth = 3, label=\"trained: UK-DALE, tested: REFIT\")#, label=\"trained: UK-DALE, tested: REFIT\")\n",
    "\n",
    "# Marks\n",
    "plt.plot(x, RU, linewidth = 2)\n",
    "plt.plot(x, UR, linewidth = 2)\n",
    "\n",
    "# Marks for PC1 and PC2\n",
    "#plt.scatter([BestKoef(UR, RU)], UR[BestElement(UR, RU)], zorder = 5, linewidth = 2, marker = '^', color = C5)#, label='best performance: PirnatCross1')\n",
    "#plt.scatter([BestKoef(UR, RU)], RU[BestElement(UR, RU)], zorder = 5, linewidth = 2, marker = 'v', color = C5)\n",
    "#plt.scatter(0.5, 0.6453254201120794*100, zorder = 5,  linewidth = 2, marker = '^', color = C6)#, label='best compromise: PirnatCross2')\n",
    "#plt.scatter(0.5, 0.7738570352768156*100, zorder = 5,  linewidth = 2, marker = 'v', color = C6)\n",
    "\n",
    "\n",
    "# Squares around PC1 and PC2\n",
    "# PC1\n",
    "xs1 = [0.64, 0.64, 0.76, 0.76, 0.64]\n",
    "ys1 = [60, 82, 82, 60, 60]\n",
    "plt.plot(xs1, ys1, color = C5, label = 'best performance: PirnatCross1')\n",
    "# PC2\n",
    "xs2 = [0.44, 0.44, 0.56, 0.56, 0.44]\n",
    "ys2 = [60, 82, 82, 60, 60]\n",
    "plt.plot(xs2, ys2, color = C6, label = 'best compromise: PirnatCross2')\n",
    "\n",
    "# Plt parameters\n",
    "plt.ylabel('average weighted F1 score [%]')\n",
    "plt.yticks([20, 30, 40, 50, 60, 70, 80])\n",
    "plt.xlabel('multiplication parameter')\n",
    "plt.xticks([0.1, 0.3, 0.5, 0.7, 0.9, 1.1, 1.3, 1.5, 1.7, 1.9, 2.1, 2.3, 2.5])  # set x-axis tick values\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig(\"FINAL_ANALYSIS_PC1&PC2_colored.pdf\")\n",
    "display(plt.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8fdbd0a7-ee29-46fa-82da-7c13ba7d79ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = [0.61, 0.61, 0.79, 0.79, 0.61]\n",
    "y = [60, 79, 79, 60, 60]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y, color = C5)\n",
    "\n",
    "ax.set_xlim([0, 2.5])\n",
    "ax.set_ylim([20, 80])\n",
    "\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_title('Square')\n",
    "#ax.grid(True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff3b2a4b-55f3-4d62-8769-516f4ea801e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7679269918128679, 0.7704236685467205, 0.7738570352768156, 0.7806925971793661, 0.7704840704683499, 0.7760211595398606, 0.7721638946239641, 0.6618498806246019, 0.7848689190115881, 0.43495783859106, 0.4726756976341457, 0.31500359994918786, 0.3362936932422124]\n",
      "[0.6363779589937109, 0.6058517124537073, 0.6453254201120794, 0.6465227528300028, 0.6330287467674053, 0.5733920494143419, 0.6496605686214515, 0.4895533912559791, 0.6009290381644974, 0.2702555138805472, 0.43605691242071676, 0.2595595394230016, 0.5578784143096115]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([1.4043049508065788,\n",
       "  1.3762753810004278,\n",
       "  1.419182455388895,\n",
       "  1.427215350009369,\n",
       "  1.4035128172357552,\n",
       "  1.3494132089542026,\n",
       "  1.4218244632454156,\n",
       "  1.151403271880581,\n",
       "  1.3857979571760854,\n",
       "  0.7052133524716072,\n",
       "  0.9087326100548625,\n",
       "  0.5745631393721895,\n",
       "  0.8941721075518239],\n",
       " 1.427215350009369,\n",
       " 0.7)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def BestKoef(lst1, lst2):\n",
    "    # We find the test that had the highest number in sum of 2 lists\n",
    "    sum_list = []\n",
    "    M, bestKoef = 0, 0\n",
    "    for i in range(len(lst1)):\n",
    "        sum_list.append(lst1[i]+lst2[i])\n",
    "    for j in range(len(sum_list)):\n",
    "        if sum_list[j] == max(sum_list): M = j \n",
    "    test_koef = [0.1, 0.3, 0.5, 0.7, 0.9, 1.1, 1.3, 1.5, 1.7, 1.9, 2.1, 2.3, 2.5]\n",
    "    bestKoef = test_koef[M]\n",
    "    return bestKoef\n",
    "print(RU)\n",
    "print(UR)\n",
    "BestOf2Lists(RU, UR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764e3750-b59e-467d-aef5-432d65df4c4e",
   "metadata": {},
   "source": [
    "# USE THIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f58d5e72-158e-4adf-8b3f-6a0b4eccafec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU enabled\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_train_UKD' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 55\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[39mTrain on UKD, evaluate on REF\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     54\u001b[0m model \u001b[39m=\u001b[39m NUK\u001b[39m.\u001b[39mPC0(NmDevices, window_size, \u001b[39m'\u001b[39m\u001b[39mgru\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m128\u001b[39m, k)\n\u001b[0;32m---> 55\u001b[0m model\u001b[39m.\u001b[39mbuild((\u001b[39mlen\u001b[39m(y_train_UKD) \u001b[39m+\u001b[39m \u001b[39mlen\u001b[39m(y_test_UKD), window_size, \u001b[39m1\u001b[39m))\n\u001b[1;32m     56\u001b[0m \u001b[39m#model.summary()\u001b[39;00m\n\u001b[1;32m     57\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39m\u001b[39m0.0003\u001b[39m), loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[NUK\u001b[39m.\u001b[39mF1Score, NUK\u001b[39m.\u001b[39mWeightedF1Score(NUK\u001b[39m.\u001b[39mclass_weights_tool(y_test_UKD))])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_train_UKD' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "               USES THE HOLY DATASET, OUR, EXPERIMENT WITH KFOLD!!!!!\n",
    "               \n",
    "            \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "epochs = 20\n",
    "window_size = 2550\n",
    "batch_size = 128\n",
    "NmDevices = 5\n",
    "# table_of_options = [1,2,3,4]\n",
    "k = 1\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from sklearn.model_selection import KFold\n",
    "import pickle\n",
    "\n",
    "# Define a learning rate scheduler function\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "\n",
    "# Load the datasets\n",
    "HolyDataset_UKD = pickle.load(open('./datasets/HolyDatasetDALE.pkl', 'rb'))\n",
    "HolyDataset_REF = pickle.load(open('./datasets/HolyDataset.pkl', 'rb'))\n",
    "\n",
    "x_UKD, y_UKD, labels_UKD = HolyDataset_UKD[0], HolyDataset_UKD[2], HolyDataset_UKD[4]\n",
    "class_weights_UKD = class_weights_tool(y_UKD)\n",
    "\n",
    "x_REF, y_REF, labels_REF = HolyDataset_REF[0], HolyDataset_REF[2], HolyDataset_REF[4]\n",
    "class_weights_REF = class_weights_tool(y_REF)\n",
    "\n",
    "\n",
    "# Lists to store the evaluation results for each fold\n",
    "evaluation_results_UKD_UKD, evaluation_results_UKD_REF, evaluation_results_REF_UKD, evaluation_results_REF_REF = [], [], [], []\n",
    "\n",
    "# x_train_UKD, x_val_UKD = x_UKD[train_idx], x_UKD[val_idx]\n",
    "# y_train_UKD, y_val_UKD = y_UKD[train_idx], y_UKD[val_idx]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Train on UKD, evaluate on REF\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "model = NUK.PC0(NmDevices, window_size, 'gru', 128, k)\n",
    "model.build((len(y_train_UKD) + len(y_test_UKD), window_size, 1))\n",
    "#model.summary()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003), loss='binary_crossentropy', metrics=[NUK.F1Score, NUK.WeightedF1Score(NUK.class_weights_tool(y_test_UKD))])\n",
    "lr_scheduler = LearningRateScheduler(scheduler)\n",
    "model.fit(x_train_UKD, y_train_UKD, batch_size=batch_size, epochs=epochs, class_weight=class_weights_UKD, callbacks=[lr_scheduler])\n",
    "\n",
    "# Evaluate the model on the UKD dataset\n",
    "y_pred_UKD = model.predict(x_val_UKD)\n",
    "y_pred_tf_UKD = (y_pred_UKD > 0.5)\n",
    "report_UKD = metrics.classification_report(y_val_UKD, y_pred_tf_UKD, target_names=labels_UKD, zero_division=0)\n",
    "# I prefer to save class. reports in pandas dataframes so i use this function\n",
    "report_UKD_DF = NUK.ClassificationReportToDF(report_UKD, labels_UKD)\n",
    "report_UKD_DF.rename(columns={report_UKD_DF.columns[0]: \"device\"}, inplace=True)\n",
    "evaluation_results_UKD_UKD.append(report_UKD_DF)\n",
    "\n",
    "# Evaluate the model on the REF dataset\n",
    "y_pred_REF = model.predict(x_REF)\n",
    "y_pred_tf_REF = (y_pred_REF > 0.5)\n",
    "report_REF = metrics.classification_report(y_REF, y_pred_tf_REF, target_names=labels_REF, zero_division=0)\n",
    "# I prefer to save class. reports in pandas dataframes so i use this function\n",
    "report_REF_DF = NUK.ClassificationReportToDF(report_REF, labels_REF)\n",
    "report_REF_DF.rename(columns={report_REF_DF.columns[0]: \"device\"}, inplace = True)\n",
    "evaluation_results_UKD_REF.append(report_REF_DF)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Train on REF, evaluate on UKD\n",
    "\"\"\"\n",
    "\n",
    "# x_train_REF, x_val_REF = x_REF[train_idx], x_REF[val_idx]  # Swap 'x_train_UKD' with 'x_train_REF' and 'x_val_UKD' with 'x_val_REF'\n",
    "# y_train_REF, y_val_REF = y_REF[train_idx], y_REF[val_idx]  # Swap 'y_train_UKD' with 'y_train_REF' and 'y_val_UKD' with 'y_val_REF'\n",
    "\n",
    "\n",
    "model = NUK.PC0(NmDevices, window_size, 'gru', 128, k)\n",
    "model.build((len(y_train_REF) + len(y_test_REF), window_size, 1))  # Swap 'y_train_UKD' with 'y_train_REF'\n",
    "#model.summary()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003), loss='binary_crossentropy', metrics=[NUK.F1Score, NUK.WeightedF1Score(NUK.class_weights_tool(y_test_REF))])  # Swap 'y_test_UKD' with 'y_test_REF'\n",
    "lr_scheduler = LearningRateScheduler(scheduler)\n",
    "model.fit(x_train_REF, y_train_REF, batch_size=batch_size, epochs=epochs, class_weight=class_weights_REF, callbacks=[lr_scheduler])  # Swap 'x_train_UKD' with 'x_train_REF' and 'y_train_UKD' with 'y_train_REF'\n",
    "\n",
    "# Evaluate the model on the REF dataset  # Swap 'UKD' with 'REF'\n",
    "y_pred_REF = model.predict(x_val_REF)  # Swap 'x_val_UKD' with 'x_val_REF'\n",
    "y_pred_tf_REF = (y_pred_REF > 0.5)\n",
    "report_REF = metrics.classification_report(y_val_REF, y_pred_tf_REF, target_names=labels_REF, zero_division=0)  # Swap 'y_val_UKD' with 'y_val_REF'\n",
    "# I prefer to save class. reports in pandas dataframes so i use this function\n",
    "report_REF_DF = NUK.ClassificationReportToDF(report_REF, labels_REF)\n",
    "report_REF_DF.rename(columns={report_REF_DF.columns[0]: \"device\"}, inplace=True)\n",
    "evaluation_results_REF_REF.append(report_REF_DF)  # Swap 'evaluation_results_UKD_REF' with 'evaluation_results_REF_REF'\n",
    "\n",
    "# Evaluate the model on the UKD dataset  # Swap 'REF' with 'UKD'\n",
    "y_pred_UKD = model.predict(x_UKD)  # Swap 'x_REF' with 'x_UKD'\n",
    "y_pred_tf_UKD = (y_pred_UKD > 0.5)\n",
    "report_UKD = metrics.classification_report(y_UKD, y_pred_tf_UKD, target_names=labels_UKD, zero_division=0)  # Swap 'y_REF' with 'y_UKD'\n",
    "# I prefer to save class. reports in pandas dataframes so i use this function\n",
    "report_UKD_DF = NUK.ClassificationReportToDF(report_UKD, labels_UKD)\n",
    "report_UKD_DF.rename(columns={report_UKD_DF.columns[0]: \"device\"}, inplace=True)\n",
    "evaluation_results_REF_UKD.append(report_UKD_DF)  # Swap 'evaluation_results_UKD_UKD' with 'evaluation_results_REF_UKD'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(evaluation_results_UKD_UKD, evaluation_results_UKD_REF, evaluation_results_REF_UKD, evaluation_results_REF_REF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81808e63-e3f5-4540-9301-58efba453434",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
