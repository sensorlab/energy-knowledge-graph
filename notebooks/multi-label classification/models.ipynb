{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... By downloading and using the CUDA Toolkit conda packages, you accept the terms and conditions of the CUDA End User License Agreement (EULA): https://docs.nvidia.com/cuda/eula/index.html\n",
      "\n",
      "By downloading and using the cuDNN conda packages, you accept the terms and conditions of the NVIDIA cuDNN EULA -\n",
      "  https://docs.nvidia.com/deeplearning/cudnn/sla/index.html\n",
      "\n",
      "done\n",
      "\u001b[33mWARNING: Skipping nilmtk as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping nilm_metadata as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting git+https://github.com/nilmtk/nilmtk@master\n",
      "  Cloning https://github.com/nilmtk/nilmtk (to revision master) to /tmp/pip-req-build-lz5e04ad\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/nilmtk/nilmtk /tmp/pip-req-build-lz5e04ad\n",
      "  Resolved https://github.com/nilmtk/nilmtk to commit b2c514479cef478cab872cb635056da08d5352a1\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: nilmtk\n",
      "  Building wheel for nilmtk (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nilmtk: filename=nilmtk-0.4.0.dev1+git.b2c5144-py3-none-any.whl size=279177 sha256=da44d1f3e8fede4ecac0335969ace5849cc9df98dd2cf226d99ed782dc4c2878\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-gat0k9y4/wheels/05/a4/8e/b767c3d1714f61fd30ec991c25780be8cc04c474da8205aeee\n",
      "Successfully built nilmtk\n",
      "Installing collected packages: nilmtk\n",
      "Successfully installed nilmtk-0.4.0.dev1+git.b2c5144\n",
      "Collecting git+https://github.com/nilmtk/nilm_metadata@master\n",
      "  Cloning https://github.com/nilmtk/nilm_metadata (to revision master) to /tmp/pip-req-build-iq0bpxir\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/nilmtk/nilm_metadata /tmp/pip-req-build-iq0bpxir\n",
      "  Resolved https://github.com/nilmtk/nilm_metadata to commit 7ed4bab9062d04cb35c6b6000b451715dc5ab4af\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: nilm-metadata\n",
      "  Building wheel for nilm-metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nilm-metadata: filename=nilm_metadata-0.2.5-py3-none-any.whl size=24340 sha256=5314a96c9b04b46ff02eb4820e2fd4bb5479a3bc97212954f3e123792d6e1593\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-vx1yu1g4/wheels/7e/2f/7f/e41975c202542dbc11228875ff8473ed4cb95e04a274222bb7\n",
      "Successfully built nilm-metadata\n",
      "Installing collected packages: nilm-metadata\n",
      "Successfully installed nilm-metadata-0.2.5\n"
     ]
    }
   ],
   "source": [
    "#!rm -r /home/jovyan/.local/share/jupyter/kernels/nilmtk\n",
    "!mamba install tensorflow-gpu==2.10 -y -q\n",
    "# !mamba install tensorflow-gpu==2.11.0 -y -q\n",
    "!pip uninstall -y -q nilmtk nilm_metadata\n",
    "#!pip install -q pandas networkx tables scikit-learn hmmlearn pyyaml matplotlib==3.1.3 xgboost pyts\n",
    "# Trick to install NILM regardless of its dependencies\n",
    "#!pip install --no-cache -U git+https://github.com/nilmtk/nilm_metadata.git\n",
    "#!pip install --no-cache -U git+https://github.com/nilmtk/nilmtk.git@0.4.3\n",
    "!python3 -m pip install --no-deps git+https://github.com/nilmtk/nilmtk@master\n",
    "!python3 -m pip install --no-deps git+https://github.com/nilmtk/nilm_metadata@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 09:35:09.930525: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA A100 80GB PCIe MIG 3g.40gb, compute capability 8.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# from nilmtk import DataSet\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from joblib import Memory\n",
    "import pickle\n",
    "from pprint import pprint\n",
    "\n",
    "#from nilmtk import DataSet\n",
    "import multiprocessing as mp\n",
    "\n",
    "from typing import Dict\n",
    "\n",
    "!pip install -q scikit-learn-intelex\n",
    "#from sklearnex import patch_sklearn\n",
    "#patch_sklearn()\n",
    "\n",
    "from sklearn import pipeline, metrics, linear_model, model_selection, multioutput, tree, ensemble, neural_network\n",
    "!pip install xgboost -q\n",
    "import xgboost as xgb\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import cross_val_predict, train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "import numpy as np\n",
    "#import graphviz\n",
    "import keras\n",
    "from sklearn.utils import class_weight\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#from ann_visualizer.visualize import ann_viz\n",
    "from matplotlib import pyplot as plt \n",
    "from sklearn.metrics import multilabel_confusion_matrix, classification_report, confusion_matrix\n",
    "# GPU goes brrrrrrrrrrrrrrrrrrrr\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_bfloat16') # bfloat16\n",
    "\n",
    "!pip3 install tqdm -q\n",
    "from tqdm.notebook import tqdm\n",
    "import NUK\n",
    "\n",
    "# import garbage collector\n",
    "import gc\n",
    "import time\n",
    "\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if physical_devices:\n",
    "    print(physical_devices)\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "else:\n",
    "    print(\"No GPU found, model will train on CPU.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "epochs =1200\n",
    "window_size = 2688\n",
    "batch_size = 128\n",
    "NmDevices = 64\n",
    "# table_of_options = [1,2,3,4]\n",
    "k = 0.125\n",
    "# Define a learning rate scheduler function\n",
    "# def scheduler(epoch, lr):\n",
    "#     return lr\n",
    "#     if epoch == 0 or epoch == 1:\n",
    "#         return lr\n",
    "#     if epoch == 35:\n",
    "#         return lr *0.5\n",
    "#     else:\n",
    "#         return lr\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "test_size = 0.2\n",
    "lambda_l2=0\n",
    "function = \"GRU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "# data= pd.read_pickle(\"../../Energy_graph/data/training_data/synthetic/X_Y_wsize2688_numW_50000_upper32_gap3600_numD64_ideal.pkl\")\n",
    "data= pd.read_pickle(\"../../shared/to_vid/X_Y_wsize2688_numW_100000_upper32_gap3600_numD64_ideal.pkl\")\n",
    "\n",
    "labels = pd.read_pickle(\"../../Energy_graph/data/labels_new.pkl\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X = np.array([i[0] for i in data])\n",
    "y = np.array([i[1] for i in data])\n",
    "\n",
    "\n",
    "\n",
    "# T/F to 1/0\n",
    "y = y.astype(int)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min-max normalization Xmin=0 \n",
    "def normalize(X):\n",
    "    max_value = 0\n",
    "\n",
    "    for x in X:\n",
    "        v = np.max(x)\n",
    "        if v > max_value:\n",
    "            max_value = v\n",
    "\n",
    "    if max_value == 0:\n",
    "        return X\n",
    "    return X / max_value\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InceptionTime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InceptionTime class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK INCEPTION TIME IMPLEMENTATION \n",
    "\n",
    "\n",
    "class_weighs_pre = NUK.class_weights_tool(y)\n",
    "\n",
    "class Classifier_INCEPTION:\n",
    "\n",
    "    def __init__(self, output_directory, input_shape, nb_classes, iteration, verbose=False, build=True, batch_size=64,\n",
    "                 nb_filters=32, use_residual=True, use_bottleneck=True, depth=6, kernel_size=41, nb_epochs=1500, lr=0.001):\n",
    "\n",
    "        self.output_directory = output_directory\n",
    "\n",
    "        self.nb_filters = nb_filters\n",
    "        self.use_residual = use_residual\n",
    "        self.use_bottleneck = use_bottleneck\n",
    "        self.depth = depth\n",
    "        self.kernel_size = kernel_size - 1\n",
    "        self.callbacks = None\n",
    "        self.batch_size = batch_size\n",
    "        self.bottleneck_size = 32\n",
    "        self.nb_epochs = nb_epochs\n",
    "        self.lr = lr\n",
    "        self.iteration = iteration\n",
    "\n",
    "        if build == True:\n",
    "            self.model = self.build_model(input_shape, nb_classes)\n",
    "            self.verbose = verbose\n",
    "            self.model.save_weights(self.output_directory + 'model_init.hdf5')\n",
    "\n",
    "    def _inception_module(self, input_tensor, stride=1, activation='linear'):\n",
    "\n",
    "        if self.use_bottleneck and int(input_tensor.shape[-1]) > 1:\n",
    "            input_inception = keras.layers.Conv1D(filters=self.bottleneck_size, kernel_size=1,\n",
    "                                                  padding='same', activation=activation, use_bias=False)(input_tensor)\n",
    "        else:\n",
    "            input_inception = input_tensor\n",
    "\n",
    "        \n",
    "        kernel_size_s = [self.kernel_size // (2 ** i) for i in range(3)]\n",
    "\n",
    "        conv_list = []\n",
    "\n",
    "        for i in range(len(kernel_size_s)):\n",
    "            conv_list.append(keras.layers.Conv1D(filters=self.nb_filters, kernel_size=kernel_size_s[i],\n",
    "                                                 strides=stride, padding='same', activation=activation, use_bias=False)(\n",
    "                input_inception))\n",
    "\n",
    "        max_pool_1 = keras.layers.MaxPool1D(pool_size=3, strides=stride, padding='same')(input_tensor)\n",
    "\n",
    "        conv_6 = keras.layers.Conv1D(filters=self.nb_filters, kernel_size=1,\n",
    "                                     padding='same', activation=activation, use_bias=False)(max_pool_1)\n",
    "\n",
    "        conv_list.append(conv_6)\n",
    "\n",
    "        x = keras.layers.Concatenate(axis=2)(conv_list)\n",
    "        x = keras.layers.BatchNormalization()(x)\n",
    "        x = keras.layers.Activation(activation='relu')(x)\n",
    "        return x\n",
    "\n",
    "    def _shortcut_layer(self, input_tensor, out_tensor):\n",
    "        shortcut_y = keras.layers.Conv1D(filters=int(out_tensor.shape[-1]), kernel_size=1,\n",
    "                                         padding='same', use_bias=False)(input_tensor)\n",
    "        shortcut_y = keras.layers.BatchNormalization()(shortcut_y)\n",
    "\n",
    "        x = keras.layers.Add()([shortcut_y, out_tensor])\n",
    "        x = keras.layers.Activation('relu')(x)\n",
    "        return x\n",
    "\n",
    "    def build_model(self, input_shape, nb_classes):\n",
    "        input_layer = keras.layers.Input(input_shape)\n",
    "\n",
    "        x = input_layer\n",
    "        input_res = input_layer\n",
    "\n",
    "        for d in range(self.depth):\n",
    "\n",
    "            x = self._inception_module(x)\n",
    "\n",
    "            if self.use_residual and d % 3 == 2:\n",
    "                x = self._shortcut_layer(input_res, x)\n",
    "                input_res = x\n",
    "\n",
    "        gap_layer = keras.layers.GlobalAveragePooling1D()(x)\n",
    "\n",
    "        output_layer = keras.layers.Dense(nb_classes, activation='sigmoid')(gap_layer)\n",
    "\n",
    "        model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "        # cross entropy loss ?\n",
    "        model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=self.lr),\n",
    "                      metrics=['accuracy', NUK.F1Score, NUK.WeightedF1Score(class_weighs_pre)])\n",
    "\n",
    "        # callbacks\n",
    "        reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.25, patience=7, min_lr=0.0001)\n",
    "        early_stopping = keras.callbacks.EarlyStopping(patience=9, restore_best_weights=True, monitor='loss')\n",
    "\n",
    "        file_path = self.output_directory + f'best_model_{self.iteration}.hdf5'\n",
    "\n",
    "        model_checkpoint = keras.callbacks.ModelCheckpoint(filepath=file_path, monitor='loss',\n",
    "                                                           save_best_only=True)\n",
    "        self.callbacks = [reduce_lr, model_checkpoint, early_stopping]\n",
    "\n",
    "        return model\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "       \n",
    "\n",
    "        if self.batch_size is None:\n",
    "            mini_batch_size = int(min(x_train.shape[0] / 10, 16))\n",
    "        else:\n",
    "            mini_batch_size = self.batch_size\n",
    "\n",
    "        self.model.fit(x_train, y_train, batch_size=mini_batch_size, epochs=self.nb_epochs,\n",
    "                                  verbose=self.verbose, callbacks=self.callbacks, validation_split=0.1)\n",
    "\n",
    "\n",
    "        self.model.save(self.output_directory + f'last_model_{self.iteration}.hdf5')\n",
    "\n",
    "        keras.backend.clear_session()\n",
    "\n",
    "        return None\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        model_path = self.output_directory + f'last_model_{self.iteration}.hdf5'\n",
    "        model = keras.models.load_model(model_path, custom_objects={'F1Score': NUK.F1Score, \"WeightedF1\": NUK.WeightedF1Score(class_weighs_pre)})\n",
    "        y_pred = model.predict(x_test, batch_size=self.batch_size)\n",
    "\n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "evaluation_results = []\n",
    "predictions = []\n",
    "class_weights_all = NUK.class_weights_tool(y)\n",
    "itr = 0\n",
    "for train_index, test_index in tqdm(kf.split(X)):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    X_train = normalize(X_train)\n",
    "    X_test = normalize(X_test)\n",
    "    print(batch_size, epochs)\n",
    "    model = Classifier_INCEPTION(output_directory=\"./models/\", input_shape=(window_size, 1), nb_classes=78, verbose=True, build=True, batch_size=batch_size, nb_epochs=epochs, lr=0.001, depth=6)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_tf = (y_pred > 0.5)\n",
    "\n",
    "    predictions.append((y_pred_tf, y_test, y_pred))\n",
    "    t = (y_pred_tf, y_test, y_pred)\n",
    "    with open(f\"./predictions/test_inception_pickle_{itr}.pkl\", 'wb') as f:\n",
    "        pickle.dump(t, f)\n",
    "\n",
    "    itr += 1\n",
    "    report = metrics.classification_report(y_test, y_pred_tf, target_names=labels, zero_division=0, output_dict=True)\n",
    "    print(report[\"weighted avg\"])\n",
    "    evaluation_results.append(report)\n",
    "    gc.collect()\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "for i in range(len(evaluation_results)):\n",
    "    if i == 0:\n",
    "        df = pd.DataFrame(evaluation_results[i]).T\n",
    "    else:\n",
    "        df = df + pd.DataFrame(evaluation_results[i]).T\n",
    "\n",
    "\n",
    "df = df / 5\n",
    "import os\n",
    "# check if directory exsits\n",
    "if not os.path.exists(f\"../../Energy_graph/data/results/{window_size}\"):\n",
    "    os.makedirs(f\"../../Energy_graph/data/results/{window_size}\")\n",
    "if lambda_l2 == 0:\n",
    "    df.to_csv(f\"../../Energy_graph/data/results/{window_size}/Inception_epochs{epochs}_batch_size{batch_size}_k{k}_classes{NmDevices}_{function}_watts_syn.csv\")\n",
    "else:\n",
    "    df.to_csv(f\"../../Energy_graph/data/results/w_size{window_size}_epochs{epochs}_batch_size{batch_size}_k{k}_classes{NmDevices}_{function}_watts_syn_reg{lambda_l2}.csv\")\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_splits = 3\n",
    "treshold = 0.3\n",
    "kf = KFold(n_splits=num_splits, shuffle=True, random_state=RANDOM_SEED)\n",
    "evaluation_results = []\n",
    "predictions = []\n",
    "class_weights_all = NUK.class_weights_tool(y)\n",
    "for fold,(train_index, test_index) in tqdm(enumerate(kf.split(X))):\n",
    "    # print(\"Train indices:\", train_index, \"Test indices:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # normalization\n",
    "    X_train = normalize(X_train)\n",
    "    X_test = normalize(X_test)\n",
    "    model_predictions = []\n",
    "\n",
    "    print(batch_size, epochs)\n",
    "    # train ensemble of 5 models\n",
    "    for i in range(5):\n",
    "\n",
    "        model = Classifier_INCEPTION(output_directory=f\"./models/{fold}/\", input_shape=(window_size, 1), nb_classes=78, verbose=True, build=True, batch_size=batch_size, nb_epochs=epochs, lr=0.001, depth=8, iteration=i)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate the model\n",
    "        y_pred = model.predict(X_test)\n",
    "        model_predictions.append(y_pred)\n",
    "\n",
    "    # average the predictions of the 5 models\n",
    "    y_pred = np.mean(model_predictions, axis=0)\n",
    "    y_pred_tf = (y_pred > treshold)\n",
    "\n",
    "    predictions.append((y_pred_tf, y_test, y_pred))\n",
    "    t = (y_pred_tf, y_test, y_pred)\n",
    "    with open(f\"./predictions/test_inception_pickle_{fold}.pkl\", 'wb') as f:\n",
    "        pickle.dump(t, f)\n",
    "\n",
    "    report = metrics.classification_report(y_test, y_pred_tf, target_names=labels, zero_division=0, output_dict=True)\n",
    "    print(report[\"weighted avg\"])\n",
    "    \n",
    "    evaluation_results.append(report)\n",
    "    gc.collect()\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "for i in range(len(evaluation_results)):\n",
    "    if i == 0:\n",
    "        df = pd.DataFrame(evaluation_results[i]).T\n",
    "    else:\n",
    "        df = df + pd.DataFrame(evaluation_results[i]).T\n",
    "\n",
    "\n",
    "df = df / num_splits\n",
    "import os\n",
    "# check if directory exsits\n",
    "if not os.path.exists(f\"../../Energy_graph/data/results/{window_size}\"):\n",
    "    os.makedirs(f\"../../Energy_graph/data/results/{window_size}\")\n",
    "if lambda_l2 == 0:\n",
    "    df.to_csv(f\"../../Energy_graph/data/results/{window_size}/NNE_epochs{epochs}_batch_size{batch_size}_k{k}_classes{NmDevices}_{function}_watts_syn_3fold.csv\")\n",
    "else:\n",
    "    df.to_csv(f\"../../Energy_graph/data/results/w_size{window_size}_epochs{epochs}_batch_size{batch_size}_k{k}_classes{NmDevices}_{function}_watts_syn_reg{lambda_l2}.csv\")\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 80/20 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 1200\n",
      "Epoch 1/1200\n",
      "563/563 [==============================] - 204s 355ms/step - loss: 0.3595 - accuracy: 0.0551 - F1Score: 0.0380 - WeightedF1: 0.0387 - val_loss: 0.3762 - val_accuracy: 0.0126 - val_F1Score: 0.0226 - val_WeightedF1: 0.0229 - lr: 0.0010\n",
      "Epoch 2/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.3283 - accuracy: 0.1077 - F1Score: 0.1283 - WeightedF1: 0.1301 - val_loss: 0.3450 - val_accuracy: 0.0834 - val_F1Score: 0.1427 - val_WeightedF1: 0.1447 - lr: 0.0010\n",
      "Epoch 3/1200\n",
      "563/563 [==============================] - 198s 352ms/step - loss: 0.3100 - accuracy: 0.1207 - F1Score: 0.2067 - WeightedF1: 0.2094 - val_loss: 0.3788 - val_accuracy: 0.0943 - val_F1Score: 0.1892 - val_WeightedF1: 0.1917 - lr: 0.0010\n",
      "Epoch 4/1200\n",
      "563/563 [==============================] - 198s 352ms/step - loss: 0.2956 - accuracy: 0.1246 - F1Score: 0.2629 - WeightedF1: 0.2662 - val_loss: 0.3022 - val_accuracy: 0.1019 - val_F1Score: 0.2669 - val_WeightedF1: 0.2702 - lr: 0.0010\n",
      "Epoch 5/1200\n",
      "563/563 [==============================] - 198s 352ms/step - loss: 0.2846 - accuracy: 0.1266 - F1Score: 0.3043 - WeightedF1: 0.3080 - val_loss: 0.2861 - val_accuracy: 0.1123 - val_F1Score: 0.3164 - val_WeightedF1: 0.3202 - lr: 0.0010\n",
      "Epoch 6/1200\n",
      "563/563 [==============================] - 200s 355ms/step - loss: 0.2760 - accuracy: 0.1288 - F1Score: 0.3375 - WeightedF1: 0.3416 - val_loss: 0.2921 - val_accuracy: 0.1184 - val_F1Score: 0.3193 - val_WeightedF1: 0.3233 - lr: 0.0010\n",
      "Epoch 7/1200\n",
      "563/563 [==============================] - 201s 356ms/step - loss: 0.2695 - accuracy: 0.1316 - F1Score: 0.3603 - WeightedF1: 0.3647 - val_loss: 0.2815 - val_accuracy: 0.1120 - val_F1Score: 0.3275 - val_WeightedF1: 0.3314 - lr: 0.0010\n",
      "Epoch 8/1200\n",
      "563/563 [==============================] - 201s 356ms/step - loss: 0.2635 - accuracy: 0.1332 - F1Score: 0.3817 - WeightedF1: 0.3863 - val_loss: 0.2892 - val_accuracy: 0.1069 - val_F1Score: 0.3469 - val_WeightedF1: 0.3513 - lr: 0.0010\n",
      "Epoch 9/1200\n",
      "563/563 [==============================] - 200s 355ms/step - loss: 0.2584 - accuracy: 0.1349 - F1Score: 0.4005 - WeightedF1: 0.4051 - val_loss: 0.2895 - val_accuracy: 0.1151 - val_F1Score: 0.3674 - val_WeightedF1: 0.3714 - lr: 0.0010\n",
      "Epoch 10/1200\n",
      "563/563 [==============================] - 200s 354ms/step - loss: 0.2542 - accuracy: 0.1366 - F1Score: 0.4157 - WeightedF1: 0.4205 - val_loss: 0.2666 - val_accuracy: 0.1135 - val_F1Score: 0.3995 - val_WeightedF1: 0.4037 - lr: 0.0010\n",
      "Epoch 11/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.2506 - accuracy: 0.1392 - F1Score: 0.4281 - WeightedF1: 0.4330 - val_loss: 0.2770 - val_accuracy: 0.0955 - val_F1Score: 0.3950 - val_WeightedF1: 0.3993 - lr: 0.0010\n",
      "Epoch 12/1200\n",
      "563/563 [==============================] - 200s 355ms/step - loss: 0.2470 - accuracy: 0.1402 - F1Score: 0.4388 - WeightedF1: 0.4437 - val_loss: 0.2597 - val_accuracy: 0.1328 - val_F1Score: 0.4051 - val_WeightedF1: 0.4094 - lr: 0.0010\n",
      "Epoch 13/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.2439 - accuracy: 0.1413 - F1Score: 0.4472 - WeightedF1: 0.4522 - val_loss: 0.2987 - val_accuracy: 0.1211 - val_F1Score: 0.3905 - val_WeightedF1: 0.3945 - lr: 0.0010\n",
      "Epoch 14/1200\n",
      "563/563 [==============================] - 200s 354ms/step - loss: 0.2415 - accuracy: 0.1441 - F1Score: 0.4538 - WeightedF1: 0.4589 - val_loss: 0.2628 - val_accuracy: 0.1294 - val_F1Score: 0.4292 - val_WeightedF1: 0.4339 - lr: 0.0010\n",
      "Epoch 15/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.2391 - accuracy: 0.1458 - F1Score: 0.4599 - WeightedF1: 0.4651 - val_loss: 0.2922 - val_accuracy: 0.1050 - val_F1Score: 0.3958 - val_WeightedF1: 0.4001 - lr: 0.0010\n",
      "Epoch 16/1200\n",
      "563/563 [==============================] - 200s 355ms/step - loss: 0.2368 - accuracy: 0.1473 - F1Score: 0.4658 - WeightedF1: 0.4710 - val_loss: 0.2515 - val_accuracy: 0.1420 - val_F1Score: 0.4374 - val_WeightedF1: 0.4421 - lr: 0.0010\n",
      "Epoch 17/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.2345 - accuracy: 0.1483 - F1Score: 0.4721 - WeightedF1: 0.4774 - val_loss: 0.2955 - val_accuracy: 0.1246 - val_F1Score: 0.4188 - val_WeightedF1: 0.4232 - lr: 0.0010\n",
      "Epoch 18/1200\n",
      "563/563 [==============================] - 200s 355ms/step - loss: 0.2329 - accuracy: 0.1499 - F1Score: 0.4767 - WeightedF1: 0.4820 - val_loss: 0.2612 - val_accuracy: 0.1435 - val_F1Score: 0.4332 - val_WeightedF1: 0.4378 - lr: 0.0010\n",
      "Epoch 19/1200\n",
      "563/563 [==============================] - 200s 355ms/step - loss: 0.2310 - accuracy: 0.1527 - F1Score: 0.4823 - WeightedF1: 0.4876 - val_loss: 0.2806 - val_accuracy: 0.1332 - val_F1Score: 0.4365 - val_WeightedF1: 0.4409 - lr: 0.0010\n",
      "Epoch 20/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.2291 - accuracy: 0.1537 - F1Score: 0.4866 - WeightedF1: 0.4919 - val_loss: 0.2852 - val_accuracy: 0.1330 - val_F1Score: 0.4418 - val_WeightedF1: 0.4463 - lr: 0.0010\n",
      "Epoch 21/1200\n",
      "563/563 [==============================] - 200s 354ms/step - loss: 0.2275 - accuracy: 0.1554 - F1Score: 0.4921 - WeightedF1: 0.4975 - val_loss: 0.3044 - val_accuracy: 0.1182 - val_F1Score: 0.4332 - val_WeightedF1: 0.4375 - lr: 0.0010\n",
      "Epoch 22/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.2261 - accuracy: 0.1566 - F1Score: 0.4966 - WeightedF1: 0.5019 - val_loss: 0.2551 - val_accuracy: 0.1434 - val_F1Score: 0.4674 - val_WeightedF1: 0.4723 - lr: 0.0010\n",
      "Epoch 23/1200\n",
      "563/563 [==============================] - 200s 354ms/step - loss: 0.2244 - accuracy: 0.1594 - F1Score: 0.5014 - WeightedF1: 0.5068 - val_loss: 0.2684 - val_accuracy: 0.1476 - val_F1Score: 0.4570 - val_WeightedF1: 0.4620 - lr: 0.0010\n",
      "Epoch 24/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.2230 - accuracy: 0.1587 - F1Score: 0.5057 - WeightedF1: 0.5110 - val_loss: 0.2621 - val_accuracy: 0.1484 - val_F1Score: 0.4766 - val_WeightedF1: 0.4810 - lr: 0.0010\n",
      "Epoch 25/1200\n",
      "563/563 [==============================] - 200s 355ms/step - loss: 0.2216 - accuracy: 0.1619 - F1Score: 0.5101 - WeightedF1: 0.5154 - val_loss: 0.2897 - val_accuracy: 0.1274 - val_F1Score: 0.4588 - val_WeightedF1: 0.4634 - lr: 0.0010\n",
      "Epoch 26/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.2202 - accuracy: 0.1631 - F1Score: 0.5134 - WeightedF1: 0.5187 - val_loss: 0.2805 - val_accuracy: 0.1214 - val_F1Score: 0.4615 - val_WeightedF1: 0.4659 - lr: 0.0010\n",
      "Epoch 27/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.2192 - accuracy: 0.1648 - F1Score: 0.5167 - WeightedF1: 0.5220 - val_loss: 0.2443 - val_accuracy: 0.1262 - val_F1Score: 0.4808 - val_WeightedF1: 0.4857 - lr: 0.0010\n",
      "Epoch 28/1200\n",
      "563/563 [==============================] - 199s 353ms/step - loss: 0.2178 - accuracy: 0.1653 - F1Score: 0.5208 - WeightedF1: 0.5260 - val_loss: 0.3101 - val_accuracy: 0.1410 - val_F1Score: 0.4476 - val_WeightedF1: 0.4518 - lr: 0.0010\n",
      "Epoch 29/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.2168 - accuracy: 0.1675 - F1Score: 0.5235 - WeightedF1: 0.5287 - val_loss: 0.3079 - val_accuracy: 0.1103 - val_F1Score: 0.4507 - val_WeightedF1: 0.4553 - lr: 0.0010\n",
      "Epoch 30/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.2155 - accuracy: 0.1677 - F1Score: 0.5274 - WeightedF1: 0.5326 - val_loss: 0.3005 - val_accuracy: 0.1281 - val_F1Score: 0.4435 - val_WeightedF1: 0.4475 - lr: 0.0010\n",
      "Epoch 31/1200\n",
      "563/563 [==============================] - 199s 353ms/step - loss: 0.2142 - accuracy: 0.1701 - F1Score: 0.5308 - WeightedF1: 0.5359 - val_loss: 0.2524 - val_accuracy: 0.1555 - val_F1Score: 0.4813 - val_WeightedF1: 0.4858 - lr: 0.0010\n",
      "Epoch 32/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.2130 - accuracy: 0.1727 - F1Score: 0.5345 - WeightedF1: 0.5395 - val_loss: 0.2394 - val_accuracy: 0.1417 - val_F1Score: 0.4899 - val_WeightedF1: 0.4950 - lr: 0.0010\n",
      "Epoch 33/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.2118 - accuracy: 0.1734 - F1Score: 0.5378 - WeightedF1: 0.5428 - val_loss: 0.2396 - val_accuracy: 0.1695 - val_F1Score: 0.5035 - val_WeightedF1: 0.5081 - lr: 0.0010\n",
      "Epoch 34/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.2112 - accuracy: 0.1745 - F1Score: 0.5399 - WeightedF1: 0.5449 - val_loss: 0.2854 - val_accuracy: 0.1733 - val_F1Score: 0.4743 - val_WeightedF1: 0.4786 - lr: 0.0010\n",
      "Epoch 35/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.2099 - accuracy: 0.1739 - F1Score: 0.5432 - WeightedF1: 0.5482 - val_loss: 0.2544 - val_accuracy: 0.1813 - val_F1Score: 0.4805 - val_WeightedF1: 0.4850 - lr: 0.0010\n",
      "Epoch 36/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.2086 - accuracy: 0.1774 - F1Score: 0.5469 - WeightedF1: 0.5517 - val_loss: 0.3143 - val_accuracy: 0.1663 - val_F1Score: 0.4890 - val_WeightedF1: 0.4938 - lr: 0.0010\n",
      "Epoch 37/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.2079 - accuracy: 0.1779 - F1Score: 0.5488 - WeightedF1: 0.5536 - val_loss: 0.2723 - val_accuracy: 0.1626 - val_F1Score: 0.4755 - val_WeightedF1: 0.4799 - lr: 0.0010\n",
      "Epoch 38/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.2067 - accuracy: 0.1804 - F1Score: 0.5526 - WeightedF1: 0.5573 - val_loss: 0.2457 - val_accuracy: 0.1730 - val_F1Score: 0.5046 - val_WeightedF1: 0.5089 - lr: 0.0010\n",
      "Epoch 39/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.2059 - accuracy: 0.1803 - F1Score: 0.5552 - WeightedF1: 0.5599 - val_loss: 0.2417 - val_accuracy: 0.2050 - val_F1Score: 0.5184 - val_WeightedF1: 0.5227 - lr: 0.0010\n",
      "Epoch 40/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.2050 - accuracy: 0.1813 - F1Score: 0.5576 - WeightedF1: 0.5623 - val_loss: 0.3897 - val_accuracy: 0.1326 - val_F1Score: 0.4388 - val_WeightedF1: 0.4429 - lr: 0.0010\n",
      "Epoch 41/1200\n",
      "563/563 [==============================] - 199s 353ms/step - loss: 0.2040 - accuracy: 0.1835 - F1Score: 0.5598 - WeightedF1: 0.5644 - val_loss: 0.3061 - val_accuracy: 0.1396 - val_F1Score: 0.4555 - val_WeightedF1: 0.4598 - lr: 0.0010\n",
      "Epoch 42/1200\n",
      "563/563 [==============================] - 199s 353ms/step - loss: 0.2032 - accuracy: 0.1865 - F1Score: 0.5622 - WeightedF1: 0.5668 - val_loss: 0.2631 - val_accuracy: 0.1469 - val_F1Score: 0.4907 - val_WeightedF1: 0.4950 - lr: 0.0010\n",
      "Epoch 43/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.2023 - accuracy: 0.1868 - F1Score: 0.5649 - WeightedF1: 0.5694 - val_loss: 0.2598 - val_accuracy: 0.1852 - val_F1Score: 0.5135 - val_WeightedF1: 0.5175 - lr: 0.0010\n",
      "Epoch 44/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.2016 - accuracy: 0.1863 - F1Score: 0.5672 - WeightedF1: 0.5717 - val_loss: 0.2538 - val_accuracy: 0.1776 - val_F1Score: 0.5018 - val_WeightedF1: 0.5054 - lr: 0.0010\n",
      "Epoch 45/1200\n",
      "563/563 [==============================] - 199s 353ms/step - loss: 0.2005 - accuracy: 0.1876 - F1Score: 0.5697 - WeightedF1: 0.5742 - val_loss: 0.2714 - val_accuracy: 0.1566 - val_F1Score: 0.4788 - val_WeightedF1: 0.4829 - lr: 0.0010\n",
      "Epoch 46/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.1996 - accuracy: 0.1894 - F1Score: 0.5726 - WeightedF1: 0.5770 - val_loss: 0.2714 - val_accuracy: 0.1636 - val_F1Score: 0.4759 - val_WeightedF1: 0.4803 - lr: 0.0010\n",
      "Epoch 47/1200\n",
      "563/563 [==============================] - 200s 355ms/step - loss: 0.1989 - accuracy: 0.1912 - F1Score: 0.5737 - WeightedF1: 0.5781 - val_loss: 0.2609 - val_accuracy: 0.1416 - val_F1Score: 0.4880 - val_WeightedF1: 0.4914 - lr: 0.0010\n",
      "Epoch 48/1200\n",
      "563/563 [==============================] - 200s 355ms/step - loss: 0.1981 - accuracy: 0.1930 - F1Score: 0.5765 - WeightedF1: 0.5809 - val_loss: 0.3445 - val_accuracy: 0.1415 - val_F1Score: 0.4879 - val_WeightedF1: 0.4913 - lr: 0.0010\n",
      "Epoch 49/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.1971 - accuracy: 0.1956 - F1Score: 0.5787 - WeightedF1: 0.5831 - val_loss: 0.2722 - val_accuracy: 0.1550 - val_F1Score: 0.4994 - val_WeightedF1: 0.5037 - lr: 0.0010\n",
      "Epoch 50/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.1962 - accuracy: 0.1974 - F1Score: 0.5813 - WeightedF1: 0.5857 - val_loss: 0.2330 - val_accuracy: 0.2011 - val_F1Score: 0.5332 - val_WeightedF1: 0.5374 - lr: 0.0010\n",
      "Epoch 51/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.1958 - accuracy: 0.1962 - F1Score: 0.5823 - WeightedF1: 0.5867 - val_loss: 0.2674 - val_accuracy: 0.1701 - val_F1Score: 0.4982 - val_WeightedF1: 0.5024 - lr: 0.0010\n",
      "Epoch 52/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.1949 - accuracy: 0.1962 - F1Score: 0.5844 - WeightedF1: 0.5888 - val_loss: 0.2318 - val_accuracy: 0.1845 - val_F1Score: 0.5330 - val_WeightedF1: 0.5366 - lr: 0.0010\n",
      "Epoch 53/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.1944 - accuracy: 0.1952 - F1Score: 0.5860 - WeightedF1: 0.5903 - val_loss: 0.3186 - val_accuracy: 0.1468 - val_F1Score: 0.4896 - val_WeightedF1: 0.4928 - lr: 0.0010\n",
      "Epoch 54/1200\n",
      "563/563 [==============================] - 199s 353ms/step - loss: 0.1932 - accuracy: 0.2017 - F1Score: 0.5886 - WeightedF1: 0.5930 - val_loss: 0.2473 - val_accuracy: 0.1595 - val_F1Score: 0.5061 - val_WeightedF1: 0.5099 - lr: 0.0010\n",
      "Epoch 55/1200\n",
      "563/563 [==============================] - 199s 353ms/step - loss: 0.1926 - accuracy: 0.2012 - F1Score: 0.5904 - WeightedF1: 0.5947 - val_loss: 0.2438 - val_accuracy: 0.1715 - val_F1Score: 0.5225 - val_WeightedF1: 0.5258 - lr: 0.0010\n",
      "Epoch 56/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.1921 - accuracy: 0.2031 - F1Score: 0.5918 - WeightedF1: 0.5961 - val_loss: 0.2796 - val_accuracy: 0.1797 - val_F1Score: 0.4905 - val_WeightedF1: 0.4944 - lr: 0.0010\n",
      "Epoch 57/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.1912 - accuracy: 0.2061 - F1Score: 0.5940 - WeightedF1: 0.5983 - val_loss: 0.2570 - val_accuracy: 0.1979 - val_F1Score: 0.5103 - val_WeightedF1: 0.5140 - lr: 0.0010\n",
      "Epoch 58/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.1901 - accuracy: 0.2033 - F1Score: 0.5961 - WeightedF1: 0.6003 - val_loss: 0.3168 - val_accuracy: 0.1775 - val_F1Score: 0.4802 - val_WeightedF1: 0.4840 - lr: 0.0010\n",
      "Epoch 59/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.1898 - accuracy: 0.2060 - F1Score: 0.5974 - WeightedF1: 0.6017 - val_loss: 0.2946 - val_accuracy: 0.1918 - val_F1Score: 0.5121 - val_WeightedF1: 0.5157 - lr: 0.0010\n",
      "Epoch 60/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.1890 - accuracy: 0.2068 - F1Score: 0.5992 - WeightedF1: 0.6035 - val_loss: 0.2708 - val_accuracy: 0.1805 - val_F1Score: 0.5077 - val_WeightedF1: 0.5110 - lr: 0.0010\n",
      "Epoch 61/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.1887 - accuracy: 0.2085 - F1Score: 0.6002 - WeightedF1: 0.6045 - val_loss: 0.3194 - val_accuracy: 0.1739 - val_F1Score: 0.4996 - val_WeightedF1: 0.5033 - lr: 0.0010\n",
      "Epoch 62/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.1875 - accuracy: 0.2079 - F1Score: 0.6028 - WeightedF1: 0.6070 - val_loss: 0.3288 - val_accuracy: 0.1676 - val_F1Score: 0.4850 - val_WeightedF1: 0.4887 - lr: 0.0010\n",
      "Epoch 63/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.1869 - accuracy: 0.2106 - F1Score: 0.6036 - WeightedF1: 0.6079 - val_loss: 0.3187 - val_accuracy: 0.1661 - val_F1Score: 0.5136 - val_WeightedF1: 0.5172 - lr: 0.0010\n",
      "Epoch 64/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.1862 - accuracy: 0.2108 - F1Score: 0.6054 - WeightedF1: 0.6096 - val_loss: 0.3861 - val_accuracy: 0.1441 - val_F1Score: 0.4598 - val_WeightedF1: 0.4630 - lr: 0.0010\n",
      "Epoch 65/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.1857 - accuracy: 0.2119 - F1Score: 0.6074 - WeightedF1: 0.6117 - val_loss: 0.2697 - val_accuracy: 0.1873 - val_F1Score: 0.5125 - val_WeightedF1: 0.5157 - lr: 0.0010\n",
      "Epoch 66/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.1852 - accuracy: 0.2142 - F1Score: 0.6082 - WeightedF1: 0.6124 - val_loss: 0.2811 - val_accuracy: 0.2016 - val_F1Score: 0.5063 - val_WeightedF1: 0.5105 - lr: 0.0010\n",
      "Epoch 67/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.1845 - accuracy: 0.2148 - F1Score: 0.6097 - WeightedF1: 0.6140 - val_loss: 0.2614 - val_accuracy: 0.1881 - val_F1Score: 0.5246 - val_WeightedF1: 0.5281 - lr: 0.0010\n",
      "Epoch 68/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.1834 - accuracy: 0.2177 - F1Score: 0.6125 - WeightedF1: 0.6167 - val_loss: 0.3353 - val_accuracy: 0.1781 - val_F1Score: 0.5104 - val_WeightedF1: 0.5139 - lr: 0.0010\n",
      "Epoch 69/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.1829 - accuracy: 0.2179 - F1Score: 0.6135 - WeightedF1: 0.6177 - val_loss: 0.2503 - val_accuracy: 0.2128 - val_F1Score: 0.5291 - val_WeightedF1: 0.5325 - lr: 0.0010\n",
      "Epoch 70/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.1823 - accuracy: 0.2186 - F1Score: 0.6152 - WeightedF1: 0.6194 - val_loss: 0.2811 - val_accuracy: 0.1723 - val_F1Score: 0.4973 - val_WeightedF1: 0.5010 - lr: 0.0010\n",
      "Epoch 71/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.1818 - accuracy: 0.2195 - F1Score: 0.6164 - WeightedF1: 0.6205 - val_loss: 0.2756 - val_accuracy: 0.1870 - val_F1Score: 0.5170 - val_WeightedF1: 0.5206 - lr: 0.0010\n",
      "Epoch 72/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.1811 - accuracy: 0.2216 - F1Score: 0.6181 - WeightedF1: 0.6223 - val_loss: 0.3969 - val_accuracy: 0.1689 - val_F1Score: 0.4666 - val_WeightedF1: 0.4702 - lr: 0.0010\n",
      "Epoch 73/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.1803 - accuracy: 0.2212 - F1Score: 0.6197 - WeightedF1: 0.6239 - val_loss: 0.3878 - val_accuracy: 0.1929 - val_F1Score: 0.5116 - val_WeightedF1: 0.5151 - lr: 0.0010\n",
      "Epoch 74/1200\n",
      "563/563 [==============================] - 199s 354ms/step - loss: 0.1796 - accuracy: 0.2236 - F1Score: 0.6211 - WeightedF1: 0.6253 - val_loss: 0.3038 - val_accuracy: 0.1945 - val_F1Score: 0.5105 - val_WeightedF1: 0.5141 - lr: 0.0010\n",
      "Epoch 75/1200\n",
      " 87/563 [===>..........................] - ETA: 2:44 - loss: 0.1761 - accuracy: 0.2227 - F1Score: 0.6289 - WeightedF1: 0.6331"
     ]
    }
   ],
   "source": [
    "# CHECK CODE HERE ############################################################################################################################################################################################################################\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)\n",
    "X_train = normalize(X_train)\n",
    "X_test = normalize(X_test)\n",
    "\n",
    "evaluation_results = []\n",
    "predictions = []\n",
    "class_weights_all = NUK.class_weights_tool(y)\n",
    "model_predictions = []\n",
    "\n",
    "print(batch_size, epochs)\n",
    "# train ensemble of 5 models\n",
    "for i in range(5):\n",
    "\n",
    "    model = Classifier_INCEPTION(output_directory=f\"./models/performance/\", input_shape=(window_size, 1), nb_classes=NmDevices, verbose=True, build=True, batch_size=batch_size, nb_epochs=epochs, lr=0.001, depth=10, iteration=i, kernel_size=128)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    model_predictions.append(y_pred)\n",
    "\n",
    "# ensemble predictions\n",
    "y_pred = np.mean(model_predictions, axis=0)\n",
    "\n",
    "# thresholding\n",
    "y_pred_tf = (y_pred > 0.3)\n",
    "\n",
    "# save predictions for later analaysis\n",
    "predictions.append((y_pred_tf, y_test, y_pred))\n",
    "t = (y_pred_tf, y_test, y_pred)\n",
    "with open(f\"./predictions/test_inception_pickle_bfloat16_testing.pkl\", 'wb') as f:\n",
    "    pickle.dump(t, f)\n",
    "\n",
    "report = metrics.classification_report(y_test, y_pred_tf, target_names=labels, zero_division=0, output_dict=True)\n",
    "print(report[\"weighted avg\"])\n",
    "\n",
    "evaluation_results.append(report)\n",
    "gc.collect()\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "\n",
    "df = pd.DataFrame(report).T\n",
    "\n",
    "import os\n",
    "# check if directory exsits\n",
    "if not os.path.exists(f\"../../Energy_graph/data/results/{window_size}\"):\n",
    "    os.makedirs(f\"../../Energy_graph/data/results/{window_size}\")\n",
    "# save results to csv\n",
    "df.to_csv(f\"../../Energy_graph/data/results/{window_size}/NNE_epochs{epochs}_batch_size{batch_size}_k{k}_classes{NmDevices}_{function}_watts_bfloat16.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## PC0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "evaluation_results = []\n",
    "predictions = []\n",
    "class_weights_all = NUK.class_weights_tool(y)\n",
    "treshold = 0.5\n",
    "debug = 0\n",
    "for train_index, test_index in tqdm(kf.split(X)):\n",
    "    print(\"Train indices:\", train_index, \"Test indices:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    X_train[:, 0] = normalize(X_train[:, 0])\n",
    "    X_test[:,0] = normalize(X_test[:, 0])\n",
    "\n",
    "    # break\n",
    "    # class_weights_all = NUK.class_weights_tool(y_train)\n",
    "    # for k in class_weights_all:\n",
    "    #     class_weights_all[k] += 1\n",
    "    \n",
    "    # print(class_weights_all)\n",
    "    # break\n",
    "    model = NUK.PC0_reg(NmDevices, window_size, function, 128, k, lambda_l2=lambda_l2)\n",
    "    # model = NUK.VGG11_1D(NmDevices, window_size)\n",
    "    model.build((len(y_train) + len(y_test), window_size, 1))\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003), loss='binary_crossentropy', metrics=[NUK.F1Score, NUK.WeightedF1Score(NUK.class_weights_tool(y_test))])\n",
    "    # lr_scheduler = LearningRateScheduler(scheduler)\n",
    "    reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.25, patience=3, min_lr=0.000001)\n",
    "    # callback = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.1,patience=2, min_lr=0.0000002)\n",
    "    # for class weights\n",
    "    # model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, class_weight=class_weights_UKD, callbacks=[lr_scheduler])\n",
    "    # class_weights = NUK.class_weights_tool(y_train)\n",
    "    model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=[reduce_lr])\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_tf = (y_pred > treshold)\n",
    "\n",
    "    predictions.append((y_pred, y_pred_tf, y_test))\n",
    "\n",
    "    # n_labels = y_test.shape[1]\n",
    "    # co_occurrence_matrix = np.zeros((n_labels, n_labels))\n",
    "\n",
    "    # for true, pred in zip(y_test, y_pred_tf):\n",
    "    #     fn_labels = np.where((true == 1) & (pred == 0))[0]  # False negatives\n",
    "    #     fp_labels = np.where((true == 0) & (pred == 1))[0]  # False positives\n",
    "\n",
    "    #     for fn in fn_labels:\n",
    "    #         for fp in fp_labels:\n",
    "    #             co_occurrence_matrix[fn, fp] += 1\n",
    "\n",
    "\n",
    "\n",
    "    report = metrics.classification_report(y_test, y_pred_tf, target_names=labels, zero_division=0, output_dict=True)\n",
    "    print(report[\"weighted avg\"], \"|||\", report[\"samples avg\"])\n",
    "\n",
    "    # report_DF = NUK.ClassificationReportToDF(report, labels)  \n",
    "    # report_DF.rename(columns={report_DF.columns[0]: \"device\"}, inplace=True)\n",
    "    evaluation_results.append(report)\n",
    "    gc.collect()\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSMixer\n",
    "https://github.com/google-research/google-research/tree/master/tsmixer/tsmixer_basic/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    }
   ],
   "source": [
    "# coding=utf-8\n",
    "# Copyright 2023 The Google Research Authors.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "\"\"\"Implementation of TSMixer.\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "def res_block(inputs, norm_type, activation, dropout, ff_dim):\n",
    "  \"\"\"Residual block of TSMixer.\"\"\"\n",
    "\n",
    "  norm = (\n",
    "      layers.LayerNormalization\n",
    "      if norm_type == 'L'\n",
    "      else layers.BatchNormalization\n",
    "  )\n",
    "\n",
    "  # Temporal Linear\n",
    "  x = norm(axis=[-2, -1])(inputs)\n",
    "  x = tf.transpose(x, perm=[0, 2, 1])  # [Batch, Channel, Input Length]\n",
    "  x = layers.Dense(x.shape[-1], activation=activation)(x)\n",
    "  x = tf.transpose(x, perm=[0, 2, 1])  # [Batch, Input Length, Channel]\n",
    "  x = layers.Dropout(dropout)(x)\n",
    "  res = x + inputs\n",
    "\n",
    "  # Feature Linear\n",
    "  x = norm(axis=[-2, -1])(res)\n",
    "  x = layers.Dense(ff_dim, activation=activation)(\n",
    "      x\n",
    "  )  # [Batch, Input Length, FF_Dim]\n",
    "  x = layers.Dropout(dropout)(x)\n",
    "  x = layers.Dense(inputs.shape[-1])(x)  # [Batch, Input Length, Channel]\n",
    "  x = layers.Dropout(dropout)(x)\n",
    "  return x + res\n",
    "\n",
    "\n",
    "def build_model(\n",
    "    input_shape,\n",
    "    pred_len,\n",
    "    norm_type,\n",
    "    activation,\n",
    "    n_block,\n",
    "    dropout,\n",
    "    ff_dim,\n",
    "    target_slice,\n",
    "):\n",
    "  \"\"\"Build TSMixer model.\"\"\"\n",
    "\n",
    "  inputs = tf.keras.Input(shape=input_shape)\n",
    "  x = inputs  # [Batch, Input Length, Channel]\n",
    "  for _ in range(n_block):\n",
    "    x = res_block(x, norm_type, activation, dropout, ff_dim)\n",
    "\n",
    "  if target_slice:\n",
    "    x = x[:, :, target_slice]\n",
    "\n",
    "  x = tf.transpose(x, perm=[0, 2, 1])  # [Batch, Channel, Input Length]\n",
    "  x = layers.Dense(pred_len, activation=tf.nn.sigmoid)(x)  # [Batch, Channel, Output Length]\n",
    "  outputs = tf.transpose(x, perm=[0, 2, 1])  # [Batch, Output Length, Channel])\n",
    "\n",
    "  return tf.keras.Model(inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train indices: [     1      2      3 ... 147053 147054 147055] Test indices: [     0      4     12 ... 147049 147050 147052]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "jobs = 110\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "evaluation_results = []\n",
    "\n",
    "for train_index, test_index in tqdm(kf.split(X)):\n",
    "    print(\"Train indices:\", train_index, \"Test indices:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Initialize the Random Forest classifier wrapped in a MultiOutputClassifier\n",
    "    classifier = RandomForestClassifier(n_estimators=100, random_state=RANDOM_SEED, n_jobs=jobs)\n",
    "    # classifier = MultiOutputClassifier(forest, n_jobs=-1)\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the labels\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    # Evaluate the model using classification report\n",
    "    report = classification_report(y_test, y_pred, target_names=labels, zero_division=0, output_dict=True)\n",
    "\n",
    "    evaluation_results.append(report)\n",
    "\n",
    "\n",
    "for i in range(len(evaluation_results)):\n",
    "    if i == 0:\n",
    "        df = pd.DataFrame(evaluation_results[i]).T\n",
    "    else:\n",
    "        df = df + pd.DataFrame(evaluation_results[i]).T\n",
    "\n",
    "\n",
    "df = df / 5\n",
    "# df.to_csv(f\"../../Energy_graph/data/results/w_size{window_size}_epochs{epochs}_batch_size{batch_size}_k{k}_classes{NmDevices}_staticLR_LSTM_watts_mixed100k.csv\")\n",
    "df.to_csv(f\"../../Energy_graph/data/results/w_size{window_size}_classes{NmDevices}_watts_RF_mixed50k.csv\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_results = []\n",
    "model = NUK.PC0(NmDevices, window_size, 'GRU',128, k)\n",
    "model.build((len(y), window_size, 1))\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003), loss='binary_crossentropy', metrics=[NUK.F1Score, NUK.WeightedF1Score(NUK.class_weights_tool(y_test))])\n",
    "lr_scheduler = LearningRateScheduler(scheduler)\n",
    "\n",
    "model.fit(X, y, batch_size=batch_size, epochs=epochs, callbacks=[lr_scheduler])\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_tf = (y_pred > 0.5)\n",
    "report = metrics.classification_report(y_test, y_pred_tf, target_names=labels, zero_division=0, output_dict=True)\n",
    "\n",
    "# report_DF = NUK.ClassificationReportToDF(report, labels)  \n",
    "# report_DF.rename(columns={report_DF.columns[0]: \"device\"}, inplace=True)\n",
    "df = pd.DataFrame(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\n",
      "  Using cached catboost-1.2.2-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
      "Collecting graphviz\n",
      "  Using cached graphviz-0.20.1-py3-none-any.whl (47 kB)\n",
      "Requirement already satisfied: pandas>=0.24 in /opt/conda/lib/python3.10/site-packages (from catboost) (1.5.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from catboost) (1.9.3)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /opt/conda/lib/python3.10/site-packages (from catboost) (1.23.5)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from catboost) (3.6.2)\n",
      "Collecting plotly\n",
      "  Using cached plotly-5.18.0-py3-none-any.whl (15.6 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2022.6)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (9.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (1.0.6)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (4.38.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (3.0.9)\n",
      "Collecting tenacity>=6.2.0\n",
      "  Using cached tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: tenacity, graphviz, plotly, catboost\n",
      "Successfully installed catboost-1.2.2 graphviz-0.20.1 plotly-5.18.0 tenacity-8.2.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install catboost\n",
    "import catboost as cb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_pickle(\"../../Energy_graph/data/training_data/synthetic/X_Y_wsize2688_numW_50000_upper32_gap3600_numD64_ideal_sanitycheck.pkl\")\n",
    "# data = pd.read_pickle(\"../../Energy_graph/data/training_data/synthetic/X_Y_wsize2688_numW_50000_upper32_gap3600_numD64_ideal.pkl\") \n",
    "# data_syn_ideal = pd.read_pickle(\"../../Energy_graph/data/training_data/synthetic/X_Y_wsize2688_numW_50000_upper32_gap3600_numD64_ideal.pkl\") \n",
    "# data_syn_unmetered = pd.read_pickle(\"../../Energy_graph/data/training_data/synthetic/X_Y_wsize2688_numW_50000_upper32_gap3600_numD64_unmetered.pkl\")\n",
    "\n",
    "labels = pd.read_pickle(\"../../Energy_graph/data/labels_new.pkl\")\n",
    "\n",
    "\n",
    "# Separate the tuples into X and y\n",
    "# X_syn_ideal = np.array([i[0] for i in data_syn_ideal])\n",
    "# y_syn_ideal = np.array([i[1] for i in data_syn_ideal])\n",
    "\n",
    "# X_syn_unmetered = np.array([i[0] for i in data_syn_unmetered])\n",
    "# y_syn_unmetered = np.array([i[1] for i in data_syn_unmetered])\n",
    "\n",
    "X = np.array([i[0] for i in data])\n",
    "y = np.array([i[1] for i in data])\n",
    "\n",
    "\n",
    "# X = np.concatenate((X, X_syn_ideal,X_syn_unmetered), axis=0)\n",
    "# y = np.concatenate((y, y_syn_ideal, y_syn_unmetered), axis=0)\n",
    "\n",
    "\n",
    "y = y.astype(int)\n",
    "\n",
    "\n",
    "# X_test = np.array([i[0] for i in data_test])\n",
    "# y_test = np.array([i[1] for i in data_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce804085ef3b45f9887cda9f2b7266ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train indices: [    0     1     2 ... 49994 49995 49999] Test indices: [   11    12    15 ... 49996 49997 49998]\n",
      "Learning rate set to 0.006507\n",
      "0:\tlearn: 0.6844442\ttotal: 1.25s\tremaining: 1h 44m 30s\n",
      "250:\tlearn: 0.2194012\ttotal: 4m 57s\tremaining: 1h 33m 55s\n",
      "500:\tlearn: 0.1995254\ttotal: 9m 50s\tremaining: 1h 28m 25s\n",
      "750:\tlearn: 0.1902022\ttotal: 14m 34s\tremaining: 1h 22m 30s\n",
      "1000:\tlearn: 0.1832065\ttotal: 19m 11s\tremaining: 1h 16m 39s\n",
      "1250:\tlearn: 0.1772213\ttotal: 23m 48s\tremaining: 1h 11m 20s\n",
      "1500:\tlearn: 0.1717494\ttotal: 28m 23s\tremaining: 1h 6m 10s\n",
      "1750:\tlearn: 0.1668553\ttotal: 32m 58s\tremaining: 1h 1m 11s\n",
      "2000:\tlearn: 0.1622493\ttotal: 37m 32s\tremaining: 56m 16s\n",
      "2250:\tlearn: 0.1577867\ttotal: 42m 9s\tremaining: 51m 28s\n",
      "2500:\tlearn: 0.1535659\ttotal: 46m 45s\tremaining: 46m 43s\n",
      "2750:\tlearn: 0.1496007\ttotal: 51m 20s\tremaining: 41m 58s\n",
      "3000:\tlearn: 0.1459705\ttotal: 55m 54s\tremaining: 37m 14s\n",
      "3250:\tlearn: 0.1423770\ttotal: 1h 28s\tremaining: 32m 32s\n",
      "3500:\tlearn: 0.1390359\ttotal: 1h 5m 3s\tremaining: 27m 51s\n",
      "3750:\tlearn: 0.1357758\ttotal: 1h 9m 35s\tremaining: 23m 10s\n",
      "4000:\tlearn: 0.1326742\ttotal: 1h 14m 8s\tremaining: 18m 30s\n",
      "4250:\tlearn: 0.1296711\ttotal: 1h 18m 42s\tremaining: 13m 52s\n",
      "4500:\tlearn: 0.1268947\ttotal: 1h 23m 14s\tremaining: 9m 13s\n",
      "4750:\tlearn: 0.1240538\ttotal: 1h 27m 48s\tremaining: 4m 36s\n",
      "4999:\tlearn: 0.1214127\ttotal: 1h 32m 21s\tremaining: 0us\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "{'precision': 0.4408025798685414, 'recall': 0.056723117731075294, 'f1-score': 0.08100608300562134, 'support': 44109}\n",
      "Train indices: [    0     1     3 ... 49997 49998 49999] Test indices: [    2     7     8 ... 49985 49994 49995]\n",
      "Learning rate set to 0.006507\n",
      "0:\tlearn: 0.6842080\ttotal: 1.27s\tremaining: 1h 45m 48s\n",
      "250:\tlearn: 0.2181177\ttotal: 5m 1s\tremaining: 1h 34m 56s\n",
      "500:\tlearn: 0.1983823\ttotal: 9m 52s\tremaining: 1h 28m 38s\n",
      "750:\tlearn: 0.1890429\ttotal: 14m 36s\tremaining: 1h 22m 36s\n",
      "1000:\tlearn: 0.1821489\ttotal: 19m 14s\tremaining: 1h 16m 52s\n",
      "1250:\tlearn: 0.1761663\ttotal: 23m 49s\tremaining: 1h 11m 23s\n",
      "1500:\tlearn: 0.1707780\ttotal: 28m 23s\tremaining: 1h 6m 11s\n",
      "1750:\tlearn: 0.1658008\ttotal: 32m 56s\tremaining: 1h 1m 7s\n",
      "2000:\tlearn: 0.1611087\ttotal: 37m 33s\tremaining: 56m 17s\n",
      "2250:\tlearn: 0.1567048\ttotal: 42m 9s\tremaining: 51m 29s\n",
      "2500:\tlearn: 0.1525708\ttotal: 46m 46s\tremaining: 46m 44s\n",
      "2750:\tlearn: 0.1486696\ttotal: 51m 24s\tremaining: 42m 1s\n",
      "3000:\tlearn: 0.1450142\ttotal: 56m 1s\tremaining: 37m 18s\n",
      "3250:\tlearn: 0.1414636\ttotal: 1h 37s\tremaining: 32m 36s\n",
      "3500:\tlearn: 0.1380836\ttotal: 1h 5m 13s\tremaining: 27m 55s\n",
      "3750:\tlearn: 0.1348500\ttotal: 1h 9m 47s\tremaining: 23m 14s\n",
      "4000:\tlearn: 0.1318546\ttotal: 1h 14m 20s\tremaining: 18m 33s\n",
      "4250:\tlearn: 0.1288564\ttotal: 1h 18m 53s\tremaining: 13m 53s\n",
      "4500:\tlearn: 0.1259589\ttotal: 1h 23m 29s\tremaining: 9m 15s\n",
      "4750:\tlearn: 0.1233008\ttotal: 1h 28m 2s\tremaining: 4m 36s\n",
      "4999:\tlearn: 0.1207115\ttotal: 1h 32m 35s\tremaining: 0us\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "{'precision': 0.38729241652191376, 'recall': 0.029420859654547864, 'f1-score': 0.04903419530885325, 'support': 45274}\n",
      "Train indices: [    0     2     4 ... 49996 49997 49998] Test indices: [    1     3     5 ... 49974 49993 49999]\n",
      "Learning rate set to 0.006507\n",
      "0:\tlearn: 0.6844013\ttotal: 1.27s\tremaining: 1h 46m 1s\n",
      "250:\tlearn: 0.2179851\ttotal: 5m 1s\tremaining: 1h 35m 2s\n",
      "500:\tlearn: 0.1987558\ttotal: 9m 49s\tremaining: 1h 28m 11s\n",
      "750:\tlearn: 0.1893806\ttotal: 14m 34s\tremaining: 1h 22m 26s\n",
      "1000:\tlearn: 0.1823203\ttotal: 19m 16s\tremaining: 1h 16m 58s\n",
      "1250:\tlearn: 0.1762454\ttotal: 23m 54s\tremaining: 1h 11m 37s\n",
      "1500:\tlearn: 0.1708995\ttotal: 28m 28s\tremaining: 1h 6m 23s\n",
      "1750:\tlearn: 0.1659844\ttotal: 33m 6s\tremaining: 1h 1m 26s\n",
      "2000:\tlearn: 0.1614619\ttotal: 37m 42s\tremaining: 56m 30s\n",
      "2250:\tlearn: 0.1569847\ttotal: 42m 19s\tremaining: 51m 41s\n",
      "2500:\tlearn: 0.1529185\ttotal: 46m 56s\tremaining: 46m 53s\n",
      "2750:\tlearn: 0.1491333\ttotal: 51m 32s\tremaining: 42m 8s\n",
      "3000:\tlearn: 0.1453915\ttotal: 56m 9s\tremaining: 37m 24s\n",
      "3250:\tlearn: 0.1418039\ttotal: 1h 45s\tremaining: 32m 41s\n",
      "3500:\tlearn: 0.1384498\ttotal: 1h 5m 19s\tremaining: 27m 58s\n",
      "3750:\tlearn: 0.1351578\ttotal: 1h 9m 51s\tremaining: 23m 15s\n",
      "4000:\tlearn: 0.1320607\ttotal: 1h 14m 23s\tremaining: 18m 34s\n",
      "4250:\tlearn: 0.1290372\ttotal: 1h 18m 54s\tremaining: 13m 54s\n",
      "4500:\tlearn: 0.1261169\ttotal: 1h 23m 28s\tremaining: 9m 15s\n",
      "4750:\tlearn: 0.1233606\ttotal: 1h 28m\tremaining: 4m 36s\n",
      "4999:\tlearn: 0.1207234\ttotal: 1h 32m 31s\tremaining: 0us\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "{'precision': 0.4210338300632099, 'recall': 0.058637329555516204, 'f1-score': 0.08431347760505552, 'support': 45176}\n",
      "Train indices: [    0     1     2 ... 49997 49998 49999] Test indices: [    4     6     9 ... 49987 49988 49989]\n",
      "Learning rate set to 0.006507\n",
      "0:\tlearn: 0.6843969\ttotal: 1.25s\tremaining: 1h 44m 33s\n",
      "250:\tlearn: 0.2189830\ttotal: 4m 56s\tremaining: 1h 33m 36s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\foglo\\Documents\\IJS\\energy-knowledge-graph\\scripts\\notebooks\\multi-label classification\\models.ipynb Cell 36\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/foglo/Documents/IJS/energy-knowledge-graph/scripts/notebooks/multi-label%20classification/models.ipynb#X46sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m model \u001b[39m=\u001b[39m cb\u001b[39m.\u001b[39mCatBoostClassifier(\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/foglo/Documents/IJS/energy-knowledge-graph/scripts/notebooks/multi-label%20classification/models.ipynb#X46sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     loss_function\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mMultiLogloss\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/foglo/Documents/IJS/energy-knowledge-graph/scripts/notebooks/multi-label%20classification/models.ipynb#X46sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39m250\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/foglo/Documents/IJS/energy-knowledge-graph/scripts/notebooks/multi-label%20classification/models.ipynb#X46sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/foglo/Documents/IJS/energy-knowledge-graph/scripts/notebooks/multi-label%20classification/models.ipynb#X46sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     )  \u001b[39m# Add other hyperparameters if needed\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/foglo/Documents/IJS/energy-knowledge-graph/scripts/notebooks/multi-label%20classification/models.ipynb#X46sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/c%3A/Users/foglo/Documents/IJS/energy-knowledge-graph/scripts/notebooks/multi-label%20classification/models.ipynb#X46sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/foglo/Documents/IJS/energy-knowledge-graph/scripts/notebooks/multi-label%20classification/models.ipynb#X46sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m# Get predictions\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/foglo/Documents/IJS/energy-knowledge-graph/scripts/notebooks/multi-label%20classification/models.ipynb#X46sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/catboost/core.py:5100\u001b[0m, in \u001b[0;36mCatBoostClassifier.fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5097\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m params:\n\u001b[1;32m   5098\u001b[0m     CatBoostClassifier\u001b[39m.\u001b[39m_check_is_compatible_loss(params[\u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m-> 5100\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, cat_features, text_features, embedding_features, \u001b[39mNone\u001b[39;49;00m, sample_weight, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, baseline, use_best_model,\n\u001b[1;32m   5101\u001b[0m           eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period,\n\u001b[1;32m   5102\u001b[0m           silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n\u001b[1;32m   5103\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/catboost/core.py:2319\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2315\u001b[0m allow_clear_pool \u001b[39m=\u001b[39m train_params[\u001b[39m\"\u001b[39m\u001b[39mallow_clear_pool\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   2317\u001b[0m \u001b[39mwith\u001b[39;00m log_fixup(log_cout, log_cerr), \\\n\u001b[1;32m   2318\u001b[0m     plot_wrapper(plot, plot_file, \u001b[39m'\u001b[39m\u001b[39mTraining plots\u001b[39m\u001b[39m'\u001b[39m, [_get_train_dir(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_params())]):\n\u001b[0;32m-> 2319\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train(\n\u001b[1;32m   2320\u001b[0m         train_pool,\n\u001b[1;32m   2321\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39meval_sets\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m   2322\u001b[0m         params,\n\u001b[1;32m   2323\u001b[0m         allow_clear_pool,\n\u001b[1;32m   2324\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39minit_model\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m   2325\u001b[0m     )\n\u001b[1;32m   2327\u001b[0m \u001b[39m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[1;32m   2328\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_object\u001b[39m.\u001b[39m_get_loss_function_name()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/catboost/core.py:1723\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1722\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_train\u001b[39m(\u001b[39mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[0;32m-> 1723\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_object\u001b[39m.\u001b[39;49m_train(train_pool, test_pool, params, allow_clear_pool, init_model\u001b[39m.\u001b[39;49m_object \u001b[39mif\u001b[39;49;00m init_model \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m   1724\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_trained_model_attributes()\n",
      "File \u001b[0;32m_catboost.pyx:4645\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:4694\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Closing remaining open files:/tmp/nilmtk-43g7cwfb.h5...done\n"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED=32\n",
    "num_splits = 5\n",
    "kf = KFold(n_splits=num_splits, shuffle=True, random_state=RANDOM_SEED)\n",
    "evaluation_results = []\n",
    "predictions = []\n",
    "class_weights_all = NUK.class_weights_tool(y)\n",
    "debug = 0\n",
    "for train_index, test_index in tqdm(kf.split(X)):\n",
    "    print(\"Train indices:\", train_index, \"Test indices:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    X_train = normalize(X_train)\n",
    "    X_test = normalize(X_test)\n",
    "\n",
    "    # break\n",
    "\n",
    "    # Initialize CatBoost multilabel classifier\n",
    "    model = cb.CatBoostClassifier(\n",
    "        loss_function='MultiLogloss',\n",
    "        verbose=250,\n",
    "        random_seed=RANDOM_SEED,\n",
    "        task_type=\"GPU\",\n",
    "        devices='0:1',\n",
    "        depth=8,   \n",
    "        # class_weights=class_weights_all,\n",
    "        iterations=5000,\n",
    "        \n",
    "\n",
    "        )  # Add other hyperparameters if needed\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Get predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Convert predictions to boolean format similar to y_test for evaluation\n",
    "    y_pred_tf = (y_pred == 1)\n",
    "    print(y_pred)\n",
    "\n",
    "    predictions.append((y_pred_tf, y_test))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    report = metrics.classification_report(y_test, y_pred_tf, target_names=labels, zero_division=0, output_dict=True)\n",
    "    print(report[\"weighted avg\"])\n",
    "    # break\n",
    "    # report_DF = NUK.ClassificationReportToDF(report, labels)  \n",
    "    # report_DF.rename(columns={report_DF.columns[0]: \"device\"}, inplace=True)\n",
    "    evaluation_results.append(report)\n",
    "    del model\n",
    "\n",
    "\n",
    "for i in range(len(evaluation_results)):\n",
    "    if i == 0:\n",
    "        df = pd.DataFrame(evaluation_results[i]).T\n",
    "    else:\n",
    "        df = df + pd.DataFrame(evaluation_results[i]).T\n",
    "\n",
    "df = df / num_splits\n",
    "df\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optuna hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Using cached optuna-3.4.0-py3-none-any.whl (409 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (21.3)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (1.4.44)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from optuna) (1.23.5)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (1.8.1)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from optuna) (6.0)\n",
      "Collecting colorlog\n",
      "  Using cached colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from optuna) (4.66.1)\n",
      "Requirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (1.2.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->optuna) (3.0.9)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna) (2.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/conda/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.1)\n",
      "Installing collected packages: colorlog, optuna\n",
      "Successfully installed colorlog-6.7.0 optuna-3.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-27 13:15:24,552] A new study created in memory with name: no-name-be90d17e-8ac2-4785-a77a-7eada4e00fed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7cfb96097874364b4821a89aa9c1ce8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-11-27 13:50:50,035] Trial 0 finished with value: 0.023022892328962187 and parameters: {'iterations': 760, 'depth': 7, 'learning_rate': 0.04064904160617694}. Best is trial 0 with value: 0.023022892328962187.\n",
      "New best value: 0.0230\n",
      "[I 2023-11-27 14:01:38,161] Trial 1 finished with value: 0.03701412972494217 and parameters: {'iterations': 630, 'depth': 5, 'learning_rate': 0.19386570776436488}. Best is trial 1 with value: 0.03701412972494217.\n",
      "New best value: 0.0370\n",
      "[I 2023-11-27 14:11:51,989] Trial 2 finished with value: 0.03336795180037944 and parameters: {'iterations': 595, 'depth': 5, 'learning_rate': 0.18128112677663014}. Best is trial 1 with value: 0.03701412972494217.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import logging\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn import metrics\n",
    "from optuna.visualization import plot_optimization_history\n",
    "\n",
    "RANDOM_SEED = 32\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X[:25000], y[:25000], test_size=0.2, random_state=RANDOM_SEED)\n",
    "# Configure logging to file\n",
    "logging.basicConfig(filename='../../Energy_graph/data/optuna_log.log', level=logging.INFO, \n",
    "                    format='%(asctime)s %(levelname)s %(message)s')\n",
    "# Enable logging at the INFO level\n",
    "optuna.logging.get_logger(\"optuna\").setLevel(logging.INFO)\n",
    "\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'iterations': trial.suggest_int('iterations', 100, 1000),\n",
    "        'depth': trial.suggest_int('depth', 4, 8),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        # Add other parameters here\n",
    "        'random_seed': RANDOM_SEED,\n",
    "        'loss_function': 'MultiLogloss',\n",
    "        'verbose': False,\n",
    "        'task_type': \"GPU\",\n",
    "        'devices': '0:1'\n",
    "    }\n",
    "\n",
    "    model = CatBoostClassifier(**param)\n",
    "    X_train_norm = normalize(X_train)\n",
    "    score = cross_val_score(model, X_train_norm, y_train, cv=5, scoring='f1_weighted').mean()\n",
    "    return score\n",
    "\n",
    "# Define a simple callback function to print the best value so far\n",
    "def callback(study, trial):\n",
    "    if study.best_trial == trial:\n",
    "        print(f\"New best value: {trial.value:.4f}\")\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100, callbacks=[callback], show_progress_bar=True)  # Adjust the number of trials\n",
    "\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.params)\n",
    "\n",
    "try: \n",
    "    # Save the study if you want to\n",
    "    with open(\"study.pkl\", \"wb\") as f:\n",
    "        pickle.dump(study, f)\n",
    "\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Train the final model with the best parameters\n",
    "best_params = study.best_trial.params\n",
    "best_model = CatBoostClassifier(**best_params)\n",
    "best_model.fit(normalize(X_train), y_train)\n",
    "\n",
    "# Evaluate the model on the holdout validation set\n",
    "X_val_norm = normalize(X_val)\n",
    "val_predictions = best_model.predict(X_val_norm)\n",
    "val_score = metrics.f1_score(y_val, val_predictions, average='weighted')\n",
    "print(\"Validation F1 Score:\", val_score)\n",
    "\n",
    "# Plot the optimization history\n",
    "plot_optimization_history(study)\n",
    "# Remember to close the logging file handler if necessary\n",
    "logging.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "# data = pd.read_pickle(\"./Energy_graph/data/training_data/synthetic/X_Y_wsize2688_numW_50000_upper32_gap3600_numD64_ideal_sanitycheck.pkl\")\n",
    "data = pd.read_pickle(\"./Energy_graph/data/training_data/synthetic/X_Y_wsize2688_numW_50000_upper32_gap3600_numD64_ideal.pkl\")\n",
    "labels  = pd.read_pickle(\"./Energy_graph/data/labels_new.pkl\")\n",
    "X = np.array([i[0] for i in data])\n",
    "y = np.array([i[1] for i in data])\n",
    "y = y.astype(int)\n",
    "# X = X[:1000]\n",
    "# y = y[:1000]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "params = dict()\n",
    "params[\"device\"] = \"cuda\"\n",
    "params[\"tree_method\"] = \"gpu_hist\"\n",
    "params[\"verbosity\"] = 3\n",
    "\n",
    "\n",
    "model = XGBClassifier(**params)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "report = classification_report(y_test, y_pred, output_dict=True, target_names=labels)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(report).T\n",
    "df.to_csv(\"./Energy_graph/data/results/2688/XGB_50000_2688.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for i in range(len(evaluation_results)):\n",
    "    if i == 0:\n",
    "        df = pd.DataFrame(evaluation_results[i]).T\n",
    "    else:\n",
    "        df = df + pd.DataFrame(evaluation_results[i]).T\n",
    "\n",
    "\n",
    "df = df / 5\n",
    "# check if directory exsits\n",
    "if not os.path.exists(f\"../../Energy_graph/data/results/{window_size}\"):\n",
    "    os.makedirs(f\"../../Energy_graph/data/results/{window_size}\")\n",
    "if lambda_l2 == 0:\n",
    "    df.to_csv(f\"../../Energy_graph/data/results/{window_size}/PC0_epochs{epochs}_batch_size{batch_size}_k{k}_classes{NmDevices}_{function}_watts_syn_mix.csv\")\n",
    "else:\n",
    "    df.to_csv(f\"../../Energy_graph/data/results/w_size{window_size}_epochs{epochs}_batch_size{batch_size}_k{k}_classes{NmDevices}_{function}_watts_syn_reg{lambda_l2}.csv\")\n",
    "# df.to_csv(f\"../../Energy_graph/data/results/w_size{window_size}_classes{NmDevices}_watts_RF_mixed50k.csv\")\n",
    "    \n",
    "# evaluation_results+ evaluation_results[1].to_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 2688, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 2688, 1)      0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 2688, 32)     1280        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 2688, 32)     640         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 2688, 32)     320         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 2688, 32)     32          ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 2688, 128)    0           ['conv1d[0][0]',                 \n",
      "                                                                  'conv1d_1[0][0]',               \n",
      "                                                                  'conv1d_2[0][0]',               \n",
      "                                                                  'conv1d_3[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 2688, 128)   512         ['concatenate[0][0]']            \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 2688, 128)    0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 2688, 32)     4096        ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 2688, 128)   0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 2688, 32)     40960       ['conv1d_4[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 2688, 32)     20480       ['conv1d_4[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 2688, 32)     10240       ['conv1d_4[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)              (None, 2688, 32)     4096        ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 2688, 128)    0           ['conv1d_5[0][0]',               \n",
      "                                                                  'conv1d_6[0][0]',               \n",
      "                                                                  'conv1d_7[0][0]',               \n",
      "                                                                  'conv1d_8[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 2688, 128)   512         ['concatenate_1[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 2688, 128)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_9 (Conv1D)              (None, 2688, 32)     4096        ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 2688, 128)   0           ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_10 (Conv1D)             (None, 2688, 32)     40960       ['conv1d_9[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_11 (Conv1D)             (None, 2688, 32)     20480       ['conv1d_9[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_12 (Conv1D)             (None, 2688, 32)     10240       ['conv1d_9[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_13 (Conv1D)             (None, 2688, 32)     4096        ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 2688, 128)    0           ['conv1d_10[0][0]',              \n",
      "                                                                  'conv1d_11[0][0]',              \n",
      "                                                                  'conv1d_12[0][0]',              \n",
      "                                                                  'conv1d_13[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_14 (Conv1D)             (None, 2688, 128)    128         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 2688, 128)   512         ['concatenate_2[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 2688, 128)   512         ['conv1d_14[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 2688, 128)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 2688, 128)    0           ['batch_normalization_3[0][0]',  \n",
      "                                                                  'activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 2688, 128)    0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv1d_15 (Conv1D)             (None, 2688, 32)     4096        ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 2688, 128)   0           ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_16 (Conv1D)             (None, 2688, 32)     40960       ['conv1d_15[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_17 (Conv1D)             (None, 2688, 32)     20480       ['conv1d_15[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_18 (Conv1D)             (None, 2688, 32)     10240       ['conv1d_15[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_19 (Conv1D)             (None, 2688, 32)     4096        ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 2688, 128)    0           ['conv1d_16[0][0]',              \n",
      "                                                                  'conv1d_17[0][0]',              \n",
      "                                                                  'conv1d_18[0][0]',              \n",
      "                                                                  'conv1d_19[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 2688, 128)   512         ['concatenate_3[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 2688, 128)    0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_20 (Conv1D)             (None, 2688, 32)     4096        ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 2688, 128)   0           ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_21 (Conv1D)             (None, 2688, 32)     40960       ['conv1d_20[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_22 (Conv1D)             (None, 2688, 32)     20480       ['conv1d_20[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_23 (Conv1D)             (None, 2688, 32)     10240       ['conv1d_20[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_24 (Conv1D)             (None, 2688, 32)     4096        ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 2688, 128)    0           ['conv1d_21[0][0]',              \n",
      "                                                                  'conv1d_22[0][0]',              \n",
      "                                                                  'conv1d_23[0][0]',              \n",
      "                                                                  'conv1d_24[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 2688, 128)   512         ['concatenate_4[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 2688, 128)    0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_25 (Conv1D)             (None, 2688, 32)     4096        ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 2688, 128)   0           ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_26 (Conv1D)             (None, 2688, 32)     40960       ['conv1d_25[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_27 (Conv1D)             (None, 2688, 32)     20480       ['conv1d_25[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_28 (Conv1D)             (None, 2688, 32)     10240       ['conv1d_25[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_29 (Conv1D)             (None, 2688, 32)     4096        ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 2688, 128)    0           ['conv1d_26[0][0]',              \n",
      "                                                                  'conv1d_27[0][0]',              \n",
      "                                                                  'conv1d_28[0][0]',              \n",
      "                                                                  'conv1d_29[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_30 (Conv1D)             (None, 2688, 128)    16384       ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 2688, 128)   512         ['concatenate_5[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 2688, 128)   512         ['conv1d_30[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 2688, 128)    0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 2688, 128)    0           ['batch_normalization_7[0][0]',  \n",
      "                                                                  'activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 2688, 128)    0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_31 (Conv1D)             (None, 2688, 32)     4096        ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 2688, 128)   0           ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_32 (Conv1D)             (None, 2688, 32)     40960       ['conv1d_31[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_33 (Conv1D)             (None, 2688, 32)     20480       ['conv1d_31[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_34 (Conv1D)             (None, 2688, 32)     10240       ['conv1d_31[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_35 (Conv1D)             (None, 2688, 32)     4096        ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 2688, 128)    0           ['conv1d_32[0][0]',              \n",
      "                                                                  'conv1d_33[0][0]',              \n",
      "                                                                  'conv1d_34[0][0]',              \n",
      "                                                                  'conv1d_35[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 2688, 128)   512         ['concatenate_6[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 2688, 128)    0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_36 (Conv1D)             (None, 2688, 32)     4096        ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling1d_7 (MaxPooling1D)  (None, 2688, 128)   0           ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_37 (Conv1D)             (None, 2688, 32)     40960       ['conv1d_36[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_38 (Conv1D)             (None, 2688, 32)     20480       ['conv1d_36[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_39 (Conv1D)             (None, 2688, 32)     10240       ['conv1d_36[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_40 (Conv1D)             (None, 2688, 32)     4096        ['max_pooling1d_7[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 2688, 128)    0           ['conv1d_37[0][0]',              \n",
      "                                                                  'conv1d_38[0][0]',              \n",
      "                                                                  'conv1d_39[0][0]',              \n",
      "                                                                  'conv1d_40[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 2688, 128)   512         ['concatenate_7[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 2688, 128)    0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_41 (Conv1D)             (None, 2688, 32)     4096        ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling1d_8 (MaxPooling1D)  (None, 2688, 128)   0           ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_42 (Conv1D)             (None, 2688, 32)     40960       ['conv1d_41[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_43 (Conv1D)             (None, 2688, 32)     20480       ['conv1d_41[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_44 (Conv1D)             (None, 2688, 32)     10240       ['conv1d_41[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_45 (Conv1D)             (None, 2688, 32)     4096        ['max_pooling1d_8[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 2688, 128)    0           ['conv1d_42[0][0]',              \n",
      "                                                                  'conv1d_43[0][0]',              \n",
      "                                                                  'conv1d_44[0][0]',              \n",
      "                                                                  'conv1d_45[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_46 (Conv1D)             (None, 2688, 128)    16384       ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 2688, 128)   512         ['concatenate_8[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 2688, 128)   512         ['conv1d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 2688, 128)    0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 2688, 128)    0           ['batch_normalization_11[0][0]', \n",
      "                                                                  'activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 2688, 128)    0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_47 (Conv1D)             (None, 2688, 32)     4096        ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling1d_9 (MaxPooling1D)  (None, 2688, 128)   0           ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_48 (Conv1D)             (None, 2688, 32)     40960       ['conv1d_47[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_49 (Conv1D)             (None, 2688, 32)     20480       ['conv1d_47[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_50 (Conv1D)             (None, 2688, 32)     10240       ['conv1d_47[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_51 (Conv1D)             (None, 2688, 32)     4096        ['max_pooling1d_9[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate)    (None, 2688, 128)    0           ['conv1d_48[0][0]',              \n",
      "                                                                  'conv1d_49[0][0]',              \n",
      "                                                                  'conv1d_50[0][0]',              \n",
      "                                                                  'conv1d_51[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 2688, 128)   512         ['concatenate_9[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 2688, 128)    0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 128)         0           ['activation_12[0][0]']          \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 64)           8256        ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 768,928\n",
      "Trainable params: 765,600\n",
      "Non-trainable params: 3,328\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"./models/test/last_model_4.hdf5\", custom_objects={'F1Score': NUK.F1Score, \"WeightedF1\": NUK.WeightedF1Score(class_weighs_pre)})\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../../Energy_graph/data/processed_watts/REFIT_clean.pkl\")\n",
    "df[\"REFIT_1\"]\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open(\"../../Energy_graph/data/processed_watts/refit/REFIT1_clean.pkl\", 'wb') as f:\n",
    "    pickle.dump({\"REFIT_1\" : df[\"REFIT_1\"]}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from collections import Counter\n",
    "import concurrent.futures\n",
    "import argparse\n",
    "# from helper import preprocess_string\n",
    "\n",
    "import re\n",
    "\n",
    "def preprocess_string(string : str) -> str:\n",
    "    string = string.lower().strip()\n",
    "    string = re.sub(' +', ' ', string)\n",
    "    string = string.replace(\"_\", \" \")\n",
    "    string = string.replace(\"-\", \" \")\n",
    "    string = string.replace(\"&\", \" \")\n",
    "    string = string.split(\"(\")[0]\n",
    "    string = string.split(\"#\")[0]\n",
    "\n",
    "    string = string.strip()\n",
    "\n",
    "    # handle known synoynms\n",
    "    synonyms = {\n",
    "        \"refrigerator\": \"fridge\",\n",
    "        \"vaccumcleaner\": \"vacuum cleaner\",\n",
    "        \"breadmaker\": \"bread maker\",\n",
    "      \n",
    "        \n",
    "    }\n",
    "    if \"freezer\" in string:\n",
    "        string = \"fridge\"\n",
    "\n",
    "    if string in synonyms:\n",
    "        string = synonyms[string]\n",
    "\n",
    "    if 'hi fi' in string:\n",
    "        string = \"audio system\"\n",
    "\n",
    "    if \"router\" in string:\n",
    "        string = \"router\"\n",
    "\n",
    "    if \"treadmill\" in string:\n",
    "        string = \"running machine\"\n",
    "        \n",
    "\n",
    "    if \"laptop\" in string:\n",
    "        string = \"laptop\"\n",
    "    \n",
    "    if \"server\" in string:\n",
    "        string = \"server\"\n",
    "\n",
    "    if \"monitor\" in string and not \"baby\" in string:\n",
    "        string = \"monitor\"\n",
    "    # special cases\n",
    "    if \"computer\" in string and \"charger\" not in string:\n",
    "        string = \"pc\"\n",
    "\n",
    "    if \"tv\" in string:\n",
    "        string = \"television\"\n",
    "\n",
    "    if \"television\" in string:\n",
    "        string = \"television\"\n",
    "\n",
    "    if \"macbook\" in string:\n",
    "        string = \"laptop\"\n",
    "        \n",
    "    if \"car charger\" == string:\n",
    "        string = \"ev\"\n",
    "    \n",
    "    if \"toast\" in string:\n",
    "        string = \"toaster\"\n",
    "    \n",
    "    if \"modem\" in string:\n",
    "        string = \"router\"\n",
    "\n",
    "    # we treat all audio devices as speakers so subwoofer is also a speaker\n",
    "    if \"subwoofer\" in string:\n",
    "        string = \"speaker\"\n",
    "\n",
    "    if \"speaker\" in string:\n",
    "        string = \"speaker\"\n",
    "\n",
    "    if \"iron\" in string and \"soldering\" not in string:\n",
    "        string = \"iron\"\n",
    "\n",
    "    \n",
    "    if \"coffeemachine\" in string:\n",
    "        string = \"coffee machine\"\n",
    "    if \"coffee maker\" in string:\n",
    "        string = \"coffee machine\"\n",
    "\n",
    "    if \"dishwasher\" in string:\n",
    "        string = \"dish washer\"\n",
    "    if \"air conditioner\" in string:\n",
    "        string = \"ac\"\n",
    "\n",
    "    if \"air conditioning\" in string:\n",
    "        string = \"ac\"\n",
    "    \n",
    "    string = re.sub(' +', ' ', string)\n",
    "    string = re.sub(r'\\d+', '', string)\n",
    "    return string.strip()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def process_dictionary(data: dict, values=0) -> pd.DataFrame:\n",
    "\n",
    "    ignored_devices = [\n",
    "        \"light\",\n",
    "        \"outlet\",\n",
    "        \"sockets\",\n",
    "        \"lamp\",\n",
    "        \"plug\",\n",
    "        'CE appliance'\n",
    "        'kettle/toaster',\n",
    "        'dehumidifier/heater',\n",
    "        'HairDryer-Straightener',\n",
    "        'Office Desk',\n",
    "        'heat basement',\n",
    "        'set top box',\n",
    "        'subpanel',\n",
    "    ]\n",
    "    dfs = []\n",
    "    for device in data:\n",
    "        # ignore devices\n",
    "        if any(ignored_device in device.lower() for ignored_device in ignored_devices):\n",
    "            continue\n",
    "        if device == \"aggregate\":\n",
    "            continue\n",
    "        # preprocess device name\n",
    "        device_name = preprocess_string(device)\n",
    "        \n",
    "        df = data[device]\n",
    "        df = df.resample(\"8s\").mean()\n",
    "\n",
    "        # rename column to standardized device name\n",
    "        df.columns = [device_name]\n",
    "        if df.max().max() < 2:\n",
    "            print(\"device with zeros: \", device_name)\n",
    "            continue\n",
    "\n",
    "        time_diffs = df.index.to_series().diff()\n",
    "        median_interval = time_diffs.median()\n",
    "\n",
    "        # if there is less than 3 days of data drop the device\n",
    "        if len(df) < (3*24 * 60 * 60) / median_interval.total_seconds():\n",
    "            print(\"less than 3 days of data for device: \", device_name)\n",
    "            continue\n",
    "        df.dropna(inplace=True)\n",
    "        dfs.append(df)\n",
    "\n",
    "    # concatenate all dataframes\n",
    "    df = pd.concat(dfs, axis=1)\n",
    "\n",
    "    # handle missing values\n",
    "    df = df.ffill(limit=6)\n",
    "    df.fillna(0, inplace=True)\n",
    "\n",
    "    # handle negative values\n",
    "    df[df<0] = 0\n",
    "\n",
    "    df[\"aggregate\"] = df.sum(axis=1)\n",
    "    # df.drop(columns=[\"aggregate\"], inplace=True)\n",
    "\n",
    "    # df.rename(columns={\"sum_ideal\": \"aggregate\"}, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "    # treshold in watts\n",
    "    treshold = 5\n",
    "    if values == 0:\n",
    "        # put 1 if device is on and 0 if device is off\n",
    "        for c in df.columns:\n",
    "            if c == \"aggregate\":\n",
    "                continue\n",
    "            # if power is less than treshold device is off\n",
    "            df[c] = (df[c] > treshold).astype(int)\n",
    "\n",
    "    # find duplicate columns\n",
    "    column_counts = Counter(df.columns)\n",
    "    duplicates = [col for col, count in column_counts.items() if count > 1]\n",
    "    # Sum duplicate columns\n",
    "    for duplicate in duplicates:\n",
    "        duplicate_cols = [col for i, col in enumerate(df.columns) if col == duplicate]\n",
    "        df[duplicate] = df[duplicate_cols].sum(axis=1)\n",
    "        # Drop other duplicate columns if needed\n",
    "        df = df.loc[:, ~df.columns.duplicated(keep='last')]\n",
    "    \n",
    "    \n",
    "    return df\n",
    "    \n",
    "\n",
    "\n",
    "def process_dataset(dataset_path):\n",
    "    data = pd.read_pickle(dataset_path)\n",
    "    # print(dataset_path)\n",
    "    for house in data:\n",
    "        data[house] = process_dictionary(data[house], house)\n",
    "        \n",
    "    return data\n",
    "\n",
    "\n",
    "def get_data(path : str, labels_path : str, values=0):\n",
    "        \n",
    "    # path = \"./Energy_graph/data/processed_watts/\"\n",
    "    dataset_paths = [os.path.join(path, dataset) for dataset in os.listdir(path) if dataset.endswith('.pkl')]\n",
    "        \n",
    "    cpu_count = int(os.cpu_count() / 2)\n",
    "    data_dict = {}\n",
    "\n",
    "    with tqdm(total=len(dataset_paths), desc=\"Processing datasets\", unit=\"dataset\") as progress_bar:\n",
    "        with concurrent.futures.ProcessPoolExecutor(max_workers=cpu_count) as executor:\n",
    "            futures = {executor.submit(process_dataset, dataset_path): dataset_path for dataset_path in dataset_paths}\n",
    "            \n",
    "            for future in concurrent.futures.as_completed(futures):\n",
    "                dataset_path = futures[future]\n",
    "                try:\n",
    "                    processed_data = future.result()\n",
    "                    data_dict.update(processed_data)\n",
    "                except Exception as e:\n",
    "                    print(f\"Dataset {dataset_path} generated an exception: {e}\")\n",
    "                \n",
    "                progress_bar.update(1)\n",
    "\n",
    "    labels = pd.read_pickle(labels_path)\n",
    "    labels.sort()\n",
    "\n",
    "    return data_dict\n",
    "\n",
    "def create_windows(data : dict, labels_path: str, save_path : str, time_window=2700, upper_bound=pd.Timedelta(seconds=32), max_gap = pd.Timedelta(seconds=3600)):\n",
    "    \"\"\"Creates windows of time_window seconds from the data and discards windows with gaps of more than 1h or 15 gaps of 32 seconds or more\"\"\"\n",
    "    \n",
    "    labels = pd.read_pickle(labels_path)\n",
    "    # windows = []\n",
    "    X_Y = [] # list of tuples (X, Y)\n",
    "    skip_count_1 = 0\n",
    "    skip_count_2 = 0\n",
    "    skip_count_3 = 0\n",
    "    total_count = 0\n",
    "\n",
    "    for df in data.values():\n",
    "        print(len(df[\"aggregate\"]))\n",
    "        for i in range(0, len(df) - time_window, time_window + 1):\n",
    "            window = df.iloc[i:i + time_window]\n",
    "            total_count += 1\n",
    "            # if there is a gap of more than max_gap skip the window\n",
    "            time_diffs = window.index.to_series().diff().dropna()\n",
    "            if  (time_diffs >= max_gap).any():\n",
    "                skip_count_1 += 1\n",
    "                continue\n",
    "            # if there are more than 15 gaps of upper_bound or more skip the window\n",
    "            if len(time_diffs[time_diffs > upper_bound]) > 15:\n",
    "                skip_count_2 += 1\n",
    "                continue\n",
    "\n",
    "            x = window[\"aggregate\"].values\n",
    "            # if there is a value bigger than 50000 skip the window\n",
    "            if (x > 50000).any():\n",
    "                skip_count_3 += 1\n",
    "                continue\n",
    "            devices = [False] * len(labels)\n",
    "            # check if device is on in the window\n",
    "            for c in window.columns:\n",
    "                if c == \"aggregate\":\n",
    "                    continue\n",
    "                on = (window[c] > 0)\n",
    "                ix = labels.index(c)\n",
    "                devices[ix] = on.any()\n",
    "\n",
    "            X_Y.append((x, devices))\n",
    "            \n",
    "\n",
    "\n",
    "            # windows.append(window)\n",
    "    print(\"Total windows: \", total_count, \"Skipped windows due to 30min gap: \", skip_count_1, \"Skipped windows due to 15 gaps of 32s or more: \", skip_count_2 ,\"Skipped windows due to values larger than 50k: \", skip_count_3 ,\"Procentage skipped: \", (skip_count_1+skip_count_2+ skip_count_3) / total_count * 100)\n",
    "    return X_Y\n",
    "    # with open(save_path+ f\"/X_Y_wsize{time_window}_upper{int(upper_bound.total_seconds())}_gap{int(max_gap.total_seconds())}_numD{len(labels)}.pkl\", \"wb\") as f:\n",
    "    #     pickle.dump(X_Y, f, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to base folder:  ../../Energy_graph/\n",
      "Path to save windows:  ../../Energy_graph//data/training_data/processed/\n",
      "Time window:  2688 rows |  21504 seconds\n",
      "Upper bound:  0 days 00:00:32\n",
      "Max gap:  0 days 01:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing datasets:  50%|█████     | 5/10 [00:15<00:10,  2.05s/dataset]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "less than 3 days of data for device:  games console\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing datasets: 100%|██████████| 10/10 [02:18<00:00, 13.87s/dataset]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "folder = \"\"\n",
    "# Initialize paths\n",
    "path_to_base = \"../../Energy_graph/\"\n",
    "path = path_to_base + \"/data/processed_watts/\"+folder\n",
    "labels_path = path_to_base + \"/data/labels_new.pkl\"\n",
    "save_path = path_to_base + \"/data/training_data/processed/\"+folder\n",
    "\n",
    "# Initialize parameters\n",
    "time_window = 2688\n",
    "upper_bound = pd.Timedelta(seconds=32)\n",
    "max_gap = pd.Timedelta(seconds=3600)\n",
    "\n",
    "# Print parameters\n",
    "print(\"Path to base folder: \", path_to_base)\n",
    "print(\"Path to save windows: \", save_path)\n",
    "print(\"Time window: \", time_window, \"rows | \", time_window*8, \"seconds\")\n",
    "print(\"Upper bound: \", upper_bound)\n",
    "print(\"Max gap: \", max_gap)\n",
    "\n",
    "# Get data and create windows\n",
    "data = get_data(path, labels_path)\n",
    "# create_windows(data, labels_path, save_path, time_window, upper_bound, max_gap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/64 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HES_1 1152268\n",
      "1152268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/64 [00:00<00:49,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  428 Skipped windows due to 30min gap:  5 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  1.1682242990654206\n",
      "IAWE_1 620447\n",
      "620447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 2/64 [00:01<00:30,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  230 Skipped windows due to 30min gap:  14 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  6.086956521739131\n",
      "DRED_1 1657798\n",
      "1657798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 3/64 [00:02<00:43,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  616 Skipped windows due to 30min gap:  0 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  0.0\n",
      "HEART_33 1004400\n",
      "1004400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 4/64 [00:02<00:40,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  373 Skipped windows due to 30min gap:  0 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  0.0\n",
      "HEART_7 1004400\n",
      "1004400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 6/64 [00:03<00:27,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  373 Skipped windows due to 30min gap:  0 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  0.0\n",
      "REDD_1 358273\n",
      "358273\n",
      "Total windows:  133 Skipped windows due to 30min gap:  5 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  3.7593984962406015\n",
      "REDD_2 148341\n",
      "148341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 8/64 [00:03<00:16,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  55 Skipped windows due to 30min gap:  3 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  5.454545454545454\n",
      "REDD_3 192499\n",
      "192499\n",
      "Total windows:  71 Skipped windows due to 30min gap:  9 Skipped windows due to 15 gaps of 32s or more:  1 Skipped windows due to values larger than 50k:  0 Procentage skipped:  14.084507042253522\n",
      "REDD_4 272058\n",
      "272058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 9/64 [00:03<00:13,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  101 Skipped windows due to 30min gap:  6 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  5.9405940594059405\n",
      "REDD_5 39395\n",
      "39395\n",
      "Total windows:  14 Skipped windows due to 30min gap:  4 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  28.57142857142857\n",
      "REDD_6 152445\n",
      "152445\n",
      "Total windows:  56 Skipped windows due to 30min gap:  4 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  7.142857142857142\n",
      "DEDDIAG_8 4500232\n",
      "4500232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 12/64 [00:05<00:24,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  1673 Skipped windows due to 30min gap:  0 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  0.0\n",
      "ECO_1 2494800\n",
      "2494800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 13/64 [00:06<00:30,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  927 Skipped windows due to 30min gap:  1 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  0.10787486515641855\n",
      "ECO_6 1998000\n",
      "1998000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 14/64 [00:07<00:32,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  743 Skipped windows due to 30min gap:  2 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  0.2691790040376851\n",
      "ECO_2 2592000\n",
      "2592000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 15/64 [00:08<00:39,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  963 Skipped windows due to 30min gap:  2 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  0.20768431983385255\n",
      "ECO_5 2354400\n",
      "2354400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 16/64 [00:10<00:42,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  875 Skipped windows due to 30min gap:  1 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  0.1142857142857143\n",
      "ECO_4 2106000\n",
      "2106000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 17/64 [00:10<00:39,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  783 Skipped windows due to 30min gap:  3 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  0.38314176245210724\n",
      "ECO_3 1047600\n",
      "1047600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 18/64 [00:11<00:32,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  389 Skipped windows due to 30min gap:  2 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  0.5141388174807198\n",
      "ENERTALK_1 1211429\n",
      "1211429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 20/64 [00:11<00:22,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  450 Skipped windows due to 30min gap:  14 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  3.111111111111111\n",
      "ENERTALK_18 509433\n",
      "509433\n",
      "Total windows:  189 Skipped windows due to 30min gap:  1 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  0.5291005291005291\n",
      "ENERTALK_12 1282152\n",
      "1282152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 21/64 [00:12<00:22,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  476 Skipped windows due to 30min gap:  6 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  1.2605042016806722\n",
      "ENERTALK_20 647946\n",
      "647946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 23/64 [00:12<00:14,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  240 Skipped windows due to 30min gap:  1 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  0.4166666666666667\n",
      "ENERTALK_15 495183\n",
      "495183\n",
      "Total windows:  184 Skipped windows due to 30min gap:  1 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  0.5434782608695652\n",
      "ENERTALK_6 464668\n",
      "464668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 24/64 [00:12<00:12,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  172 Skipped windows due to 30min gap:  1 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  0.5813953488372093\n",
      "ENERTALK_8 657789\n",
      "657789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 26/64 [00:13<00:09,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  244 Skipped windows due to 30min gap:  1 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  0.4098360655737705\n",
      "ENERTALK_2 334755\n",
      "334755\n",
      "Total windows:  124 Skipped windows due to 30min gap:  0 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  0.0\n",
      "ENERTALK_11 322716\n",
      "322716\n",
      "Total windows:  120 Skipped windows due to 30min gap:  0 Skipped windows due to 15 gaps of 32s or more:  1 Skipped windows due to values larger than 50k:  0 Procentage skipped:  0.8333333333333334\n",
      "ENERTALK_16 767570\n",
      "767570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 28/64 [00:13<00:07,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  285 Skipped windows due to 30min gap:  4 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  1.4035087719298245\n",
      "ENERTALK_5 617543\n",
      "617543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 30/64 [00:14<00:07,  4.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  229 Skipped windows due to 30min gap:  1 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  0.43668122270742354\n",
      "ENERTALK_7 657441\n",
      "657441\n",
      "Total windows:  244 Skipped windows due to 30min gap:  1 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  0.4098360655737705\n",
      "ENERTALK_14 1062395\n",
      "1062395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 31/64 [00:14<00:07,  4.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  395 Skipped windows due to 30min gap:  10 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  2.5316455696202533\n",
      "ENERTALK_13 947873\n",
      "947873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 33/64 [00:14<00:07,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  352 Skipped windows due to 30min gap:  4 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  1.1363636363636365\n",
      "ENERTALK_19 637122\n",
      "637122\n",
      "Total windows:  236 Skipped windows due to 30min gap:  2 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  0.847457627118644\n",
      "ENERTALK_21 657552\n",
      "657552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 34/64 [00:15<00:07,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  244 Skipped windows due to 30min gap:  1 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  0.4098360655737705\n",
      "ENERTALK_0 936253\n",
      "936253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 35/64 [00:15<00:08,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  348 Skipped windows due to 30min gap:  6 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  1.7241379310344827\n",
      "ENERTALK_4 906831\n",
      "906831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 36/64 [00:15<00:08,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  337 Skipped windows due to 30min gap:  7 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  2.0771513353115725\n",
      "ENERTALK_17 912460\n",
      "912460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 37/64 [00:16<00:09,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  339 Skipped windows due to 30min gap:  7 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  2.0648967551622417\n",
      "ENERTALK_10 1249051\n",
      "1249051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 38/64 [00:16<00:09,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  464 Skipped windows due to 30min gap:  8 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  1.7241379310344827\n",
      "ENERTALK_3 1215991\n",
      "1215991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 39/64 [00:17<00:08,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  452 Skipped windows due to 30min gap:  11 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  2.433628318584071\n",
      "ENERTALK_9 1293445\n",
      "1293445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 40/64 [00:17<00:09,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  481 Skipped windows due to 30min gap:  4 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  0.8316008316008316\n",
      "REFIT_13 4075515\n",
      "4075515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 41/64 [00:19<00:18,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  1515 Skipped windows due to 30min gap:  35 Skipped windows due to 15 gaps of 32s or more:  124 Skipped windows due to values larger than 50k:  0 Procentage skipped:  10.495049504950495\n",
      "REFIT_6 5246422\n",
      "5246422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 42/64 [00:21<00:30,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  1951 Skipped windows due to 30min gap:  22 Skipped windows due to 15 gaps of 32s or more:  32 Skipped windows due to values larger than 50k:  0 Procentage skipped:  2.7678113787801126\n",
      "REFIT_1 6003014\n",
      "6003014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 43/64 [00:24<00:37,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  2232 Skipped windows due to 30min gap:  25 Skipped windows due to 15 gaps of 32s or more:  13 Skipped windows due to values larger than 50k:  0 Procentage skipped:  1.702508960573477\n",
      "REFIT_21 4770403\n",
      "4770403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 44/64 [00:27<00:38,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  1774 Skipped windows due to 30min gap:  18 Skipped windows due to 15 gaps of 32s or more:  5 Skipped windows due to values larger than 50k:  0 Procentage skipped:  1.2965050732807215\n",
      "REFIT_8 5346837\n",
      "5346837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 45/64 [00:29<00:41,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  1988 Skipped windows due to 30min gap:  18 Skipped windows due to 15 gaps of 32s or more:  11 Skipped windows due to values larger than 50k:  0 Procentage skipped:  1.4587525150905434\n",
      "REFIT_9 5161252\n",
      "5161252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 46/64 [00:33<00:46,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  1919 Skipped windows due to 30min gap:  16 Skipped windows due to 15 gaps of 32s or more:  9 Skipped windows due to values larger than 50k:  0 Procentage skipped:  1.3027618551328817\n",
      "REFIT_20 4651687\n",
      "4651687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 47/64 [00:35<00:43,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  1729 Skipped windows due to 30min gap:  12 Skipped windows due to 15 gaps of 32s or more:  8 Skipped windows due to values larger than 50k:  0 Procentage skipped:  1.156737998843262\n",
      "REFIT_7 5758682\n",
      "5758682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 48/64 [00:38<00:41,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  2141 Skipped windows due to 30min gap:  24 Skipped windows due to 15 gaps of 32s or more:  10 Skipped windows due to values larger than 50k:  0 Procentage skipped:  1.5880429705744978\n",
      "REFIT_15 5262277\n",
      "5262277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 49/64 [00:41<00:40,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  1956 Skipped windows due to 30min gap:  30 Skipped windows due to 15 gaps of 32s or more:  9 Skipped windows due to values larger than 50k:  0 Procentage skipped:  1.9938650306748467\n",
      "REFIT_12 4884120\n",
      "4884120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 50/64 [00:43<00:34,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  1816 Skipped windows due to 30min gap:  16 Skipped windows due to 15 gaps of 32s or more:  43 Skipped windows due to values larger than 50k:  0 Procentage skipped:  3.248898678414097\n",
      "REFIT_4 5881600\n",
      "5881600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 51/64 [00:45<00:32,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  2187 Skipped windows due to 30min gap:  40 Skipped windows due to 15 gaps of 32s or more:  27 Skipped windows due to values larger than 50k:  0 Procentage skipped:  3.063557384545039\n",
      "REFIT_3 5858072\n",
      "5858072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 52/64 [00:48<00:31,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  2178 Skipped windows due to 30min gap:  20 Skipped windows due to 15 gaps of 32s or more:  11 Skipped windows due to values larger than 50k:  0 Procentage skipped:  1.423324150596878\n",
      "REFIT_18 4488860\n",
      "4488860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 53/64 [00:51<00:27,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  1669 Skipped windows due to 30min gap:  16 Skipped windows due to 15 gaps of 32s or more:  4 Skipped windows due to values larger than 50k:  0 Procentage skipped:  1.1983223487118035\n",
      "REFIT_11 3745057\n",
      "3745057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 54/64 [00:53<00:23,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  1392 Skipped windows due to 30min gap:  15 Skipped windows due to 15 gaps of 32s or more:  8 Skipped windows due to values larger than 50k:  0 Procentage skipped:  1.6522988505747127\n",
      "REFIT_16 4829646\n",
      "4829646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 55/64 [00:55<00:20,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  1796 Skipped windows due to 30min gap:  32 Skipped windows due to 15 gaps of 32s or more:  6 Skipped windows due to values larger than 50k:  0 Procentage skipped:  2.1158129175946545\n",
      "REFIT_17 4733420\n",
      "4733420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 56/64 [00:57<00:18,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  1760 Skipped windows due to 30min gap:  17 Skipped windows due to 15 gaps of 32s or more:  8 Skipped windows due to values larger than 50k:  0 Procentage skipped:  1.4204545454545454\n",
      "REFIT_10 5573669\n",
      "5573669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 57/64 [01:00<00:17,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  2072 Skipped windows due to 30min gap:  32 Skipped windows due to 15 gaps of 32s or more:  51 Skipped windows due to values larger than 50k:  0 Procentage skipped:  4.005791505791506\n",
      "REFIT_19 4720415\n",
      "4720415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 58/64 [01:02<00:14,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  1755 Skipped windows due to 30min gap:  15 Skipped windows due to 15 gaps of 32s or more:  20 Skipped windows due to values larger than 50k:  0 Procentage skipped:  1.9943019943019942\n",
      "REFIT_2 4999158\n",
      "4999158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 59/64 [01:05<00:12,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  1859 Skipped windows due to 30min gap:  33 Skipped windows due to 15 gaps of 32s or more:  8 Skipped windows due to values larger than 50k:  0 Procentage skipped:  2.205486820871436\n",
      "REFIT_5 6287475\n",
      "6287475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 60/64 [01:08<00:11,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  2338 Skipped windows due to 30min gap:  33 Skipped windows due to 15 gaps of 32s or more:  31 Skipped windows due to values larger than 50k:  0 Procentage skipped:  2.737382378100941\n",
      "UKDALE_5 1425706\n",
      "1425706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 61/64 [01:10<00:07,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  530 Skipped windows due to 30min gap:  2 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  0.37735849056603776\n",
      "UKDALE_2 2156879\n",
      "2156879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 62/64 [01:12<00:04,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  802 Skipped windows due to 30min gap:  8 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  0.997506234413965\n",
      "UKDALE_1 17064863\n",
      "17064863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [01:32<00:00,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows:  6346 Skipped windows due to 30min gap:  35 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  0.5515285219035614\n",
      "UKDALE_3 396227\n",
      "396227\n",
      "Total windows:  147 Skipped windows due to 30min gap:  7 Skipped windows due to 15 gaps of 32s or more:  0 Skipped windows due to values larger than 50k:  0 Procentage skipped:  4.761904761904762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# data.keys()\n",
    "processed = {}\n",
    "\n",
    "for key in tqdm(data.keys()):\n",
    "    # if \"UKDALE\" not in key: \n",
    "    #     continue\n",
    "    print(key, len(data[key]))\n",
    "    processed[key] = create_windows({key : data[key]}, labels_path, save_path, time_window, upper_bound, max_gap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aggregate</th>\n",
       "      <th>kettle</th>\n",
       "      <th>projector</th>\n",
       "      <th>laptop</th>\n",
       "      <th>electric space heater</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-02-27 20:35:12</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-27 20:35:20</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-27 20:35:28</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-27 20:35:36</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-27 20:35:44</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-04-08 05:14:32</th>\n",
       "      <td>176.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-04-08 05:14:40</th>\n",
       "      <td>174.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-04-08 05:14:48</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-04-08 05:14:56</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-04-08 05:15:04</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>425100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     aggregate  kettle  projector  laptop  \\\n",
       "0                                                           \n",
       "2013-02-27 20:35:12        5.0       0          0       0   \n",
       "2013-02-27 20:35:20        4.0       0          1       0   \n",
       "2013-02-27 20:35:28        5.0       0          1       0   \n",
       "2013-02-27 20:35:36        4.0       0          0       0   \n",
       "2013-02-27 20:35:44        4.0       0          0       0   \n",
       "...                        ...     ...        ...     ...   \n",
       "2013-04-08 05:14:32      176.0       0          0       0   \n",
       "2013-04-08 05:14:40      174.0       0          0       0   \n",
       "2013-04-08 05:14:48        0.0       0          0       0   \n",
       "2013-04-08 05:14:56        0.0       1          0       0   \n",
       "2013-04-08 05:15:04        0.0       0          0       0   \n",
       "\n",
       "                     electric space heater  \n",
       "0                                           \n",
       "2013-02-27 20:35:12                      0  \n",
       "2013-02-27 20:35:20                      0  \n",
       "2013-02-27 20:35:28                      0  \n",
       "2013-02-27 20:35:36                      0  \n",
       "2013-02-27 20:35:44                      0  \n",
       "...                                    ...  \n",
       "2013-04-08 05:14:32                      0  \n",
       "2013-04-08 05:14:40                      0  \n",
       "2013-04-08 05:14:48                      0  \n",
       "2013-04-08 05:14:56                      0  \n",
       "2013-04-08 05:15:04                      0  \n",
       "\n",
       "[425100 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_devices(data):\n",
    "\n",
    "    devices = set()\n",
    "    real_str = \" \"\n",
    "    for key in data.keys():\n",
    "        if key == \"aggregate\":\n",
    "            continue\n",
    "        real_str+= key + \", \"\n",
    "        devices.add(preprocess_string(key))\n",
    "        \n",
    "\n",
    "    return list(devices), real_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"../../Energy_graph/data/training_data/real_house.pkl\", \"wb\") as f:\n",
    "    pickle.dump(processed, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HES_1\n",
      "2\n",
      "14/14 [==============================] - 1s 41ms/step\n",
      "14/14 [==============================] - 1s 25ms/step\n",
      "14/14 [==============================] - 1s 25ms/step\n",
      "14/14 [==============================] - 1s 25ms/step\n",
      "14/14 [==============================] - 1s 26ms/step\n",
      "0.9336485220415739 1.0 0.8800236406619385\n",
      "IAWE_1\n",
      "2\n",
      "7/7 [==============================] - 1s 88ms/step\n",
      "7/7 [==============================] - 0s 26ms/step\n",
      "7/7 [==============================] - 0s 25ms/step\n",
      "7/7 [==============================] - 0s 26ms/step\n",
      "7/7 [==============================] - 0s 26ms/step\n",
      "0.5008752495756639 0.6483688948976613 0.46766169154228854\n",
      "DRED_1\n",
      "2\n",
      "20/20 [==============================] - 1s 37ms/step\n",
      "20/20 [==============================] - 1s 26ms/step\n",
      "20/20 [==============================] - 0s 25ms/step\n",
      "20/20 [==============================] - 1s 26ms/step\n",
      "20/20 [==============================] - 0s 25ms/step\n",
      "0.3613230390192975 0.6204464870610003 0.32207407407407407\n",
      "HEART_33\n",
      "2\n",
      "12/12 [==============================] - 1s 58ms/step\n",
      "12/12 [==============================] - 0s 26ms/step\n",
      "12/12 [==============================] - 0s 25ms/step\n",
      "12/12 [==============================] - 0s 26ms/step\n",
      "12/12 [==============================] - 0s 26ms/step\n",
      "0.3430030937477516 0.33018970189701896 0.36829268292682926\n",
      "HEART_7\n",
      "2\n",
      "12/12 [==============================] - 0s 25ms/step\n",
      "12/12 [==============================] - 0s 25ms/step\n",
      "12/12 [==============================] - 0s 26ms/step\n",
      "12/12 [==============================] - 0s 26ms/step\n",
      "12/12 [==============================] - 0s 25ms/step\n",
      "0.35986203191925475 0.35865287188359446 0.3611342785654712\n",
      "REDD_1\n",
      "2\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 26ms/step\n",
      "4/4 [==============================] - 0s 26ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "0.19309986010022545 0.4746600741656366 0.16563658838071693\n",
      "REDD_2\n",
      "2\n",
      "2/2 [==============================] - 0s 361ms/step\n",
      "2/2 [==============================] - 0s 25ms/step\n",
      "2/2 [==============================] - 0s 24ms/step\n",
      "2/2 [==============================] - 0s 25ms/step\n",
      "2/2 [==============================] - 0s 25ms/step\n",
      "0.48504702660240756 0.582089552238806 0.43656716417910446\n",
      "REDD_3\n",
      "2\n",
      "2/2 [==============================] - 0s 467ms/step\n",
      "2/2 [==============================] - 0s 25ms/step\n",
      "2/2 [==============================] - 0s 25ms/step\n",
      "2/2 [==============================] - 0s 25ms/step\n",
      "2/2 [==============================] - 0s 25ms/step\n",
      "0.19243143563985396 0.43884892086330934 0.1630695443645084\n",
      "REDD_4\n",
      "2\n",
      "3/3 [==============================] - 1s 254ms/step\n",
      "3/3 [==============================] - 0s 24ms/step\n",
      "3/3 [==============================] - 0s 25ms/step\n",
      "3/3 [==============================] - 0s 26ms/step\n",
      "3/3 [==============================] - 0s 27ms/step\n",
      "0.09473283976124885 0.37109375 0.05859375\n",
      "REDD_5\n",
      "2\n",
      "1/1 [==============================] - 0s 253ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "0.4062575794324521 0.4838709677419355 0.3709677419354839\n",
      "REDD_6\n",
      "2\n",
      "2/2 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 25ms/step\n",
      "2/2 [==============================] - 0s 25ms/step\n",
      "2/2 [==============================] - 0s 25ms/step\n",
      "2/2 [==============================] - 0s 25ms/step\n",
      "0.19418426691153964 0.3501683501683502 0.18518518518518517\n",
      "DEDDIAG_8\n",
      "2\n",
      "53/53 [==============================] - 2s 30ms/step\n",
      "53/53 [==============================] - 1s 26ms/step\n",
      "53/53 [==============================] - 1s 25ms/step\n",
      "53/53 [==============================] - 1s 26ms/step\n",
      "53/53 [==============================] - 1s 25ms/step\n",
      "0.5356829900571298 0.8939638012865683 0.43100065402223675\n",
      "ECO_1\n",
      "2\n",
      "29/29 [==============================] - 1s 42ms/step\n",
      "29/29 [==============================] - 1s 25ms/step\n",
      "29/29 [==============================] - 1s 25ms/step\n",
      "29/29 [==============================] - 1s 25ms/step\n",
      "29/29 [==============================] - 1s 26ms/step\n",
      "0.27352528289181305 0.8616935142537381 0.22764227642276422\n",
      "ECO_6\n",
      "2\n",
      "24/24 [==============================] - 1s 32ms/step\n",
      "24/24 [==============================] - 1s 26ms/step\n",
      "24/24 [==============================] - 1s 25ms/step\n",
      "24/24 [==============================] - 1s 25ms/step\n",
      "24/24 [==============================] - 1s 25ms/step\n",
      "0.45390835202627133 0.6848777000471161 0.3463541666666667\n",
      "ECO_2\n",
      "2\n",
      "31/31 [==============================] - 1s 29ms/step\n",
      "31/31 [==============================] - 1s 25ms/step\n",
      "31/31 [==============================] - 1s 25ms/step\n",
      "31/31 [==============================] - 1s 25ms/step\n",
      "31/31 [==============================] - 1s 25ms/step\n",
      "0.2957932328210172 0.6231134045085699 0.278561209891682\n",
      "ECO_5\n",
      "2\n",
      "28/28 [==============================] - 1s 25ms/step\n",
      "28/28 [==============================] - 1s 25ms/step\n",
      "28/28 [==============================] - 1s 25ms/step\n",
      "28/28 [==============================] - 1s 25ms/step\n",
      "28/28 [==============================] - 1s 25ms/step\n",
      "0.47195018658088017 0.9077831547647703 0.43652371485373476\n",
      "ECO_4\n",
      "2\n",
      "25/25 [==============================] - 1s 36ms/step\n",
      "25/25 [==============================] - 1s 25ms/step\n",
      "25/25 [==============================] - 1s 25ms/step\n",
      "25/25 [==============================] - 1s 25ms/step\n",
      "25/25 [==============================] - 1s 25ms/step\n",
      "0.7032456460306385 0.7452192998889746 0.6678032148075986\n",
      "ECO_3\n",
      "2\n",
      "13/13 [==============================] - 0s 37ms/step\n",
      "13/13 [==============================] - 0s 26ms/step\n",
      "13/13 [==============================] - 0s 25ms/step\n",
      "13/13 [==============================] - 0s 25ms/step\n",
      "13/13 [==============================] - 0s 26ms/step\n",
      "0.6029031141997384 0.7598817009248773 0.6286644951140065\n",
      "ENERTALK_1\n",
      "2\n",
      "14/14 [==============================] - 0s 26ms/step\n",
      "14/14 [==============================] - 0s 26ms/step\n",
      "14/14 [==============================] - 0s 25ms/step\n",
      "14/14 [==============================] - 0s 25ms/step\n",
      "14/14 [==============================] - 0s 25ms/step\n",
      "0.5368382177333908 0.9717026819888461 0.4714537963507946\n",
      "ENERTALK_18\n",
      "2\n",
      "6/6 [==============================] - 1s 108ms/step\n",
      "6/6 [==============================] - 0s 25ms/step\n",
      "6/6 [==============================] - 0s 25ms/step\n",
      "6/6 [==============================] - 0s 25ms/step\n",
      "6/6 [==============================] - 0s 25ms/step\n",
      "0.6620204606809102 0.75 0.5997340425531915\n",
      "ENERTALK_12\n",
      "2\n",
      "15/15 [==============================] - 1s 51ms/step\n",
      "15/15 [==============================] - 0s 25ms/step\n",
      "15/15 [==============================] - 0s 25ms/step\n",
      "15/15 [==============================] - 0s 25ms/step\n",
      "15/15 [==============================] - 0s 25ms/step\n",
      "0.4739489736147738 0.5833426086316169 0.44888108819657746\n",
      "ENERTALK_20\n",
      "2\n",
      "8/8 [==============================] - 0s 67ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "0.31736878506109273 0.33426573426573425 0.3020979020979021\n",
      "ENERTALK_15\n",
      "2\n",
      "6/6 [==============================] - 1s 99ms/step\n",
      "6/6 [==============================] - 0s 25ms/step\n",
      "6/6 [==============================] - 0s 25ms/step\n",
      "6/6 [==============================] - 0s 25ms/step\n",
      "6/6 [==============================] - 0s 25ms/step\n",
      "0.938832021005673 0.9875956027108486 0.8947368421052632\n",
      "ENERTALK_6\n",
      "2\n",
      "6/6 [==============================] - 0s 74ms/step\n",
      "6/6 [==============================] - 0s 25ms/step\n",
      "6/6 [==============================] - 0s 26ms/step\n",
      "6/6 [==============================] - 0s 25ms/step\n",
      "6/6 [==============================] - 0s 25ms/step\n",
      "0.47444418120802656 0.7590144230769231 0.43345543345543347\n",
      "ENERTALK_8\n",
      "2\n",
      "8/8 [==============================] - 1s 72ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "0.3234914276434333 0.5 0.24074074074074073\n",
      "ENERTALK_2\n",
      "2\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 26ms/step\n",
      "4/4 [==============================] - 0s 26ms/step\n",
      "0.6806172047162045 0.9927098186492077 0.6247464503042597\n",
      "ENERTALK_11\n",
      "2\n",
      "4/4 [==============================] - 0s 26ms/step\n",
      "4/4 [==============================] - 0s 27ms/step\n",
      "4/4 [==============================] - 0s 26ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "0.7878276003276004 1.0 0.6722689075630253\n",
      "ENERTALK_16\n",
      "2\n",
      "9/9 [==============================] - 1s 75ms/step\n",
      "9/9 [==============================] - 0s 25ms/step\n",
      "9/9 [==============================] - 0s 25ms/step\n",
      "9/9 [==============================] - 0s 25ms/step\n",
      "9/9 [==============================] - 0s 26ms/step\n",
      "0.9436090225563909 1.0 0.8932384341637011\n",
      "ENERTALK_5\n",
      "2\n",
      "8/8 [==============================] - 0s 45ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "0.4966494157471601 0.5063011015911874 0.511578947368421\n",
      "ENERTALK_7\n",
      "2\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "0.5 0.5 0.5\n",
      "ENERTALK_14\n",
      "2\n",
      "13/13 [==============================] - 0s 26ms/step\n",
      "13/13 [==============================] - 0s 26ms/step\n",
      "13/13 [==============================] - 0s 25ms/step\n",
      "13/13 [==============================] - 0s 25ms/step\n",
      "13/13 [==============================] - 0s 26ms/step\n",
      "0.15347721822541965 1.0 0.08311688311688312\n",
      "ENERTALK_13\n",
      "2\n",
      "11/11 [==============================] - 0s 25ms/step\n",
      "11/11 [==============================] - 0s 25ms/step\n",
      "11/11 [==============================] - 0s 25ms/step\n",
      "11/11 [==============================] - 0s 25ms/step\n",
      "11/11 [==============================] - 0s 25ms/step\n",
      "0.3365146100483498 0.3501006036217304 0.323943661971831\n",
      "ENERTALK_19\n",
      "2\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "0.6481948714749804 0.9740255257239991 0.48577680525164113\n",
      "ENERTALK_21\n",
      "2\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "0.33072191433779696 0.5159235668789809 0.2791932059447983\n",
      "ENERTALK_0\n",
      "2\n",
      "11/11 [==============================] - 0s 25ms/step\n",
      "11/11 [==============================] - 0s 25ms/step\n",
      "11/11 [==============================] - 0s 25ms/step\n",
      "11/11 [==============================] - 0s 26ms/step\n",
      "11/11 [==============================] - 0s 25ms/step\n",
      "0.5085194757098893 0.6464675913862539 0.4950805008944544\n",
      "ENERTALK_4\n",
      "2\n",
      "11/11 [==============================] - 0s 25ms/step\n",
      "11/11 [==============================] - 0s 26ms/step\n",
      "11/11 [==============================] - 0s 26ms/step\n",
      "11/11 [==============================] - 0s 26ms/step\n",
      "11/11 [==============================] - 0s 25ms/step\n",
      "0.7128795064755322 0.9353220825833164 0.6495934959349593\n",
      "ENERTALK_17\n",
      "2\n",
      "11/11 [==============================] - 0s 25ms/step\n",
      "11/11 [==============================] - 0s 25ms/step\n",
      "11/11 [==============================] - 0s 26ms/step\n",
      "11/11 [==============================] - 0s 26ms/step\n",
      "11/11 [==============================] - 0s 26ms/step\n",
      "0.5552453930852128 0.7818407279385825 0.5315822388993121\n",
      "ENERTALK_10\n",
      "2\n",
      "15/15 [==============================] - 0s 26ms/step\n",
      "15/15 [==============================] - 0s 25ms/step\n",
      "15/15 [==============================] - 0s 26ms/step\n",
      "15/15 [==============================] - 0s 26ms/step\n",
      "15/15 [==============================] - 0s 26ms/step\n",
      "0.4207670310715854 1.0 0.3534675615212528\n",
      "ENERTALK_3\n",
      "2\n",
      "14/14 [==============================] - 0s 25ms/step\n",
      "14/14 [==============================] - 0s 26ms/step\n",
      "14/14 [==============================] - 0s 26ms/step\n",
      "14/14 [==============================] - 0s 25ms/step\n",
      "14/14 [==============================] - 0s 25ms/step\n",
      "0.04211619543650794 0.4965277777777778 0.02199074074074074\n",
      "ENERTALK_9\n",
      "2\n",
      "15/15 [==============================] - 0s 26ms/step\n",
      "15/15 [==============================] - 0s 26ms/step\n",
      "15/15 [==============================] - 0s 25ms/step\n",
      "15/15 [==============================] - 0s 25ms/step\n",
      "15/15 [==============================] - 0s 26ms/step\n",
      "0.4397902574645901 0.9538688210745934 0.40801354401805867\n",
      "REFIT_13\n",
      "2\n",
      "43/43 [==============================] - 1s 25ms/step\n",
      "43/43 [==============================] - 1s 26ms/step\n",
      "43/43 [==============================] - 1s 25ms/step\n",
      "43/43 [==============================] - 1s 25ms/step\n",
      "43/43 [==============================] - 1s 25ms/step\n",
      "0.4794494784860013 0.7986656579340571 0.40770725388601037\n",
      "REFIT_6\n",
      "2\n",
      "60/60 [==============================] - 2s 26ms/step\n",
      "60/60 [==============================] - 2s 26ms/step\n",
      "60/60 [==============================] - 2s 26ms/step\n",
      "60/60 [==============================] - 2s 26ms/step\n",
      "60/60 [==============================] - 2s 26ms/step\n",
      "0.6749540826097389 0.9081763593824688 0.593030242339275\n",
      "REFIT_1\n",
      "2\n",
      "69/69 [==============================] - 2s 30ms/step\n",
      "69/69 [==============================] - 2s 26ms/step\n",
      "69/69 [==============================] - 2s 25ms/step\n",
      "69/69 [==============================] - 2s 25ms/step\n",
      "69/69 [==============================] - 2s 26ms/step\n",
      "0.3980972921759798 0.766385631188681 0.4018416677324466\n",
      "REFIT_21\n",
      "2\n",
      "55/55 [==============================] - 1s 25ms/step\n",
      "55/55 [==============================] - 1s 26ms/step\n",
      "55/55 [==============================] - 1s 25ms/step\n",
      "55/55 [==============================] - 1s 26ms/step\n",
      "55/55 [==============================] - 1s 26ms/step\n",
      "0.45505766917916557 0.6217043220527281 0.4354744808849214\n",
      "REFIT_8\n",
      "2\n",
      "62/62 [==============================] - 2s 26ms/step\n",
      "62/62 [==============================] - 2s 26ms/step\n",
      "62/62 [==============================] - 2s 25ms/step\n",
      "62/62 [==============================] - 2s 25ms/step\n",
      "62/62 [==============================] - 2s 25ms/step\n",
      "0.6186423292351364 0.897914435512884 0.5729982887507881\n",
      "REFIT_9\n",
      "2\n",
      "60/60 [==============================] - 2s 28ms/step\n",
      "60/60 [==============================] - 2s 26ms/step\n",
      "60/60 [==============================] - 2s 26ms/step\n",
      "60/60 [==============================] - 2s 25ms/step\n",
      "60/60 [==============================] - 2s 25ms/step\n",
      "0.498968870074634 0.903633554551245 0.4430954272098037\n",
      "REFIT_20\n",
      "2\n",
      "54/54 [==============================] - 2s 30ms/step\n",
      "54/54 [==============================] - 1s 25ms/step\n",
      "54/54 [==============================] - 1s 26ms/step\n",
      "54/54 [==============================] - 1s 26ms/step\n",
      "54/54 [==============================] - 1s 26ms/step\n",
      "0.6125393778774827 0.8743209111549864 0.5311355311355311\n",
      "REFIT_7\n",
      "2\n",
      "66/66 [==============================] - 2s 32ms/step\n",
      "66/66 [==============================] - 2s 26ms/step\n",
      "66/66 [==============================] - 2s 26ms/step\n",
      "66/66 [==============================] - 2s 26ms/step\n",
      "66/66 [==============================] - 2s 25ms/step\n",
      "0.6184004394121984 0.8309242965030035 0.5740226986128626\n",
      "REFIT_15\n",
      "2\n",
      "60/60 [==============================] - 2s 25ms/step\n",
      "60/60 [==============================] - 2s 25ms/step\n",
      "60/60 [==============================] - 2s 25ms/step\n",
      "60/60 [==============================] - 2s 25ms/step\n",
      "60/60 [==============================] - 2s 25ms/step\n",
      "0.4571135315464248 0.8047035226950325 0.4426062980699463\n",
      "REFIT_12\n",
      "2\n",
      "55/55 [==============================] - 1s 26ms/step\n",
      "55/55 [==============================] - 1s 26ms/step\n",
      "55/55 [==============================] - 1s 25ms/step\n",
      "55/55 [==============================] - 1s 25ms/step\n",
      "55/55 [==============================] - 1s 26ms/step\n",
      "0.6213138032576755 0.9043113210512488 0.5349623482403565\n",
      "REFIT_4\n",
      "2\n",
      "67/67 [==============================] - 2s 26ms/step\n",
      "67/67 [==============================] - 2s 26ms/step\n",
      "67/67 [==============================] - 2s 25ms/step\n",
      "67/67 [==============================] - 2s 25ms/step\n",
      "67/67 [==============================] - 2s 26ms/step\n",
      "0.5927398444822197 0.8935679968195096 0.511986301369863\n",
      "REFIT_3\n",
      "2\n",
      "68/68 [==============================] - 2s 25ms/step\n",
      "68/68 [==============================] - 2s 25ms/step\n",
      "68/68 [==============================] - 2s 25ms/step\n",
      "68/68 [==============================] - 2s 25ms/step\n",
      "68/68 [==============================] - 2s 25ms/step\n",
      "0.5835016399019964 0.742024950596074 0.5790172642762285\n",
      "REFIT_18\n",
      "2\n",
      "52/52 [==============================] - 2s 31ms/step\n",
      "52/52 [==============================] - 1s 26ms/step\n",
      "52/52 [==============================] - 1s 25ms/step\n",
      "52/52 [==============================] - 1s 26ms/step\n",
      "52/52 [==============================] - 1s 25ms/step\n",
      "0.6613141886259535 0.9273352337435147 0.5542554673352834\n",
      "REFIT_11\n",
      "2\n",
      "43/43 [==============================] - 1s 25ms/step\n",
      "43/43 [==============================] - 1s 25ms/step\n",
      "43/43 [==============================] - 1s 25ms/step\n",
      "43/43 [==============================] - 1s 25ms/step\n",
      "43/43 [==============================] - 1s 26ms/step\n",
      "0.3239436741091002 0.7806991503168546 0.28835462058602557\n",
      "REFIT_16\n",
      "2\n",
      "55/55 [==============================] - 1s 26ms/step\n",
      "55/55 [==============================] - 1s 26ms/step\n",
      "55/55 [==============================] - 1s 25ms/step\n",
      "55/55 [==============================] - 1s 26ms/step\n",
      "55/55 [==============================] - 1s 26ms/step\n",
      "0.608615766294815 0.6987664035047385 0.5841446453407511\n",
      "REFIT_17\n",
      "2\n",
      "55/55 [==============================] - 1s 26ms/step\n",
      "55/55 [==============================] - 1s 26ms/step\n",
      "55/55 [==============================] - 1s 26ms/step\n",
      "55/55 [==============================] - 1s 25ms/step\n",
      "55/55 [==============================] - 1s 25ms/step\n",
      "0.6129264919242996 0.9148831072099401 0.5414779631061527\n",
      "REFIT_10\n",
      "2\n",
      "63/63 [==============================] - 2s 25ms/step\n",
      "63/63 [==============================] - 2s 25ms/step\n",
      "63/63 [==============================] - 2s 25ms/step\n",
      "63/63 [==============================] - 2s 25ms/step\n",
      "63/63 [==============================] - 2s 25ms/step\n",
      "0.49508534801038906 0.7048704588249881 0.47951558876578204\n",
      "REFIT_19\n",
      "2\n",
      "54/54 [==============================] - 1s 25ms/step\n",
      "54/54 [==============================] - 1s 25ms/step\n",
      "54/54 [==============================] - 1s 25ms/step\n",
      "54/54 [==============================] - 1s 25ms/step\n",
      "54/54 [==============================] - 1s 26ms/step\n",
      "0.47783858611386104 0.6254716616733725 0.41051616015436565\n",
      "REFIT_2\n",
      "2\n",
      "57/57 [==============================] - 2s 33ms/step\n",
      "57/57 [==============================] - 1s 26ms/step\n",
      "57/57 [==============================] - 1s 26ms/step\n",
      "57/57 [==============================] - 1s 26ms/step\n",
      "57/57 [==============================] - 1s 26ms/step\n",
      "0.4822822485346139 0.7896359941103305 0.4353133839511687\n",
      "REFIT_5\n",
      "2\n",
      "72/72 [==============================] - 2s 27ms/step\n",
      "72/72 [==============================] - 2s 25ms/step\n",
      "72/72 [==============================] - 2s 25ms/step\n",
      "72/72 [==============================] - 2s 26ms/step\n",
      "72/72 [==============================] - 2s 25ms/step\n",
      "0.5289473319012725 0.7802312454689498 0.4613081873970962\n",
      "UKDALE_5\n",
      "2\n",
      "17/17 [==============================] - 0s 25ms/step\n",
      "17/17 [==============================] - 0s 25ms/step\n",
      "17/17 [==============================] - 0s 25ms/step\n",
      "17/17 [==============================] - 0s 25ms/step\n",
      "17/17 [==============================] - 0s 25ms/step\n",
      "0.29220143640157703 0.5050456606805548 0.24193294506532348\n",
      "UKDALE_2\n",
      "2\n",
      "25/25 [==============================] - 1s 25ms/step\n",
      "25/25 [==============================] - 1s 25ms/step\n",
      "25/25 [==============================] - 1s 25ms/step\n",
      "25/25 [==============================] - 1s 26ms/step\n",
      "25/25 [==============================] - 1s 25ms/step\n",
      "0.2287783570121012 0.2753419158712448 0.2076704895794796\n",
      "UKDALE_1\n",
      "2\n",
      "198/198 [==============================] - 5s 26ms/step\n",
      "198/198 [==============================] - 5s 26ms/step\n",
      "198/198 [==============================] - 5s 25ms/step\n",
      "198/198 [==============================] - 5s 25ms/step\n",
      "198/198 [==============================] - 5s 25ms/step\n",
      "0.1896290030041717 0.4496575532812503 0.1608097535532664\n",
      "UKDALE_3\n",
      "2\n",
      "5/5 [==============================] - 0s 25ms/step\n",
      "5/5 [==============================] - 0s 26ms/step\n",
      "5/5 [==============================] - 0s 26ms/step\n",
      "5/5 [==============================] - 0s 26ms/step\n",
      "5/5 [==============================] - 0s 26ms/step\n",
      "0.033344139304404205 0.2980132450331126 0.017660044150110375\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "labels = pd.read_pickle(labels_path)\n",
    "\n",
    "for f in os.listdir(\"./models/test_IDEAL/\"):\n",
    "        if \"last\" in f:\n",
    "            model = tf.keras.models.load_model(\"./models/test_IDEAL/\"+f, custom_objects={'F1Score': NUK.F1Score, \"WeightedF1\": NUK.WeightedF1Score(class_weighs_pre)})\n",
    "            models.append(model)\n",
    "\n",
    "for h in processed:\n",
    "    print(h)\n",
    "    df = processed[h]\n",
    "    curr_devices, real_str = get_devices(data[h])\n",
    "    X = np.array([i[0] for i in df])\n",
    "    y = np.array([i[1] for i in df])\n",
    "    X= normalize(X)\n",
    "    print(len(X.shape))\n",
    "\n",
    "    if len(X.shape) !=2 or X.shape[1] != 2688:\n",
    "        print(\"wrong shape\", X.shape)\n",
    "        continue\n",
    "    \n",
    "    model_predictions = []\n",
    "    for m in models:\n",
    "            y_pred = m.predict(X)\n",
    "            model_predictions.append(y_pred)\n",
    "\n",
    "\n",
    "    y_pred_avg = np.mean(model_predictions, axis=0)\n",
    "    y_pred_tf = np.where(y_pred_avg > 0.3, 1, 0)\n",
    "\n",
    "    y_pred_num_devices = np.sum(y_pred_tf, axis=1)\n",
    "    y_real_num_devices = np.sum(y, axis=1)\n",
    "\n",
    "    # print(\"average number of devices misspredcited: \", np.mean(y_pred_num_devices - y_real_num_devices)\t)\n",
    "\n",
    "    res = metrics.classification_report(y, y_pred_tf, target_names=labels, zero_division=0, output_dict=True)\n",
    "    print(res[\"weighted avg\"][\"f1-score\"], res[\"weighted avg\"][\"precision\"], res[\"weighted avg\"][\"recall\"])\n",
    "\n",
    "    # barplot y_pred_tf\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.bar(labels, y_pred_tf.sum(axis=0))\n",
    "    # plt.title(h + real_str + \"f1: \"+ str(res[\"weighted avg\"][\"f1-score\"]) + \"precision: \"+ str(res[\"weighted avg\"][\"precision\"]) + \"recall: \"+ str(res[\"weighted avg\"][\"recall\"]))\n",
    "    plt.title(h + \" f1: \"+ str(res[\"weighted avg\"][\"f1-score\"])[:5] + \" average number of devices misspredcited: \" + str(np.mean(y_pred_num_devices - y_real_num_devices))[:5]\t)\n",
    "\n",
    "    # Get current axis\n",
    "    ax = plt.gca()\n",
    "\n",
    "    # Loop through label list and set the color to red for highlighted labels\n",
    "    for label in ax.get_xticklabels():\n",
    "        if label.get_text() in curr_devices:\n",
    "            label.set_color('red')\n",
    "\n",
    "    # Rotate all labels\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.savefig(f\"./plots/real_ideal/{h}_barplot.svg\", format=\"svg\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "[[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "pc\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Closing remaining open files:/tmp/nilmtk-zbuuzryk.h5...done\n"
     ]
    }
   ],
   "source": [
    "tb = pd.read_pickle(\"../../Energy_graph/data/tracebase/devices_data.pkl\")\n",
    "device = \"washing machine\"\n",
    "from random import randint\n",
    "i = randint(0, len(tb[device])-1)\n",
    "offset = randint(0, len(tb[device][i])-2688)\n",
    "x = tb[device][i][offset:offset+2668].copy()\n",
    "x[x<5] = 0\n",
    "plt.plot(x)\n",
    "x = x.values.reshape(1, -1)\n",
    "# print(x.values.reshape(1, -1)[0])\n",
    "model_predictions = []\n",
    "for m in models:\n",
    "    y_pred = m.predict(x)\n",
    "    model_predictions.append(y_pred)\n",
    "    \n",
    "y_pred_avg = np.mean(model_predictions, axis=0)\n",
    "y_pred_tf = np.where(y_pred_avg > 0.3, 1, 0)\n",
    "print(y_pred_tf)\n",
    "for i in range(len(labels)):\n",
    "    if y_pred_tf[0][i] == 1:\n",
    "        print(labels[i])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "def preprocess_string(string : str) -> str:\n",
    "    string = string.lower().strip()\n",
    "    string = re.sub(' +', ' ', string)\n",
    "    string = string.replace(\"_\", \" \")\n",
    "    string = string.replace(\"-\", \" \")\n",
    "    string = string.replace(\"&\", \" \")\n",
    "    string = string.split(\"(\")[0]\n",
    "    string = string.split(\"#\")[0]\n",
    "\n",
    "    string = string.strip()\n",
    "\n",
    "    # handle known synoynms\n",
    "    synonyms = {\n",
    "        \"refrigerator\": \"fridge\",\n",
    "        \"vaccumcleaner\": \"vacuum cleaner\",\n",
    "        \"breadmaker\": \"bread maker\",\n",
    "      \n",
    "        \n",
    "    }\n",
    "    if \"freezer\" in string:\n",
    "        string = \"fridge\"\n",
    "\n",
    "    if string in synonyms:\n",
    "        string = synonyms[string]\n",
    "\n",
    "    if 'hi fi' in string:\n",
    "        string = \"audio system\"\n",
    "\n",
    "    if \"router\" in string:\n",
    "        string = \"router\"\n",
    "\n",
    "    if \"treadmill\" in string:\n",
    "        string = \"running machine\"\n",
    "        \n",
    "\n",
    "    if \"laptop\" in string:\n",
    "        string = \"laptop\"\n",
    "    \n",
    "    if \"server\" in string:\n",
    "        string = \"server\"\n",
    "\n",
    "    if \"monitor\" in string and not \"baby\" in string:\n",
    "        string = \"monitor\"\n",
    "    # special cases\n",
    "    if \"computer\" in string and \"charger\" not in string:\n",
    "        string = \"pc\"\n",
    "\n",
    "    if \"tv\" in string:\n",
    "        string = \"television\"\n",
    "\n",
    "    if \"television\" in string:\n",
    "        string = \"television\"\n",
    "\n",
    "    if \"macbook\" in string:\n",
    "        string = \"laptop\"\n",
    "        \n",
    "    if \"car charger\" == string:\n",
    "        string = \"ev\"\n",
    "    \n",
    "    if \"toast\" in string:\n",
    "        string = \"toaster\"\n",
    "    \n",
    "    if \"modem\" in string:\n",
    "        string = \"router\"\n",
    "\n",
    "    # we treat all audio devices as speakers so subwoofer is also a speaker\n",
    "    if \"subwoofer\" in string:\n",
    "        string = \"speaker\"\n",
    "\n",
    "    if \"speaker\" in string:\n",
    "        string = \"speaker\"\n",
    "\n",
    "    if \"iron\" in string and \"soldering\" not in string:\n",
    "        string = \"iron\"\n",
    "\n",
    "    \n",
    "    if \"coffeemachine\" in string:\n",
    "        string = \"coffee machine\"\n",
    "    if \"coffee maker\" in string:\n",
    "        string = \"coffee machine\"\n",
    "\n",
    "    if \"dishwasher\" in string:\n",
    "        string = \"dish washer\"\n",
    "    if \"air conditioner\" in string:\n",
    "        string = \"ac\"\n",
    "\n",
    "    if \"air conditioning\" in string:\n",
    "        string = \"ac\"\n",
    "    \n",
    "    string = re.sub(' +', ' ', string)\n",
    "    string = re.sub(r'\\d+', '', string)\n",
    "    return string.strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3125/3125 [==============================] - 80s 25ms/step\n",
      "3125/3125 [==============================] - 81s 26ms/step\n",
      "3125/3125 [==============================] - 81s 26ms/step\n",
      "3125/3125 [==============================] - 80s 26ms/step\n",
      "3125/3125 [==============================] - 80s 25ms/step\n",
      "Ensemble:  0.05498499229837306 0.11609638926021774 0.08664122375031907\n",
      "Single_0:  0.05454351664771011 0.11638884656663885 0.07865223102832133\n",
      "Single_1:  0.049593168530481076 0.1060938875113711 0.07316602436792201\n",
      "Single_2:  0.05078556918896599 0.11523552292479254 0.07438628821885059\n",
      "Single_3:  0.05283913267450157 0.11186682159508442 0.0734636193274852\n",
      "Single_4:  0.052719927047926246 0.1114511583901698 0.07810809296418277\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>microwave</th>\n",
       "      <td>0.161126</td>\n",
       "      <td>0.593877</td>\n",
       "      <td>0.253480</td>\n",
       "      <td>12772.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>air exchanger</th>\n",
       "      <td>0.145669</td>\n",
       "      <td>0.014225</td>\n",
       "      <td>0.025919</td>\n",
       "      <td>13005.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combination microwave</th>\n",
       "      <td>0.165685</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.094123</td>\n",
       "      <td>12840.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>router</th>\n",
       "      <td>0.133913</td>\n",
       "      <td>0.006010</td>\n",
       "      <td>0.011503</td>\n",
       "      <td>12813.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water purifier</th>\n",
       "      <td>0.856909</td>\n",
       "      <td>0.121826</td>\n",
       "      <td>0.213324</td>\n",
       "      <td>12879.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stove</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro avg</th>\n",
       "      <td>0.165996</td>\n",
       "      <td>0.086641</td>\n",
       "      <td>0.113856</td>\n",
       "      <td>803105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.114437</td>\n",
       "      <td>0.085215</td>\n",
       "      <td>0.054144</td>\n",
       "      <td>803105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.116096</td>\n",
       "      <td>0.086641</td>\n",
       "      <td>0.054985</td>\n",
       "      <td>803105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samples avg</th>\n",
       "      <td>0.145674</td>\n",
       "      <td>0.081627</td>\n",
       "      <td>0.097161</td>\n",
       "      <td>803105.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       precision    recall  f1-score   support\n",
       "microwave               0.161126  0.593877  0.253480   12772.0\n",
       "air exchanger           0.145669  0.014225  0.025919   13005.0\n",
       "combination microwave   0.165685  0.065732  0.094123   12840.0\n",
       "router                  0.133913  0.006010  0.011503   12813.0\n",
       "water purifier          0.856909  0.121826  0.213324   12879.0\n",
       "...                          ...       ...       ...       ...\n",
       "stove                   0.000000  0.000000  0.000000   12640.0\n",
       "micro avg               0.165996  0.086641  0.113856  803105.0\n",
       "macro avg               0.114437  0.085215  0.054144  803105.0\n",
       "weighted avg            0.116096  0.086641  0.054985  803105.0\n",
       "samples avg             0.145674  0.081627  0.097161  803105.0\n",
       "\n",
       "[68 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder = \"\"\n",
    "path_to_base = \"../../Energy_graph/\"\n",
    "path = path_to_base + \"/data/processed_watts/\"+folder\n",
    "labels_path = path_to_base + \"/data/labels_new.pkl\"\n",
    "save_path = path_to_base + \"/data/training_data/processed/\"+folder\n",
    "\n",
    "models = []\n",
    "labels = pd.read_pickle(labels_path)\n",
    "\n",
    "for f in os.listdir(\"./models/test_IDEAL/\"):\n",
    "        if \"best\" in f:\n",
    "            model = tf.keras.models.load_model(\"./models/test_IDEAL/\"+f, custom_objects={'F1Score': NUK.F1Score, \"WeightedF1\": NUK.WeightedF1Score(class_weighs_pre)})\n",
    "            models.append(model)\n",
    "\n",
    "\n",
    "X= normalize(X)\n",
    "print(len(X.shape))\n",
    "\n",
    "if len(X.shape) !=2 or X.shape[1] != 2688:\n",
    "    print(\"wrong shape\", X.shape)\n",
    "\n",
    "model_predictions = []\n",
    "for m in models:\n",
    "        y_pred = m.predict(X)\n",
    "        model_predictions.append(y_pred)\n",
    "\n",
    "\n",
    "\n",
    "y_pred_avg = np.mean(model_predictions, axis=0)\n",
    "y_pred_tf = np.where(y_pred_avg > 0.3, 1, 0)\n",
    "\n",
    "y_pred_num_devices = np.sum(y_pred_tf, axis=1)\n",
    "y_real_num_devices = np.sum(y, axis=1)\n",
    "\n",
    "# print(\"average number of devices misspredcited: \", np.mean(y_pred_num_devices - y_real_num_devices)\t)\n",
    "path = \"../../Energy_graph/data/results/test\"\n",
    "# check if directory exsits\n",
    "if not os.path.exists(f\"{path}\"):\n",
    "    os.makedirs(f\"{path}\")\n",
    "\n",
    "\n",
    "res = metrics.classification_report(y, y_pred_tf, target_names=labels, zero_division=0, output_dict=True)\n",
    "df = pd.DataFrame(res).T\n",
    "\n",
    "df.to_csv(f\"{path}/ensemble.csv\")\n",
    "\n",
    "print(\"Ensemble: \", res[\"weighted avg\"][\"f1-score\"], res[\"weighted avg\"][\"precision\"], res[\"weighted avg\"][\"recall\"])\n",
    "for i, p in enumerate(model_predictions):\n",
    "    y_pred_tf = np.where(p > 0.3, 1, 0)\n",
    "    single = metrics.classification_report(y, y_pred_tf, target_names=labels, zero_division=0, output_dict=True)\n",
    "    df = pd.DataFrame(single).T\n",
    "    df.to_csv(f\"{path}/single_{i}.csv\")\n",
    "    print(f\"Single_{i}: \", single[\"weighted avg\"][\"f1-score\"], single[\"weighted avg\"][\"precision\"], single[\"weighted avg\"][\"recall\"])\n",
    "\n",
    "# # barplot y_pred_tf\n",
    "# plt.figure(figsize=(20,10))\n",
    "# plt.bar(labels, y_pred_tf.sum(axis=0))\n",
    "# # plt.title(h + real_str + \"f1: \"+ str(res[\"weighted avg\"][\"f1-score\"]) + \"precision: \"+ str(res[\"weighted avg\"][\"precision\"]) + \"recall: \"+ str(res[\"weighted avg\"][\"recall\"]))\n",
    "# plt.title(\" f1: \"+ str(res[\"weighted avg\"][\"f1-score\"])[:5] + \" average number of devices misspredcited: \" + str(np.mean(y_pred_num_devices - y_real_num_devices))[:5]\t)\n",
    "\n",
    "# # Get current axis\n",
    "# ax = plt.gca()\n",
    "\n",
    "# # Loop through label list and set the color to red for highlighted labels\n",
    "# for label in ax.get_xticklabels():\n",
    "#     if label.get_text() in curr_devices:\n",
    "#         label.set_color('red')\n",
    "\n",
    "# # Rotate all labels\n",
    "# plt.xticks(rotation=90)\n",
    "# plt.savefig(f\"./plots/real_ideal/test_barplot.svg\", format=\"svg\")\n",
    "# plt.close()\n",
    "pd.DataFrame(res).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "data = pd.read_pickle(\"../../Energy_graph/data/training_data/synthetic/X_Y_wsize2688_numW_50001_upper32_gap3600_numD64_ideal.pkl\")\n",
    "\n",
    "X = np.array([i[0] for i in data])\n",
    "y = np.array([i[1] for i in data])\n",
    "\n",
    "X = normalize(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       ...,\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, len(X)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "real:   dryer\n",
      "pred:   pc television\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ix = randint(0, len(X)-1)\n",
    "# x = X[ix]\n",
    "\n",
    "predictions = []\n",
    "for m in models:\n",
    "    y_pred = m.predict(X[ix].reshape(1, -1))\n",
    "    predictions.append(y_pred)\n",
    "\n",
    "y_pred_avg = np.mean(predictions, axis=0)\n",
    "y_pred_tf = np.where(y_pred_avg > 0.3, 1, 0)\n",
    "\n",
    "labels = pd.read_pickle(labels_path)\n",
    "pred = \"\"\n",
    "real = \"\"\n",
    "for i in range(len(labels)):\n",
    "    if y[ix][i] == 1:\n",
    "        real+=\" \" + str(labels[i])\n",
    "    if y_pred_tf[0][i] == 1:\n",
    "        pred+= \" \" + str(labels[i])\n",
    "plt.plot(X[ix])\n",
    "plt.show()\n",
    "\n",
    "print()\n",
    "print(\"real: \", real)\n",
    "print(\"pred: \", pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
